{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is a cleaner and more detailed version of fairAssign with some minor corrections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "eKUbySV1laji"
   },
   "outputs": [],
   "source": [
    "# Importing all the libraries\n",
    "import csv\n",
    "import math\n",
    "import time\n",
    "import ortools                          # operations research tools: https://pypi.org/project/ortools/\n",
    "import datetime\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import configparser    \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from geopy.geocoders import Nominatim   # OpenStreetMap Nominatim; https://pypi.org/project/geopy/\n",
    "\n",
    "# matplotlib.rc('xtick', labelsize=26) \n",
    "# matplotlib.rc('ytick', labelsize=26) \n",
    "\n",
    "# plt.rcParams['font.size'] = '26'\n",
    "plt.rcParams['figure.figsize'] = (10,7.5)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# fig.set_size_inches(10, 7.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\"flag\" decides which distance metric/measure to consider:\\n0: euclidean distance\\n1: rating\\n3: combination of euclidean distance and rating\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag = 0\n",
    "\n",
    "if flag==2:\n",
    "    w1 = 0.5 # weight given to euclidean distance\n",
    "    w2 = 0.5 # weight given to ratings\n",
    "'''\n",
    "\"flag\" decides which distance metric/measure to consider:\n",
    "0: euclidean distance\n",
    "1: rating\n",
    "3: combination of euclidean distance and rating\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oPc-NN5Dj1DX",
    "outputId": "a2f6f457-c0b3-49e2-b102-ac2a224770b4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration file read done !\n",
      "File Paths obtained !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-a600526ce66f>:60: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  return pd.datetime(dt.year, dt.month, int(dt.day/club_num_dates)*club_num_dates+1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_df.shape: (99441, 5)\n",
      "order_df.shape: (96470, 9)\n",
      "overall_customer_df.shape: (96470, 13)\n",
      "location_df.shape: (1868, 5)\n",
      "overall_customer_loc_df.shape: (11345, 18)\n"
     ]
    }
   ],
   "source": [
    "# Setting up configParser:\n",
    "configParser = configparser.RawConfigParser()   \n",
    "configFilePath = 'config.cfg' \n",
    "configParser.read(configFilePath)\n",
    "print(\"Configuration file read done !\")\n",
    "\n",
    "\n",
    "# File paths\n",
    "customer_dir = configParser.get('file-paths','customer_dir')\n",
    "geolocation_dir = configParser.get('file-paths','geolocation_dir')\n",
    "seller_dir = configParser.get('file-paths','seller_dir')\n",
    "order_dir = configParser.get('file-paths','order_dir')\n",
    "order_item_dir = configParser.get('file-paths','order_item_dir')\n",
    "print(\"File Paths obtained !\")\n",
    "\n",
    "\n",
    "# Creating dataframes\n",
    "customer_df = pd.read_csv(customer_dir)\n",
    "location_df = pd.read_csv(geolocation_dir)\n",
    "seller_df = pd.read_csv(seller_dir)\n",
    "order_df = pd.read_csv(order_dir)\n",
    "order_item_df = pd.read_csv(order_item_dir)\n",
    "\n",
    "# more work for location dataframe:\n",
    "state_or_city = configParser.get('dataset-generation','state_or_city') # state\n",
    "city_dataset = configParser.get('dataset-generation','city')           # sao paulo\n",
    "state_dataset = configParser.get('dataset-generation','state')         # RJ\n",
    "equal_or_not = int(configParser.get('dataset-generation','equal_to'))  # 1\n",
    "\n",
    "if state_or_city == 'state':\n",
    "  if equal_or_not == 1:\n",
    "    location_df = location_df[location_df['geolocation_state']==state_dataset]\n",
    "  else:\n",
    "    location_df = location_df[location_df['geolocation_state']!=state_dataset]\n",
    "else:\n",
    "  if equal_or_not == 1:\n",
    "    location_df = location_df[location_df['geolocation_city']==city_dataset]\n",
    "  else:\n",
    "    location_df = location_df[location_df['geolocation_city']!=city_dataset]\n",
    "\n",
    "# consider only zip code prefix level info (not fine-grained till lat-lng level)\n",
    "# Finally, location_df contains locations of the state \"state_dataset\"\n",
    "location_df = location_df.drop_duplicates('geolocation_zip_code_prefix')\n",
    "\n",
    "\n",
    "# Processing \"order_df\" \n",
    "# Take only 'delivered' orders with known delivery dates \n",
    "order_df = order_df[order_df['order_status']=='delivered']\n",
    "order_df = order_df[order_df['order_delivered_customer_date'].notna()]\n",
    "order_df['order_delivered_customer_date'] = pd.to_datetime(order_df['order_delivered_customer_date'])\n",
    "# Take only delivery dates, not delivery time\n",
    "order_df['order_delivered_customer_date'] = order_df['order_delivered_customer_date'].dt.date\n",
    "# Clubbing multiple dates into one, because the data for one date is too small\n",
    "club_num_dates = int(configParser.get('dataset-generation','club_num_dates')) # 16 (first 15 days will be mapped to 1st day and last 15-16 days will be mapped to 17th day)\n",
    "\n",
    "\n",
    "def club_date(dt,club_num_dates):\n",
    "  if(club_num_dates > 30): # monthwise clubbing is the intention\n",
    "    return pd.datetime(dt.year, dt.month, 1)\n",
    "  return pd.datetime(dt.year, dt.month, int(dt.day/club_num_dates)*club_num_dates+1) \n",
    "\n",
    "order_df['order_delivered_customer_date'] = order_df['order_delivered_customer_date'].map(lambda x: club_date(x,club_num_dates))\n",
    "\n",
    "order_df = order_df.sort_values(\"order_delivered_customer_date\")\n",
    "order_df = order_df.reset_index()\n",
    "\n",
    "\n",
    "# Merging DataFrames\n",
    "overall_customer_df = pd.merge(customer_df,order_df,on='customer_id')\n",
    "# left_on and right_on are used when the attribute to be merged upon has different name in the left and right tables\n",
    "overall_customer_loc_df = pd.merge(overall_customer_df,location_df,left_on='customer_zip_code_prefix',right_on='geolocation_zip_code_prefix')\n",
    "\n",
    "print(\"customer_df.shape:\", customer_df.shape)\n",
    "print(\"order_df.shape:\", order_df.shape)\n",
    "print(\"overall_customer_df.shape:\", overall_customer_df.shape)\n",
    "print(\"location_df.shape:\", location_df.shape)\n",
    "print(\"overall_customer_loc_df.shape:\", overall_customer_loc_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# effective number of days in the dataset:\n",
    "total_num_days = order_df['order_delivered_customer_date'].nunique()\n",
    "all_dates = np.unique(order_df['order_delivered_customer_date'])\n",
    "total_num_days, all_dates.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we have total 50 unique dates BUT locations of drivers etc is known only for 46 days. \n",
    "Found by doing: testing_order_df = order_df[order_df['order_delivered_customer_date'] >= all_dates[0]]\n",
    "                ...\n",
    "                num_days = testing_customer_loc_df['order_delivered_customer_date'].nuniuqe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data percentage: 20\n",
      "Training data duration: 2017-05-17 00:00:00 to 2017-10-17 00:00:00\n",
      "Number of days in training data: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-3c1825c91f2f>:25: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  training_order_df = training_order_df[order_df['order_delivered_customer_date']>=start_training_date]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the training data duration:\n",
      "Number of unique customers: 21137\n",
      "Number of unique sellers: 1219\n",
      "\n",
      "However\n",
      "Number of unique customers whose lat-lng lvl loc is known: 2434\n",
      "Number of unique sellers whose lat-lng lvl loc is known: 124\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Training Data\"\"\"\n",
    "training_data_percent = int(configParser.get('dataset-generation','training_data_percent'))\n",
    "print(\"Training data percentage:\", training_data_percent)\n",
    "\n",
    "################################################################################################################\n",
    "# Training data is taken chronologically wrt \"order_delivered_customer_date\" in the range [10, 30]% of the data\n",
    "# len(order_df.index) <=> order_df.shape[0]\n",
    "start_date_loc = int(0.1*len(order_df.index)) \n",
    "# start_date_loc = 0 #correction\n",
    "start_training_date = order_df[\"order_delivered_customer_date\"].iloc[start_date_loc]\n",
    "\n",
    "end_date_loc = int((10+training_data_percent)/100*len(order_df.index))\n",
    "# end_date_loc = int(training_data_percent/100 * len(order_df.index)) #correction\n",
    "end_training_date = order_df[\"order_delivered_customer_date\"].iloc[end_date_loc]\n",
    "################################################################################################################\n",
    "\n",
    "################################################################################################################\n",
    "# # training: first 10 days {day_0 to day_10}; testing: remaining 40 days\n",
    "# # NOT day_0 to day_9 bcz that gives capacities which lead to an infeasible solution; basically day_0 to day_10 has lower orders than the normal trend\n",
    "# start_training_date = all_dates[0]\n",
    "# end_training_date = all_dates[10]\n",
    "################################################################################################################\n",
    "\n",
    "training_order_df = order_df[order_df['order_delivered_customer_date']<=end_training_date]\n",
    "training_order_df = training_order_df[order_df['order_delivered_customer_date']>=start_training_date]\n",
    "num_training_days = training_order_df['order_delivered_customer_date'].nunique()\n",
    "\n",
    "print(f\"Training data duration: {start_training_date} to {end_training_date}\")\n",
    "print(\"Number of days in training data:\", num_training_days) \n",
    "\n",
    "\n",
    "# Merging dataframes to create relevant \n",
    "# \"training_customer_df\" => customers who ordered at least once in the training data duration\n",
    "# customer_id is unique for every order and present in both customer_df and training_order_df, \n",
    "# customer_unique_id is unique wrt to every customer !\n",
    "training_customer_df = pd.merge(customer_df,training_order_df,on='customer_id') \n",
    "training_customer_df = training_customer_df.drop_duplicates('customer_unique_id')\n",
    "\n",
    "# \"training_order_item_df\" => items ordered in the training data duration\n",
    "# order_item_df is being merged with training_order_df to get seller_id in there which will then be used to calculate training_seller_df\n",
    "training_order_item_df = pd.merge(order_item_df,training_order_df,on='order_id')\n",
    "# \"training_seller_df\" => sellers' who sold any of the orders in the training data duration  \n",
    "training_seller_df = pd.merge(seller_df,training_order_item_df,on='seller_id')\n",
    "# training_seller_df = training_seller_df.drop_duplicates('seller_zip_code_prefix') #?? 1037\n",
    "# if we use the above line then only one seller per zip code loc will be shown but we want to show the unique seller in different (zip code level) locations !\n",
    "training_seller_df = training_seller_df.drop_duplicates('seller_id') # 1219 sellers\n",
    "\n",
    "print(\"In the training data duration:\")\n",
    "print(\"Number of unique customers:\", training_customer_df.shape[0])\n",
    "print(\"Number of unique sellers:\", training_seller_df.shape[0])\n",
    "\n",
    "\n",
    "# Getting lattitude-longitude lvl locs of unique customers and seller who ordered/sold items in the training data duration \n",
    "training_customer_loc_df = pd.merge(training_customer_df, location_df,left_on='customer_zip_code_prefix', right_on='geolocation_zip_code_prefix')\n",
    "training_seller_loc_df = pd.merge(training_seller_df, location_df,left_on='seller_zip_code_prefix', right_on='geolocation_zip_code_prefix')\n",
    "\n",
    "print(\"\\nHowever\")\n",
    "print(\"Number of unique customers whose lat-lng lvl loc is known:\", training_customer_loc_df.shape[0])\n",
    "print(\"Number of unique sellers whose lat-lng lvl loc is known:\", training_seller_loc_df.shape[0])\n",
    "\n",
    "training_customer_loc_df.rename(columns = {'customer_city':'city'}, inplace = True)\n",
    "training_seller_loc_df.rename(columns = {'seller_city':'city'}, inplace = True)\n",
    "\n",
    "training_customer_locations = training_customer_loc_df[['geolocation_lat','geolocation_lng','city']]\n",
    "training_seller_locations = training_seller_loc_df[['geolocation_lat','geolocation_lng','city']]\n",
    "\n",
    "training_combined_locations = pd.concat([training_customer_locations,training_seller_locations])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding maximum and minimum capacity of a warehouse for training data\n",
    "lis = ['geolocation_lat','geolocation_lng']\n",
    "prediction_array = np.array(kmeans.predict(training_customer_loc_df[lis].values))\n",
    "# unique, counts = np.unique(prediction_array, return_counts=True)\n",
    "training_customer_loc_df['ffc_index'] = prediction_array\n",
    "\n",
    "\n",
    "# Finding the number of orders of particular ffc center for each date\n",
    "training_customer_group_date = training_customer_loc_df.groupby(['ffc_index','order_delivered_customer_date'])['order_id'].count()\n",
    "training_customer_group_date = pd.DataFrame({'count':training_customer_group_date}).reset_index()\n",
    "\n",
    "\n",
    "# Finding 'quantile_capacity'-th quantile values for each ffc wrt the number of order over all dates\n",
    "# configParser.read(configFilePath)\n",
    "quantile_capacity=float(configParser.get('dataset-generation','qauntile_capacity')) \n",
    "\n",
    "training_customer_group_date = training_customer_group_date.groupby(['ffc_index'])['count'].quantile(quantile_capacity)\n",
    "training_customer_group_date = pd.DataFrame({'cap':training_customer_group_date}).reset_index()\n",
    "\n",
    "# For each ffc:\n",
    "# minimum-capactity (min_cap) for each ffc will be half of the 'quantile_capacity'-th quantile value, and\n",
    "# maximum-capacity (max_cap) for each ffc will be 1.5 times the 'quantile_capacity'-th quantile values\n",
    "training_customer_group_date['min_cap'] = 0.5 * training_customer_group_date['cap']\n",
    "training_customer_group_date['max_cap'] = 1.5 * training_customer_group_date['cap']\n",
    "training_customer_group_date = training_customer_group_date.sort_values('ffc_index')\n",
    "\n",
    "max_cap = training_customer_group_date['max_cap'].values\n",
    "min_cap = training_customer_group_date['min_cap'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # [ Capacities consistent with the paper ] :\n",
    "\n",
    "# # Finding maximum and minimum capacity of a warehouse for training data\n",
    "# lis = ['geolocation_lat','geolocation_lng']\n",
    "# prediction_array = np.array(kmeans.predict(training_customer_loc_df[lis].values))\n",
    "# # unique, counts = np.unique(prediction_array, return_counts=True)\n",
    "# training_customer_loc_df['ffc_index'] = prediction_array\n",
    "\n",
    "\n",
    "# # Finding the number of orders of particular ffc center for each date\n",
    "# training_customer_group_date = training_customer_loc_df.groupby(['ffc_index','order_delivered_customer_date'])['order_id'].count()\n",
    "# training_customer_group_date = pd.DataFrame({'count':training_customer_group_date}).reset_index()\n",
    "\n",
    "\n",
    "# # Finding 'quantile_capacity'-th quantile values for each ffc wrt the number of order over all dates\n",
    "# # configParser.read(configFilePath)\n",
    "# # quantile_capacity=float(configParser.get('dataset-generation','qauntile_capacity')) \n",
    "\n",
    "# training_customer_group_date = training_customer_group_date.groupby(['ffc_index'])['count']\n",
    "# capacities = [training_customer_group_date.get_group(idx).values.mean() for idx in range(num_ffc)] \n",
    "# training_customer_group_date = pd.DataFrame({'cap':capacities}).reset_index()\n",
    "\n",
    "# # For each ffc:\n",
    "# # minimum-capactity (min_cap) for each ffc will be half of the 'quantile_capacity'-th quantile value, and\n",
    "# # maximum-capacity (max_cap) for each ffc will be 1.5 times the 'quantile_capacity'-th quantile values\n",
    "# # training_customer_group_date['min_cap'] = 0.5 * training_customer_group_date['cap']\n",
    "# # training_customer_group_date['max_cap'] = 1.5 * training_customer_group_date['cap']\n",
    "# training_customer_group_date['min_cap'] = 0.4 * training_customer_group_date['cap']\n",
    "# training_customer_group_date['max_cap'] = 1.0 * training_customer_group_date['cap']\n",
    "\n",
    "# training_customer_group_date = training_customer_group_date.rename(columns={'index': 'ffc_index'})\n",
    "# training_customer_group_date = training_customer_group_date.sort_values('ffc_index')\n",
    "\n",
    "# max_cap = training_customer_group_date['max_cap'].values\n",
    "# min_cap = training_customer_group_date['min_cap'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ffc_index</th>\n",
       "      <th>cap</th>\n",
       "      <th>min_cap</th>\n",
       "      <th>max_cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>49.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>101.0</td>\n",
       "      <td>50.5</td>\n",
       "      <td>151.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>37.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>338.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>29.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>43.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>185.0</td>\n",
       "      <td>92.5</td>\n",
       "      <td>277.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ffc_index    cap  min_cap  max_cap\n",
       "0          0   33.0     16.5     49.5\n",
       "1          1   40.0     20.0     60.0\n",
       "2          2   18.0      9.0     27.0\n",
       "3          3  101.0     50.5    151.5\n",
       "4          4   40.0     20.0     60.0\n",
       "5          5   25.0     12.5     37.5\n",
       "6          6  338.0    169.0    507.0\n",
       "7          7   29.0     14.5     43.5\n",
       "8          8  185.0     92.5    277.5\n",
       "9          9   24.0     12.0     36.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_customer_group_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416.5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_customer_group_date['min_cap'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "kfpCtYS7Z80E",
    "outputId": "80091956-89e4-45b3-9b62-6a5feb3702ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Drivers: 394\n",
      "Drivers' Locations:\n",
      " [[-23.81728879 -49.07425473]\n",
      " [-24.17611856 -46.90168688]\n",
      " [-24.25049617 -47.00922859]\n",
      " [-24.23914621 -47.17195445]\n",
      " [-24.05048251 -47.52033528]\n",
      " [-23.68708696 -47.99664986]\n",
      " [-24.24908662 -46.89050653]\n",
      " [-23.926864   -47.9073448 ]\n",
      " [-23.58302271 -46.85141596]\n",
      " [-24.2118824  -47.49739339]\n",
      " [-24.06806896 -46.01882612]\n",
      " [-24.17521489 -45.92580831]\n",
      " [-24.25586798 -46.57439428]\n",
      " [-23.70628891 -46.29144531]\n",
      " [-23.99163745 -46.05026821]\n",
      " [-23.94998602 -46.31111105]\n",
      " [-24.27086597 -45.88941569]\n",
      " [-23.59716951 -45.58095896]\n",
      " [-23.81565305 -46.34595293]\n",
      " [-24.03169526 -45.93410045]\n",
      " [-23.80833574 -46.64520006]\n",
      " [-24.12384211 -46.33734347]\n",
      " [-23.92512068 -45.78603632]\n",
      " [-23.9332732  -46.75093562]\n",
      " [-23.70134926 -46.25487656]\n",
      " [-23.91962247 -46.51152009]\n",
      " [-23.98559564 -46.30658898]\n",
      " [-23.73776695 -46.65904395]\n",
      " [-23.89735149 -46.56595974]\n",
      " [-23.79242906 -46.74019683]\n",
      " [-24.0939487  -46.36096596]\n",
      " [-23.83482673 -46.72142518]\n",
      " [-23.96257334 -46.52802349]\n",
      " [-24.09010326 -46.19798181]\n",
      " [-23.60343274 -46.19210568]\n",
      " [-23.60548642 -46.57889952]\n",
      " [-23.62823776 -46.33626945]\n",
      " [-24.15673021 -45.86202171]\n",
      " [-23.63701545 -46.77742718]\n",
      " [-24.09991195 -45.83469605]\n",
      " [-24.0470383  -46.48755841]\n",
      " [-24.28658701 -46.73627678]\n",
      " [-23.84766307 -45.57169044]\n",
      " [-23.57485381 -46.16424943]\n",
      " [-24.27560059 -46.38776976]\n",
      " [-23.72663396 -45.7590781 ]\n",
      " [-23.83304254 -46.5024552 ]\n",
      " [-23.91369791 -46.19659231]\n",
      " [-23.84196322 -46.46153288]\n",
      " [-23.61211181 -45.68212427]\n",
      " [-24.17620461 -46.42618866]\n",
      " [-23.66496541 -46.44225008]\n",
      " [-23.61410619 -46.14996958]\n",
      " [-23.79237451 -45.91610791]\n",
      " [-24.13887174 -46.43396342]\n",
      " [-24.10948388 -45.94251538]\n",
      " [-23.79371669 -46.62311319]\n",
      " [-23.65542587 -46.2670081 ]\n",
      " [-24.11934201 -46.24855307]\n",
      " [-23.58852784 -46.09473855]\n",
      " [-23.84359229 -45.65051595]\n",
      " [-23.6011034  -45.84732974]\n",
      " [-23.99248906 -46.05956663]\n",
      " [-23.64498242 -45.81179398]\n",
      " [-23.87564269 -46.35689442]\n",
      " [-24.02785458 -45.87768349]\n",
      " [-23.88774835 -46.76454757]\n",
      " [-23.78219324 -45.67041672]\n",
      " [-23.71920709 -45.67822726]\n",
      " [-23.63811673 -46.12558463]\n",
      " [-23.72540154 -46.31741657]\n",
      " [-24.22211682 -46.34987194]\n",
      " [-24.06837632 -45.63313053]\n",
      " [-23.79730617 -46.11734322]\n",
      " [-24.20311552 -44.89247867]\n",
      " [-23.78903283 -45.06535158]\n",
      " [-23.08104099 -50.31251001]\n",
      " [-23.34909428 -48.39500745]\n",
      " [-23.09965474 -46.86623117]\n",
      " [-23.31089475 -47.98290867]\n",
      " [-23.2230173  -47.47211915]\n",
      " [-23.44480153 -47.19607669]\n",
      " [-23.32839529 -47.72550268]\n",
      " [-23.33832904 -46.85501522]\n",
      " [-23.56821777 -47.57500307]\n",
      " [-23.37266688 -47.77116991]\n",
      " [-23.26282824 -47.74767041]\n",
      " [-22.9130918  -47.40135809]\n",
      " [-23.07182795 -47.8192805 ]\n",
      " [-23.23969329 -47.27118227]\n",
      " [-22.96772591 -47.71127324]\n",
      " [-23.24328708 -46.96480695]\n",
      " [-22.9757842  -47.73887828]\n",
      " [-23.18694579 -47.08020789]\n",
      " [-23.28955012 -47.18868285]\n",
      " [-23.09686475 -46.81967584]\n",
      " [-23.17551963 -47.17955842]\n",
      " [-23.32194985 -47.11604471]\n",
      " [-23.34205701 -47.40275784]\n",
      " [-23.31432045 -47.64054256]\n",
      " [-23.47604833 -47.74113718]\n",
      " [-23.18240877 -47.70883756]\n",
      " [-23.54076126 -47.0279997 ]\n",
      " [-23.36839738 -46.86446984]\n",
      " [-23.14322929 -47.53950651]\n",
      " [-22.94599673 -46.91248453]\n",
      " [-23.34298986 -47.86432791]\n",
      " [-23.1129198  -46.97977787]\n",
      " [-23.13624593 -47.05178104]\n",
      " [-23.27723107 -47.25727174]\n",
      " [-23.38452653 -47.51751178]\n",
      " [-23.30076737 -47.54496979]\n",
      " [-23.28648609 -47.02358878]\n",
      " [-23.45166293 -47.76653748]\n",
      " [-23.39065687 -46.82139711]\n",
      " [-23.19790318 -47.95430166]\n",
      " [-22.97310556 -46.94171479]\n",
      " [-22.98334919 -47.57687465]\n",
      " [-23.0455445  -47.64264274]\n",
      " [-23.47506749 -46.9518996 ]\n",
      " [-22.97480125 -47.75898835]\n",
      " [-22.94117126 -47.98926184]\n",
      " [-23.35201574 -48.00362007]\n",
      " [-23.45078862 -47.81815446]\n",
      " [-23.05907598 -47.65363417]\n",
      " [-23.43711985 -47.79248608]\n",
      " [-23.34946478 -46.95573669]\n",
      " [-23.13742447 -47.89333871]\n",
      " [-23.08124734 -47.3579089 ]\n",
      " [-23.25132546 -47.36861439]\n",
      " [-23.10533286 -47.03157778]\n",
      " [-23.2104643  -47.23537452]\n",
      " [-23.2377801  -47.23720447]\n",
      " [-23.29444742 -47.50768203]\n",
      " [-23.20228468 -47.13732177]\n",
      " [-23.3735187  -46.87837841]\n",
      " [-23.22034028 -46.96395698]\n",
      " [-23.0773621  -46.83955189]\n",
      " [-23.08307538 -47.49291778]\n",
      " [-23.28194667 -47.26976265]\n",
      " [-23.03172358 -46.98426661]\n",
      " [-23.48079529 -47.94262565]\n",
      " [-23.49601468 -47.91565323]\n",
      " [-23.53319665 -48.00923773]\n",
      " [-23.39435903 -47.87995602]\n",
      " [-23.08106881 -47.25972825]\n",
      " [-22.88313994 -45.86424633]\n",
      " [-22.89097925 -46.75102939]\n",
      " [-23.40987905 -45.64284404]\n",
      " [-23.23191082 -46.53074145]\n",
      " [-23.02961288 -46.26302801]\n",
      " [-23.18327675 -46.39582359]\n",
      " [-23.39996951 -46.67809286]\n",
      " [-23.13743245 -45.6100269 ]\n",
      " [-22.86429503 -45.84141558]\n",
      " [-22.90263311 -46.3386941 ]\n",
      " [-23.35937681 -45.64610796]\n",
      " [-23.14227385 -45.96002802]\n",
      " [-23.56475528 -46.50366772]\n",
      " [-23.22690067 -45.88365196]\n",
      " [-22.98000241 -45.85119915]\n",
      " [-23.32952391 -46.31475708]\n",
      " [-22.95372152 -45.56459351]\n",
      " [-23.22505129 -46.5453312 ]\n",
      " [-23.12478937 -46.12436193]\n",
      " [-23.3137267  -46.50122607]\n",
      " [-23.29669903 -46.02999734]\n",
      " [-23.48257422 -46.11818486]\n",
      " [-22.88904822 -45.86644516]\n",
      " [-23.39248519 -46.26928477]\n",
      " [-23.5001904  -45.87618123]\n",
      " [-23.11944952 -46.57240865]\n",
      " [-23.17970027 -46.05041165]\n",
      " [-23.158767   -46.31874544]\n",
      " [-23.35099179 -46.34780467]\n",
      " [-22.85650458 -46.37802189]\n",
      " [-23.21248504 -46.2181494 ]\n",
      " [-23.44937358 -46.29238113]\n",
      " [-23.42640143 -46.3879183 ]\n",
      " [-23.30979368 -46.35391087]\n",
      " [-22.89937285 -46.41934376]\n",
      " [-23.33478343 -45.97428339]\n",
      " [-23.28814035 -46.1492722 ]\n",
      " [-23.10817593 -46.69475702]\n",
      " [-23.09090239 -46.66083042]\n",
      " [-23.39385375 -45.78644736]\n",
      " [-22.86226534 -45.95431898]\n",
      " [-23.45038973 -46.24487214]\n",
      " [-23.37054578 -45.74770719]\n",
      " [-23.40608647 -46.54350173]\n",
      " [-23.11497742 -45.99941431]\n",
      " [-23.14973095 -46.19479699]\n",
      " [-22.88418143 -46.21996444]\n",
      " [-22.90003512 -46.30227728]\n",
      " [-23.23917118 -46.34217654]\n",
      " [-23.05958622 -45.85835915]\n",
      " [-23.40178935 -46.13659448]\n",
      " [-23.05140442 -46.16676202]\n",
      " [-23.09750228 -46.02532204]\n",
      " [-23.06015168 -46.34727101]\n",
      " [-23.35334088 -46.75523746]\n",
      " [-22.93360131 -45.81099961]\n",
      " [-23.29315295 -45.59219179]\n",
      " [-22.92489453 -46.59871283]\n",
      " [-22.97218352 -46.26635553]\n",
      " [-23.34781147 -46.46589971]\n",
      " [-23.27622905 -46.72174174]\n",
      " [-23.53750951 -46.64145577]\n",
      " [-23.35281422 -46.59008479]\n",
      " [-23.4861719  -45.75914302]\n",
      " [-23.30078681 -46.18068765]\n",
      " [-23.1414606  -45.63441812]\n",
      " [-23.46871679 -46.504231  ]\n",
      " [-22.95515302 -45.66320698]\n",
      " [-22.90379092 -46.13366612]\n",
      " [-23.30985642 -46.55287725]\n",
      " [-22.91901233 -45.84128313]\n",
      " [-23.17711724 -45.80912844]\n",
      " [-23.38630764 -46.12707135]\n",
      " [-22.9219527  -46.65167696]\n",
      " [-23.12987271 -46.55694333]\n",
      " [-22.9713989  -45.7500648 ]\n",
      " [-23.11066748 -46.24771593]\n",
      " [-23.55830896 -46.17603355]\n",
      " [-23.31550795 -46.2919105 ]\n",
      " [-23.51790442 -45.65008436]\n",
      " [-23.19843188 -46.09257935]\n",
      " [-22.96813456 -45.67963429]\n",
      " [-23.17853964 -46.11439627]\n",
      " [-22.96471913 -46.32596295]\n",
      " [-22.92637071 -46.75561354]\n",
      " [-23.00134455 -46.1344514 ]\n",
      " [-23.12625669 -45.56354432]\n",
      " [-23.41568273 -46.28298529]\n",
      " [-22.99883212 -45.86426258]\n",
      " [-23.19684316 -45.82684325]\n",
      " [-23.08680932 -45.71315954]\n",
      " [-23.10628213 -46.33738965]\n",
      " [-23.36756364 -46.68440644]\n",
      " [-23.48510281 -46.73319849]\n",
      " [-22.87227387 -46.61203219]\n",
      " [-23.14033093 -46.62018342]\n",
      " [-22.8790599  -46.12827649]\n",
      " [-23.44646976 -45.76565952]\n",
      " [-22.95533273 -45.57898597]\n",
      " [-23.41316796 -46.28893981]\n",
      " [-23.09866049 -46.43706704]\n",
      " [-23.16442508 -45.92053387]\n",
      " [-23.03339482 -45.76894494]\n",
      " [-23.03384857 -46.43348045]\n",
      " [-23.0305225  -46.25051743]\n",
      " [-23.45195599 -46.76010164]\n",
      " [-23.12634416 -46.3439695 ]\n",
      " [-23.50617561 -46.18095619]\n",
      " [-23.27545593 -46.38431825]\n",
      " [-23.16662969 -46.12082074]\n",
      " [-23.19283634 -45.56744093]\n",
      " [-22.92323094 -46.41709923]\n",
      " [-22.94679468 -46.39679706]\n",
      " [-22.90004732 -46.71460148]\n",
      " [-23.34509598 -45.63578067]\n",
      " [-23.09818644 -45.91390283]\n",
      " [-23.42677891 -46.63553024]\n",
      " [-22.88374053 -46.70431056]\n",
      " [-23.44764506 -46.25405548]\n",
      " [-22.98474343 -45.94752554]\n",
      " [-22.85588834 -45.82408923]\n",
      " [-23.25937578 -45.66099565]\n",
      " [-23.34610505 -46.72211742]\n",
      " [-22.88394296 -45.6983263 ]\n",
      " [-23.09901361 -46.19334691]\n",
      " [-23.42725395 -46.51503474]\n",
      " [-23.52527273 -46.66974053]\n",
      " [-23.22929518 -45.67971935]\n",
      " [-22.90346479 -46.1509738 ]\n",
      " [-23.08949851 -46.20829895]\n",
      " [-23.01567766 -45.91413123]\n",
      " [-22.86564043 -45.74218478]\n",
      " [-23.08632758 -46.05719168]\n",
      " [-23.45249125 -46.203757  ]\n",
      " [-23.2519019  -46.59526736]\n",
      " [-23.42876775 -46.27810998]\n",
      " [-23.44735909 -46.01546769]\n",
      " [-23.33791577 -45.56666968]\n",
      " [-23.08188872 -46.14817859]\n",
      " [-23.26178735 -46.30240407]\n",
      " [-23.42968498 -45.59754303]\n",
      " [-22.91686715 -45.98349422]\n",
      " [-23.10633774 -46.60785326]\n",
      " [-23.18442199 -46.57962066]\n",
      " [-23.34058738 -46.06123929]\n",
      " [-23.45140067 -46.49796866]\n",
      " [-23.04856707 -46.18751011]\n",
      " [-22.93407261 -46.58919408]\n",
      " [-23.51012779 -45.6277459 ]\n",
      " [-23.13604487 -45.92996195]\n",
      " [-23.17377553 -46.60226971]\n",
      " [-22.87073476 -46.17423658]\n",
      " [-22.92006387 -46.60517478]\n",
      " [-23.37586991 -46.10812289]\n",
      " [-23.39575893 -45.72489832]\n",
      " [-23.38631301 -46.6881121 ]\n",
      " [-23.45657971 -46.45022842]\n",
      " [-22.8923025  -45.70182793]\n",
      " [-23.09228702 -46.2593727 ]\n",
      " [-23.54397559 -45.75960198]\n",
      " [-23.48320502 -46.5388053 ]\n",
      " [-23.26093807 -45.72140422]\n",
      " [-23.44228715 -46.7085858 ]\n",
      " [-22.92142765 -46.77541977]\n",
      " [-23.0458381  -46.61206199]\n",
      " [-23.35881525 -46.529474  ]\n",
      " [-23.25819506 -45.64862179]\n",
      " [-22.9698126  -46.1243471 ]\n",
      " [-23.51072103 -46.5688727 ]\n",
      " [-23.36139095 -45.80593537]\n",
      " [-22.9152     -46.75422971]\n",
      " [-23.3334188  -45.60092915]\n",
      " [-23.46524492 -46.68710136]\n",
      " [-23.38262795 -45.68847177]\n",
      " [-23.38457594 -45.89576331]\n",
      " [-23.10066106 -45.34310247]\n",
      " [-22.22298089 -51.18336556]\n",
      " [-22.14662595 -51.2201056 ]\n",
      " [-22.19760402 -49.25528237]\n",
      " [-22.77863421 -50.15004843]\n",
      " [-22.35422989 -49.3949035 ]\n",
      " [-22.6701419  -49.53948598]\n",
      " [-22.51180655 -50.48252546]\n",
      " [-22.84951858 -48.97152787]\n",
      " [-22.18409636 -48.4152096 ]\n",
      " [-22.23414976 -48.12294166]\n",
      " [-22.35415838 -47.21198119]\n",
      " [-22.35723544 -47.90532988]\n",
      " [-22.21591846 -47.82588556]\n",
      " [-22.53451616 -47.1711526 ]\n",
      " [-22.31934474 -46.99997519]\n",
      " [-22.63019852 -47.65186868]\n",
      " [-22.33158887 -47.96156159]\n",
      " [-22.22667266 -47.63053119]\n",
      " [-22.57257363 -47.63352656]\n",
      " [-22.34164503 -47.80501597]\n",
      " [-22.7573845  -47.93794621]\n",
      " [-22.76061532 -47.25070148]\n",
      " [-22.14364037 -48.0123385 ]\n",
      " [-22.5223725  -47.58097821]\n",
      " [-22.63187409 -47.59552762]\n",
      " [-22.7770861  -47.49664889]\n",
      " [-22.66327977 -47.94598846]\n",
      " [-22.75778776 -46.87451293]\n",
      " [-22.33831205 -46.80663688]\n",
      " [-22.26954585 -47.10841964]\n",
      " [-22.69170007 -47.8853208 ]\n",
      " [-22.36257196 -45.89356197]\n",
      " [-22.75153709 -45.80870095]\n",
      " [-22.79155465 -45.29214847]\n",
      " [-22.15899213 -44.78335269]\n",
      " [-22.78942207 -45.45179957]\n",
      " [-21.79205065 -51.55232831]\n",
      " [-22.00761126 -51.10783391]\n",
      " [-21.82842415 -51.49199111]\n",
      " [-21.81589397 -50.34755873]\n",
      " [-21.79523834 -49.19036793]\n",
      " [-21.58366036 -47.14919158]\n",
      " [-21.45163151 -47.81512367]\n",
      " [-21.83243967 -47.50772168]\n",
      " [-22.08372035 -46.95871962]\n",
      " [-22.10645596 -46.80658318]\n",
      " [-21.64988788 -46.80450958]\n",
      " [-22.09255415 -46.9170662 ]\n",
      " [-21.57619835 -46.0699586 ]\n",
      " [-21.00086087 -51.04586496]\n",
      " [-20.96502723 -49.76367906]\n",
      " [-20.74068159 -49.53377937]\n",
      " [-21.17952613 -49.59896307]\n",
      " [-21.24868235 -49.89329975]\n",
      " [-21.03849222 -49.59049675]\n",
      " [-21.36459182 -50.30659944]\n",
      " [-20.97106366 -49.04317341]\n",
      " [-21.01431554 -48.16560834]\n",
      " [-21.10933477 -48.97773915]\n",
      " [-21.12092332 -47.48054706]\n",
      " [-21.28855217 -47.17731269]\n",
      " [-21.16866965 -46.80399171]\n",
      " [-21.05970884 -47.17778878]\n",
      " [-20.75197311 -46.80550559]\n",
      " [-21.4014047  -46.87488315]\n",
      " [-21.34233518 -46.84881102]\n",
      " [-20.37247898 -50.947863  ]\n",
      " [-20.36940645 -50.91038741]\n",
      " [-20.69365452 -49.6987455 ]\n",
      " [-20.19082676 -49.41817429]\n",
      " [-20.30844903 -49.07466479]\n",
      " [-20.05381005 -47.94285847]]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def driver_generation(seed_val):\n",
    "  '''\n",
    "  Creating drivers through grid formation:\n",
    "  - Divide the city into an MxN grid\n",
    "  - Number of drivers in a grid cell = rand_num * number of customers in the grid cell\n",
    "      where rand_num is a random number in range [0.5, 1.5]\n",
    "  '''\n",
    "\n",
    "  lis = ['geolocation_lat', 'geolocation_lng']\n",
    "    \n",
    "  # the drivers' locations are predicted based on the training data\n",
    "  # for making the grid we use combined_locs\n",
    "  combined_locs = training_combined_locations[lis].values \n",
    "  combined_locs = np.transpose(combined_locs)\n",
    "    \n",
    "  # for getting the number of customers in each grid cell we use customer_locs\n",
    "  customer_locs = training_customer_loc_df[lis].values\n",
    "  customer_locs = np.transpose(customer_locs)\n",
    "  \n",
    "  # min- and max-longitude values\n",
    "  min_long, max_long = np.amin(combined_locs[0]), np.amax(combined_locs[0])\n",
    "  # min- and max-lattitude values\n",
    "  min_lat, max_lat = np.amin(combined_locs[1]), np.amax(combined_locs[1])\n",
    "\n",
    "  # configParser.read(configFilePath)\n",
    "  prop_constant_driver_customer = float(configParser.get('dataset-generation','prop_constant_driver_customer'))\n",
    "  grid_length = int(configParser.get('dataset-generation','grid_length'))\n",
    "  grid_width = int(configParser.get('dataset-generation','grid_width'))   \n",
    "  prop_constant_lower_range = float(configParser.get('dataset-generation','prop_constant_lower_range'))  # 0.5 \n",
    "  prop_constant_higher_range = float(configParser.get('dataset-generation','prop_constant_upper_range')) # 1.5\n",
    "\n",
    "  # random.seed(int(configParser.get('dataset-generation','Random_seed_value'))) # leads to 128 drivers with combined_locs\n",
    "  random.seed(seed_val) # leads to 85 drivers with combined_locs; 96 with customer_locs\n",
    "    \n",
    "  # Making the grid:  \n",
    "  grid_size=[grid_length,grid_width]\n",
    "  \n",
    "  drivers=[[],[]]\n",
    "  sum_customer = 0\n",
    "  sum_driver = 0\n",
    "\n",
    "  for i in range(grid_size[0]):\n",
    "    left_long = min_long + ((max_long-min_long)/grid_size[0])*i\n",
    "    right_long = min_long + ((max_long-min_long)/grid_size[0])*(i+1)\n",
    "#     ind1 = combined_locs[0]>=left_long  \n",
    "#     ind2 = combined_locs[0]<=right_long\n",
    "    ind1 = customer_locs[0]>=left_long  \n",
    "    ind2 = customer_locs[0]<=right_long\n",
    "\n",
    "    for j in range(grid_size[1]):\n",
    "      up_lat = min_lat + ((max_lat-min_lat)/grid_size[1])*(j+1)\n",
    "      down_lat = min_lat + ((max_lat-min_lat)/grid_size[1])*j\n",
    "#       ind3 = combined_locs[1]>=down_lat \n",
    "#       ind4 = combined_locs[1]<=up_lat  \n",
    "      ind3 = customer_locs[1]>=down_lat\n",
    "      ind4 = customer_locs[1]<=up_lat\n",
    "       \n",
    "      ind = ind1 & ind2 & ind3 & ind4\n",
    "     \n",
    "      # ideally, for all ind's we should consider customer_locs and not combined locs\n",
    "      # but since the number of ffcs is very low compared to the customers so it works\n",
    "        \n",
    "      # num_customers is the number of customers in the [i,j]-th grid cell\n",
    "      # prop_constant_driver_customer number of customers per driver assumption:\n",
    "      num_customers = np.count_nonzero(ind) / num_training_days\n",
    "      num_drivers = num_customers / prop_constant_driver_customer\n",
    "      \n",
    "      # num_drivers is the number of drivers in the [i,j]-th grid cell\n",
    "      # num_drivers = random([0.5, 1.5])*num_drivers\n",
    "      random_constant = random.uniform(prop_constant_lower_range,prop_constant_higher_range) \n",
    "      num_drivers = int(num_drivers * random_constant)\n",
    "      \n",
    "      # Assigning random locations in the [i,j]-th grid cell to all num_drivers in the grid cell\n",
    "      if num_drivers==0:\n",
    "        continue\n",
    "      for k in range(num_drivers):\n",
    "        drivers[0].append(random.uniform(left_long,right_long))\n",
    "        drivers[1].append(random.uniform(down_lat,up_lat))\n",
    "        \n",
    "\n",
    "      sum_driver += num_drivers\n",
    "      sum_customer += num_customers\n",
    "    \n",
    "  drivers = np.array(drivers)\n",
    "\n",
    "  print(\"Number of Drivers:\",len(drivers[0]))\n",
    "  new_drivers = np.transpose(drivers)\n",
    "  \n",
    "\n",
    "  # # Plot Customers, Sellers, FFCs and Drivers\n",
    "  # fig, ax = plt.subplots()\n",
    "  \n",
    "  # # Customers\n",
    "  # customer_locs = testing_customer_loc_df[lis].values\n",
    "  # customer_locs = np.transpose(customer_locs)\n",
    "  # c_lts, c_lngs = customer_locs[0], customer_locs[1]\n",
    "  # plt.scatter(c_lngs,c_lts,color='Red',label='Customer')\n",
    " \n",
    "  # # Sellers\n",
    "  # seller_locs = testing_seller_loc_df[lis].values\n",
    "  # seller_locs = np.transpose(seller_locs)\n",
    "  # s_lts, s_lngs = seller_locs[0], seller_locs[1]\n",
    "  # plt.scatter(s_lngs,s_lts,color='Blue',label='Seller')\n",
    "  \n",
    "  # # FFCs\n",
    "  # ffc_locs = np.transpose(centre)\n",
    "  # f_lts, f_lngs = ffc_locs[0], ffc_locs[1]\n",
    "  # plt.scatter(f_lngs,f_lts,color='Black',label='FF centres',s=100)\n",
    "    \n",
    "  # # Drivers\n",
    "  # driver_locs = drivers\n",
    "  # d_lts, d_lngs = driver_locs[0], driver_locs[1]\n",
    "  # plt.scatter(d_lngs,d_lts,color='Cyan',label='Drivers')\n",
    "  \n",
    "  # plt.legend(loc='lower left',prop={'size':20})\n",
    "  # plt.xlabel('Longitude')\n",
    "  # plt.ylabel('Latitude')\n",
    "  # # plt.savefig(\"Plots/Coordinate Plots/\"+state_dataset+\".pdf\")\n",
    "  # plt.show()\n",
    "  # plt.close()\n",
    "\n",
    "    \n",
    "  return new_drivers\n",
    "\n",
    "\n",
    "# Generating Drivers\n",
    "driver_locs = driver_generation(12)\n",
    "print(\"Drivers' Locations:\\n\", driver_locs)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avg similar drivers wrt EUCLIDEAN DISTANCE   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.1652952243944\n",
      "0.0\n",
      "1.5007325628794748\n"
     ]
    }
   ],
   "source": [
    "def L2Distance(data):\n",
    "  # \"data\": latitude-longitude level locations \n",
    "  transposed = np.expand_dims(data, axis = 1)\n",
    "  distance = np.power(data - transposed, 2)\n",
    "  distance = np.power(np.abs(distance).sum(axis = 2), 0.5) \n",
    "  # @marker1: distance = distance*110 # why multiply by 110? Is it Euclidean to Haversine??\n",
    "\n",
    "  return distance \n",
    "  # this is going to be a [num_dirvers x num_drivers] shaped symmetric matrix giving distance between all drivers \n",
    "    \n",
    "driver_dists = L2Distance(driver_locs)\n",
    "print(np.max(driver_dists.reshape(1,-1)))\n",
    "print(np.min(driver_dists.reshape(1,-1)))\n",
    "print(np.average(driver_dists.reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.421319796954315\n"
     ]
    }
   ],
   "source": [
    "# finding number of drivers within fair distance for each driver\n",
    "# @marker1: fair_dist = 15\n",
    "fair_dist = 0.15 # driver_dists.mean()/3\n",
    "# print(fair_dist)\n",
    "\n",
    "num_similar_drivers = []\n",
    "for idx in range(len(driver_dists)):\n",
    "    curr_driver = driver_dists[idx]\n",
    "    # the drivers 'similar' to this driver are the ones within fair_distance from this driver\n",
    "    num_sim = curr_driver[curr_driver<=fair_dist].shape[0]\n",
    "    # print(num_sim)\n",
    "    num_similar_drivers.append(num_sim) \n",
    "\n",
    "# print(num_similar_drivers)\n",
    "print(np.mean(num_similar_drivers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 7.1652952243944, 1.5007325628794748)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = L2Distance(driver_locs) \n",
    "dist.min(), dist.max(), dist.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avg similar drivers wrt RATINGS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Drivers: 350\n"
     ]
    }
   ],
   "source": [
    "# assigning ratings to sellers:\n",
    "import random\n",
    "\n",
    "def generate_ratings(num_drivers):\n",
    "    r_set = list(np.arange(0, 6, 0.1)) #[1, 2, 3, 4, 5]\n",
    "    ratings = [0.0]*num_drivers\n",
    "    for i in range(num_drivers):\n",
    "        ratings[i] = np.round(random.sample(r_set, 1)[0],1)\n",
    "\n",
    "    return ratings\n",
    "    \n",
    "new_drivers = driver_generation(3249+1)\n",
    "ratings_list = generate_ratings(new_drivers.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_difference(ratings):\n",
    "    transposed = np.expand_dims(ratings, axis=1)\n",
    "    diff = abs(ratings-transposed) \n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.622857142857143\n"
     ]
    }
   ],
   "source": [
    "ratings_matrix = abs_difference(ratings_list)\n",
    "size = min(driver_dists.shape[0], ratings_matrix.shape[0])\n",
    "fair_dist = 0.15\n",
    "\n",
    "ratings_matrix = abs_difference(ratings_list[:size])\n",
    "num_similar_drivers = []\n",
    "for idx in range(size):\n",
    "    curr_driver = ratings_matrix[idx]\n",
    "    # the drivers 'similar' to this driver are the ones within fair_distance from this driver\n",
    "    num_sim = curr_driver[curr_driver<=fair_dist].shape[0]\n",
    "    num_similar_drivers.append(num_sim) \n",
    "\n",
    "# print(num_similar_drivers)\n",
    "print(np.mean(num_similar_drivers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avg similar drivers wrt LINEAR COMBINATION of EUCLIDEAN DISTANCE and RATINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = 0.5\n",
    "w2 = 0.5\n",
    "\n",
    "combined_matrix = w1*driver_dists[:size, :size] + w2*ratings_matrix[:size, :size]\n",
    "# combined_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.668571428571429\n"
     ]
    }
   ],
   "source": [
    "# n = driver_dists.shape[0] \n",
    "n = size \n",
    "fair_dist = 0.30\n",
    "\n",
    "num_similar_drivers = []\n",
    "for idx in range(n):\n",
    "    curr_driver = combined_matrix[idx]\n",
    "    # the drivers 'similar' to this driver are the ones within fair_distance from this driver\n",
    "    num_sim = curr_driver[curr_driver<=fair_dist].shape[0]\n",
    "    num_similar_drivers.append(num_sim) \n",
    "\n",
    "# print(num_similar_drivers)\n",
    "print(np.mean(num_similar_drivers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using max flow for the Vanilla Distribution of Drivers to the warehouse\n",
    "import networkx as nx\n",
    "from networkx.algorithms.flow import maximum_flow\n",
    "from math import cos, asin, sqrt, pi\n",
    "\n",
    "# Haversine formula \n",
    "# angular distance between two points on the surface of a sphere \n",
    "# Refer: https://stackoverflow.com/questions/27928/calculate-distance-between-two-latitude-longitude-points-haversine-formula\n",
    "def distance(lat1, lon1, lat2, lon2):\n",
    "    p = pi/180\n",
    "    a = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p) * cos(lat2*p) * (1-cos((lon2-lon1)*p))/2\n",
    "    return 12742 * asin(sqrt(a))\n",
    "    \n",
    "\n",
    "# configParser.read(configFilePath)\n",
    "prop_constant_driver_customer=float(configParser.get('dataset-generation','prop_constant_driver_customer'))\n",
    "\n",
    "# Since prop_constant_driver_customer number of orders/customers are being mapped to one driver\n",
    "# so upper_cap and lower_cap (wrt drivers) of each FFC will be (1/prop_constant_driver_customer) times max_cap and min_cap (wrt orders (or customers))\n",
    "upper_cap = max_cap / prop_constant_driver_customer\n",
    "lower_cap = min_cap / prop_constant_driver_customer\n",
    "lower_cap = lower_cap.astype(int)\n",
    "upper_cap = upper_cap.astype(int)\n",
    "upper_cap = np.array(upper_cap)\n",
    "lower_cap = np.array(lower_cap)\n",
    "lower_cap[lower_cap<=0] = 1    # just a sanity check\n",
    "\n",
    "\n",
    "'''\n",
    "MCCA (Minimum Cost Capacitated Assignment) problem !\n",
    "- It can be cast as a \"minimum cost b-matching problem\" in bipartite graphs\n",
    "- The \"min cost b-matching problem\" reduces to thte classical \"min cost flow problem\"\n",
    "'''\n",
    "\n",
    "\"\"\"Code to generate MCCA distribution using networkX library\"\"\"\n",
    "# only upper_cap respected, lower_cap not included\n",
    "def flow_with_max_capacity(driver_loc,centre):\n",
    "  G = nx.DiGraph()\n",
    "  # len(centre) and len(driver_loc) are proxy for num_ffc and num_drivers respectively\n",
    "  num_variables = len(centre) + len(driver_loc)\n",
    "    \n",
    "  # source node (s): 1\n",
    "  # sink node (t) : num_variables+2\n",
    "   \n",
    "  # 'weight' <=> cost\n",
    "    \n",
    "  # edges from source_node to driver_nodes\n",
    "  for i in range(len(driver_loc)):\n",
    "    G.add_edge(1,i+2,capacity=1,weight=0)\n",
    "  \n",
    "  # edges from ffc_nodes (or centre_nodes) to sink_node\n",
    "  for i in range(len(centre)):\n",
    "    G.add_edge(len(driver_loc)+1+(i+1),num_variables+2,capacity=int(upper_cap[i]),weight=0)\n",
    "  \n",
    "  # edges from driver_nodes to ffc_nodes (or centre_nodes)\n",
    "  for i in range(len(driver_loc)):\n",
    "    for j in range(len(centre)):\n",
    "      # (d(v,c))^2 : cost/weight of the edge in the flow network\n",
    "      dis = (driver_loc[i][0]-centre[j][0])**2 + (driver_loc[i][1]-centre[j][1])**2 \n",
    "      # cost of flow in an edge (or weight of an edge) is the distance calculated above \n",
    "      # (multiplied by 1000 bcz the algorithm is not guaranteed to work if edge weights or demands are floating point numbers)\n",
    "      G.add_edge(i+2,len(driver_loc)+1+(j+1),capacity=1,weight=int(dis*1000))\n",
    "    \n",
    "  # max_flow_min_cost returns a maximum (s, t)-flow of minimum cost\n",
    "  mincostFlow = nx.max_flow_min_cost(G, 1, num_variables+2) # actual solving being done!\n",
    "  minCost = nx.cost_of_flow(G, mincostFlow)\n",
    "  print(\"max_flow_min_cost cost value:\", minCost) \n",
    "#   print(\"THISSSSSSSS \\n\", mincostFlow)\n",
    "  \n",
    "  # Sanity check: usually (maxflowCost >= minCost) and (maxflowValue >= mincostFlow) ?\n",
    "  maxFlow = maximum_flow(G, 1, num_variables+2)[1]\n",
    "  maxflowValue = nx.maximum_flow_value(G,1,num_variables+2)\n",
    "#   print(\"maximum_flow cost value:\", maxflowCost)\n",
    "  print(\"maximum_flow flow value:\", maxflowValue)\n",
    "\n",
    "  driver_df = pd.DataFrame(driver_loc,columns=[\"geolocation_lat\",\"geolocation_lng\"])\n",
    "  driver_df['ffc_index'] = -1 # unassigned \n",
    "  \n",
    "  # Driver to ffc assignment based on a mincostFlow values from corresponding driver_node to ffc_nodes\n",
    "  for i in range(len(driver_loc)):\n",
    "    for j in range(len(centre)):\n",
    "      # assign driver_i to ffc_j if flow(d_,f_j) is close (with some arbitrary delta, here 0.1) to 1\n",
    "      if abs(mincostFlow[i+2][len(driver_loc)+(j+2)] - 1) < 0.1: \n",
    "        driver_df.at[i,'ffc_index'] = j\n",
    "  \n",
    "  return driver_df\n",
    "\n",
    "\n",
    "'''\n",
    "Above is an Integer Flow Problem (IFP) (since capacities are integers) so an integer solution is guaranteed.\n",
    "However, to account for machine generated floating errors, an additional check for 'close to 1' values \n",
    "(using some arbitrary delta 0.1) was done !\n",
    "Higher value of the flow will be on the edge with the lower weight or cost !\n",
    "'''\n",
    "\n",
    "\n",
    "'''Code to generate MCCA distribution using ortools library'''\n",
    "# lower_cap and upper_cap both considered\n",
    "from ortools.graph import pywrapgraph\n",
    "\n",
    "def flow_with_maxmin_capacity(driver_loc,centre):\n",
    "  '''\n",
    "  - Instantiate a \"SimpleMinCostFlow\" solver.\n",
    "  - Using min-max flow for the Vanilla Distribution of Drivers to the warehouse\n",
    "  '''\n",
    "  num_variables = len(centre) + len(driver_loc)\n",
    "    \n",
    "  # source node (s): 1\n",
    "  # sink node (t) : num_variables+2\n",
    "  \n",
    "  min_cost_flow = pywrapgraph.SimpleMinCostFlow()\n",
    "  for i in range(len(driver_loc)):\n",
    "    min_cost_flow.AddArcWithCapacityAndUnitCost(1,i+2,1,0)\n",
    "\n",
    "  for i in range(len(driver_loc)):\n",
    "    for j in range(len(centre)):\n",
    "      dis=(driver_loc[i][0]-centre[j][0])**2 + (driver_loc[i][1]-centre[j][1])**2\n",
    "      min_cost_flow.AddArcWithCapacityAndUnitCost(i+2,len(driver_loc)+1+(j+1),1,int(dis*1000))\n",
    "        # dis multiplied by 1000 to make it large enough and ensure no floating point errors \n",
    "\n",
    "  for i in range(len(centre)):\n",
    "    # edges from centre (ffc) nodes to sink have capacity = upper_cap[ffc_label] - lower_cap[ffc_label]\n",
    "    min_cost_flow.AddArcWithCapacityAndUnitCost(len(driver_loc)+1+(i+1),num_variables+2,int(upper_cap[i])-int(lower_cap[i]),0)\n",
    "\n",
    "  for i in range(0,len(centre)): \n",
    "    # each centre has a demand of lower_cap[centre_label] below which it won't operate\n",
    "    # negative supply <=> demand\n",
    "    min_cost_flow.SetNodeSupply(len(driver_loc)+1+(i+1), -int(lower_cap[i]))\n",
    "\n",
    "  source_supply = int(len(driver_loc))\n",
    "  sink_supply = int(len(driver_loc)-np.sum(lower_cap))\n",
    "\n",
    "  min_cost_flow.SetNodeSupply(1,source_supply)\n",
    "  min_cost_flow.SetNodeSupply(num_variables+2,-sink_supply)\n",
    "\n",
    "  for i in range(0,len(driver_loc)):\n",
    "    min_cost_flow.SetNodeSupply(i+2,0)\n",
    "\n",
    "  if min_cost_flow.Solve() == min_cost_flow.OPTIMAL:\n",
    "      print('Minimum cost:', min_cost_flow.OptimalCost())\n",
    "      print('')\n",
    "      print('  Arc    Flow / Capacity  Cost')\n",
    "      for i in range(min_cost_flow.NumArcs()):\n",
    "        if min_cost_flow.Flow(i)!=0:\n",
    "          cost = min_cost_flow.Flow(i) * min_cost_flow.UnitCost(i)\n",
    "          print('%1s -> %1s   %3s  / %3s       %3s' % (\n",
    "              min_cost_flow.Tail(i),\n",
    "              min_cost_flow.Head(i),\n",
    "              min_cost_flow.Flow(i),\n",
    "              min_cost_flow.Capacity(i),\n",
    "              cost))\n",
    "  else:\n",
    "    print('There was an issue with the min cost flow input.')\n",
    "\n",
    "  driver_df1 = pd.DataFrame(driver_loc,columns=[\"geolocation_lat\",\"geolocation_lng\"])\n",
    "  driver_df1['ffc_index'] = -1 # unassigned\n",
    "  \n",
    "  for i in range(min_cost_flow.NumArcs()):\n",
    "    # if min_cost_flow is non-zero and it's not originating from the source_node and going into the sink node\n",
    "    # => for non-zero flows from driver_nodes to ffc_nodes\n",
    "    # so, here: tail => a driver_node; head => a ffc_node\n",
    "    if min_cost_flow.Flow(i)!=0 and min_cost_flow.Tail(i)!=1 and min_cost_flow.Head(i)!=(num_variables+2):\n",
    "      tail = min_cost_flow.Tail(i)\n",
    "      head = min_cost_flow.Head(i)\n",
    "      driver_df1.at[tail-2,'ffc_index'] = head-len(driver_loc)-2  # (head-len(driver_loc)-2) is ffc_label ! -len(driver_loc)-2 ensures that it's in {0, ..., (num_ffc-1)} \n",
    "\n",
    "  return driver_df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1e-06, 1e-06, 0.01)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cplex import Cplex\n",
    "model = Cplex()\n",
    "model.parameters.simplex.tolerances.feasibility.get(),\\\n",
    "model.parameters.simplex.tolerances.optimality.get(),\\\n",
    "model.parameters.simplex.tolerances.markowitz.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "Dkp5iSoyG5oe",
    "outputId": "ee6c9a1c-94a4-4928-b536-005ce8640e4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThe fairness constraint is NOT going to be applied for all driver pairs.  \\nInstead, for a given driver 'i', it's going to be applied to all driver j's which are within a 'fair_distance'\\nfrom the driver 'i'.\\nCheck out prepare_to_add_constraints implementation for this info\\n\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fair Clustering - LPP contstraints and Cplex\n",
    "from cplex import Cplex\n",
    "from lp_tools import *\n",
    "\n",
    "# configParser.read(configFilePath)\n",
    "# fair_distance = int(configParser.get('fairness-constraint','fair_distance')) \n",
    "fair_distance = float(configParser.get('fairness-constraint','fair_distance')) \n",
    "alpha_fair = float(configParser.get('fairness-constraint','alpha_fair'))     \n",
    "\n",
    "# fair_distance = 1e9 # uncomment to consider \"global fairness constraints\" #cwp\n",
    "# alpha_fair = 2 #cwp\n",
    "\n",
    "def fair_clustering(dataset, centres, ratings):\n",
    "\n",
    "  # Step 1: \t Create an instance of Cplex \n",
    "  problem = Cplex()\n",
    "  \n",
    "  ## changing tolerances to improve solution quality (prevent ill-conditioning and avoid numerical instability)\n",
    "  ## https://www.ibm.com/docs/en/icos/20.1.0?topic=cplex-list-parameters\n",
    "  problem.parameters.simplex.tolerances.feasibility.set(float(1e-9))\n",
    "  problem.parameters.simplex.tolerances.optimality.set(float(1e-9))\n",
    "  problem.parameters.simplex.tolerances.markowitz.set(float(0.9))\n",
    "  \n",
    "\n",
    "  # Step 2: \t Declare that this is a minimization problem\n",
    "  problem.objective.set_sense(problem.objective.sense.minimize)\n",
    "    \n",
    "  \"\"\"\n",
    "   Step 3.   Declare and  add variables to the model. \n",
    "        The function prepare_to_add_variables (dataset, centres) prepares all the required information for this stage.\n",
    "  \n",
    "    objective: a list of coefficients (float) in the linear objective function\n",
    "    lower bound: a list of floats containing the lower bounds for each variable\n",
    "    upper bound: a list of floats containing the upper bounds for each variable\n",
    "    variable_names: a list of strings that contains the name of the variables\n",
    "  \"\"\"\n",
    "  objective, lower_bound, upper_bound, variable_names, P,C = prepare_to_add_variables(dataset, centres)\n",
    "  problem.variables.add(\n",
    "      obj = objective,\n",
    "      lb = lower_bound,\n",
    "      ub = upper_bound,\n",
    "      names = variable_names\n",
    "     \n",
    "    )\n",
    "    \n",
    "  \"\"\"\n",
    "  Step 4.   Declare and add constraints to the model.\n",
    "            There are few ways of adding constraints: row wise, col wise and non-zero entry wise.\n",
    "            Assume the constraint matrix is A. We add the constraints non-zero entry wise.\n",
    "            The function prepare_to_add_constraints(dataset, centres) prepares the required data for this step.\n",
    "  \n",
    "   coefficients: Three tuple containing the row number, column number and the value of the constraint matrix\n",
    "   senses: a list of strings that identifies whether the corresponding constraint is\n",
    "           an equality or inequality. \"E\" : equals to (=), \"L\" : less than (<=), \"G\" : greater than equals (>=)\n",
    "   rhs: a list of floats corresponding to the rhs of the constraints.\n",
    "   constraint_names: a list of string corresponding to the name of the constraint\n",
    "  \"\"\"\n",
    "  rhs, senses, row_names, coefficients = prepare_to_add_constraints(dataset, centres, upper_cap,lower_cap, P,C, alpha_fair, fair_distance, ratings, flag)\n",
    "  print(\"num_constraints:\", len(senses))\n",
    "  problem.linear_constraints.add(\n",
    "      rhs = rhs,\n",
    "      senses = senses,\n",
    "      names = row_names\n",
    "    )\n",
    "  problem.linear_constraints.set_coefficients(coefficients)\n",
    "\n",
    "  # Step 5.\tSolve the problem\n",
    "  problem.solve()\n",
    "\n",
    "  result = {\n",
    "    \"status\": problem.solution.get_status(),\n",
    "    \"success\": problem.solution.get_status_string(),\n",
    "    \"objective\": problem.solution.get_objective_value(),\n",
    "    \"assignment\": problem.solution.get_values(),\n",
    "  }\n",
    "    \n",
    "  qm = problem.solution.quality_metric  \n",
    "  print(\"Solution Quality:\", problem.solution.get_float_quality([qm.max_x, qm.max_primal_infeasibility]))\n",
    "  # qm.max_primal_infeasibility is the \"maximum bound violation\" across all parameters\n",
    "  # print(\"Solution Kappa:\", )\n",
    "  \n",
    "  # print(\"Status:\", result['status'])\n",
    "  print(\"Status:\", problem.solution.get_status_string())\n",
    "  return result\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "The fairness constraint is NOT going to be applied for all driver pairs.  \n",
    "Instead, for a given driver 'i', it's going to be applied to all driver j's which are within a 'fair_distance'\n",
    "from the driver 'i'.\n",
    "Check out prepare_to_add_constraints implementation for this info\n",
    "'''\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caluclate average distance each driver has to travel each day from going to home to the location of FF Center\n",
    "def average_distance(driver_dist, label):\n",
    "    distance_warehouse_driver_df = pd.merge(driver_dist, label, left_on = 'ffc_index' ,right_on='label')\n",
    "    dist1=0.0\n",
    "    \n",
    "    for i in range(len(distance_warehouse_driver_df)):\n",
    "        dist1 = dist1 + math.sqrt((distance_warehouse_driver_df.loc[i].at[\"geolocation_lat\"] - distance_warehouse_driver_df.loc[i].at[\"x\"])**2 + (distance_warehouse_driver_df.loc[i].at[\"geolocation_lng\"] - distance_warehouse_driver_df.loc[i].at[\"y\"])**2)\n",
    "    \n",
    "    return round(dist1/len(distance_warehouse_driver_df),2)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Returns gini index on income list\n",
    "def gini_index(incomes):\n",
    "  driver_income = np.array(incomes)\n",
    "  driver_income = np.sort(driver_income)\n",
    "  integer_array = np.array([(i+1) for i in range(len(driver_income))])\n",
    "  driver_income = driver_income*750\n",
    "  gini_index = 2*(np.dot(driver_income,integer_array))/(len(driver_income)*(np.sum(driver_income))) - 1 -1/(len(driver_income))\n",
    "  return round(gini_index,3)\n",
    "\n",
    "\n",
    "\n",
    "# def gini_index(incomes):\n",
    "#     num = len(incomes)\n",
    "#     total = incomes.sum() \n",
    "\n",
    "#     inc_sum = 0.0\n",
    "#     for i in range(num):\n",
    "#         for j in range(num):\n",
    "#             inc_sum += abs(incomes[i]-incomes[j])\n",
    "\n",
    "#     gini = inc_sum / (2*num*total)\n",
    "\n",
    "#     return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fair Assignment of drivers to the FFCs / warehouses\n",
    "import dependent_routing as dp\n",
    "\n",
    "# configParser.read(configFilePath)\n",
    "\n",
    "\n",
    "def fair_assignment(prob_dis,driver_loc):\n",
    "  '''Assigning the driver using the probaility distribution using dependent rounding''' \n",
    "# driver_loc is not a necessary argument for the logic of the function\n",
    "  \n",
    "  # \"prob_dis\" is the result of the Fair-LP program \"fair_clustering\"  \n",
    "  prob_dist = copy.deepcopy(prob_dis)\n",
    "  # print(\"prob_dist shape [num_drivers x num_ffc]:\", prob_dist.shape)\n",
    "\n",
    "  rounding = dp.DependentRounding(prob_dist)\n",
    "  rounding._buildGraph(prob_dist)\n",
    "  final_assignment = rounding.round()\n",
    "  final_assignment = np.around(final_assignment,2)\n",
    "\n",
    "  driver_df2 = pd.DataFrame(driver_loc,columns=[\"geolocation_lat\",\"geolocation_lng\"])\n",
    "  driver_df2['ffc_index'] = -1 # unassigned\n",
    "  ##############################################\n",
    "# Ideally:\n",
    "#   for i in range(num_samples):\n",
    "#     for j in range(num_centres):\n",
    "#         if final_assignment[i][j] == 1:\n",
    "#             driver_df2.at[i, 'ffc_index'] = j\n",
    "  ##############################################\n",
    "  for i in range(num_samples):\n",
    "    for j in range(num_centres):\n",
    "      # choose values which are close to 1\n",
    "      if abs(final_assignment[i][j]-1) < 0.01: \n",
    "        driver_df2.at[i,'ffc_index'] = j\n",
    "  ##############################################\n",
    "        \n",
    "  return driver_df2,final_assignment\n",
    "\n",
    "\n",
    "\n",
    "# Randomly assigning the drivers to ffc keeping the upper_cap constraint\n",
    "def random_dist(driver_loc):\n",
    "  driver_df4 = pd.DataFrame(driver_loc,columns=[\"geolocation_lat\",\"geolocation_lng\"])\n",
    "  driver_df4['ffc_index'] = -1 # unassigned\n",
    "    \n",
    "  temp_upper_cap = list(upper_cap)\n",
    "  \n",
    "  for i in range(num_samples):\n",
    "    ffc = random.randint(1,num_centres)-1\n",
    "    \n",
    "    # if the above chosen ffc is exhausted then choose next ffc randomly until one with a positive current capacity is found\n",
    "    while(temp_upper_cap[ffc] <= 0):\n",
    "      ffc = random.randint(1,num_centres)-1\n",
    "    \n",
    "    driver_df4.at[i,'ffc_index'] = ffc\n",
    "    temp_upper_cap[ffc] -= 1\n",
    "    \n",
    "  return driver_df4\n",
    "\n",
    "\n",
    "\n",
    "# Assign the drivers in round robin manner to ffc keeping the upper_cap constraint\n",
    "def round_robin_dist(d,driver_loc):\n",
    "  # input 'd' is the current date in {1,..,30}\n",
    "  driver_df5 = pd.DataFrame(driver_loc,columns=[\"geolocation_lat\",\"geolocation_lng\"])\n",
    "  driver_df5['ffc_index'] = -1 # unassigned\n",
    "    \n",
    "  temp_upper_cap = list(upper_cap)\n",
    "  \n",
    "  for i in range(num_samples):\n",
    "    ffc = (d+i) % num_centres\n",
    "    \n",
    "    # if the above chosen ffc is exhausted then choose next ffc in a round robin fashion until one with a positive current capacity is found\n",
    "    while(temp_upper_cap[ffc]<=0):\n",
    "      ffc = (ffc+1)%num_centres\n",
    "    \n",
    "    driver_df5.at[i,'ffc_index']=ffc\n",
    "    temp_upper_cap[ffc] -= 1\n",
    "  \n",
    "  return driver_df5\n",
    "\n",
    "\n",
    "\n",
    "# Assign the drivers with LIPA manner to ffc keeping the upper_cap constraint\n",
    "'''\n",
    "LIPA (Least Income Priority Assignment):\n",
    "- sort drivers in non-decreasing order wrt to their cumulative incomes until before this day\n",
    "- sort ffcs in non-increasing order wrt to the number of deliveries (#deliveries is proxy to ffc income) \n",
    "'''\n",
    "def low_income_dist(prev_income_drivers,prev_incomes_warehouse,driver_loc,lpp_prob_dis):\n",
    "  if len(prev_income_drivers)==0:\n",
    "    return random_dist(driver_loc)\n",
    "    # return fair_assignment(lpp_prob_dis,driver_loc)[0] # Why initialize with FairAssign assignments?\n",
    "\n",
    "  driver_df6 = pd.DataFrame(driver_loc,columns=[\"geolocation_lat\",\"geolocation_lng\"])\n",
    "  driver_df6['ffc_index'] = -1 # unassigned\n",
    "\n",
    "  temp_upper_cap = list(upper_cap)\n",
    "  \n",
    "  driver_index_inc = np.argsort(np.array(prev_income_drivers))\n",
    "  \n",
    "  warehouse_index_inc = np.argsort(np.array(prev_incomes_warehouse))\n",
    "  j = num_centres-1\n",
    "  \n",
    "  for i in driver_index_inc:\n",
    "    ffc = warehouse_index_inc[j]\n",
    "    \n",
    "    # repeatedly choose the ffc with a positive current capacity and max previous income\n",
    "    while(temp_upper_cap[ffc]<=0):\n",
    "      j = j-1\n",
    "      ffc = warehouse_index_inc[j]\n",
    "    \n",
    "    driver_df6.at[i,'ffc_index'] = ffc\n",
    "    temp_upper_cap[ffc] -= 1\n",
    "  \n",
    "  return driver_df6\n",
    "\n",
    "\n",
    "\n",
    "# Returns the total cost of the drivers from their location to ffc\n",
    "def total_cost(df):\n",
    "  sum = 0\n",
    "\n",
    "  for index,row in df.iterrows():\n",
    "    sum += np.sqrt( (row['geolocation_lat']-centre[int(row['ffc_index'])][0])**2 + (row['geolocation_lng']-centre[int(row['ffc_index'])][1])**2 )\n",
    "  \n",
    "  return round(sum,2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inequality(df,date_index):\n",
    "  # \"df\" is an driver-ffc assignment\n",
    "  # calculation of the inequality is being done for the \"date_index\"-th day of delivery (starting from the start date of the dataset after clubbing 15 dates into one....)\n",
    "\n",
    "  # Finding the number of drivers assigned to every ffc\n",
    "  df['driver_index'] = np.arange(len(df.index))  \n",
    "  driver_assign = df.groupby('ffc_index')['geolocation_lat'].count() # for every ffc_index, counts the number of drivers\n",
    "  # any two drivers can't practically be present at exactly the same lat-lng; so taking just lat or lng works equivalently;\n",
    "  # if we take both then 2 identical count cols will be returned and below line would have to be modified to take one of those cols\n",
    "  driver_assign = pd.DataFrame({'num_drivers':driver_assign}).reset_index()\n",
    "\n",
    "  # Adding 0 driver count to center to whom no driver was assigned\n",
    "  for i in range(len(centre)):\n",
    "    if i not in driver_assign['ffc_index'].values:\n",
    "      driver_assign.loc[len(driver_assign.index)] = [i,0]\n",
    "\n",
    "  driver_assign = driver_assign.sort_values('ffc_index')\n",
    "  driver_assign['min_cap'] = lower_cap\n",
    "  driver_assign['max_cap'] = upper_cap\n",
    "\n",
    "  # Finding income of each driver as total number of customers divided by total number of drivers in that center\n",
    "  # For a particular data: dates[date_index] \n",
    "\n",
    "  # Finding the income of each warehouse\n",
    "  testing_customer_group_date = testing_customer_loc_df.groupby(['ffc_index','order_delivered_customer_date'])['order_id'].count() # for each ffc, counts the number of orders on each day\n",
    "  testing_customer_group_date = pd.DataFrame({'num_delivery_per_date':testing_customer_group_date}).reset_index()\n",
    "  \n",
    "  dates = testing_customer_group_date['order_delivered_customer_date'].unique()\n",
    "  # make sure that the date_index does not exceed len(dates) or number of unique dates on which any delivery reached the customer\n",
    "  # len(dates) need not be >=30 since dates does not contain monthly data. It contains dates over the span of the entire dataset with 15 days clubbed as one ...,\n",
    "  testing_customer_group_date = testing_customer_group_date[testing_customer_group_date['order_delivered_customer_date']==dates[date_index]]\n",
    "\n",
    "  warehouse_income_df = pd.merge(testing_customer_group_date, driver_assign, on='ffc_index', how='right')\n",
    "  # (income_warehouse_driver = total orders / total drivers) on a particular day for a given ffc;\n",
    "  # this income_warehouse_drivers will be the income of each driver in the corresponding ffc\n",
    "  warehouse_income_df['income_warehouse_driver'] = warehouse_income_df['num_delivery_per_date'] / warehouse_income_df['num_drivers']\n",
    "  warehouse_income_df.loc[~np.isfinite(warehouse_income_df['income_warehouse_driver']), 'income_warehouse_driver'] = 0 # takes care of divide by 0 i.e., if the number of drivers is 0; handles infintiy and NaN\n",
    "  warehouse_income_df = warehouse_income_df.round(2)\n",
    "#   warehouse_income_df.loc[warehouse_income_df['num_drivers']==0,'income_warehouse_driver'] = 0 # takes care of divide by 0 i.e., if the number of drivers is 0; Again??\n",
    "  warehouse_income_df.reset_index(inplace=True)\n",
    " \n",
    "  # (warehouse income = avg income (or orders) per driver) on a given day  \n",
    "  warehouse_incomes = warehouse_income_df['income_warehouse_driver'].values\n",
    "\n",
    "  df['date'] = dates[date_index]\n",
    "  df['income'] = -1.0\n",
    "  \n",
    "    \n",
    "  # Assigning the income of ffc to which the driver was assigned\n",
    "  for i in range(len(df.index)):\n",
    "    df.at[i,'income'] = warehouse_income_df.at[df.iloc[i]['ffc_index'],'income_warehouse_driver']\n",
    "    \n",
    "  return df, warehouse_incomes\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_ffc_maps = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the income of all drivers for {num_testing_days}, with given distribution type\n",
    "# when club_num_dates>30, make num_days=15\n",
    "def inequality2(algo_type=\"random\",num_days=30,lpp_prob_dis=[[]]):\n",
    "  if club_num_dates > 30:\n",
    "    num_days = 15\n",
    "  fair_assignment_totaldays = None\n",
    "  overall_cost = 0\n",
    "  prev_income_drivers = []\n",
    "  prev_incomes_warehouse = []\n",
    "  df = None\n",
    "  \n",
    "  if algo_type==\"vanilla_max\":      df_vanilla_max = flow_with_max_capacity(new_drivers,centre)\n",
    "  if algo_type==\"vanilla_maxmin\":   df_vanilla_maxmin = flow_with_maxmin_capacity(new_drivers,centre)\n",
    "  # The above two methods are static, so just calculated them once and will use those assignments for all of num_days\n",
    "  # The other assignment algo types are dynamic and have to calculated every day\n",
    "    \n",
    "  # Calling appropriate function according to the given algo_type paramtric value\n",
    "  for i in range(num_days):\n",
    "    if algo_type==\"random\":          df = random_dist(new_drivers)\n",
    "    if algo_type==\"round_robin\":     df = round_robin_dist(i,new_drivers)\n",
    "    if algo_type==\"fair_algo\":       df = fair_assignment(lpp_prob_dis,new_drivers)[0]\n",
    "    if algo_type==\"vanilla_max\":     df = df_vanilla_max   \n",
    "    if algo_type==\"vanilla_maxmin\":  df = df_vanilla_maxmin  \n",
    "    if algo_type==\"low_income_dist\": df = low_income_dist(prev_income_drivers,prev_incomes_warehouse,new_drivers,lpp_prob_dis)\n",
    "    \n",
    "    ###########################\n",
    "    if algo_type==\"fair_algo\":\n",
    "        driver_ffc_maps.append(df)\n",
    "    ###########################\n",
    "\n",
    "    df_result, prev_incomes_warehouse = inequality(df,i)\n",
    "    overall_cost += total_cost(df)\n",
    "\n",
    "    if fair_assignment_totaldays is None:\n",
    "      fair_assignment_totaldays = df_result\n",
    "    else:\n",
    "      fair_assignment_totaldays = pd.concat([fair_assignment_totaldays,df_result])\n",
    "    \n",
    "    prev_income_drivers = fair_assignment_totaldays.groupby('driver_index')['income'].sum().values # for low_income_dist or LIPA\n",
    "\n",
    "\n",
    "  # Finding total income of drivers over all days  \n",
    "  lis1 = fair_assignment_totaldays.groupby('driver_index')['income'].sum().values\n",
    "  \n",
    "  fair_assignment_totaldays['total_income'] = fair_assignment_totaldays['income'].groupby(fair_assignment_totaldays['driver_index']).transform('sum')\n",
    "  # shape: [sigma(driver_index*num corresponding date entries) x 6]; for each driver, it's the sum of incomes over all days\n",
    "\n",
    "  # take the first date data for each driver (total_income is there in each row for all dates for a driver so the motive is not to take first date data but to take one entry per driver?) \n",
    "  driver_income_df = fair_assignment_totaldays.groupby('driver_index').first().reset_index()  \n",
    "  # shape: [num_drivers x 7]\n",
    "    \n",
    "  avg_distance = average_distance(fair_assignment_totaldays, label_)\n",
    "\n",
    "  return gini_index(lis1),avg_distance,fair_assignment_totaldays,np.sum(np.array(lis1)),lis1\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find the \"income gap per pair of those drivers which are separated by less than fair_distance\"\n",
    "# def helper_func(table,driver_loc):\n",
    "#     ''' \"table\" is \"fair_assignment_totaldays\" form inequality2(...) '''\n",
    "#     income_gap = 0.0\n",
    "    \n",
    "#     assignment_total = table.groupby(['driver_index','geolocation_lat','geolocation_lng'])['income'].sum() # <=> fair_assignment_totaldays.groupby('driver_index')['income'].sum().values\n",
    "#     assignment_total = pd.DataFrame({'income_sum':assignment_total}).reset_index()\n",
    "#     # assignment_total contains income of each driver\n",
    "    \n",
    "#     income_array = []\n",
    "#     for i in range(len(driver_loc)):\n",
    "#         income_array.append(assignment_total.loc[i].at['income_sum'])\n",
    "#     income_array = np.array(income_array)\n",
    "\n",
    "#     transposed = np.expand_dims(driver_loc, axis = 1)\n",
    "#     distance_drivers = np.power(driver_loc - transposed, 2)\n",
    "#     distance_drivers = np.power(np.abs(distance_drivers).sum(axis = 2), 0.5) \n",
    "#     distance_drivers = distance_drivers * 110\n",
    "\n",
    "#     transposed = np.expand_dims(income_array, axis = 1)\n",
    "#     income_diff = np.abs(income_array - transposed)\n",
    "#     # income_diff will be a [num_drivers x num_drivers] symmetric matrix with cell[i,j] telling the difference between driver_i and driver_j\n",
    "    \n",
    "\n",
    "#     configParser.read(configFilePath)\n",
    "#     # fair_distance=int(configParser.get('fairness-constraint','fair_distance'))\n",
    "#     fair_distance = float(configParser.get('fairness-constraint','fair_distance'))\n",
    "#     # fair_distance = 1e9 # uncomment this for getting global income gap #cwp\n",
    "    \n",
    "#     num_pair_fair_drivers=1e-7\n",
    "#     for i in range(len(driver_loc)-1):\n",
    "#         for j in range(i+1,len(driver_loc)):\n",
    "#             if(distance_drivers[i][j] <= fair_distance):\n",
    "#                 income_gap += (float(income_diff[i][j])/distance_drivers[i][j])\n",
    "#                 num_pair_fair_drivers = num_pair_fair_drivers+1\n",
    "# #     num_pair_fair_drivers=1e-7\n",
    "# #     for i in range(len(driver_loc)-1):\n",
    "# #         for j in range(i+1,len(driver_loc)):\n",
    "# #             income_gap += (float(income_diff[i][j])/distance_drivers[i][j])\n",
    "# #             num_pair_fair_drivers = num_pair_fair_drivers+1\n",
    "    \n",
    "#     net_income_gap_within_fair_distance = round(income_gap/num_pair_fair_drivers,2)\n",
    "    \n",
    "#     return net_income_gap_within_fair_distance,income_diff,distance_drivers,assignment_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the \"income gap per pair of those drivers which are separated by less than fair_distance\"\n",
    "\n",
    "## Note: The spurious multiplication by 110 to distances (and hence fair_distance for consistency) is done to ensure that the results are in scale.\n",
    "## This multiplication is ONLY to be done in helper_func\n",
    "\n",
    "def helper_func(table, driver_loc, ratings):\n",
    "    ''' \"table\" is \"fair_assignment_totaldays\" form inequality2(...) '''\n",
    "    income_gap = 0.0\n",
    "    \n",
    "    assignment_total = table.groupby(['driver_index','geolocation_lat','geolocation_lng'])['income'].sum() # <=> fair_assignment_totaldays.groupby('driver_index')['income'].sum().values\n",
    "    assignment_total = pd.DataFrame({'income_sum':assignment_total}).reset_index()\n",
    "    # assignment_total contains income of each driver\n",
    "    \n",
    "    # configParser.read(configFilePath)\n",
    "    # fair_distance=int(configParser.get('fairness-constraint','fair_distance'))\n",
    "    fair_distance = float(configParser.get('fairness-constraint','fair_distance'))\n",
    "    # fair_distance = 1e9 # uncomment this for getting global income gap #cwp\n",
    "\n",
    "    income_array = []\n",
    "    for i in range(len(driver_loc)):\n",
    "        income_array.append(assignment_total.loc[i].at['income_sum'])\n",
    "    income_array = np.array(income_array)\n",
    "\n",
    "    if flag==0:\n",
    "        transposed = np.expand_dims(driver_loc, axis = 1)\n",
    "        distance_drivers = np.power(driver_loc - transposed, 2)\n",
    "        distance_drivers = np.power(np.abs(distance_drivers).sum(axis = 2), 0.5) \n",
    "\n",
    "    transposed = np.expand_dims(income_array, axis = 1)\n",
    "    income_diff = np.abs(income_array - transposed)\n",
    "    # income_diff will be a [num_drivers x num_drivers] symmetric matrix with cell[i,j] telling the difference between driver_i and driver_j\n",
    "    \n",
    "    ###########################\n",
    "    if flag==1: \n",
    "        transposed = np.expand_dims(ratings, axis=1)\n",
    "        ratings_diff = abs(ratings-transposed)\n",
    "        distance_drivers = ratings_diff\n",
    "    ###########################\n",
    "\n",
    "    if flag==2:\n",
    "        transposed1 = np.expand_dims(driver_loc, axis = 1)\n",
    "        dists_diff = np.power(driver_loc - transposed1, 2)\n",
    "        dists_diff = np.power(np.abs(dists_diff).sum(axis = 2), 0.5)\n",
    "\n",
    "        transposed2 = np.expand_dims(ratings, axis=1)\n",
    "        ratings_diff = abs(ratings-transposed2)\n",
    "\n",
    "        combination = w1*dists_diff + w2*ratings_diff\n",
    "        distance_drivers = combination\n",
    "\n",
    "    # @ set:\n",
    "    distance_drivers *= 110 \n",
    "    fair_distance *= 110\n",
    "    \n",
    "    num_pair_fair_drivers=1e-7\n",
    "    for i in range(len(driver_loc)-1):\n",
    "        for j in range(i+1,len(driver_loc)):\n",
    "            if(distance_drivers[i][j] <= fair_distance and distance_drivers[i][j]>0): \n",
    "                income_gap += (float(income_diff[i][j])/distance_drivers[i][j])\n",
    "                num_pair_fair_drivers = num_pair_fair_drivers+1\n",
    "#     num_pair_fair_drivers=1e-7\n",
    "#     for i in range(len(driver_loc)-1):\n",
    "#         for j in range(i+1,len(driver_loc)):\n",
    "#             income_gap += (float(income_diff[i][j])/distance_drivers[i][j])\n",
    "#             num_pair_fair_drivers = num_pair_fair_drivers+1\n",
    "    \n",
    "    # @ reset: \n",
    "    distance_drivers /= 110\n",
    "    \n",
    "    net_income_gap_within_fair_distance = round(income_gap/num_pair_fair_drivers,2)\n",
    "    \n",
    "    return net_income_gap_within_fair_distance,income_diff,distance_drivers,assignment_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Returns spatial inequality.\n",
    "# def spatial_inequality(income_diff, distance_drivers, table, driver_loc, ratings):\n",
    "#     sum_i = 0.0\n",
    "#     total_sum = 0.0\n",
    "    \n",
    "#     configParser.read(configFilePath)\n",
    "\n",
    "#     # fair_distance = int(configParser.get('fairness-constraint','fair_distance')) \n",
    "#     fair_distance = float(configParser.get('fairness-constraint','fair_distance'))\n",
    "\n",
    "#     for i in range(len(driver_loc)):\n",
    "#         sum_i = sum_i + table.loc[i].at[\"income_sum\"]\n",
    "#         sum_i_j = 0.0\n",
    "#         num_i_j = 1e-7\n",
    "        \n",
    "#         # only consider the drivers j's which are located at a certain distance (here, fair distance) from the concerened driver_i\n",
    "#         for j in range(i+1,len(driver_loc)):\n",
    "#             dist = distance_drivers[i][j]  # this 'distance_drivers' comes into spatial_inequality from helper_func\n",
    "#             if (dist < fair_distance):\n",
    "#                 sum_i_j = sum_i_j + income_diff[i][j]\n",
    "#                 num_i_j = num_i_j + 1\n",
    "                \n",
    "#         total_sum = total_sum + float(sum_i_j)/num_i_j\n",
    "    \n",
    "#     sp_index = float(total_sum)/sum_i\n",
    "    \n",
    "#     return round(sp_index,4)\n",
    "\n",
    "\n",
    "# def fraction(base,fair):\n",
    "#     ''' \n",
    "#     improvement in income = ((fair_income - base_income)/base_income)\n",
    "#     '''   \n",
    "#     fair_income_array = fair[\"income_sum\"].values\n",
    "#     base_income_array = base[\"income_sum\"].values\n",
    " \n",
    "#     return np.around((np.divide(fair_income_array,(base_income_array+1e-5))-1)*100,2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns spatial inequality.\n",
    "def spatial_inequality(income_diff, distance_drivers, table, driver_loc, ratings):\n",
    "    sum_i = 0.0\n",
    "    total_sum = 0.0\n",
    "    \n",
    "    # configParser.read(configFilePath)\n",
    "\n",
    "    # fair_distance = int(configParser.get('fairness-constraint','fair_distance')) \n",
    "    fair_distance = float(configParser.get('fairness-constraint','fair_distance'))\n",
    "\n",
    "    distance_drivers = distance_drivers \n",
    "\n",
    "    if flag==1:\n",
    "        ###########################\n",
    "        transposed = np.expand_dims(ratings, axis=1)\n",
    "        ratings_diff = abs(ratings-transposed)\n",
    "        distance_drivers = ratings_diff\n",
    "        ###########################\n",
    "    if flag==2:\n",
    "        transposed2 = np.expand_dims(ratings, axis=1)\n",
    "        ratings_diff = abs(ratings-transposed2)\n",
    "\n",
    "        combined = w1*distance_drivers + w2*ratings_diff\n",
    "        distance_drivers = combined\n",
    "\n",
    "\n",
    "    for i in range(len(driver_loc)):\n",
    "        sum_i = sum_i + table.loc[i].at[\"income_sum\"]\n",
    "        sum_i_j = 0.0\n",
    "        num_i_j = 1e-7\n",
    "        \n",
    "        # only consider the drivers j's which are located at a certain distance (here, fair distance) from the concerened driver_i\n",
    "        for j in range(i+1,len(driver_loc)):\n",
    "            dist = distance_drivers[i][j]  # this 'distance_drivers' comes into spatial_inequality from helper_func\n",
    "            if (dist < fair_distance): \n",
    "                sum_i_j = sum_i_j + income_diff[i][j]\n",
    "                num_i_j = num_i_j + 1\n",
    "                \n",
    "        total_sum = total_sum + float(sum_i_j)/num_i_j\n",
    "    \n",
    "    sp_index = float(total_sum)/sum_i\n",
    "    \n",
    "    return round(sp_index,4)\n",
    "\n",
    "\n",
    "def fraction(base,fair):\n",
    "    ''' \n",
    "    improvement in income = ((fair_income - base_income)/base_income)\n",
    "    '''   \n",
    "    fair_income_array = fair[\"income_sum\"].values\n",
    "    base_income_array = base[\"income_sum\"].values\n",
    " \n",
    "    return np.around((np.divide(fair_income_array,(base_income_array+1e-5))-1)*100,2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_constraints: 363084\n",
      "Version identifier: 22.1.0.0 | 2022-03-09 | 1a383f8ce\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "CPXPARAM_Simplex_Tolerances_Markowitz            0.90000000000000002\n",
      "CPXPARAM_Simplex_Tolerances_Optimality           1.0000000000000001e-09\n",
      "CPXPARAM_Simplex_Tolerances_Feasibility          1.0000000000000001e-09\n",
      "Parallel mode: deterministic, using up to 4 threads for concurrent optimization:\n",
      " * Starting dual Simplex on 1 thread...\n",
      " * Starting Barrier on 3 threads...\n",
      "Tried aggregator 1 time.\n",
      "LP Presolve eliminated 0 rows and 601510 columns.\n",
      "Reduced LP has 363084 rows, 176640 columns, and 1220720 nonzeros.\n",
      "Presolve time = 6.16 sec. (515.73 ticks)\n",
      "\n",
      "Iteration log . . .\n",
      "Iteration:     1   Dual objective     =             2.257272\n",
      "Iteration:    45   Dual objective     =             2.286455\n",
      "Initializing dual steep norms . . .\n",
      "Iteration:    46   Dual objective     =             2.287461\n",
      "Iteration:  2628   Dual objective     =             2.792788\n",
      "Iteration:  3844   Dual objective     =             3.059196\n",
      "Iteration:  6097   Dual objective     =             3.135895\n"
     ]
    }
   ],
   "source": [
    "# new_drivers = driver_generation(3249+1)\n",
    "new_drivers = driver_locs\n",
    "ratings_list = generate_ratings(new_drivers.shape[0])\n",
    "result = fair_clustering(new_drivers,centre,ratings_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.        0.        0.4704953 0.        0.25      0.2795047 0.\n",
      " 0.        0.        0.       ]\n"
     ]
    }
   ],
   "source": [
    "# result['assignment']\n",
    "num_samples = len(new_drivers)\n",
    "num_centres = len(centre)\n",
    "    \n",
    "# Probability Distribution output from cplex\n",
    "lpp_prob_dis = np.reshape(result['assignment'][:num_samples*num_centres],(-1,num_centres))\n",
    "# print(np.argmax(lpp_prob_dis[0]))\n",
    "print(lpp_prob_dis[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result['assignment'] contains the values of the variables of the linear optimization problem \n",
    "\n",
    "values upto result['assignment'][:num_samples*num_centres] correspond to the values of the variables P_i_k1, P_i_k2,...,P_i+1_k1, P_i+1_k2,... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naively sampling : taking argmax (this is also an independent sampling)\n",
    "ffc_assignments = [np.argmax(lpp_prob_dis[i]) for i in range(num_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ffc_index</th>\n",
       "      <th>cap</th>\n",
       "      <th>min_cap</th>\n",
       "      <th>max_cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>86.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>87.0</td>\n",
       "      <td>43.5</td>\n",
       "      <td>130.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ffc_index   cap  min_cap  max_cap\n",
       "0          0  13.0      6.5     19.5\n",
       "1          1  86.0     43.0    129.0\n",
       "2          2  11.0      5.5     16.5\n",
       "3          3  40.0     20.0     60.0\n",
       "4          4   5.0      2.5      7.5\n",
       "5          5   7.0      3.5     10.5\n",
       "6          6  87.0     43.5    130.5\n",
       "7          7  10.0      5.0     15.0\n",
       "8          8   4.0      2.0      6.0\n",
       "9          9  17.0      8.5     25.5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_customer_group_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 2, 6, 2, 2, 5]\n"
     ]
    }
   ],
   "source": [
    "print(ffc_assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 6, 1, 3, 6, 6, 1, 6, 6, 9, 6, 1, 6, 6, 6, 3, 6, 1, 1, 3, 6, 1,\n",
       "       6, 6, 6, 6, 3, 6, 6, 8, 6, 6, 6, 1, 0, 1, 3, 6, 6, 1, 6, 6, 3, 1,\n",
       "       1, 6, 6, 6, 9, 6, 6, 1, 6, 1, 3, 6, 6, 6, 7, 6, 1, 3, 6, 1, 6, 6,\n",
       "       6, 9, 1, 6, 6, 6, 1, 9, 6, 3, 6, 6, 6, 6, 1, 1, 6, 7, 6, 3, 0, 6,\n",
       "       6, 1, 6, 5, 1, 2, 2, 4])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "df = fair_assignment(lpp_prob_dis,new_drivers)[0] \n",
    "# df[df['ffc_index']==5].shape\n",
    "df['ffc_index'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dp_results = []\n",
    "for i in range(100):\n",
    "    df = fair_assignment(lpp_prob_dis, new_drivers)[0]\n",
    "    dp_results.append(df['ffc_index'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 6 6 6 6 3 6 1 1 6 6 6 6 1 6 6 6 3 6 1 1 6 3 6 6 6 1 6 6 3 6 6 6 6 6 1 6 6 7 6 6 6 6 6 6 6 1 6 6 6 6 6 6 1 6 6 1 7 1 6 3 6 6 6 6 6 6 6 6 9 9 6 1 6 6 6 6 6 6 6 6 6 6 1 6 6 7 6 6 1 3 1 6 6 6 6 1 6 6 6 "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(dp_results[i][9],end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Drivers: 143\n",
      "num_constraints: 43045\n",
      "Version identifier: 22.1.0.0 | 2022-03-09 | 1a383f8ce\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "CPXPARAM_Simplex_Tolerances_Markowitz            0.90000000000000002\n",
      "CPXPARAM_Simplex_Tolerances_Optimality           1.0000000000000001e-09\n",
      "CPXPARAM_Simplex_Tolerances_Feasibility          1.0000000000000001e-09\n",
      "Parallel mode: deterministic, using up to 4 threads for concurrent optimization:\n",
      " * Starting dual Simplex on 1 thread...\n",
      " * Starting Barrier on 3 threads...\n",
      "Tried aggregator 1 time.\n",
      "LP Presolve eliminated 0 rows and 81110 columns.\n",
      "Reduced LP has 43045 rows, 21850 columns, and 147230 nonzeros.\n",
      "Presolve time = 0.57 sec. (63.38 ticks)\n",
      "Initializing dual steep norms . . .\n",
      "\n",
      "Iteration log . . .\n",
      "Iteration:     1   Dual objective     =             0.671565\n",
      "Iteration:   281   Dual objective     =             1.343549\n",
      "Iteration:   848   Dual objective     =             1.749470\n",
      "Iteration:  1382   Dual objective     =             1.979993\n",
      "Iteration:  1633   Dual objective     =             2.117621\n",
      "Iteration:  1937   Dual objective     =             2.205016\n",
      "Iteration:  2267   Dual objective     =             2.259057\n",
      "Iteration:  2502   Dual objective     =             2.279847\n",
      "Iteration:  2745   Dual objective     =             2.306067\n",
      "Iteration:  2977   Dual objective     =             2.330338\n",
      "Iteration:  3222   Dual objective     =             2.349064\n",
      "Iteration:  3466   Dual objective     =             2.361897\n",
      "Iteration:  3733   Dual objective     =             2.378905\n",
      "Iteration:  3978   Dual objective     =             2.390481\n",
      "Iteration:  4201   Dual objective     =             2.400930\n",
      "Iteration:  4423   Dual objective     =             2.407210\n",
      "Iteration:  4683   Dual objective     =             2.418752\n",
      "Iteration:  4964   Dual objective     =             2.425590\n",
      "Iteration:  5198   Dual objective     =             2.431614\n",
      "Iteration:  5411   Dual objective     =             2.443269\n",
      "\n",
      "Barrier solved model.\n",
      "\n",
      "Solution Quality: [0.694388129660147, 0.0]\n",
      "Status: optimal\n",
      "Everything solved, graphs start\n",
      "max_flow_min_cost cost value: 8183\n",
      "maximum_flow flow value: 143\n",
      "Minimum cost: 8183\n",
      "\n",
      "  Arc    Flow / Capacity  Cost\n",
      "1 -> 2     1  /   1         0\n",
      "1 -> 3     1  /   1         0\n",
      "1 -> 4     1  /   1         0\n",
      "1 -> 5     1  /   1         0\n",
      "1 -> 6     1  /   1         0\n",
      "1 -> 7     1  /   1         0\n",
      "1 -> 8     1  /   1         0\n",
      "1 -> 9     1  /   1         0\n",
      "1 -> 10     1  /   1         0\n",
      "1 -> 11     1  /   1         0\n",
      "1 -> 12     1  /   1         0\n",
      "1 -> 13     1  /   1         0\n",
      "1 -> 14     1  /   1         0\n",
      "1 -> 15     1  /   1         0\n",
      "1 -> 16     1  /   1         0\n",
      "1 -> 17     1  /   1         0\n",
      "1 -> 18     1  /   1         0\n",
      "1 -> 19     1  /   1         0\n",
      "1 -> 20     1  /   1         0\n",
      "1 -> 21     1  /   1         0\n",
      "1 -> 22     1  /   1         0\n",
      "1 -> 23     1  /   1         0\n",
      "1 -> 24     1  /   1         0\n",
      "1 -> 25     1  /   1         0\n",
      "1 -> 26     1  /   1         0\n",
      "1 -> 27     1  /   1         0\n",
      "1 -> 28     1  /   1         0\n",
      "1 -> 29     1  /   1         0\n",
      "1 -> 30     1  /   1         0\n",
      "1 -> 31     1  /   1         0\n",
      "1 -> 32     1  /   1         0\n",
      "1 -> 33     1  /   1         0\n",
      "1 -> 34     1  /   1         0\n",
      "1 -> 35     1  /   1         0\n",
      "1 -> 36     1  /   1         0\n",
      "1 -> 37     1  /   1         0\n",
      "1 -> 38     1  /   1         0\n",
      "1 -> 39     1  /   1         0\n",
      "1 -> 40     1  /   1         0\n",
      "1 -> 41     1  /   1         0\n",
      "1 -> 42     1  /   1         0\n",
      "1 -> 43     1  /   1         0\n",
      "1 -> 44     1  /   1         0\n",
      "1 -> 45     1  /   1         0\n",
      "1 -> 46     1  /   1         0\n",
      "1 -> 47     1  /   1         0\n",
      "1 -> 48     1  /   1         0\n",
      "1 -> 49     1  /   1         0\n",
      "1 -> 50     1  /   1         0\n",
      "1 -> 51     1  /   1         0\n",
      "1 -> 52     1  /   1         0\n",
      "1 -> 53     1  /   1         0\n",
      "1 -> 54     1  /   1         0\n",
      "1 -> 55     1  /   1         0\n",
      "1 -> 56     1  /   1         0\n",
      "1 -> 57     1  /   1         0\n",
      "1 -> 58     1  /   1         0\n",
      "1 -> 59     1  /   1         0\n",
      "1 -> 60     1  /   1         0\n",
      "1 -> 61     1  /   1         0\n",
      "1 -> 62     1  /   1         0\n",
      "1 -> 63     1  /   1         0\n",
      "1 -> 64     1  /   1         0\n",
      "1 -> 65     1  /   1         0\n",
      "1 -> 66     1  /   1         0\n",
      "1 -> 67     1  /   1         0\n",
      "1 -> 68     1  /   1         0\n",
      "1 -> 69     1  /   1         0\n",
      "1 -> 70     1  /   1         0\n",
      "1 -> 71     1  /   1         0\n",
      "1 -> 72     1  /   1         0\n",
      "1 -> 73     1  /   1         0\n",
      "1 -> 74     1  /   1         0\n",
      "1 -> 75     1  /   1         0\n",
      "1 -> 76     1  /   1         0\n",
      "1 -> 77     1  /   1         0\n",
      "1 -> 78     1  /   1         0\n",
      "1 -> 79     1  /   1         0\n",
      "1 -> 80     1  /   1         0\n",
      "1 -> 81     1  /   1         0\n",
      "1 -> 82     1  /   1         0\n",
      "1 -> 83     1  /   1         0\n",
      "1 -> 84     1  /   1         0\n",
      "1 -> 85     1  /   1         0\n",
      "1 -> 86     1  /   1         0\n",
      "1 -> 87     1  /   1         0\n",
      "1 -> 88     1  /   1         0\n",
      "1 -> 89     1  /   1         0\n",
      "1 -> 90     1  /   1         0\n",
      "1 -> 91     1  /   1         0\n",
      "1 -> 92     1  /   1         0\n",
      "1 -> 93     1  /   1         0\n",
      "1 -> 94     1  /   1         0\n",
      "1 -> 95     1  /   1         0\n",
      "1 -> 96     1  /   1         0\n",
      "1 -> 97     1  /   1         0\n",
      "1 -> 98     1  /   1         0\n",
      "1 -> 99     1  /   1         0\n",
      "1 -> 100     1  /   1         0\n",
      "1 -> 101     1  /   1         0\n",
      "1 -> 102     1  /   1         0\n",
      "1 -> 103     1  /   1         0\n",
      "1 -> 104     1  /   1         0\n",
      "1 -> 105     1  /   1         0\n",
      "1 -> 106     1  /   1         0\n",
      "1 -> 107     1  /   1         0\n",
      "1 -> 108     1  /   1         0\n",
      "1 -> 109     1  /   1         0\n",
      "1 -> 110     1  /   1         0\n",
      "1 -> 111     1  /   1         0\n",
      "1 -> 112     1  /   1         0\n",
      "1 -> 113     1  /   1         0\n",
      "1 -> 114     1  /   1         0\n",
      "1 -> 115     1  /   1         0\n",
      "1 -> 116     1  /   1         0\n",
      "1 -> 117     1  /   1         0\n",
      "1 -> 118     1  /   1         0\n",
      "1 -> 119     1  /   1         0\n",
      "1 -> 120     1  /   1         0\n",
      "1 -> 121     1  /   1         0\n",
      "1 -> 122     1  /   1         0\n",
      "1 -> 123     1  /   1         0\n",
      "1 -> 124     1  /   1         0\n",
      "1 -> 125     1  /   1         0\n",
      "1 -> 126     1  /   1         0\n",
      "1 -> 127     1  /   1         0\n",
      "1 -> 128     1  /   1         0\n",
      "1 -> 129     1  /   1         0\n",
      "1 -> 130     1  /   1         0\n",
      "1 -> 131     1  /   1         0\n",
      "1 -> 132     1  /   1         0\n",
      "1 -> 133     1  /   1         0\n",
      "1 -> 134     1  /   1         0\n",
      "1 -> 135     1  /   1         0\n",
      "1 -> 136     1  /   1         0\n",
      "1 -> 137     1  /   1         0\n",
      "1 -> 138     1  /   1         0\n",
      "1 -> 139     1  /   1         0\n",
      "1 -> 140     1  /   1         0\n",
      "1 -> 141     1  /   1         0\n",
      "1 -> 142     1  /   1         0\n",
      "1 -> 143     1  /   1         0\n",
      "1 -> 144     1  /   1         0\n",
      "2 -> 145     1  /   1       303\n",
      "3 -> 145     1  /   1       152\n",
      "4 -> 148     1  /   1        88\n",
      "5 -> 151     1  /   1        67\n",
      "6 -> 151     1  /   1        11\n",
      "7 -> 146     1  /   1         0\n",
      "8 -> 148     1  /   1        32\n",
      "9 -> 151     1  /   1        14\n",
      "10 -> 151     1  /   1        44\n",
      "11 -> 151     1  /   1        59\n",
      "12 -> 151     1  /   1        25\n",
      "13 -> 146     1  /   1        68\n",
      "14 -> 148     1  /   1        89\n",
      "15 -> 151     1  /   1        11\n",
      "16 -> 151     1  /   1        70\n",
      "17 -> 146     1  /   1        56\n",
      "18 -> 146     1  /   1        64\n",
      "19 -> 148     1  /   1        10\n",
      "20 -> 151     1  /   1        85\n",
      "21 -> 151     1  /   1        76\n",
      "22 -> 146     1  /   1         5\n",
      "23 -> 151     1  /   1       101\n",
      "24 -> 151     1  /   1         3\n",
      "25 -> 151     1  /   1        72\n",
      "26 -> 151     1  /   1        76\n",
      "27 -> 151     1  /   1        38\n",
      "28 -> 151     1  /   1        29\n",
      "29 -> 148     1  /   1        90\n",
      "30 -> 151     1  /   1        21\n",
      "31 -> 151     1  /   1        44\n",
      "32 -> 148     1  /   1        31\n",
      "33 -> 151     1  /   1        13\n",
      "34 -> 151     1  /   1        18\n",
      "35 -> 151     1  /   1        89\n",
      "36 -> 146     1  /   1        29\n",
      "37 -> 148     1  /   1       140\n",
      "38 -> 146     1  /   1        26\n",
      "39 -> 151     1  /   1       113\n",
      "40 -> 151     1  /   1        70\n",
      "41 -> 151     1  /   1        56\n",
      "42 -> 151     1  /   1        44\n",
      "43 -> 148     1  /   1        13\n",
      "44 -> 151     1  /   1       102\n",
      "45 -> 148     1  /   1        17\n",
      "46 -> 151     1  /   1        49\n",
      "47 -> 151     1  /   1        77\n",
      "48 -> 151     1  /   1       117\n",
      "49 -> 146     1  /   1        13\n",
      "50 -> 148     1  /   1        11\n",
      "51 -> 146     1  /   1        32\n",
      "52 -> 148     1  /   1        48\n",
      "53 -> 146     1  /   1       106\n",
      "54 -> 146     1  /   1        15\n",
      "55 -> 151     1  /   1         6\n",
      "56 -> 148     1  /   1        34\n",
      "57 -> 151     1  /   1        15\n",
      "58 -> 151     1  /   1        92\n",
      "59 -> 146     1  /   1        10\n",
      "60 -> 146     1  /   1         7\n",
      "61 -> 151     1  /   1        31\n",
      "62 -> 146     1  /   1        21\n",
      "63 -> 146     1  /   1        86\n",
      "64 -> 151     1  /   1        48\n",
      "65 -> 151     1  /   1        38\n",
      "66 -> 151     1  /   1        30\n",
      "67 -> 151     1  /   1        22\n",
      "68 -> 146     1  /   1        72\n",
      "69 -> 146     1  /   1       259\n",
      "70 -> 146     1  /   1       183\n",
      "71 -> 146     1  /   1        43\n",
      "72 -> 146     1  /   1        17\n",
      "73 -> 146     1  /   1       300\n",
      "74 -> 145     1  /   1        50\n",
      "75 -> 148     1  /   1        24\n",
      "76 -> 151     1  /   1        43\n",
      "77 -> 148     1  /   1         7\n",
      "78 -> 148     1  /   1         6\n",
      "79 -> 148     1  /   1         1\n",
      "80 -> 151     1  /   1        21\n",
      "81 -> 154     1  /   1        19\n",
      "82 -> 148     1  /   1         3\n",
      "83 -> 151     1  /   1         3\n",
      "84 -> 151     1  /   1         2\n",
      "85 -> 151     1  /   1        22\n",
      "86 -> 148     1  /   1         5\n",
      "87 -> 148     1  /   1        58\n",
      "88 -> 154     1  /   1        58\n",
      "89 -> 151     1  /   1        58\n",
      "90 -> 154     1  /   1        19\n",
      "91 -> 154     1  /   1        44\n",
      "92 -> 148     1  /   1        61\n",
      "93 -> 154     1  /   1        22\n",
      "94 -> 154     1  /   1        21\n",
      "95 -> 151     1  /   1        11\n",
      "96 -> 151     1  /   1        45\n",
      "97 -> 148     1  /   1        60\n",
      "98 -> 151     1  /   1         3\n",
      "99 -> 148     1  /   1         8\n",
      "100 -> 146     1  /   1        54\n",
      "101 -> 151     1  /   1        17\n",
      "102 -> 151     1  /   1        51\n",
      "103 -> 148     1  /   1        37\n",
      "104 -> 151     1  /   1         1\n",
      "105 -> 148     1  /   1        45\n",
      "106 -> 151     1  /   1         4\n",
      "107 -> 148     1  /   1        10\n",
      "108 -> 148     1  /   1         4\n",
      "109 -> 148     1  /   1        12\n",
      "110 -> 148     1  /   1        61\n",
      "111 -> 151     1  /   1        45\n",
      "112 -> 148     1  /   1        54\n",
      "113 -> 151     1  /   1        54\n",
      "114 -> 154     1  /   1        41\n",
      "115 -> 151     1  /   1        50\n",
      "116 -> 151     1  /   1        56\n",
      "117 -> 151     1  /   1         0\n",
      "118 -> 151     1  /   1         6\n",
      "119 -> 146     1  /   1       163\n",
      "120 -> 146     1  /   1        78\n",
      "121 -> 152     1  /   1       238\n",
      "122 -> 146     1  /   1       135\n",
      "123 -> 146     1  /   1        41\n",
      "124 -> 146     1  /   1        28\n",
      "125 -> 154     1  /   1        18\n",
      "126 -> 154     1  /   1       177\n",
      "127 -> 152     1  /   1       196\n",
      "128 -> 152     1  /   1         9\n",
      "129 -> 147     1  /   1        41\n",
      "130 -> 145     1  /   1        99\n",
      "131 -> 145     1  /   1       155\n",
      "132 -> 145     1  /   1       100\n",
      "133 -> 145     1  /   1       104\n",
      "134 -> 154     1  /   1       319\n",
      "135 -> 148     1  /   1        76\n",
      "136 -> 153     1  /   1        99\n",
      "137 -> 154     1  /   1        84\n",
      "138 -> 154     1  /   1       111\n",
      "139 -> 147     1  /   1        26\n",
      "140 -> 147     1  /   1         6\n",
      "141 -> 147     1  /   1         5\n",
      "142 -> 147     1  /   1        11\n",
      "143 -> 150     1  /   1         7\n",
      "144 -> 149     1  /   1       235\n",
      "145 -> 155     4  /   6         0\n",
      "146 -> 155     6  /  43         0\n",
      "147 -> 155     3  /   6         0\n",
      "148 -> 155    20  /  20         0\n",
      "151 -> 155    35  /  44         0\n",
      "152 -> 155     1  /   5         0\n",
      "154 -> 155     8  /   8         0\n",
      "[ Raw Info all runs for each dist_type ] :\n",
      "     Dist Type   Gini  Avg Dist  Income_Gap  spatial_index\n",
      "0      Random  0.112      0.76        0.40         0.1601\n",
      "1        LIPA  0.079      0.45        0.26         0.1438\n",
      "2  RoundRobin  0.104      0.76        0.38         0.1438\n",
      "3        MCCA  0.220      0.21        0.69         0.3971\n",
      "4      MCCA-L  0.220      0.21        0.69         0.3971\n",
      "5  FairAssign  0.098      0.40        0.27         0.1595\n",
      "[ Mean for each Dist Type ] :\n",
      "              Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                             \n",
      "FairAssign  0.098      0.40        0.27         0.1595\n",
      "LIPA        0.079      0.45        0.26         0.1438\n",
      "MCCA        0.220      0.21        0.69         0.3971\n",
      "MCCA-L      0.220      0.21        0.69         0.3971\n",
      "Random      0.112      0.76        0.40         0.1601\n",
      "RoundRobin  0.104      0.76        0.38         0.1438\n",
      "\n",
      "[ Max for each Dist Type ] :\n",
      "              Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                             \n",
      "FairAssign  0.098      0.40        0.27         0.1595\n",
      "LIPA        0.079      0.45        0.26         0.1438\n",
      "MCCA        0.220      0.21        0.69         0.3971\n",
      "MCCA-L      0.220      0.21        0.69         0.3971\n",
      "Random      0.112      0.76        0.40         0.1601\n",
      "RoundRobin  0.104      0.76        0.38         0.1438\n",
      "\n",
      "[ Min for each Dist Type ] :\n",
      "              Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                             \n",
      "FairAssign  0.098      0.40        0.27         0.1595\n",
      "LIPA        0.079      0.45        0.26         0.1438\n",
      "MCCA        0.220      0.21        0.69         0.3971\n",
      "MCCA-L      0.220      0.21        0.69         0.3971\n",
      "Random      0.112      0.76        0.40         0.1601\n",
      "RoundRobin  0.104      0.76        0.38         0.1438\n",
      "\n",
      "Number of Drivers: 120\n",
      "num_constraints: 31346\n",
      "Version identifier: 22.1.0.0 | 2022-03-09 | 1a383f8ce\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "CPXPARAM_Simplex_Tolerances_Markowitz            0.90000000000000002\n",
      "CPXPARAM_Simplex_Tolerances_Optimality           1.0000000000000001e-09\n",
      "CPXPARAM_Simplex_Tolerances_Feasibility          1.0000000000000001e-09\n",
      "Parallel mode: deterministic, using up to 4 threads for concurrent optimization:\n",
      " * Starting dual Simplex on 1 thread...\n",
      " * Starting Barrier on 3 threads...\n",
      "Tried aggregator 1 time.\n",
      "LP Presolve eliminated 0 rows and 56540 columns.\n",
      "Reduced LP has 31346 rows, 16060 columns, and 107620 nonzeros.\n",
      "Presolve time = 0.27 sec. (45.68 ticks)\n",
      "Initializing dual steep norms . . .\n",
      "\n",
      "Iteration log . . .\n",
      "Iteration:     1   Dual objective     =             0.513210\n",
      "Iteration:   363   Dual objective     =             1.113875\n",
      "Iteration:   854   Dual objective     =             1.220006\n",
      "Iteration:  1267   Dual objective     =             1.278137\n",
      "Iteration:  1459   Dual objective     =             1.330615\n",
      "Iteration:  1684   Dual objective     =             1.412498\n",
      "Iteration:  1911   Dual objective     =             1.507367\n",
      "Iteration:  2122   Dual objective     =             1.613047\n",
      "Iteration:  2343   Dual objective     =             1.649095\n",
      "Iteration:  2565   Dual objective     =             1.655551\n",
      "Iteration:  2760   Dual objective     =             1.670406\n",
      "Iteration:  2972   Dual objective     =             1.681766\n",
      "Iteration:  3172   Dual objective     =             1.688968\n",
      "Iteration:  3379   Dual objective     =             1.696511\n",
      "Iteration:  3594   Dual objective     =             1.702397\n",
      "Iteration:  3787   Dual objective     =             1.713599\n",
      "Iteration:  3992   Dual objective     =             1.726251\n",
      "Iteration:  4178   Dual objective     =             1.736278\n",
      "\n",
      "Barrier solved model.\n",
      "\n",
      "Solution Quality: [1.0, 0.0]\n",
      "Status: optimal\n",
      "Everything solved, graphs start\n",
      "max_flow_min_cost cost value: 6489\n",
      "maximum_flow flow value: 120\n",
      "Minimum cost: 6818\n",
      "\n",
      "  Arc    Flow / Capacity  Cost\n",
      "1 -> 2     1  /   1         0\n",
      "1 -> 3     1  /   1         0\n",
      "1 -> 4     1  /   1         0\n",
      "1 -> 5     1  /   1         0\n",
      "1 -> 6     1  /   1         0\n",
      "1 -> 7     1  /   1         0\n",
      "1 -> 8     1  /   1         0\n",
      "1 -> 9     1  /   1         0\n",
      "1 -> 10     1  /   1         0\n",
      "1 -> 11     1  /   1         0\n",
      "1 -> 12     1  /   1         0\n",
      "1 -> 13     1  /   1         0\n",
      "1 -> 14     1  /   1         0\n",
      "1 -> 15     1  /   1         0\n",
      "1 -> 16     1  /   1         0\n",
      "1 -> 17     1  /   1         0\n",
      "1 -> 18     1  /   1         0\n",
      "1 -> 19     1  /   1         0\n",
      "1 -> 20     1  /   1         0\n",
      "1 -> 21     1  /   1         0\n",
      "1 -> 22     1  /   1         0\n",
      "1 -> 23     1  /   1         0\n",
      "1 -> 24     1  /   1         0\n",
      "1 -> 25     1  /   1         0\n",
      "1 -> 26     1  /   1         0\n",
      "1 -> 27     1  /   1         0\n",
      "1 -> 28     1  /   1         0\n",
      "1 -> 29     1  /   1         0\n",
      "1 -> 30     1  /   1         0\n",
      "1 -> 31     1  /   1         0\n",
      "1 -> 32     1  /   1         0\n",
      "1 -> 33     1  /   1         0\n",
      "1 -> 34     1  /   1         0\n",
      "1 -> 35     1  /   1         0\n",
      "1 -> 36     1  /   1         0\n",
      "1 -> 37     1  /   1         0\n",
      "1 -> 38     1  /   1         0\n",
      "1 -> 39     1  /   1         0\n",
      "1 -> 40     1  /   1         0\n",
      "1 -> 41     1  /   1         0\n",
      "1 -> 42     1  /   1         0\n",
      "1 -> 43     1  /   1         0\n",
      "1 -> 44     1  /   1         0\n",
      "1 -> 45     1  /   1         0\n",
      "1 -> 46     1  /   1         0\n",
      "1 -> 47     1  /   1         0\n",
      "1 -> 48     1  /   1         0\n",
      "1 -> 49     1  /   1         0\n",
      "1 -> 50     1  /   1         0\n",
      "1 -> 51     1  /   1         0\n",
      "1 -> 52     1  /   1         0\n",
      "1 -> 53     1  /   1         0\n",
      "1 -> 54     1  /   1         0\n",
      "1 -> 55     1  /   1         0\n",
      "1 -> 56     1  /   1         0\n",
      "1 -> 57     1  /   1         0\n",
      "1 -> 58     1  /   1         0\n",
      "1 -> 59     1  /   1         0\n",
      "1 -> 60     1  /   1         0\n",
      "1 -> 61     1  /   1         0\n",
      "1 -> 62     1  /   1         0\n",
      "1 -> 63     1  /   1         0\n",
      "1 -> 64     1  /   1         0\n",
      "1 -> 65     1  /   1         0\n",
      "1 -> 66     1  /   1         0\n",
      "1 -> 67     1  /   1         0\n",
      "1 -> 68     1  /   1         0\n",
      "1 -> 69     1  /   1         0\n",
      "1 -> 70     1  /   1         0\n",
      "1 -> 71     1  /   1         0\n",
      "1 -> 72     1  /   1         0\n",
      "1 -> 73     1  /   1         0\n",
      "1 -> 74     1  /   1         0\n",
      "1 -> 75     1  /   1         0\n",
      "1 -> 76     1  /   1         0\n",
      "1 -> 77     1  /   1         0\n",
      "1 -> 78     1  /   1         0\n",
      "1 -> 79     1  /   1         0\n",
      "1 -> 80     1  /   1         0\n",
      "1 -> 81     1  /   1         0\n",
      "1 -> 82     1  /   1         0\n",
      "1 -> 83     1  /   1         0\n",
      "1 -> 84     1  /   1         0\n",
      "1 -> 85     1  /   1         0\n",
      "1 -> 86     1  /   1         0\n",
      "1 -> 87     1  /   1         0\n",
      "1 -> 88     1  /   1         0\n",
      "1 -> 89     1  /   1         0\n",
      "1 -> 90     1  /   1         0\n",
      "1 -> 91     1  /   1         0\n",
      "1 -> 92     1  /   1         0\n",
      "1 -> 93     1  /   1         0\n",
      "1 -> 94     1  /   1         0\n",
      "1 -> 95     1  /   1         0\n",
      "1 -> 96     1  /   1         0\n",
      "1 -> 97     1  /   1         0\n",
      "1 -> 98     1  /   1         0\n",
      "1 -> 99     1  /   1         0\n",
      "1 -> 100     1  /   1         0\n",
      "1 -> 101     1  /   1         0\n",
      "1 -> 102     1  /   1         0\n",
      "1 -> 103     1  /   1         0\n",
      "1 -> 104     1  /   1         0\n",
      "1 -> 105     1  /   1         0\n",
      "1 -> 106     1  /   1         0\n",
      "1 -> 107     1  /   1         0\n",
      "1 -> 108     1  /   1         0\n",
      "1 -> 109     1  /   1         0\n",
      "1 -> 110     1  /   1         0\n",
      "1 -> 111     1  /   1         0\n",
      "1 -> 112     1  /   1         0\n",
      "1 -> 113     1  /   1         0\n",
      "1 -> 114     1  /   1         0\n",
      "1 -> 115     1  /   1         0\n",
      "1 -> 116     1  /   1         0\n",
      "1 -> 117     1  /   1         0\n",
      "1 -> 118     1  /   1         0\n",
      "1 -> 119     1  /   1         0\n",
      "1 -> 120     1  /   1         0\n",
      "1 -> 121     1  /   1         0\n",
      "2 -> 122     1  /   1       312\n",
      "3 -> 125     1  /   1        91\n",
      "4 -> 123     1  /   1        40\n",
      "5 -> 128     1  /   1         8\n",
      "6 -> 128     1  /   1       107\n",
      "7 -> 128     1  /   1       148\n",
      "8 -> 128     1  /   1       120\n",
      "9 -> 128     1  /   1       102\n",
      "10 -> 125     1  /   1        17\n",
      "11 -> 128     1  /   1         4\n",
      "12 -> 128     1  /   1        95\n",
      "13 -> 125     1  /   1       139\n",
      "14 -> 128     1  /   1        84\n",
      "15 -> 128     1  /   1         4\n",
      "16 -> 125     1  /   1       109\n",
      "17 -> 123     1  /   1        74\n",
      "18 -> 128     1  /   1       114\n",
      "19 -> 123     1  /   1        29\n",
      "20 -> 125     1  /   1        61\n",
      "21 -> 128     1  /   1        10\n",
      "22 -> 128     1  /   1        80\n",
      "23 -> 123     1  /   1         1\n",
      "24 -> 125     1  /   1        81\n",
      "25 -> 128     1  /   1         6\n",
      "26 -> 128     1  /   1       119\n",
      "27 -> 128     1  /   1        21\n",
      "28 -> 123     1  /   1        38\n",
      "29 -> 128     1  /   1        45\n",
      "30 -> 128     1  /   1        71\n",
      "31 -> 125     1  /   1        51\n",
      "32 -> 128     1  /   1       145\n",
      "33 -> 125     1  /   1        84\n",
      "34 -> 128     1  /   1        94\n",
      "35 -> 128     1  /   1       104\n",
      "36 -> 128     1  /   1        51\n",
      "37 -> 123     1  /   1        52\n",
      "38 -> 128     1  /   1         0\n",
      "39 -> 128     1  /   1        68\n",
      "40 -> 128     1  /   1         3\n",
      "41 -> 123     1  /   1        24\n",
      "42 -> 128     1  /   1         3\n",
      "43 -> 125     1  /   1        70\n",
      "44 -> 128     1  /   1       111\n",
      "45 -> 125     1  /   1        64\n",
      "46 -> 128     1  /   1       103\n",
      "47 -> 125     1  /   1        23\n",
      "48 -> 123     1  /   1        85\n",
      "49 -> 123     1  /   1       182\n",
      "50 -> 123     1  /   1        13\n",
      "51 -> 122     1  /   1       115\n",
      "52 -> 128     1  /   1        12\n",
      "53 -> 125     1  /   1         3\n",
      "54 -> 131     1  /   1        28\n",
      "55 -> 128     1  /   1        16\n",
      "56 -> 128     1  /   1         3\n",
      "57 -> 125     1  /   1         7\n",
      "58 -> 128     1  /   1        20\n",
      "59 -> 128     1  /   1        53\n",
      "60 -> 128     1  /   1         3\n",
      "61 -> 128     1  /   1        10\n",
      "62 -> 123     1  /   1        28\n",
      "63 -> 125     1  /   1         9\n",
      "64 -> 123     1  /   1        10\n",
      "65 -> 128     1  /   1         1\n",
      "66 -> 123     1  /   1        32\n",
      "67 -> 125     1  /   1         3\n",
      "68 -> 125     1  /   1        44\n",
      "69 -> 131     1  /   1        52\n",
      "70 -> 123     1  /   1        31\n",
      "71 -> 125     1  /   1        57\n",
      "72 -> 125     1  /   1         1\n",
      "73 -> 128     1  /   1         0\n",
      "74 -> 125     1  /   1        32\n",
      "75 -> 125     1  /   1        21\n",
      "76 -> 128     1  /   1         7\n",
      "77 -> 125     1  /   1         7\n",
      "78 -> 125     1  /   1         9\n",
      "79 -> 125     1  /   1        25\n",
      "80 -> 125     1  /   1         1\n",
      "81 -> 131     1  /   1        17\n",
      "82 -> 131     1  /   1        41\n",
      "83 -> 128     1  /   1        52\n",
      "84 -> 125     1  /   1        39\n",
      "85 -> 131     1  /   1        24\n",
      "86 -> 131     1  /   1        53\n",
      "87 -> 128     1  /   1        22\n",
      "88 -> 128     1  /   1         1\n",
      "89 -> 128     1  /   1        13\n",
      "90 -> 128     1  /   1         0\n",
      "91 -> 125     1  /   1        28\n",
      "92 -> 123     1  /   1        13\n",
      "93 -> 123     1  /   1        52\n",
      "94 -> 128     1  /   1         5\n",
      "95 -> 123     1  /   1        29\n",
      "96 -> 128     1  /   1         0\n",
      "97 -> 131     1  /   1        44\n",
      "98 -> 125     1  /   1        18\n",
      "99 -> 128     1  /   1         7\n",
      "100 -> 131     1  /   1        30\n",
      "101 -> 128     1  /   1         6\n",
      "102 -> 128     1  /   1        27\n",
      "103 -> 123     1  /   1       186\n",
      "104 -> 130     1  /   1       245\n",
      "105 -> 131     1  /   1        51\n",
      "106 -> 123     1  /   1         4\n",
      "107 -> 123     1  /   1       238\n",
      "108 -> 123     1  /   1        80\n",
      "109 -> 129     1  /   1        10\n",
      "110 -> 129     1  /   1       204\n",
      "111 -> 122     1  /   1       100\n",
      "112 -> 122     1  /   1       185\n",
      "113 -> 131     1  /   1       252\n",
      "114 -> 131     1  /   1        28\n",
      "115 -> 131     1  /   1        98\n",
      "116 -> 124     1  /   1        33\n",
      "117 -> 124     1  /   1         7\n",
      "118 -> 124     1  /   1        33\n",
      "119 -> 126     1  /   1       310\n",
      "120 -> 127     1  /   1        54\n",
      "121 -> 127     1  /   1        79\n",
      "122 -> 132     1  /   6         0\n",
      "124 -> 132     1  /   6         0\n",
      "125 -> 132    17  /  20         0\n",
      "127 -> 132     1  /   4         0\n",
      "128 -> 132    26  /  44         0\n",
      "131 -> 132     8  /   8         0\n",
      "[ Raw Info all runs for each dist_type ] :\n",
      "      Dist Type   Gini  Avg Dist  Income_Gap  spatial_index\n",
      "0       Random  0.112      0.76        0.40         0.1601\n",
      "1         LIPA  0.079      0.45        0.26         0.1438\n",
      "2   RoundRobin  0.104      0.76        0.38         0.1438\n",
      "3         MCCA  0.220      0.21        0.69         0.3971\n",
      "4       MCCA-L  0.220      0.21        0.69         0.3971\n",
      "5   FairAssign  0.098      0.40        0.27         0.1595\n",
      "6       Random  0.135      0.81        0.61         0.2126\n",
      "7         LIPA  0.018      0.54        0.06         0.0313\n",
      "8   RoundRobin  0.140      0.80        0.61         0.1988\n",
      "9         MCCA  0.274      0.20        1.05         0.5310\n",
      "10      MCCA-L  0.267      0.20        1.04         0.4922\n",
      "11  FairAssign  0.103      0.36        0.27         0.1427\n",
      "[ Mean for each Dist Type ] :\n",
      "               Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                              \n",
      "FairAssign  0.1005     0.380       0.270        0.15110\n",
      "LIPA        0.0485     0.495       0.160        0.08755\n",
      "MCCA        0.2470     0.205       0.870        0.46405\n",
      "MCCA-L      0.2435     0.205       0.865        0.44465\n",
      "Random      0.1235     0.785       0.505        0.18635\n",
      "RoundRobin  0.1220     0.780       0.495        0.17130\n",
      "\n",
      "[ Max for each Dist Type ] :\n",
      "              Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                             \n",
      "FairAssign  0.103      0.40        0.27         0.1595\n",
      "LIPA        0.079      0.54        0.26         0.1438\n",
      "MCCA        0.274      0.21        1.05         0.5310\n",
      "MCCA-L      0.267      0.21        1.04         0.4922\n",
      "Random      0.135      0.81        0.61         0.2126\n",
      "RoundRobin  0.140      0.80        0.61         0.1988\n",
      "\n",
      "[ Min for each Dist Type ] :\n",
      "              Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                             \n",
      "FairAssign  0.098      0.36        0.27         0.1427\n",
      "LIPA        0.018      0.45        0.06         0.0313\n",
      "MCCA        0.220      0.20        0.69         0.3971\n",
      "MCCA-L      0.220      0.20        0.69         0.3971\n",
      "Random      0.112      0.76        0.40         0.1601\n",
      "RoundRobin  0.104      0.76        0.38         0.1438\n",
      "\n",
      "Number of Drivers: 145\n",
      "num_constraints: 48276\n",
      "Version identifier: 22.1.0.0 | 2022-03-09 | 1a383f8ce\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "CPXPARAM_Simplex_Tolerances_Markowitz            0.90000000000000002\n",
      "CPXPARAM_Simplex_Tolerances_Optimality           1.0000000000000001e-09\n",
      "CPXPARAM_Simplex_Tolerances_Feasibility          1.0000000000000001e-09\n",
      "Parallel mode: deterministic, using up to 4 threads for concurrent optimization:\n",
      " * Starting dual Simplex on 1 thread...\n",
      " * Starting Barrier on 3 threads...\n",
      "Tried aggregator 1 time.\n",
      "LP Presolve eliminated 0 rows and 81490 columns.\n",
      "Reduced LP has 48276 rows, 24360 columns, and 164720 nonzeros.\n",
      "Presolve time = 0.43 sec. (69.16 ticks)\n",
      "Initializing dual steep norms . . .\n",
      "\n",
      "Iteration log . . .\n",
      "Iteration:     1   Dual objective     =             0.612835\n",
      "Iteration:   308   Dual objective     =             1.281391\n",
      "Iteration:   792   Dual objective     =             1.628685\n",
      "Iteration:  1325   Dual objective     =             1.916696\n",
      "Iteration:  2072   Dual objective     =             2.057457\n",
      "Iteration:  2338   Dual objective     =             2.096429\n",
      "Iteration:  2598   Dual objective     =             2.151000\n",
      "Iteration:  2840   Dual objective     =             2.179500\n",
      "Iteration:  3095   Dual objective     =             2.219952\n",
      "Iteration:  3350   Dual objective     =             2.239640\n",
      "Iteration:  3587   Dual objective     =             2.262084\n",
      "Iteration:  3885   Dual objective     =             2.277302\n",
      "Iteration:  4136   Dual objective     =             2.290574\n",
      "Iteration:  4358   Dual objective     =             2.300382\n",
      "Iteration:  4573   Dual objective     =             2.313517\n",
      "Iteration:  4807   Dual objective     =             2.334035\n",
      "\n",
      "Barrier solved model.\n",
      "\n",
      "Solution Quality: [1.0, 0.0]\n",
      "Status: optimal\n",
      "Everything solved, graphs start\n",
      "max_flow_min_cost cost value: 8032\n",
      "maximum_flow flow value: 145\n",
      "Minimum cost: 8354\n",
      "\n",
      "  Arc    Flow / Capacity  Cost\n",
      "1 -> 2     1  /   1         0\n",
      "1 -> 3     1  /   1         0\n",
      "1 -> 4     1  /   1         0\n",
      "1 -> 5     1  /   1         0\n",
      "1 -> 6     1  /   1         0\n",
      "1 -> 7     1  /   1         0\n",
      "1 -> 8     1  /   1         0\n",
      "1 -> 9     1  /   1         0\n",
      "1 -> 10     1  /   1         0\n",
      "1 -> 11     1  /   1         0\n",
      "1 -> 12     1  /   1         0\n",
      "1 -> 13     1  /   1         0\n",
      "1 -> 14     1  /   1         0\n",
      "1 -> 15     1  /   1         0\n",
      "1 -> 16     1  /   1         0\n",
      "1 -> 17     1  /   1         0\n",
      "1 -> 18     1  /   1         0\n",
      "1 -> 19     1  /   1         0\n",
      "1 -> 20     1  /   1         0\n",
      "1 -> 21     1  /   1         0\n",
      "1 -> 22     1  /   1         0\n",
      "1 -> 23     1  /   1         0\n",
      "1 -> 24     1  /   1         0\n",
      "1 -> 25     1  /   1         0\n",
      "1 -> 26     1  /   1         0\n",
      "1 -> 27     1  /   1         0\n",
      "1 -> 28     1  /   1         0\n",
      "1 -> 29     1  /   1         0\n",
      "1 -> 30     1  /   1         0\n",
      "1 -> 31     1  /   1         0\n",
      "1 -> 32     1  /   1         0\n",
      "1 -> 33     1  /   1         0\n",
      "1 -> 34     1  /   1         0\n",
      "1 -> 35     1  /   1         0\n",
      "1 -> 36     1  /   1         0\n",
      "1 -> 37     1  /   1         0\n",
      "1 -> 38     1  /   1         0\n",
      "1 -> 39     1  /   1         0\n",
      "1 -> 40     1  /   1         0\n",
      "1 -> 41     1  /   1         0\n",
      "1 -> 42     1  /   1         0\n",
      "1 -> 43     1  /   1         0\n",
      "1 -> 44     1  /   1         0\n",
      "1 -> 45     1  /   1         0\n",
      "1 -> 46     1  /   1         0\n",
      "1 -> 47     1  /   1         0\n",
      "1 -> 48     1  /   1         0\n",
      "1 -> 49     1  /   1         0\n",
      "1 -> 50     1  /   1         0\n",
      "1 -> 51     1  /   1         0\n",
      "1 -> 52     1  /   1         0\n",
      "1 -> 53     1  /   1         0\n",
      "1 -> 54     1  /   1         0\n",
      "1 -> 55     1  /   1         0\n",
      "1 -> 56     1  /   1         0\n",
      "1 -> 57     1  /   1         0\n",
      "1 -> 58     1  /   1         0\n",
      "1 -> 59     1  /   1         0\n",
      "1 -> 60     1  /   1         0\n",
      "1 -> 61     1  /   1         0\n",
      "1 -> 62     1  /   1         0\n",
      "1 -> 63     1  /   1         0\n",
      "1 -> 64     1  /   1         0\n",
      "1 -> 65     1  /   1         0\n",
      "1 -> 66     1  /   1         0\n",
      "1 -> 67     1  /   1         0\n",
      "1 -> 68     1  /   1         0\n",
      "1 -> 69     1  /   1         0\n",
      "1 -> 70     1  /   1         0\n",
      "1 -> 71     1  /   1         0\n",
      "1 -> 72     1  /   1         0\n",
      "1 -> 73     1  /   1         0\n",
      "1 -> 74     1  /   1         0\n",
      "1 -> 75     1  /   1         0\n",
      "1 -> 76     1  /   1         0\n",
      "1 -> 77     1  /   1         0\n",
      "1 -> 78     1  /   1         0\n",
      "1 -> 79     1  /   1         0\n",
      "1 -> 80     1  /   1         0\n",
      "1 -> 81     1  /   1         0\n",
      "1 -> 82     1  /   1         0\n",
      "1 -> 83     1  /   1         0\n",
      "1 -> 84     1  /   1         0\n",
      "1 -> 85     1  /   1         0\n",
      "1 -> 86     1  /   1         0\n",
      "1 -> 87     1  /   1         0\n",
      "1 -> 88     1  /   1         0\n",
      "1 -> 89     1  /   1         0\n",
      "1 -> 90     1  /   1         0\n",
      "1 -> 91     1  /   1         0\n",
      "1 -> 92     1  /   1         0\n",
      "1 -> 93     1  /   1         0\n",
      "1 -> 94     1  /   1         0\n",
      "1 -> 95     1  /   1         0\n",
      "1 -> 96     1  /   1         0\n",
      "1 -> 97     1  /   1         0\n",
      "1 -> 98     1  /   1         0\n",
      "1 -> 99     1  /   1         0\n",
      "1 -> 100     1  /   1         0\n",
      "1 -> 101     1  /   1         0\n",
      "1 -> 102     1  /   1         0\n",
      "1 -> 103     1  /   1         0\n",
      "1 -> 104     1  /   1         0\n",
      "1 -> 105     1  /   1         0\n",
      "1 -> 106     1  /   1         0\n",
      "1 -> 107     1  /   1         0\n",
      "1 -> 108     1  /   1         0\n",
      "1 -> 109     1  /   1         0\n",
      "1 -> 110     1  /   1         0\n",
      "1 -> 111     1  /   1         0\n",
      "1 -> 112     1  /   1         0\n",
      "1 -> 113     1  /   1         0\n",
      "1 -> 114     1  /   1         0\n",
      "1 -> 115     1  /   1         0\n",
      "1 -> 116     1  /   1         0\n",
      "1 -> 117     1  /   1         0\n",
      "1 -> 118     1  /   1         0\n",
      "1 -> 119     1  /   1         0\n",
      "1 -> 120     1  /   1         0\n",
      "1 -> 121     1  /   1         0\n",
      "1 -> 122     1  /   1         0\n",
      "1 -> 123     1  /   1         0\n",
      "1 -> 124     1  /   1         0\n",
      "1 -> 125     1  /   1         0\n",
      "1 -> 126     1  /   1         0\n",
      "1 -> 127     1  /   1         0\n",
      "1 -> 128     1  /   1         0\n",
      "1 -> 129     1  /   1         0\n",
      "1 -> 130     1  /   1         0\n",
      "1 -> 131     1  /   1         0\n",
      "1 -> 132     1  /   1         0\n",
      "1 -> 133     1  /   1         0\n",
      "1 -> 134     1  /   1         0\n",
      "1 -> 135     1  /   1         0\n",
      "1 -> 136     1  /   1         0\n",
      "1 -> 137     1  /   1         0\n",
      "1 -> 138     1  /   1         0\n",
      "1 -> 139     1  /   1         0\n",
      "1 -> 140     1  /   1         0\n",
      "1 -> 141     1  /   1         0\n",
      "1 -> 142     1  /   1         0\n",
      "1 -> 143     1  /   1         0\n",
      "1 -> 144     1  /   1         0\n",
      "1 -> 145     1  /   1         0\n",
      "1 -> 146     1  /   1         0\n",
      "2 -> 147     1  /   1       449\n",
      "3 -> 150     1  /   1       126\n",
      "4 -> 153     1  /   1         1\n",
      "5 -> 148     1  /   1        71\n",
      "6 -> 150     1  /   1        47\n",
      "7 -> 148     1  /   1        67\n",
      "8 -> 148     1  /   1        32\n",
      "9 -> 153     1  /   1        75\n",
      "10 -> 148     1  /   1        28\n",
      "11 -> 153     1  /   1        23\n",
      "12 -> 153     1  /   1         9\n",
      "13 -> 153     1  /   1        42\n",
      "14 -> 150     1  /   1        27\n",
      "15 -> 148     1  /   1        38\n",
      "16 -> 150     1  /   1        26\n",
      "17 -> 148     1  /   1        58\n",
      "18 -> 153     1  /   1         2\n",
      "19 -> 153     1  /   1        29\n",
      "20 -> 153     1  /   1         1\n",
      "21 -> 153     1  /   1       143\n",
      "22 -> 150     1  /   1        91\n",
      "23 -> 153     1  /   1        98\n",
      "24 -> 153     1  /   1        41\n",
      "25 -> 153     1  /   1        14\n",
      "26 -> 153     1  /   1        41\n",
      "27 -> 148     1  /   1        17\n",
      "28 -> 153     1  /   1         9\n",
      "29 -> 153     1  /   1        71\n",
      "30 -> 153     1  /   1        88\n",
      "31 -> 150     1  /   1        63\n",
      "32 -> 153     1  /   1        17\n",
      "33 -> 153     1  /   1        22\n",
      "34 -> 153     1  /   1         0\n",
      "35 -> 153     1  /   1        18\n",
      "36 -> 153     1  /   1        20\n",
      "37 -> 153     1  /   1        83\n",
      "38 -> 150     1  /   1         6\n",
      "39 -> 150     1  /   1        11\n",
      "40 -> 153     1  /   1       114\n",
      "41 -> 150     1  /   1        51\n",
      "42 -> 153     1  /   1        68\n",
      "43 -> 148     1  /   1        21\n",
      "44 -> 153     1  /   1       121\n",
      "45 -> 148     1  /   1       101\n",
      "46 -> 153     1  /   1       132\n",
      "47 -> 150     1  /   1        10\n",
      "48 -> 150     1  /   1        84\n",
      "49 -> 153     1  /   1        48\n",
      "50 -> 153     1  /   1        52\n",
      "51 -> 153     1  /   1        19\n",
      "52 -> 153     1  /   1        66\n",
      "53 -> 153     1  /   1       138\n",
      "54 -> 153     1  /   1        86\n",
      "55 -> 153     1  /   1        20\n",
      "56 -> 153     1  /   1        41\n",
      "57 -> 150     1  /   1        83\n",
      "58 -> 148     1  /   1        69\n",
      "59 -> 148     1  /   1       169\n",
      "60 -> 148     1  /   1       154\n",
      "61 -> 147     1  /   1       130\n",
      "62 -> 147     1  /   1        92\n",
      "63 -> 148     1  /   1         4\n",
      "64 -> 153     1  /   1        21\n",
      "65 -> 150     1  /   1         5\n",
      "66 -> 148     1  /   1         2\n",
      "67 -> 153     1  /   1        10\n",
      "68 -> 156     1  /   1        48\n",
      "69 -> 153     1  /   1        61\n",
      "70 -> 156     1  /   1        68\n",
      "71 -> 150     1  /   1        32\n",
      "72 -> 148     1  /   1        16\n",
      "73 -> 148     1  /   1        50\n",
      "74 -> 153     1  /   1         6\n",
      "75 -> 150     1  /   1        25\n",
      "76 -> 148     1  /   1        34\n",
      "77 -> 153     1  /   1        17\n",
      "78 -> 150     1  /   1         9\n",
      "79 -> 150     1  /   1         1\n",
      "80 -> 153     1  /   1        59\n",
      "81 -> 153     1  /   1        13\n",
      "82 -> 156     1  /   1        40\n",
      "83 -> 153     1  /   1        48\n",
      "84 -> 153     1  /   1        10\n",
      "85 -> 153     1  /   1        54\n",
      "86 -> 156     1  /   1        57\n",
      "87 -> 150     1  /   1        17\n",
      "88 -> 148     1  /   1         7\n",
      "89 -> 153     1  /   1        34\n",
      "90 -> 150     1  /   1        48\n",
      "91 -> 150     1  /   1        15\n",
      "92 -> 150     1  /   1        25\n",
      "93 -> 153     1  /   1        18\n",
      "94 -> 148     1  /   1        35\n",
      "95 -> 150     1  /   1        37\n",
      "96 -> 150     1  /   1        19\n",
      "97 -> 153     1  /   1         3\n",
      "98 -> 153     1  /   1        49\n",
      "99 -> 153     1  /   1        14\n",
      "100 -> 156     1  /   1        27\n",
      "101 -> 150     1  /   1        37\n",
      "102 -> 153     1  /   1        31\n",
      "103 -> 150     1  /   1        40\n",
      "104 -> 148     1  /   1        22\n",
      "105 -> 150     1  /   1         8\n",
      "106 -> 150     1  /   1        61\n",
      "107 -> 153     1  /   1         4\n",
      "108 -> 150     1  /   1         1\n",
      "109 -> 153     1  /   1        38\n",
      "110 -> 150     1  /   1         1\n",
      "111 -> 153     1  /   1        20\n",
      "112 -> 156     1  /   1        45\n",
      "113 -> 153     1  /   1        66\n",
      "114 -> 148     1  /   1         8\n",
      "115 -> 150     1  /   1         3\n",
      "116 -> 153     1  /   1        52\n",
      "117 -> 148     1  /   1       168\n",
      "118 -> 148     1  /   1        35\n",
      "119 -> 156     1  /   1       102\n",
      "120 -> 148     1  /   1       171\n",
      "121 -> 148     1  /   1       212\n",
      "122 -> 155     1  /   1       253\n",
      "123 -> 148     1  /   1       181\n",
      "124 -> 148     1  /   1        36\n",
      "125 -> 148     1  /   1        47\n",
      "126 -> 148     1  /   1       224\n",
      "127 -> 154     1  /   1        82\n",
      "128 -> 149     1  /   1       120\n",
      "129 -> 154     1  /   1        65\n",
      "130 -> 147     1  /   1        88\n",
      "131 -> 147     1  /   1       122\n",
      "132 -> 147     1  /   1       176\n",
      "133 -> 147     1  /   1       105\n",
      "134 -> 156     1  /   1        87\n",
      "135 -> 156     1  /   1        66\n",
      "136 -> 156     1  /   1        63\n",
      "137 -> 156     1  /   1         7\n",
      "138 -> 155     1  /   1        64\n",
      "139 -> 149     1  /   1        20\n",
      "140 -> 149     1  /   1         2\n",
      "141 -> 149     1  /   1        27\n",
      "142 -> 149     1  /   1        74\n",
      "143 -> 155     1  /   1         1\n",
      "144 -> 152     1  /   1        10\n",
      "145 -> 152     1  /   1        37\n",
      "146 -> 151     1  /   1       361\n",
      "147 -> 157     4  /   6         0\n",
      "148 -> 157     8  /  43         0\n",
      "149 -> 157     3  /   6         0\n",
      "150 -> 157    20  /  20         0\n",
      "152 -> 157     1  /   4         0\n",
      "153 -> 157    34  /  44         0\n",
      "155 -> 157     2  /   2         0\n",
      "156 -> 157     7  /   8         0\n",
      "[ Raw Info all runs for each dist_type ] :\n",
      "      Dist Type   Gini  Avg Dist  Income_Gap  spatial_index\n",
      "0       Random  0.112      0.76        0.40         0.1601\n",
      "1         LIPA  0.079      0.45        0.26         0.1438\n",
      "2   RoundRobin  0.104      0.76        0.38         0.1438\n",
      "3         MCCA  0.220      0.21        0.69         0.3971\n",
      "4       MCCA-L  0.220      0.21        0.69         0.3971\n",
      "5   FairAssign  0.098      0.40        0.27         0.1595\n",
      "6       Random  0.135      0.81        0.61         0.2126\n",
      "7         LIPA  0.018      0.54        0.06         0.0313\n",
      "8   RoundRobin  0.140      0.80        0.61         0.1988\n",
      "9         MCCA  0.274      0.20        1.05         0.5310\n",
      "10      MCCA-L  0.267      0.20        1.04         0.4922\n",
      "11  FairAssign  0.103      0.36        0.27         0.1427\n",
      "12      Random  0.106      0.76        0.38         0.1514\n",
      "13        LIPA  0.069      0.46        0.24         0.1363\n",
      "14  RoundRobin  0.100      0.77        0.40         0.1360\n",
      "15        MCCA  0.208      0.21        0.61         0.3601\n",
      "16      MCCA-L  0.208      0.21        0.61         0.3598\n",
      "17  FairAssign  0.088      0.41        0.26         0.1399\n",
      "[ Mean for each Dist Type ] :\n",
      "                 Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                                \n",
      "FairAssign  0.096333  0.390000    0.266667       0.147367\n",
      "LIPA        0.055333  0.483333    0.186667       0.103800\n",
      "MCCA        0.234000  0.206667    0.783333       0.429400\n",
      "MCCA-L      0.231667  0.206667    0.780000       0.416367\n",
      "Random      0.117667  0.776667    0.463333       0.174700\n",
      "RoundRobin  0.114667  0.776667    0.463333       0.159533\n",
      "\n",
      "[ Max for each Dist Type ] :\n",
      "              Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                             \n",
      "FairAssign  0.103      0.41        0.27         0.1595\n",
      "LIPA        0.079      0.54        0.26         0.1438\n",
      "MCCA        0.274      0.21        1.05         0.5310\n",
      "MCCA-L      0.267      0.21        1.04         0.4922\n",
      "Random      0.135      0.81        0.61         0.2126\n",
      "RoundRobin  0.140      0.80        0.61         0.1988\n",
      "\n",
      "[ Min for each Dist Type ] :\n",
      "              Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                             \n",
      "FairAssign  0.088      0.36        0.26         0.1399\n",
      "LIPA        0.018      0.45        0.06         0.0313\n",
      "MCCA        0.208      0.20        0.61         0.3601\n",
      "MCCA-L      0.208      0.20        0.61         0.3598\n",
      "Random      0.106      0.76        0.38         0.1514\n",
      "RoundRobin  0.100      0.76        0.38         0.1360\n",
      "\n",
      "Number of Drivers: 98\n",
      "num_constraints: 19312\n",
      "Version identifier: 22.1.0.0 | 2022-03-09 | 1a383f8ce\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "CPXPARAM_Simplex_Tolerances_Markowitz            0.90000000000000002\n",
      "CPXPARAM_Simplex_Tolerances_Optimality           1.0000000000000001e-09\n",
      "CPXPARAM_Simplex_Tolerances_Feasibility          1.0000000000000001e-09\n",
      "Parallel mode: deterministic, using up to 4 threads for concurrent optimization:\n",
      " * Starting dual Simplex on 1 thread...\n",
      " * Starting Barrier on 3 threads...\n",
      "Tried aggregator 1 time.\n",
      "LP Presolve eliminated 0 rows and 38390 columns.\n",
      "Reduced LP has 19312 rows, 10120 columns, and 66920 nonzeros.\n",
      "Presolve time = 0.21 sec. (28.91 ticks)\n",
      "Initializing dual steep norms . . .\n",
      "\n",
      "Iteration log . . .\n",
      "Iteration:     1   Dual objective     =             0.514742\n",
      "Iteration:   213   Dual objective     =             1.066857\n",
      "Iteration:   595   Dual objective     =             1.306522\n",
      "Iteration:   795   Dual objective     =             1.420482\n",
      "Iteration:   954   Dual objective     =             1.518043\n",
      "Iteration:  1138   Dual objective     =             1.603568\n",
      "Iteration:  1332   Dual objective     =             1.687470\n",
      "Iteration:  1501   Dual objective     =             1.736675\n",
      "Iteration:  1717   Dual objective     =             1.797857\n",
      "Iteration:  1887   Dual objective     =             1.807059\n",
      "Iteration:  2044   Dual objective     =             1.824197\n",
      "Iteration:  2205   Dual objective     =             1.836621\n",
      "Iteration:  2397   Dual objective     =             1.854903\n",
      "Iteration:  2576   Dual objective     =             1.925508\n",
      "Iteration:  2753   Dual objective     =             1.939328\n",
      "Iteration:  2916   Dual objective     =             1.959438\n",
      "Iteration:  3079   Dual objective     =             1.970087\n",
      "Iteration:  3242   Dual objective     =             1.975953\n",
      "Iteration:  3402   Dual objective     =             1.985876\n",
      "Iteration:  3562   Dual objective     =             1.995794\n",
      "\n",
      "Barrier solved model.\n",
      "\n",
      "Solution Quality: [1.0, 0.0]\n",
      "Status: optimal\n",
      "Everything solved, graphs start\n",
      "max_flow_min_cost cost value: 5743\n",
      "maximum_flow flow value: 98\n",
      "Minimum cost: 5990\n",
      "\n",
      "  Arc    Flow / Capacity  Cost\n",
      "1 -> 2     1  /   1         0\n",
      "1 -> 3     1  /   1         0\n",
      "1 -> 4     1  /   1         0\n",
      "1 -> 5     1  /   1         0\n",
      "1 -> 6     1  /   1         0\n",
      "1 -> 7     1  /   1         0\n",
      "1 -> 8     1  /   1         0\n",
      "1 -> 9     1  /   1         0\n",
      "1 -> 10     1  /   1         0\n",
      "1 -> 11     1  /   1         0\n",
      "1 -> 12     1  /   1         0\n",
      "1 -> 13     1  /   1         0\n",
      "1 -> 14     1  /   1         0\n",
      "1 -> 15     1  /   1         0\n",
      "1 -> 16     1  /   1         0\n",
      "1 -> 17     1  /   1         0\n",
      "1 -> 18     1  /   1         0\n",
      "1 -> 19     1  /   1         0\n",
      "1 -> 20     1  /   1         0\n",
      "1 -> 21     1  /   1         0\n",
      "1 -> 22     1  /   1         0\n",
      "1 -> 23     1  /   1         0\n",
      "1 -> 24     1  /   1         0\n",
      "1 -> 25     1  /   1         0\n",
      "1 -> 26     1  /   1         0\n",
      "1 -> 27     1  /   1         0\n",
      "1 -> 28     1  /   1         0\n",
      "1 -> 29     1  /   1         0\n",
      "1 -> 30     1  /   1         0\n",
      "1 -> 31     1  /   1         0\n",
      "1 -> 32     1  /   1         0\n",
      "1 -> 33     1  /   1         0\n",
      "1 -> 34     1  /   1         0\n",
      "1 -> 35     1  /   1         0\n",
      "1 -> 36     1  /   1         0\n",
      "1 -> 37     1  /   1         0\n",
      "1 -> 38     1  /   1         0\n",
      "1 -> 39     1  /   1         0\n",
      "1 -> 40     1  /   1         0\n",
      "1 -> 41     1  /   1         0\n",
      "1 -> 42     1  /   1         0\n",
      "1 -> 43     1  /   1         0\n",
      "1 -> 44     1  /   1         0\n",
      "1 -> 45     1  /   1         0\n",
      "1 -> 46     1  /   1         0\n",
      "1 -> 47     1  /   1         0\n",
      "1 -> 48     1  /   1         0\n",
      "1 -> 49     1  /   1         0\n",
      "1 -> 50     1  /   1         0\n",
      "1 -> 51     1  /   1         0\n",
      "1 -> 52     1  /   1         0\n",
      "1 -> 53     1  /   1         0\n",
      "1 -> 54     1  /   1         0\n",
      "1 -> 55     1  /   1         0\n",
      "1 -> 56     1  /   1         0\n",
      "1 -> 57     1  /   1         0\n",
      "1 -> 58     1  /   1         0\n",
      "1 -> 59     1  /   1         0\n",
      "1 -> 60     1  /   1         0\n",
      "1 -> 61     1  /   1         0\n",
      "1 -> 62     1  /   1         0\n",
      "1 -> 63     1  /   1         0\n",
      "1 -> 64     1  /   1         0\n",
      "1 -> 65     1  /   1         0\n",
      "1 -> 66     1  /   1         0\n",
      "1 -> 67     1  /   1         0\n",
      "1 -> 68     1  /   1         0\n",
      "1 -> 69     1  /   1         0\n",
      "1 -> 70     1  /   1         0\n",
      "1 -> 71     1  /   1         0\n",
      "1 -> 72     1  /   1         0\n",
      "1 -> 73     1  /   1         0\n",
      "1 -> 74     1  /   1         0\n",
      "1 -> 75     1  /   1         0\n",
      "1 -> 76     1  /   1         0\n",
      "1 -> 77     1  /   1         0\n",
      "1 -> 78     1  /   1         0\n",
      "1 -> 79     1  /   1         0\n",
      "1 -> 80     1  /   1         0\n",
      "1 -> 81     1  /   1         0\n",
      "1 -> 82     1  /   1         0\n",
      "1 -> 83     1  /   1         0\n",
      "1 -> 84     1  /   1         0\n",
      "1 -> 85     1  /   1         0\n",
      "1 -> 86     1  /   1         0\n",
      "1 -> 87     1  /   1         0\n",
      "1 -> 88     1  /   1         0\n",
      "1 -> 89     1  /   1         0\n",
      "1 -> 90     1  /   1         0\n",
      "1 -> 91     1  /   1         0\n",
      "1 -> 92     1  /   1         0\n",
      "1 -> 93     1  /   1         0\n",
      "1 -> 94     1  /   1         0\n",
      "1 -> 95     1  /   1         0\n",
      "1 -> 96     1  /   1         0\n",
      "1 -> 97     1  /   1         0\n",
      "1 -> 98     1  /   1         0\n",
      "1 -> 99     1  /   1         0\n",
      "2 -> 100     1  /   1       198\n",
      "3 -> 100     1  /   1       259\n",
      "4 -> 103     1  /   1        24\n",
      "5 -> 106     1  /   1        12\n",
      "6 -> 106     1  /   1        81\n",
      "7 -> 103     1  /   1        48\n",
      "8 -> 103     1  /   1        19\n",
      "9 -> 101     1  /   1        92\n",
      "10 -> 103     1  /   1        45\n",
      "11 -> 106     1  /   1        50\n",
      "12 -> 103     1  /   1         7\n",
      "13 -> 106     1  /   1        75\n",
      "14 -> 103     1  /   1        90\n",
      "15 -> 103     1  /   1        58\n",
      "16 -> 101     1  /   1        31\n",
      "17 -> 101     1  /   1       103\n",
      "18 -> 101     1  /   1        14\n",
      "19 -> 106     1  /   1       146\n",
      "20 -> 103     1  /   1        85\n",
      "21 -> 103     1  /   1        19\n",
      "22 -> 103     1  /   1       115\n",
      "23 -> 106     1  /   1        40\n",
      "24 -> 106     1  /   1       134\n",
      "25 -> 106     1  /   1       128\n",
      "26 -> 101     1  /   1        58\n",
      "27 -> 106     1  /   1        13\n",
      "28 -> 106     1  /   1         1\n",
      "29 -> 103     1  /   1        30\n",
      "30 -> 106     1  /   1        46\n",
      "31 -> 106     1  /   1        28\n",
      "32 -> 103     1  /   1        17\n",
      "33 -> 101     1  /   1         3\n",
      "34 -> 106     1  /   1       104\n",
      "35 -> 106     1  /   1        12\n",
      "36 -> 106     1  /   1       127\n",
      "37 -> 106     1  /   1        43\n",
      "38 -> 103     1  /   1        51\n",
      "39 -> 103     1  /   1        47\n",
      "40 -> 106     1  /   1       117\n",
      "41 -> 101     1  /   1        51\n",
      "42 -> 106     1  /   1        59\n",
      "43 -> 103     1  /   1        64\n",
      "44 -> 101     1  /   1         2\n",
      "45 -> 101     1  /   1         6\n",
      "46 -> 106     1  /   1        61\n",
      "47 -> 106     1  /   1        24\n",
      "48 -> 106     1  /   1        99\n",
      "49 -> 103     1  /   1        76\n",
      "50 -> 103     1  /   1        50\n",
      "51 -> 106     1  /   1        83\n",
      "52 -> 106     1  /   1       127\n",
      "53 -> 106     1  /   1        45\n",
      "54 -> 103     1  /   1         8\n",
      "55 -> 103     1  /   1        85\n",
      "56 -> 101     1  /   1       129\n",
      "57 -> 107     1  /   1       279\n",
      "58 -> 101     1  /   1        58\n",
      "59 -> 103     1  /   1       107\n",
      "60 -> 106     1  /   1        11\n",
      "61 -> 101     1  /   1        43\n",
      "62 -> 109     1  /   1        72\n",
      "63 -> 106     1  /   1        22\n",
      "64 -> 103     1  /   1        12\n",
      "65 -> 109     1  /   1        17\n",
      "66 -> 109     1  /   1        18\n",
      "67 -> 101     1  /   1        19\n",
      "68 -> 101     1  /   1        62\n",
      "69 -> 106     1  /   1         1\n",
      "70 -> 103     1  /   1         3\n",
      "71 -> 103     1  /   1         3\n",
      "72 -> 101     1  /   1        24\n",
      "73 -> 103     1  /   1        39\n",
      "74 -> 101     1  /   1        27\n",
      "75 -> 109     1  /   1        48\n",
      "76 -> 103     1  /   1         2\n",
      "77 -> 101     1  /   1        78\n",
      "78 -> 103     1  /   1        10\n",
      "79 -> 103     1  /   1         4\n",
      "80 -> 101     1  /   1        39\n",
      "81 -> 109     1  /   1        23\n",
      "82 -> 101     1  /   1       185\n",
      "83 -> 101     1  /   1        83\n",
      "84 -> 101     1  /   1       170\n",
      "85 -> 107     1  /   1        86\n",
      "86 -> 102     1  /   1        97\n",
      "87 -> 100     1  /   1       109\n",
      "88 -> 100     1  /   1        38\n",
      "89 -> 100     1  /   1        43\n",
      "90 -> 100     1  /   1        60\n",
      "91 -> 109     1  /   1        19\n",
      "92 -> 109     1  /   1       135\n",
      "93 -> 102     1  /   1        17\n",
      "94 -> 102     1  /   1        50\n",
      "95 -> 102     1  /   1         5\n",
      "96 -> 102     1  /   1        10\n",
      "97 -> 108     1  /   1        14\n",
      "98 -> 105     1  /   1         6\n",
      "99 -> 104     1  /   1       303\n",
      "100 -> 110     3  /   6         0\n",
      "102 -> 110     3  /   6         0\n",
      "103 -> 110    17  /  20         0\n",
      "106 -> 110     6  /  44         0\n",
      "109 -> 110     3  /   8         0\n",
      "[ Raw Info all runs for each dist_type ] :\n",
      "      Dist Type   Gini  Avg Dist  Income_Gap  spatial_index\n",
      "0       Random  0.112      0.76        0.40         0.1601\n",
      "1         LIPA  0.079      0.45        0.26         0.1438\n",
      "2   RoundRobin  0.104      0.76        0.38         0.1438\n",
      "3         MCCA  0.220      0.21        0.69         0.3971\n",
      "4       MCCA-L  0.220      0.21        0.69         0.3971\n",
      "5   FairAssign  0.098      0.40        0.27         0.1595\n",
      "6       Random  0.135      0.81        0.61         0.2126\n",
      "7         LIPA  0.018      0.54        0.06         0.0313\n",
      "8   RoundRobin  0.140      0.80        0.61         0.1988\n",
      "9         MCCA  0.274      0.20        1.05         0.5310\n",
      "10      MCCA-L  0.267      0.20        1.04         0.4922\n",
      "11  FairAssign  0.103      0.36        0.27         0.1427\n",
      "12      Random  0.106      0.76        0.38         0.1514\n",
      "13        LIPA  0.069      0.46        0.24         0.1363\n",
      "14  RoundRobin  0.100      0.77        0.40         0.1360\n",
      "15        MCCA  0.208      0.21        0.61         0.3601\n",
      "16      MCCA-L  0.208      0.21        0.61         0.3598\n",
      "17  FairAssign  0.088      0.41        0.26         0.1399\n",
      "18      Random  0.174      0.95        0.91         0.2705\n",
      "19        LIPA  0.029      0.56        0.10         0.0573\n",
      "20  RoundRobin  0.169      0.95        0.67         0.2456\n",
      "21        MCCA  0.299      0.21        1.45         0.5626\n",
      "22      MCCA-L  0.240      0.22        1.25         0.4655\n",
      "23  FairAssign  0.095      0.41        0.33         0.1364\n",
      "[ Mean for each Dist Type ] :\n",
      "                Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                               \n",
      "FairAssign  0.09600    0.3950      0.2825       0.144625\n",
      "LIPA        0.04875    0.5025      0.1650       0.092175\n",
      "MCCA        0.25025    0.2075      0.9500       0.462700\n",
      "MCCA-L      0.23375    0.2100      0.8975       0.428650\n",
      "Random      0.13175    0.8200      0.5750       0.198650\n",
      "RoundRobin  0.12825    0.8200      0.5150       0.181050\n",
      "\n",
      "[ Max for each Dist Type ] :\n",
      "              Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                             \n",
      "FairAssign  0.103      0.41        0.33         0.1595\n",
      "LIPA        0.079      0.56        0.26         0.1438\n",
      "MCCA        0.299      0.21        1.45         0.5626\n",
      "MCCA-L      0.267      0.22        1.25         0.4922\n",
      "Random      0.174      0.95        0.91         0.2705\n",
      "RoundRobin  0.169      0.95        0.67         0.2456\n",
      "\n",
      "[ Min for each Dist Type ] :\n",
      "              Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                             \n",
      "FairAssign  0.088      0.36        0.26         0.1364\n",
      "LIPA        0.018      0.45        0.06         0.0313\n",
      "MCCA        0.208      0.20        0.61         0.3601\n",
      "MCCA-L      0.208      0.20        0.61         0.3598\n",
      "Random      0.106      0.76        0.38         0.1514\n",
      "RoundRobin  0.100      0.76        0.38         0.1360\n",
      "\n",
      "Number of Drivers: 115\n",
      "num_constraints: 27855\n",
      "Version identifier: 22.1.0.0 | 2022-03-09 | 1a383f8ce\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "CPXPARAM_Simplex_Tolerances_Markowitz            0.90000000000000002\n",
      "CPXPARAM_Simplex_Tolerances_Optimality           1.0000000000000001e-09\n",
      "CPXPARAM_Simplex_Tolerances_Feasibility          1.0000000000000001e-09\n",
      "Parallel mode: deterministic, using up to 4 threads for concurrent optimization:\n",
      " * Starting dual Simplex on 1 thread...\n",
      " * Starting Barrier on 3 threads...\n",
      "Tried aggregator 1 time.\n",
      "LP Presolve eliminated 0 rows and 52350 columns.\n",
      "Reduced LP has 27855 rows, 14350 columns, and 95850 nonzeros.\n",
      "Presolve time = 0.25 sec. (41.03 ticks)\n",
      "Initializing dual steep norms . . .\n",
      "\n",
      "Iteration log . . .\n",
      "Iteration:     1   Dual objective     =             0.557888\n",
      "Iteration:   239   Dual objective     =             1.218389\n",
      "Iteration:   670   Dual objective     =             1.525914\n",
      "Iteration:  1129   Dual objective     =             1.664250\n",
      "Iteration:  1339   Dual objective     =             1.690773\n",
      "Iteration:  1539   Dual objective     =             1.709983\n",
      "Iteration:  1765   Dual objective     =             1.723257\n",
      "Iteration:  1959   Dual objective     =             1.734684\n",
      "Iteration:  2167   Dual objective     =             1.744358\n",
      "Iteration:  2360   Dual objective     =             1.761234\n",
      "Iteration:  2569   Dual objective     =             1.776203\n",
      "Iteration:  2823   Dual objective     =             1.799691\n",
      "Iteration:  3030   Dual objective     =             1.808639\n",
      "Iteration:  3209   Dual objective     =             1.820138\n",
      "Iteration:  3390   Dual objective     =             1.837157\n",
      "Iteration:  3587   Dual objective     =             1.848199\n",
      "Iteration:  3778   Dual objective     =             1.857804\n",
      "Iteration:  3982   Dual objective     =             1.870859\n",
      "Iteration:  4176   Dual objective     =             1.882329\n",
      "Iteration:  4371   Dual objective     =             1.893116\n",
      "\n",
      "Barrier solved model.\n",
      "\n",
      "Solution Quality: [1.0, 0.0]\n",
      "Status: optimal\n",
      "Everything solved, graphs start\n",
      "max_flow_min_cost cost value: 6530\n",
      "maximum_flow flow value: 115\n",
      "Minimum cost: 6560\n",
      "\n",
      "  Arc    Flow / Capacity  Cost\n",
      "1 -> 2     1  /   1         0\n",
      "1 -> 3     1  /   1         0\n",
      "1 -> 4     1  /   1         0\n",
      "1 -> 5     1  /   1         0\n",
      "1 -> 6     1  /   1         0\n",
      "1 -> 7     1  /   1         0\n",
      "1 -> 8     1  /   1         0\n",
      "1 -> 9     1  /   1         0\n",
      "1 -> 10     1  /   1         0\n",
      "1 -> 11     1  /   1         0\n",
      "1 -> 12     1  /   1         0\n",
      "1 -> 13     1  /   1         0\n",
      "1 -> 14     1  /   1         0\n",
      "1 -> 15     1  /   1         0\n",
      "1 -> 16     1  /   1         0\n",
      "1 -> 17     1  /   1         0\n",
      "1 -> 18     1  /   1         0\n",
      "1 -> 19     1  /   1         0\n",
      "1 -> 20     1  /   1         0\n",
      "1 -> 21     1  /   1         0\n",
      "1 -> 22     1  /   1         0\n",
      "1 -> 23     1  /   1         0\n",
      "1 -> 24     1  /   1         0\n",
      "1 -> 25     1  /   1         0\n",
      "1 -> 26     1  /   1         0\n",
      "1 -> 27     1  /   1         0\n",
      "1 -> 28     1  /   1         0\n",
      "1 -> 29     1  /   1         0\n",
      "1 -> 30     1  /   1         0\n",
      "1 -> 31     1  /   1         0\n",
      "1 -> 32     1  /   1         0\n",
      "1 -> 33     1  /   1         0\n",
      "1 -> 34     1  /   1         0\n",
      "1 -> 35     1  /   1         0\n",
      "1 -> 36     1  /   1         0\n",
      "1 -> 37     1  /   1         0\n",
      "1 -> 38     1  /   1         0\n",
      "1 -> 39     1  /   1         0\n",
      "1 -> 40     1  /   1         0\n",
      "1 -> 41     1  /   1         0\n",
      "1 -> 42     1  /   1         0\n",
      "1 -> 43     1  /   1         0\n",
      "1 -> 44     1  /   1         0\n",
      "1 -> 45     1  /   1         0\n",
      "1 -> 46     1  /   1         0\n",
      "1 -> 47     1  /   1         0\n",
      "1 -> 48     1  /   1         0\n",
      "1 -> 49     1  /   1         0\n",
      "1 -> 50     1  /   1         0\n",
      "1 -> 51     1  /   1         0\n",
      "1 -> 52     1  /   1         0\n",
      "1 -> 53     1  /   1         0\n",
      "1 -> 54     1  /   1         0\n",
      "1 -> 55     1  /   1         0\n",
      "1 -> 56     1  /   1         0\n",
      "1 -> 57     1  /   1         0\n",
      "1 -> 58     1  /   1         0\n",
      "1 -> 59     1  /   1         0\n",
      "1 -> 60     1  /   1         0\n",
      "1 -> 61     1  /   1         0\n",
      "1 -> 62     1  /   1         0\n",
      "1 -> 63     1  /   1         0\n",
      "1 -> 64     1  /   1         0\n",
      "1 -> 65     1  /   1         0\n",
      "1 -> 66     1  /   1         0\n",
      "1 -> 67     1  /   1         0\n",
      "1 -> 68     1  /   1         0\n",
      "1 -> 69     1  /   1         0\n",
      "1 -> 70     1  /   1         0\n",
      "1 -> 71     1  /   1         0\n",
      "1 -> 72     1  /   1         0\n",
      "1 -> 73     1  /   1         0\n",
      "1 -> 74     1  /   1         0\n",
      "1 -> 75     1  /   1         0\n",
      "1 -> 76     1  /   1         0\n",
      "1 -> 77     1  /   1         0\n",
      "1 -> 78     1  /   1         0\n",
      "1 -> 79     1  /   1         0\n",
      "1 -> 80     1  /   1         0\n",
      "1 -> 81     1  /   1         0\n",
      "1 -> 82     1  /   1         0\n",
      "1 -> 83     1  /   1         0\n",
      "1 -> 84     1  /   1         0\n",
      "1 -> 85     1  /   1         0\n",
      "1 -> 86     1  /   1         0\n",
      "1 -> 87     1  /   1         0\n",
      "1 -> 88     1  /   1         0\n",
      "1 -> 89     1  /   1         0\n",
      "1 -> 90     1  /   1         0\n",
      "1 -> 91     1  /   1         0\n",
      "1 -> 92     1  /   1         0\n",
      "1 -> 93     1  /   1         0\n",
      "1 -> 94     1  /   1         0\n",
      "1 -> 95     1  /   1         0\n",
      "1 -> 96     1  /   1         0\n",
      "1 -> 97     1  /   1         0\n",
      "1 -> 98     1  /   1         0\n",
      "1 -> 99     1  /   1         0\n",
      "1 -> 100     1  /   1         0\n",
      "1 -> 101     1  /   1         0\n",
      "1 -> 102     1  /   1         0\n",
      "1 -> 103     1  /   1         0\n",
      "1 -> 104     1  /   1         0\n",
      "1 -> 105     1  /   1         0\n",
      "1 -> 106     1  /   1         0\n",
      "1 -> 107     1  /   1         0\n",
      "1 -> 108     1  /   1         0\n",
      "1 -> 109     1  /   1         0\n",
      "1 -> 110     1  /   1         0\n",
      "1 -> 111     1  /   1         0\n",
      "1 -> 112     1  /   1         0\n",
      "1 -> 113     1  /   1         0\n",
      "1 -> 114     1  /   1         0\n",
      "1 -> 115     1  /   1         0\n",
      "1 -> 116     1  /   1         0\n",
      "2 -> 117     1  /   1       254\n",
      "3 -> 120     1  /   1       270\n",
      "4 -> 120     1  /   1        70\n",
      "5 -> 123     1  /   1        12\n",
      "6 -> 123     1  /   1        34\n",
      "7 -> 123     1  /   1        28\n",
      "8 -> 123     1  /   1        70\n",
      "9 -> 118     1  /   1        97\n",
      "10 -> 123     1  /   1        32\n",
      "11 -> 123     1  /   1        81\n",
      "12 -> 123     1  /   1        25\n",
      "13 -> 123     1  /   1        49\n",
      "14 -> 118     1  /   1         3\n",
      "15 -> 120     1  /   1        13\n",
      "16 -> 118     1  /   1         6\n",
      "17 -> 123     1  /   1        65\n",
      "18 -> 120     1  /   1        76\n",
      "19 -> 123     1  /   1        54\n",
      "20 -> 120     1  /   1        27\n",
      "21 -> 120     1  /   1        45\n",
      "22 -> 123     1  /   1        84\n",
      "23 -> 123     1  /   1         4\n",
      "24 -> 123     1  /   1        55\n",
      "25 -> 123     1  /   1        19\n",
      "26 -> 120     1  /   1       149\n",
      "27 -> 123     1  /   1        28\n",
      "28 -> 120     1  /   1       158\n",
      "29 -> 123     1  /   1        73\n",
      "30 -> 120     1  /   1        21\n",
      "31 -> 118     1  /   1        18\n",
      "32 -> 123     1  /   1       153\n",
      "33 -> 120     1  /   1        23\n",
      "34 -> 123     1  /   1       127\n",
      "35 -> 118     1  /   1        17\n",
      "36 -> 120     1  /   1       148\n",
      "37 -> 120     1  /   1        40\n",
      "38 -> 120     1  /   1        99\n",
      "39 -> 123     1  /   1       100\n",
      "40 -> 118     1  /   1        31\n",
      "41 -> 118     1  /   1        96\n",
      "42 -> 123     1  /   1        76\n",
      "43 -> 118     1  /   1        14\n",
      "44 -> 120     1  /   1        49\n",
      "45 -> 120     1  /   1        16\n",
      "46 -> 120     1  /   1        20\n",
      "47 -> 123     1  /   1         9\n",
      "48 -> 118     1  /   1         1\n",
      "49 -> 124     1  /   1       257\n",
      "50 -> 118     1  /   1        56\n",
      "51 -> 118     1  /   1       153\n",
      "52 -> 118     1  /   1        28\n",
      "53 -> 118     1  /   1        62\n",
      "54 -> 117     1  /   1        52\n",
      "55 -> 117     1  /   1        93\n",
      "56 -> 123     1  /   1        25\n",
      "57 -> 120     1  /   1         0\n",
      "58 -> 126     1  /   1        34\n",
      "59 -> 120     1  /   1         8\n",
      "60 -> 118     1  /   1         6\n",
      "61 -> 120     1  /   1        34\n",
      "62 -> 126     1  /   1        15\n",
      "63 -> 123     1  /   1        67\n",
      "64 -> 126     1  /   1        45\n",
      "65 -> 118     1  /   1        55\n",
      "66 -> 123     1  /   1         3\n",
      "67 -> 120     1  /   1         9\n",
      "68 -> 120     1  /   1        67\n",
      "69 -> 123     1  /   1        22\n",
      "70 -> 126     1  /   1        33\n",
      "71 -> 123     1  /   1        12\n",
      "72 -> 120     1  /   1        32\n",
      "73 -> 123     1  /   1         3\n",
      "74 -> 120     1  /   1        68\n",
      "75 -> 123     1  /   1        44\n",
      "76 -> 123     1  /   1        14\n",
      "77 -> 126     1  /   1        28\n",
      "78 -> 120     1  /   1         8\n",
      "79 -> 120     1  /   1         5\n",
      "80 -> 120     1  /   1         1\n",
      "81 -> 126     1  /   1        34\n",
      "82 -> 118     1  /   1        10\n",
      "83 -> 123     1  /   1        15\n",
      "84 -> 120     1  /   1        15\n",
      "85 -> 120     1  /   1         5\n",
      "86 -> 123     1  /   1         1\n",
      "87 -> 123     1  /   1        28\n",
      "88 -> 123     1  /   1        17\n",
      "89 -> 123     1  /   1         9\n",
      "90 -> 118     1  /   1        26\n",
      "91 -> 120     1  /   1        41\n",
      "92 -> 123     1  /   1        13\n",
      "93 -> 120     1  /   1        33\n",
      "94 -> 123     1  /   1        14\n",
      "95 -> 118     1  /   1       252\n",
      "96 -> 126     1  /   1        69\n",
      "97 -> 126     1  /   1       179\n",
      "98 -> 118     1  /   1        34\n",
      "99 -> 118     1  /   1        98\n",
      "100 -> 118     1  /   1         5\n",
      "101 -> 126     1  /   1        88\n",
      "102 -> 124     1  /   1        70\n",
      "103 -> 119     1  /   1        66\n",
      "104 -> 117     1  /   1       174\n",
      "105 -> 117     1  /   1        82\n",
      "106 -> 126     1  /   1       269\n",
      "107 -> 117     1  /   1       214\n",
      "108 -> 126     1  /   1         4\n",
      "109 -> 126     1  /   1        94\n",
      "110 -> 125     1  /   1        94\n",
      "111 -> 125     1  /   1        48\n",
      "112 -> 119     1  /   1        31\n",
      "113 -> 119     1  /   1        18\n",
      "114 -> 119     1  /   1        23\n",
      "115 -> 122     1  /   1        50\n",
      "116 -> 121     1  /   1        59\n",
      "117 -> 127     3  /   6         0\n",
      "119 -> 127     2  /   6         0\n",
      "120 -> 127    20  /  20         0\n",
      "123 -> 127    15  /  44         0\n",
      "125 -> 127     1  /   2         0\n",
      "126 -> 127     8  /   8         0\n",
      "[ Raw Info all runs for each dist_type ] :\n",
      "      Dist Type   Gini  Avg Dist  Income_Gap  spatial_index\n",
      "0       Random  0.112      0.76        0.40         0.1601\n",
      "1         LIPA  0.079      0.45        0.26         0.1438\n",
      "2   RoundRobin  0.104      0.76        0.38         0.1438\n",
      "3         MCCA  0.220      0.21        0.69         0.3971\n",
      "4       MCCA-L  0.220      0.21        0.69         0.3971\n",
      "5   FairAssign  0.098      0.40        0.27         0.1595\n",
      "6       Random  0.135      0.81        0.61         0.2126\n",
      "7         LIPA  0.018      0.54        0.06         0.0313\n",
      "8   RoundRobin  0.140      0.80        0.61         0.1988\n",
      "9         MCCA  0.274      0.20        1.05         0.5310\n",
      "10      MCCA-L  0.267      0.20        1.04         0.4922\n",
      "11  FairAssign  0.103      0.36        0.27         0.1427\n",
      "12      Random  0.106      0.76        0.38         0.1514\n",
      "13        LIPA  0.069      0.46        0.24         0.1363\n",
      "14  RoundRobin  0.100      0.77        0.40         0.1360\n",
      "15        MCCA  0.208      0.21        0.61         0.3601\n",
      "16      MCCA-L  0.208      0.21        0.61         0.3598\n",
      "17  FairAssign  0.088      0.41        0.26         0.1399\n",
      "18      Random  0.174      0.95        0.91         0.2705\n",
      "19        LIPA  0.029      0.56        0.10         0.0573\n",
      "20  RoundRobin  0.169      0.95        0.67         0.2456\n",
      "21        MCCA  0.299      0.21        1.45         0.5626\n",
      "22      MCCA-L  0.240      0.22        1.25         0.4655\n",
      "23  FairAssign  0.095      0.41        0.33         0.1364\n",
      "24      Random  0.143      0.84        0.64         0.2163\n",
      "25        LIPA  0.008      0.53        0.02         0.0165\n",
      "26  RoundRobin  0.150      0.84        0.66         0.2232\n",
      "27        MCCA  0.297      0.21        1.37         0.5749\n",
      "28      MCCA-L  0.257      0.21        1.16         0.4896\n",
      "29  FairAssign  0.113      0.38        0.32         0.1704\n",
      "[ Mean for each Dist Type ] :\n",
      "               Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                              \n",
      "FairAssign  0.0994     0.392       0.290        0.14978\n",
      "LIPA        0.0406     0.508       0.136        0.07704\n",
      "MCCA        0.2596     0.208       1.034        0.48514\n",
      "MCCA-L      0.2384     0.210       0.950        0.44084\n",
      "Random      0.1340     0.824       0.588        0.20218\n",
      "RoundRobin  0.1326     0.824       0.544        0.18948\n",
      "\n",
      "[ Max for each Dist Type ] :\n",
      "              Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                             \n",
      "FairAssign  0.113      0.41        0.33         0.1704\n",
      "LIPA        0.079      0.56        0.26         0.1438\n",
      "MCCA        0.299      0.21        1.45         0.5749\n",
      "MCCA-L      0.267      0.22        1.25         0.4922\n",
      "Random      0.174      0.95        0.91         0.2705\n",
      "RoundRobin  0.169      0.95        0.67         0.2456\n",
      "\n",
      "[ Min for each Dist Type ] :\n",
      "              Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                             \n",
      "FairAssign  0.088      0.36        0.26         0.1364\n",
      "LIPA        0.008      0.45        0.02         0.0165\n",
      "MCCA        0.208      0.20        0.61         0.3601\n",
      "MCCA-L      0.208      0.20        0.61         0.3598\n",
      "Random      0.106      0.76        0.38         0.1514\n",
      "RoundRobin  0.100      0.76        0.38         0.1360\n",
      "\n",
      "Number of Drivers: 117\n",
      "num_constraints: 26828\n",
      "Version identifier: 22.1.0.0 | 2022-03-09 | 1a383f8ce\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "CPXPARAM_Simplex_Tolerances_Markowitz            0.90000000000000002\n",
      "CPXPARAM_Simplex_Tolerances_Optimality           1.0000000000000001e-09\n",
      "CPXPARAM_Simplex_Tolerances_Feasibility          1.0000000000000001e-09\n",
      "Parallel mode: deterministic, using up to 4 threads for concurrent optimization:\n",
      " * Starting dual Simplex on 1 thread...\n",
      " * Starting Barrier on 3 threads...\n",
      "Tried aggregator 1 time.\n",
      "LP Presolve eliminated 0 rows and 55150 columns.\n",
      "Reduced LP has 26828 rows, 13880 columns, and 92480 nonzeros.\n",
      "Presolve time = 0.21 sec. (40.48 ticks)\n",
      "Initializing dual steep norms . . .\n",
      "\n",
      "Iteration log . . .\n",
      "Iteration:     1   Dual objective     =             0.707817\n",
      "Iteration:   282   Dual objective     =             1.705106\n",
      "Iteration:   687   Dual objective     =             2.079705\n",
      "Iteration:  1138   Dual objective     =             2.363894\n",
      "Iteration:  1355   Dual objective     =             2.592283\n",
      "Iteration:  1573   Dual objective     =             2.770929\n",
      "Iteration:  1780   Dual objective     =             3.023140\n",
      "Iteration:  1977   Dual objective     =             3.285139\n",
      "Iteration:  2308   Dual objective     =             3.356163\n",
      "Iteration:  2510   Dual objective     =             3.464584\n",
      "Iteration:  2684   Dual objective     =             3.504463\n",
      "Iteration:  2881   Dual objective     =             3.543923\n",
      "Iteration:  3099   Dual objective     =             3.569122\n",
      "Iteration:  3265   Dual objective     =             3.590291\n",
      "Iteration:  3438   Dual objective     =             3.614566\n",
      "Iteration:  3618   Dual objective     =             3.659106\n",
      "Iteration:  3803   Dual objective     =             3.687364\n",
      "\n",
      "Barrier solved model.\n",
      "\n",
      "Solution Quality: [0.6291602418925756, 0.0]\n",
      "Status: optimal\n",
      "Everything solved, graphs start\n",
      "max_flow_min_cost cost value: 7135\n",
      "maximum_flow flow value: 117\n",
      "Minimum cost: 7316\n",
      "\n",
      "  Arc    Flow / Capacity  Cost\n",
      "1 -> 2     1  /   1         0\n",
      "1 -> 3     1  /   1         0\n",
      "1 -> 4     1  /   1         0\n",
      "1 -> 5     1  /   1         0\n",
      "1 -> 6     1  /   1         0\n",
      "1 -> 7     1  /   1         0\n",
      "1 -> 8     1  /   1         0\n",
      "1 -> 9     1  /   1         0\n",
      "1 -> 10     1  /   1         0\n",
      "1 -> 11     1  /   1         0\n",
      "1 -> 12     1  /   1         0\n",
      "1 -> 13     1  /   1         0\n",
      "1 -> 14     1  /   1         0\n",
      "1 -> 15     1  /   1         0\n",
      "1 -> 16     1  /   1         0\n",
      "1 -> 17     1  /   1         0\n",
      "1 -> 18     1  /   1         0\n",
      "1 -> 19     1  /   1         0\n",
      "1 -> 20     1  /   1         0\n",
      "1 -> 21     1  /   1         0\n",
      "1 -> 22     1  /   1         0\n",
      "1 -> 23     1  /   1         0\n",
      "1 -> 24     1  /   1         0\n",
      "1 -> 25     1  /   1         0\n",
      "1 -> 26     1  /   1         0\n",
      "1 -> 27     1  /   1         0\n",
      "1 -> 28     1  /   1         0\n",
      "1 -> 29     1  /   1         0\n",
      "1 -> 30     1  /   1         0\n",
      "1 -> 31     1  /   1         0\n",
      "1 -> 32     1  /   1         0\n",
      "1 -> 33     1  /   1         0\n",
      "1 -> 34     1  /   1         0\n",
      "1 -> 35     1  /   1         0\n",
      "1 -> 36     1  /   1         0\n",
      "1 -> 37     1  /   1         0\n",
      "1 -> 38     1  /   1         0\n",
      "1 -> 39     1  /   1         0\n",
      "1 -> 40     1  /   1         0\n",
      "1 -> 41     1  /   1         0\n",
      "1 -> 42     1  /   1         0\n",
      "1 -> 43     1  /   1         0\n",
      "1 -> 44     1  /   1         0\n",
      "1 -> 45     1  /   1         0\n",
      "1 -> 46     1  /   1         0\n",
      "1 -> 47     1  /   1         0\n",
      "1 -> 48     1  /   1         0\n",
      "1 -> 49     1  /   1         0\n",
      "1 -> 50     1  /   1         0\n",
      "1 -> 51     1  /   1         0\n",
      "1 -> 52     1  /   1         0\n",
      "1 -> 53     1  /   1         0\n",
      "1 -> 54     1  /   1         0\n",
      "1 -> 55     1  /   1         0\n",
      "1 -> 56     1  /   1         0\n",
      "1 -> 57     1  /   1         0\n",
      "1 -> 58     1  /   1         0\n",
      "1 -> 59     1  /   1         0\n",
      "1 -> 60     1  /   1         0\n",
      "1 -> 61     1  /   1         0\n",
      "1 -> 62     1  /   1         0\n",
      "1 -> 63     1  /   1         0\n",
      "1 -> 64     1  /   1         0\n",
      "1 -> 65     1  /   1         0\n",
      "1 -> 66     1  /   1         0\n",
      "1 -> 67     1  /   1         0\n",
      "1 -> 68     1  /   1         0\n",
      "1 -> 69     1  /   1         0\n",
      "1 -> 70     1  /   1         0\n",
      "1 -> 71     1  /   1         0\n",
      "1 -> 72     1  /   1         0\n",
      "1 -> 73     1  /   1         0\n",
      "1 -> 74     1  /   1         0\n",
      "1 -> 75     1  /   1         0\n",
      "1 -> 76     1  /   1         0\n",
      "1 -> 77     1  /   1         0\n",
      "1 -> 78     1  /   1         0\n",
      "1 -> 79     1  /   1         0\n",
      "1 -> 80     1  /   1         0\n",
      "1 -> 81     1  /   1         0\n",
      "1 -> 82     1  /   1         0\n",
      "1 -> 83     1  /   1         0\n",
      "1 -> 84     1  /   1         0\n",
      "1 -> 85     1  /   1         0\n",
      "1 -> 86     1  /   1         0\n",
      "1 -> 87     1  /   1         0\n",
      "1 -> 88     1  /   1         0\n",
      "1 -> 89     1  /   1         0\n",
      "1 -> 90     1  /   1         0\n",
      "1 -> 91     1  /   1         0\n",
      "1 -> 92     1  /   1         0\n",
      "1 -> 93     1  /   1         0\n",
      "1 -> 94     1  /   1         0\n",
      "1 -> 95     1  /   1         0\n",
      "1 -> 96     1  /   1         0\n",
      "1 -> 97     1  /   1         0\n",
      "1 -> 98     1  /   1         0\n",
      "1 -> 99     1  /   1         0\n",
      "1 -> 100     1  /   1         0\n",
      "1 -> 101     1  /   1         0\n",
      "1 -> 102     1  /   1         0\n",
      "1 -> 103     1  /   1         0\n",
      "1 -> 104     1  /   1         0\n",
      "1 -> 105     1  /   1         0\n",
      "1 -> 106     1  /   1         0\n",
      "1 -> 107     1  /   1         0\n",
      "1 -> 108     1  /   1         0\n",
      "1 -> 109     1  /   1         0\n",
      "1 -> 110     1  /   1         0\n",
      "1 -> 111     1  /   1         0\n",
      "1 -> 112     1  /   1         0\n",
      "1 -> 113     1  /   1         0\n",
      "1 -> 114     1  /   1         0\n",
      "1 -> 115     1  /   1         0\n",
      "1 -> 116     1  /   1         0\n",
      "1 -> 117     1  /   1         0\n",
      "1 -> 118     1  /   1         0\n",
      "2 -> 119     1  /   1       384\n",
      "3 -> 120     1  /   1         2\n",
      "4 -> 122     1  /   1        14\n",
      "5 -> 120     1  /   1        78\n",
      "6 -> 122     1  /   1        96\n",
      "7 -> 125     1  /   1        35\n",
      "8 -> 125     1  /   1        78\n",
      "9 -> 125     1  /   1         2\n",
      "10 -> 120     1  /   1        23\n",
      "11 -> 122     1  /   1        96\n",
      "12 -> 122     1  /   1        48\n",
      "13 -> 120     1  /   1         1\n",
      "14 -> 125     1  /   1        18\n",
      "15 -> 125     1  /   1        92\n",
      "16 -> 125     1  /   1        54\n",
      "17 -> 125     1  /   1         5\n",
      "18 -> 125     1  /   1        26\n",
      "19 -> 120     1  /   1         1\n",
      "20 -> 122     1  /   1        70\n",
      "21 -> 122     1  /   1        56\n",
      "22 -> 125     1  /   1         1\n",
      "23 -> 125     1  /   1        32\n",
      "24 -> 120     1  /   1        71\n",
      "25 -> 125     1  /   1        62\n",
      "26 -> 122     1  /   1       164\n",
      "27 -> 122     1  /   1       123\n",
      "28 -> 120     1  /   1        89\n",
      "29 -> 122     1  /   1        32\n",
      "30 -> 120     1  /   1         9\n",
      "31 -> 122     1  /   1        27\n",
      "32 -> 125     1  /   1        98\n",
      "33 -> 120     1  /   1        44\n",
      "34 -> 125     1  /   1         4\n",
      "35 -> 125     1  /   1         7\n",
      "36 -> 125     1  /   1        90\n",
      "37 -> 125     1  /   1        47\n",
      "38 -> 122     1  /   1        17\n",
      "39 -> 125     1  /   1        66\n",
      "40 -> 125     1  /   1         4\n",
      "41 -> 125     1  /   1         1\n",
      "42 -> 120     1  /   1        26\n",
      "43 -> 122     1  /   1        95\n",
      "44 -> 122     1  /   1       105\n",
      "45 -> 120     1  /   1        15\n",
      "46 -> 122     1  /   1        58\n",
      "47 -> 122     1  /   1        17\n",
      "48 -> 125     1  /   1        74\n",
      "49 -> 122     1  /   1        65\n",
      "50 -> 125     1  /   1        70\n",
      "51 -> 125     1  /   1        96\n",
      "52 -> 125     1  /   1       139\n",
      "53 -> 125     1  /   1        92\n",
      "54 -> 125     1  /   1        86\n",
      "55 -> 120     1  /   1        40\n",
      "56 -> 125     1  /   1        32\n",
      "57 -> 120     1  /   1        26\n",
      "58 -> 120     1  /   1        12\n",
      "59 -> 126     1  /   1       307\n",
      "60 -> 120     1  /   1       301\n",
      "61 -> 119     1  /   1        13\n",
      "62 -> 122     1  /   1         9\n",
      "63 -> 122     1  /   1        30\n",
      "64 -> 120     1  /   1        46\n",
      "65 -> 122     1  /   1        32\n",
      "66 -> 122     1  /   1        39\n",
      "67 -> 120     1  /   1        16\n",
      "68 -> 128     1  /   1        50\n",
      "69 -> 122     1  /   1        26\n",
      "70 -> 122     1  /   1         2\n",
      "71 -> 122     1  /   1         2\n",
      "72 -> 125     1  /   1        13\n",
      "73 -> 125     1  /   1         3\n",
      "74 -> 125     1  /   1        34\n",
      "75 -> 120     1  /   1         9\n",
      "76 -> 122     1  /   1         0\n",
      "77 -> 125     1  /   1        28\n",
      "78 -> 125     1  /   1         8\n",
      "79 -> 122     1  /   1         1\n",
      "80 -> 125     1  /   1         1\n",
      "81 -> 125     1  /   1         5\n",
      "82 -> 122     1  /   1        21\n",
      "83 -> 122     1  /   1        24\n",
      "84 -> 128     1  /   1        15\n",
      "85 -> 120     1  /   1        28\n",
      "86 -> 125     1  /   1        22\n",
      "87 -> 120     1  /   1        56\n",
      "88 -> 127     1  /   1       234\n",
      "89 -> 120     1  /   1        23\n",
      "90 -> 120     1  /   1         6\n",
      "91 -> 120     1  /   1        29\n",
      "92 -> 126     1  /   1       239\n",
      "93 -> 128     1  /   1       130\n",
      "94 -> 120     1  /   1       253\n",
      "95 -> 128     1  /   1        72\n",
      "96 -> 127     1  /   1       220\n",
      "97 -> 120     1  /   1        19\n",
      "98 -> 121     1  /   1        51\n",
      "99 -> 121     1  /   1        63\n",
      "100 -> 119     1  /   1        63\n",
      "101 -> 119     1  /   1        73\n",
      "102 -> 119     1  /   1       135\n",
      "103 -> 119     1  /   1        89\n",
      "104 -> 128     1  /   1       289\n",
      "105 -> 119     1  /   1        13\n",
      "106 -> 128     1  /   1        22\n",
      "107 -> 127     1  /   1        84\n",
      "108 -> 128     1  /   1       151\n",
      "109 -> 121     1  /   1         5\n",
      "110 -> 121     1  /   1        63\n",
      "111 -> 121     1  /   1        76\n",
      "112 -> 121     1  /   1        19\n",
      "113 -> 121     1  /   1         3\n",
      "114 -> 121     1  /   1       186\n",
      "115 -> 124     1  /   1        15\n",
      "116 -> 124     1  /   1        31\n",
      "117 -> 123     1  /   1       244\n",
      "118 -> 124     1  /   1        60\n",
      "119 -> 129     4  /   6         0\n",
      "120 -> 129     4  /  43         0\n",
      "121 -> 129     6  /   6         0\n",
      "122 -> 129    17  /  20         0\n",
      "124 -> 129     2  /   4         0\n",
      "125 -> 129    13  /  44         0\n",
      "127 -> 129     2  /   2         0\n",
      "128 -> 129     3  /   8         0\n",
      "[ Raw Info all runs for each dist_type ] :\n",
      "      Dist Type   Gini  Avg Dist  Income_Gap  spatial_index\n",
      "0       Random  0.112      0.76        0.40         0.1601\n",
      "1         LIPA  0.079      0.45        0.26         0.1438\n",
      "2   RoundRobin  0.104      0.76        0.38         0.1438\n",
      "3         MCCA  0.220      0.21        0.69         0.3971\n",
      "4       MCCA-L  0.220      0.21        0.69         0.3971\n",
      "5   FairAssign  0.098      0.40        0.27         0.1595\n",
      "6       Random  0.135      0.81        0.61         0.2126\n",
      "7         LIPA  0.018      0.54        0.06         0.0313\n",
      "8   RoundRobin  0.140      0.80        0.61         0.1988\n",
      "9         MCCA  0.274      0.20        1.05         0.5310\n",
      "10      MCCA-L  0.267      0.20        1.04         0.4922\n",
      "11  FairAssign  0.103      0.36        0.27         0.1427\n",
      "12      Random  0.106      0.76        0.38         0.1514\n",
      "13        LIPA  0.069      0.46        0.24         0.1363\n",
      "14  RoundRobin  0.100      0.77        0.40         0.1360\n",
      "15        MCCA  0.208      0.21        0.61         0.3601\n",
      "16      MCCA-L  0.208      0.21        0.61         0.3598\n",
      "17  FairAssign  0.088      0.41        0.26         0.1399\n",
      "18      Random  0.174      0.95        0.91         0.2705\n",
      "19        LIPA  0.029      0.56        0.10         0.0573\n",
      "20  RoundRobin  0.169      0.95        0.67         0.2456\n",
      "21        MCCA  0.299      0.21        1.45         0.5626\n",
      "22      MCCA-L  0.240      0.22        1.25         0.4655\n",
      "23  FairAssign  0.095      0.41        0.33         0.1364\n",
      "24      Random  0.143      0.84        0.64         0.2163\n",
      "25        LIPA  0.008      0.53        0.02         0.0165\n",
      "26  RoundRobin  0.150      0.84        0.66         0.2232\n",
      "27        MCCA  0.297      0.21        1.37         0.5749\n",
      "28      MCCA-L  0.257      0.21        1.16         0.4896\n",
      "29  FairAssign  0.113      0.38        0.32         0.1704\n",
      "30      Random  0.147      0.91        0.62         0.2165\n",
      "31        LIPA  0.036      0.62        0.08         0.0633\n",
      "32  RoundRobin  0.146      0.91        0.55         0.1941\n",
      "33        MCCA  0.230      0.21        0.81         0.4209\n",
      "34      MCCA-L  0.227      0.22        0.82         0.3952\n",
      "35  FairAssign  0.081      0.45        0.24         0.1257\n",
      "[ Mean for each Dist Type ] :\n",
      "                 Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                                \n",
      "FairAssign  0.096333  0.401667    0.281667       0.145767\n",
      "LIPA        0.039833  0.526667    0.126667       0.074750\n",
      "MCCA        0.254667  0.208333    0.996667       0.474433\n",
      "MCCA-L      0.236500  0.211667    0.928333       0.433233\n",
      "Random      0.136167  0.838333    0.593333       0.204567\n",
      "RoundRobin  0.134833  0.838333    0.545000       0.190250\n",
      "\n",
      "[ Max for each Dist Type ] :\n",
      "              Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                             \n",
      "FairAssign  0.113      0.45        0.33         0.1704\n",
      "LIPA        0.079      0.62        0.26         0.1438\n",
      "MCCA        0.299      0.21        1.45         0.5749\n",
      "MCCA-L      0.267      0.22        1.25         0.4922\n",
      "Random      0.174      0.95        0.91         0.2705\n",
      "RoundRobin  0.169      0.95        0.67         0.2456\n",
      "\n",
      "[ Min for each Dist Type ] :\n",
      "              Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                             \n",
      "FairAssign  0.081      0.36        0.24         0.1257\n",
      "LIPA        0.008      0.45        0.02         0.0165\n",
      "MCCA        0.208      0.20        0.61         0.3601\n",
      "MCCA-L      0.208      0.20        0.61         0.3598\n",
      "Random      0.106      0.76        0.38         0.1514\n",
      "RoundRobin  0.100      0.76        0.38         0.1360\n",
      "\n",
      "Number of Drivers: 110\n",
      "num_constraints: 24616\n",
      "Version identifier: 22.1.0.0 | 2022-03-09 | 1a383f8ce\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "CPXPARAM_Simplex_Tolerances_Markowitz            0.90000000000000002\n",
      "CPXPARAM_Simplex_Tolerances_Optimality           1.0000000000000001e-09\n",
      "CPXPARAM_Simplex_Tolerances_Feasibility          1.0000000000000001e-09\n",
      "Parallel mode: deterministic, using up to 4 threads for concurrent optimization:\n",
      " * Starting dual Simplex on 1 thread...\n",
      " * Starting Barrier on 3 threads...\n",
      "Tried aggregator 1 time.\n",
      "LP Presolve eliminated 0 rows and 48290 columns.\n",
      "Reduced LP has 24616 rows, 12760 columns, and 84920 nonzeros.\n",
      "Presolve time = 0.14 sec. (36.68 ticks)\n",
      "Initializing dual steep norms . . .\n",
      "\n",
      "Iteration log . . .\n",
      "Iteration:     1   Dual objective     =             0.593940\n",
      "Iteration:   294   Dual objective     =             1.389478\n",
      "Iteration:   733   Dual objective     =             1.522977\n",
      "Iteration:  1212   Dual objective     =             1.692899\n",
      "Iteration:  1423   Dual objective     =             1.983618\n",
      "Iteration:  1683   Dual objective     =             2.115763\n",
      "Iteration:  1924   Dual objective     =             2.150133\n",
      "Iteration:  2107   Dual objective     =             2.160666\n",
      "Iteration:  2292   Dual objective     =             2.184419\n",
      "Iteration:  2491   Dual objective     =             2.202345\n",
      "Iteration:  2679   Dual objective     =             2.224585\n",
      "Iteration:  2847   Dual objective     =             2.237471\n",
      "Iteration:  3022   Dual objective     =             2.249559\n",
      "Iteration:  3187   Dual objective     =             2.266083\n",
      "Iteration:  3378   Dual objective     =             2.280920\n",
      "Iteration:  3547   Dual objective     =             2.292479\n",
      "\n",
      "Barrier solved model.\n",
      "\n",
      "Solution Quality: [1.0, 0.0]\n",
      "Status: optimal\n",
      "Everything solved, graphs start\n",
      "max_flow_min_cost cost value: 6205\n",
      "maximum_flow flow value: 110\n",
      "Minimum cost: 6375\n",
      "\n",
      "  Arc    Flow / Capacity  Cost\n",
      "1 -> 2     1  /   1         0\n",
      "1 -> 3     1  /   1         0\n",
      "1 -> 4     1  /   1         0\n",
      "1 -> 5     1  /   1         0\n",
      "1 -> 6     1  /   1         0\n",
      "1 -> 7     1  /   1         0\n",
      "1 -> 8     1  /   1         0\n",
      "1 -> 9     1  /   1         0\n",
      "1 -> 10     1  /   1         0\n",
      "1 -> 11     1  /   1         0\n",
      "1 -> 12     1  /   1         0\n",
      "1 -> 13     1  /   1         0\n",
      "1 -> 14     1  /   1         0\n",
      "1 -> 15     1  /   1         0\n",
      "1 -> 16     1  /   1         0\n",
      "1 -> 17     1  /   1         0\n",
      "1 -> 18     1  /   1         0\n",
      "1 -> 19     1  /   1         0\n",
      "1 -> 20     1  /   1         0\n",
      "1 -> 21     1  /   1         0\n",
      "1 -> 22     1  /   1         0\n",
      "1 -> 23     1  /   1         0\n",
      "1 -> 24     1  /   1         0\n",
      "1 -> 25     1  /   1         0\n",
      "1 -> 26     1  /   1         0\n",
      "1 -> 27     1  /   1         0\n",
      "1 -> 28     1  /   1         0\n",
      "1 -> 29     1  /   1         0\n",
      "1 -> 30     1  /   1         0\n",
      "1 -> 31     1  /   1         0\n",
      "1 -> 32     1  /   1         0\n",
      "1 -> 33     1  /   1         0\n",
      "1 -> 34     1  /   1         0\n",
      "1 -> 35     1  /   1         0\n",
      "1 -> 36     1  /   1         0\n",
      "1 -> 37     1  /   1         0\n",
      "1 -> 38     1  /   1         0\n",
      "1 -> 39     1  /   1         0\n",
      "1 -> 40     1  /   1         0\n",
      "1 -> 41     1  /   1         0\n",
      "1 -> 42     1  /   1         0\n",
      "1 -> 43     1  /   1         0\n",
      "1 -> 44     1  /   1         0\n",
      "1 -> 45     1  /   1         0\n",
      "1 -> 46     1  /   1         0\n",
      "1 -> 47     1  /   1         0\n",
      "1 -> 48     1  /   1         0\n",
      "1 -> 49     1  /   1         0\n",
      "1 -> 50     1  /   1         0\n",
      "1 -> 51     1  /   1         0\n",
      "1 -> 52     1  /   1         0\n",
      "1 -> 53     1  /   1         0\n",
      "1 -> 54     1  /   1         0\n",
      "1 -> 55     1  /   1         0\n",
      "1 -> 56     1  /   1         0\n",
      "1 -> 57     1  /   1         0\n",
      "1 -> 58     1  /   1         0\n",
      "1 -> 59     1  /   1         0\n",
      "1 -> 60     1  /   1         0\n",
      "1 -> 61     1  /   1         0\n",
      "1 -> 62     1  /   1         0\n",
      "1 -> 63     1  /   1         0\n",
      "1 -> 64     1  /   1         0\n",
      "1 -> 65     1  /   1         0\n",
      "1 -> 66     1  /   1         0\n",
      "1 -> 67     1  /   1         0\n",
      "1 -> 68     1  /   1         0\n",
      "1 -> 69     1  /   1         0\n",
      "1 -> 70     1  /   1         0\n",
      "1 -> 71     1  /   1         0\n",
      "1 -> 72     1  /   1         0\n",
      "1 -> 73     1  /   1         0\n",
      "1 -> 74     1  /   1         0\n",
      "1 -> 75     1  /   1         0\n",
      "1 -> 76     1  /   1         0\n",
      "1 -> 77     1  /   1         0\n",
      "1 -> 78     1  /   1         0\n",
      "1 -> 79     1  /   1         0\n",
      "1 -> 80     1  /   1         0\n",
      "1 -> 81     1  /   1         0\n",
      "1 -> 82     1  /   1         0\n",
      "1 -> 83     1  /   1         0\n",
      "1 -> 84     1  /   1         0\n",
      "1 -> 85     1  /   1         0\n",
      "1 -> 86     1  /   1         0\n",
      "1 -> 87     1  /   1         0\n",
      "1 -> 88     1  /   1         0\n",
      "1 -> 89     1  /   1         0\n",
      "1 -> 90     1  /   1         0\n",
      "1 -> 91     1  /   1         0\n",
      "1 -> 92     1  /   1         0\n",
      "1 -> 93     1  /   1         0\n",
      "1 -> 94     1  /   1         0\n",
      "1 -> 95     1  /   1         0\n",
      "1 -> 96     1  /   1         0\n",
      "1 -> 97     1  /   1         0\n",
      "1 -> 98     1  /   1         0\n",
      "1 -> 99     1  /   1         0\n",
      "1 -> 100     1  /   1         0\n",
      "1 -> 101     1  /   1         0\n",
      "1 -> 102     1  /   1         0\n",
      "1 -> 103     1  /   1         0\n",
      "1 -> 104     1  /   1         0\n",
      "1 -> 105     1  /   1         0\n",
      "1 -> 106     1  /   1         0\n",
      "1 -> 107     1  /   1         0\n",
      "1 -> 108     1  /   1         0\n",
      "1 -> 109     1  /   1         0\n",
      "1 -> 110     1  /   1         0\n",
      "1 -> 111     1  /   1         0\n",
      "2 -> 115     1  /   1       305\n",
      "3 -> 113     1  /   1        66\n",
      "4 -> 113     1  /   1        24\n",
      "5 -> 115     1  /   1       116\n",
      "6 -> 113     1  /   1        57\n",
      "7 -> 115     1  /   1        29\n",
      "8 -> 118     1  /   1        86\n",
      "9 -> 118     1  /   1        14\n",
      "10 -> 115     1  /   1        15\n",
      "11 -> 118     1  /   1        71\n",
      "12 -> 118     1  /   1        24\n",
      "13 -> 115     1  /   1        57\n",
      "14 -> 113     1  /   1        54\n",
      "15 -> 113     1  /   1        13\n",
      "16 -> 115     1  /   1        31\n",
      "17 -> 118     1  /   1        86\n",
      "18 -> 118     1  /   1        72\n",
      "19 -> 118     1  /   1        79\n",
      "20 -> 118     1  /   1        26\n",
      "21 -> 113     1  /   1        33\n",
      "22 -> 118     1  /   1        36\n",
      "23 -> 113     1  /   1        15\n",
      "24 -> 113     1  /   1        88\n",
      "25 -> 115     1  /   1        38\n",
      "26 -> 118     1  /   1        86\n",
      "27 -> 118     1  /   1        66\n",
      "28 -> 113     1  /   1        33\n",
      "29 -> 118     1  /   1         8\n",
      "30 -> 113     1  /   1        98\n",
      "31 -> 113     1  /   1        15\n",
      "32 -> 115     1  /   1        16\n",
      "33 -> 113     1  /   1         4\n",
      "34 -> 118     1  /   1        21\n",
      "35 -> 115     1  /   1        16\n",
      "36 -> 113     1  /   1        19\n",
      "37 -> 115     1  /   1        37\n",
      "38 -> 115     1  /   1        74\n",
      "39 -> 118     1  /   1       104\n",
      "40 -> 118     1  /   1       124\n",
      "41 -> 113     1  /   1       164\n",
      "42 -> 113     1  /   1        94\n",
      "43 -> 113     1  /   1        47\n",
      "44 -> 113     1  /   1       200\n",
      "45 -> 113     1  /   1       215\n",
      "46 -> 112     1  /   1        35\n",
      "47 -> 113     1  /   1         7\n",
      "48 -> 118     1  /   1        29\n",
      "49 -> 121     1  /   1        34\n",
      "50 -> 118     1  /   1        46\n",
      "51 -> 115     1  /   1        55\n",
      "52 -> 115     1  /   1         0\n",
      "53 -> 118     1  /   1         8\n",
      "54 -> 115     1  /   1        21\n",
      "55 -> 118     1  /   1        29\n",
      "56 -> 113     1  /   1        41\n",
      "57 -> 118     1  /   1         9\n",
      "58 -> 115     1  /   1         4\n",
      "59 -> 118     1  /   1         0\n",
      "60 -> 121     1  /   1        30\n",
      "61 -> 121     1  /   1        22\n",
      "62 -> 118     1  /   1         3\n",
      "63 -> 115     1  /   1        10\n",
      "64 -> 118     1  /   1         8\n",
      "65 -> 121     1  /   1        54\n",
      "66 -> 118     1  /   1        35\n",
      "67 -> 118     1  /   1         3\n",
      "68 -> 115     1  /   1        39\n",
      "69 -> 118     1  /   1        43\n",
      "70 -> 115     1  /   1         2\n",
      "71 -> 115     1  /   1         9\n",
      "72 -> 118     1  /   1        17\n",
      "73 -> 115     1  /   1         4\n",
      "74 -> 113     1  /   1        54\n",
      "75 -> 113     1  /   1        33\n",
      "76 -> 118     1  /   1         6\n",
      "77 -> 115     1  /   1        24\n",
      "78 -> 115     1  /   1        18\n",
      "79 -> 118     1  /   1        44\n",
      "80 -> 115     1  /   1        72\n",
      "81 -> 121     1  /   1        37\n",
      "82 -> 121     1  /   1        27\n",
      "83 -> 118     1  /   1        48\n",
      "84 -> 118     1  /   1        14\n",
      "85 -> 115     1  /   1        53\n",
      "86 -> 118     1  /   1         8\n",
      "87 -> 113     1  /   1        52\n",
      "88 -> 118     1  /   1        14\n",
      "89 -> 115     1  /   1        12\n",
      "90 -> 121     1  /   1        58\n",
      "91 -> 121     1  /   1        57\n",
      "92 -> 113     1  /   1       133\n",
      "93 -> 113     1  /   1       241\n",
      "94 -> 119     1  /   1        79\n",
      "95 -> 119     1  /   1       209\n",
      "96 -> 112     1  /   1       118\n",
      "97 -> 112     1  /   1        89\n",
      "98 -> 112     1  /   1       321\n",
      "99 -> 112     1  /   1        29\n",
      "100 -> 121     1  /   1       106\n",
      "101 -> 121     1  /   1       228\n",
      "102 -> 121     1  /   1       109\n",
      "103 -> 120     1  /   1       135\n",
      "104 -> 114     1  /   1         4\n",
      "105 -> 114     1  /   1        37\n",
      "106 -> 114     1  /   1        19\n",
      "107 -> 121     1  /   1        78\n",
      "108 -> 117     1  /   1        39\n",
      "109 -> 117     1  /   1        17\n",
      "110 -> 117     1  /   1        68\n",
      "111 -> 116     1  /   1       212\n",
      "112 -> 122     2  /   6         0\n",
      "113 -> 122     4  /  43         0\n",
      "114 -> 122     1  /   6         0\n",
      "115 -> 122    15  /  20         0\n",
      "117 -> 122     2  /   4         0\n",
      "118 -> 122    12  /  44         0\n",
      "121 -> 122     8  /   8         0\n",
      "[ Raw Info all runs for each dist_type ] :\n",
      "      Dist Type   Gini  Avg Dist  Income_Gap  spatial_index\n",
      "0       Random  0.112      0.76        0.40         0.1601\n",
      "1         LIPA  0.079      0.45        0.26         0.1438\n",
      "2   RoundRobin  0.104      0.76        0.38         0.1438\n",
      "3         MCCA  0.220      0.21        0.69         0.3971\n",
      "4       MCCA-L  0.220      0.21        0.69         0.3971\n",
      "5   FairAssign  0.098      0.40        0.27         0.1595\n",
      "6       Random  0.135      0.81        0.61         0.2126\n",
      "7         LIPA  0.018      0.54        0.06         0.0313\n",
      "8   RoundRobin  0.140      0.80        0.61         0.1988\n",
      "9         MCCA  0.274      0.20        1.05         0.5310\n",
      "10      MCCA-L  0.267      0.20        1.04         0.4922\n",
      "11  FairAssign  0.103      0.36        0.27         0.1427\n",
      "12      Random  0.106      0.76        0.38         0.1514\n",
      "13        LIPA  0.069      0.46        0.24         0.1363\n",
      "14  RoundRobin  0.100      0.77        0.40         0.1360\n",
      "15        MCCA  0.208      0.21        0.61         0.3601\n",
      "16      MCCA-L  0.208      0.21        0.61         0.3598\n",
      "17  FairAssign  0.088      0.41        0.26         0.1399\n",
      "18      Random  0.174      0.95        0.91         0.2705\n",
      "19        LIPA  0.029      0.56        0.10         0.0573\n",
      "20  RoundRobin  0.169      0.95        0.67         0.2456\n",
      "21        MCCA  0.299      0.21        1.45         0.5626\n",
      "22      MCCA-L  0.240      0.22        1.25         0.4655\n",
      "23  FairAssign  0.095      0.41        0.33         0.1364\n",
      "24      Random  0.143      0.84        0.64         0.2163\n",
      "25        LIPA  0.008      0.53        0.02         0.0165\n",
      "26  RoundRobin  0.150      0.84        0.66         0.2232\n",
      "27        MCCA  0.297      0.21        1.37         0.5749\n",
      "28      MCCA-L  0.257      0.21        1.16         0.4896\n",
      "29  FairAssign  0.113      0.38        0.32         0.1704\n",
      "30      Random  0.147      0.91        0.62         0.2165\n",
      "31        LIPA  0.036      0.62        0.08         0.0633\n",
      "32  RoundRobin  0.146      0.91        0.55         0.1941\n",
      "33        MCCA  0.230      0.21        0.81         0.4209\n",
      "34      MCCA-L  0.227      0.22        0.82         0.3952\n",
      "35  FairAssign  0.081      0.45        0.24         0.1257\n",
      "36      Random  0.152      0.87        0.66         0.2226\n",
      "37        LIPA  0.004      0.57        0.01         0.0083\n",
      "38  RoundRobin  0.156      0.88        0.62         0.2161\n",
      "39        MCCA  0.231      0.21        0.90         0.4657\n",
      "40      MCCA-L  0.229      0.21        0.91         0.4158\n",
      "41  FairAssign  0.124      0.38        0.39         0.1485\n",
      "[ Mean for each Dist Type ] :\n",
      "                 Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                                \n",
      "FairAssign  0.100286  0.398571    0.297143       0.146157\n",
      "LIPA        0.034714  0.532857    0.110000       0.065257\n",
      "MCCA        0.251286  0.208571    0.982857       0.473186\n",
      "MCCA-L      0.235429  0.211429    0.925714       0.430743\n",
      "Random      0.138429  0.842857    0.602857       0.207143\n",
      "RoundRobin  0.137857  0.844286    0.555714       0.193943\n",
      "\n",
      "[ Max for each Dist Type ] :\n",
      "              Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                             \n",
      "FairAssign  0.124      0.45        0.39         0.1704\n",
      "LIPA        0.079      0.62        0.26         0.1438\n",
      "MCCA        0.299      0.21        1.45         0.5749\n",
      "MCCA-L      0.267      0.22        1.25         0.4922\n",
      "Random      0.174      0.95        0.91         0.2705\n",
      "RoundRobin  0.169      0.95        0.67         0.2456\n",
      "\n",
      "[ Min for each Dist Type ] :\n",
      "              Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                             \n",
      "FairAssign  0.081      0.36        0.24         0.1257\n",
      "LIPA        0.004      0.45        0.01         0.0083\n",
      "MCCA        0.208      0.20        0.61         0.3601\n",
      "MCCA-L      0.208      0.20        0.61         0.3598\n",
      "Random      0.106      0.76        0.38         0.1514\n",
      "RoundRobin  0.100      0.76        0.38         0.1360\n",
      "\n",
      "Number of Drivers: 120\n",
      "num_constraints: 31157\n",
      "Version identifier: 22.1.0.0 | 2022-03-09 | 1a383f8ce\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "CPXPARAM_Simplex_Tolerances_Markowitz            0.90000000000000002\n",
      "CPXPARAM_Simplex_Tolerances_Optimality           1.0000000000000001e-09\n",
      "CPXPARAM_Simplex_Tolerances_Feasibility          1.0000000000000001e-09\n",
      "Parallel mode: deterministic, using up to 4 threads for concurrent optimization:\n",
      " * Starting dual Simplex on 1 thread...\n",
      " * Starting Barrier on 3 threads...\n",
      "Tried aggregator 1 time.\n",
      "LP Presolve eliminated 0 rows and 56630 columns.\n",
      "Reduced LP has 31157 rows, 15970 columns, and 106990 nonzeros.\n",
      "Presolve time = 0.16 sec. (45.49 ticks)\n",
      "Initializing dual steep norms . . .\n",
      "\n",
      "Iteration log . . .\n",
      "Iteration:     1   Dual objective     =             0.673815\n",
      "Iteration:   253   Dual objective     =             1.336743\n",
      "Iteration:   718   Dual objective     =             1.768747\n",
      "Iteration:  1211   Dual objective     =             1.931808\n",
      "Iteration:  1649   Dual objective     =             2.042850\n",
      "Iteration:  1878   Dual objective     =             2.120367\n",
      "Iteration:  2100   Dual objective     =             2.188833\n",
      "Iteration:  2345   Dual objective     =             2.267919\n",
      "Iteration:  2553   Dual objective     =             2.309263\n",
      "Iteration:  2746   Dual objective     =             2.329608\n",
      "Iteration:  2950   Dual objective     =             2.348927\n",
      "Iteration:  3130   Dual objective     =             2.379380\n",
      "Iteration:  3321   Dual objective     =             2.413012\n",
      "Iteration:  3518   Dual objective     =             2.470828\n",
      "Iteration:  3709   Dual objective     =             2.528515\n",
      "Iteration:  3946   Dual objective     =             2.544015\n",
      "\n",
      "Barrier solved model.\n",
      "\n",
      "Solution Quality: [0.917612779862639, 0.0]\n",
      "Status: optimal\n",
      "Everything solved, graphs start\n",
      "max_flow_min_cost cost value: 6967\n",
      "maximum_flow flow value: 120\n",
      "Minimum cost: 7513\n",
      "\n",
      "  Arc    Flow / Capacity  Cost\n",
      "1 -> 2     1  /   1         0\n",
      "1 -> 3     1  /   1         0\n",
      "1 -> 4     1  /   1         0\n",
      "1 -> 5     1  /   1         0\n",
      "1 -> 6     1  /   1         0\n",
      "1 -> 7     1  /   1         0\n",
      "1 -> 8     1  /   1         0\n",
      "1 -> 9     1  /   1         0\n",
      "1 -> 10     1  /   1         0\n",
      "1 -> 11     1  /   1         0\n",
      "1 -> 12     1  /   1         0\n",
      "1 -> 13     1  /   1         0\n",
      "1 -> 14     1  /   1         0\n",
      "1 -> 15     1  /   1         0\n",
      "1 -> 16     1  /   1         0\n",
      "1 -> 17     1  /   1         0\n",
      "1 -> 18     1  /   1         0\n",
      "1 -> 19     1  /   1         0\n",
      "1 -> 20     1  /   1         0\n",
      "1 -> 21     1  /   1         0\n",
      "1 -> 22     1  /   1         0\n",
      "1 -> 23     1  /   1         0\n",
      "1 -> 24     1  /   1         0\n",
      "1 -> 25     1  /   1         0\n",
      "1 -> 26     1  /   1         0\n",
      "1 -> 27     1  /   1         0\n",
      "1 -> 28     1  /   1         0\n",
      "1 -> 29     1  /   1         0\n",
      "1 -> 30     1  /   1         0\n",
      "1 -> 31     1  /   1         0\n",
      "1 -> 32     1  /   1         0\n",
      "1 -> 33     1  /   1         0\n",
      "1 -> 34     1  /   1         0\n",
      "1 -> 35     1  /   1         0\n",
      "1 -> 36     1  /   1         0\n",
      "1 -> 37     1  /   1         0\n",
      "1 -> 38     1  /   1         0\n",
      "1 -> 39     1  /   1         0\n",
      "1 -> 40     1  /   1         0\n",
      "1 -> 41     1  /   1         0\n",
      "1 -> 42     1  /   1         0\n",
      "1 -> 43     1  /   1         0\n",
      "1 -> 44     1  /   1         0\n",
      "1 -> 45     1  /   1         0\n",
      "1 -> 46     1  /   1         0\n",
      "1 -> 47     1  /   1         0\n",
      "1 -> 48     1  /   1         0\n",
      "1 -> 49     1  /   1         0\n",
      "1 -> 50     1  /   1         0\n",
      "1 -> 51     1  /   1         0\n",
      "1 -> 52     1  /   1         0\n",
      "1 -> 53     1  /   1         0\n",
      "1 -> 54     1  /   1         0\n",
      "1 -> 55     1  /   1         0\n",
      "1 -> 56     1  /   1         0\n",
      "1 -> 57     1  /   1         0\n",
      "1 -> 58     1  /   1         0\n",
      "1 -> 59     1  /   1         0\n",
      "1 -> 60     1  /   1         0\n",
      "1 -> 61     1  /   1         0\n",
      "1 -> 62     1  /   1         0\n",
      "1 -> 63     1  /   1         0\n",
      "1 -> 64     1  /   1         0\n",
      "1 -> 65     1  /   1         0\n",
      "1 -> 66     1  /   1         0\n",
      "1 -> 67     1  /   1         0\n",
      "1 -> 68     1  /   1         0\n",
      "1 -> 69     1  /   1         0\n",
      "1 -> 70     1  /   1         0\n",
      "1 -> 71     1  /   1         0\n",
      "1 -> 72     1  /   1         0\n",
      "1 -> 73     1  /   1         0\n",
      "1 -> 74     1  /   1         0\n",
      "1 -> 75     1  /   1         0\n",
      "1 -> 76     1  /   1         0\n",
      "1 -> 77     1  /   1         0\n",
      "1 -> 78     1  /   1         0\n",
      "1 -> 79     1  /   1         0\n",
      "1 -> 80     1  /   1         0\n",
      "1 -> 81     1  /   1         0\n",
      "1 -> 82     1  /   1         0\n",
      "1 -> 83     1  /   1         0\n",
      "1 -> 84     1  /   1         0\n",
      "1 -> 85     1  /   1         0\n",
      "1 -> 86     1  /   1         0\n",
      "1 -> 87     1  /   1         0\n",
      "1 -> 88     1  /   1         0\n",
      "1 -> 89     1  /   1         0\n",
      "1 -> 90     1  /   1         0\n",
      "1 -> 91     1  /   1         0\n",
      "1 -> 92     1  /   1         0\n",
      "1 -> 93     1  /   1         0\n",
      "1 -> 94     1  /   1         0\n",
      "1 -> 95     1  /   1         0\n",
      "1 -> 96     1  /   1         0\n",
      "1 -> 97     1  /   1         0\n",
      "1 -> 98     1  /   1         0\n",
      "1 -> 99     1  /   1         0\n",
      "1 -> 100     1  /   1         0\n",
      "1 -> 101     1  /   1         0\n",
      "1 -> 102     1  /   1         0\n",
      "1 -> 103     1  /   1         0\n",
      "1 -> 104     1  /   1         0\n",
      "1 -> 105     1  /   1         0\n",
      "1 -> 106     1  /   1         0\n",
      "1 -> 107     1  /   1         0\n",
      "1 -> 108     1  /   1         0\n",
      "1 -> 109     1  /   1         0\n",
      "1 -> 110     1  /   1         0\n",
      "1 -> 111     1  /   1         0\n",
      "1 -> 112     1  /   1         0\n",
      "1 -> 113     1  /   1         0\n",
      "1 -> 114     1  /   1         0\n",
      "1 -> 115     1  /   1         0\n",
      "1 -> 116     1  /   1         0\n",
      "1 -> 117     1  /   1         0\n",
      "1 -> 118     1  /   1         0\n",
      "1 -> 119     1  /   1         0\n",
      "1 -> 120     1  /   1         0\n",
      "1 -> 121     1  /   1         0\n",
      "2 -> 128     1  /   1        32\n",
      "3 -> 125     1  /   1        21\n",
      "4 -> 128     1  /   1        31\n",
      "5 -> 125     1  /   1        32\n",
      "6 -> 128     1  /   1        55\n",
      "7 -> 128     1  /   1        50\n",
      "8 -> 128     1  /   1       130\n",
      "9 -> 128     1  /   1         4\n",
      "10 -> 125     1  /   1        87\n",
      "11 -> 128     1  /   1        53\n",
      "12 -> 128     1  /   1        57\n",
      "13 -> 128     1  /   1        22\n",
      "14 -> 125     1  /   1        38\n",
      "15 -> 123     1  /   1        75\n",
      "16 -> 128     1  /   1       103\n",
      "17 -> 128     1  /   1        28\n",
      "18 -> 128     1  /   1       127\n",
      "19 -> 128     1  /   1         0\n",
      "20 -> 128     1  /   1       115\n",
      "21 -> 128     1  /   1        64\n",
      "22 -> 128     1  /   1       100\n",
      "23 -> 123     1  /   1        31\n",
      "24 -> 123     1  /   1        62\n",
      "25 -> 128     1  /   1        87\n",
      "26 -> 128     1  /   1        50\n",
      "27 -> 128     1  /   1        57\n",
      "28 -> 123     1  /   1        89\n",
      "29 -> 128     1  /   1        24\n",
      "30 -> 128     1  /   1       109\n",
      "31 -> 128     1  /   1        26\n",
      "32 -> 123     1  /   1        66\n",
      "33 -> 123     1  /   1        17\n",
      "34 -> 128     1  /   1        45\n",
      "35 -> 128     1  /   1         8\n",
      "36 -> 125     1  /   1        32\n",
      "37 -> 125     1  /   1        31\n",
      "38 -> 125     1  /   1        17\n",
      "39 -> 128     1  /   1        60\n",
      "40 -> 128     1  /   1        27\n",
      "41 -> 123     1  /   1        54\n",
      "42 -> 123     1  /   1        44\n",
      "43 -> 129     1  /   1       248\n",
      "44 -> 123     1  /   1       172\n",
      "45 -> 123     1  /   1       206\n",
      "46 -> 123     1  /   1         4\n",
      "47 -> 123     1  /   1        14\n",
      "48 -> 123     1  /   1        53\n",
      "49 -> 125     1  /   1        30\n",
      "50 -> 122     1  /   1       115\n",
      "51 -> 125     1  /   1        45\n",
      "52 -> 125     1  /   1        26\n",
      "53 -> 128     1  /   1         6\n",
      "54 -> 125     1  /   1         3\n",
      "55 -> 128     1  /   1        13\n",
      "56 -> 125     1  /   1        15\n",
      "57 -> 125     1  /   1        54\n",
      "58 -> 128     1  /   1        52\n",
      "59 -> 125     1  /   1         3\n",
      "60 -> 131     1  /   1        50\n",
      "61 -> 125     1  /   1         7\n",
      "62 -> 131     1  /   1        27\n",
      "63 -> 128     1  /   1        62\n",
      "64 -> 125     1  /   1        52\n",
      "65 -> 125     1  /   1        11\n",
      "66 -> 123     1  /   1        27\n",
      "67 -> 128     1  /   1         8\n",
      "68 -> 125     1  /   1        44\n",
      "69 -> 128     1  /   1        36\n",
      "70 -> 125     1  /   1        61\n",
      "71 -> 123     1  /   1        49\n",
      "72 -> 128     1  /   1         3\n",
      "73 -> 125     1  /   1        18\n",
      "74 -> 125     1  /   1        48\n",
      "75 -> 125     1  /   1        11\n",
      "76 -> 128     1  /   1        29\n",
      "77 -> 128     1  /   1         7\n",
      "78 -> 128     1  /   1        28\n",
      "79 -> 131     1  /   1        17\n",
      "80 -> 131     1  /   1        73\n",
      "81 -> 128     1  /   1        14\n",
      "82 -> 125     1  /   1        31\n",
      "83 -> 131     1  /   1        35\n",
      "84 -> 131     1  /   1        19\n",
      "85 -> 128     1  /   1         3\n",
      "86 -> 131     1  /   1        21\n",
      "87 -> 125     1  /   1        10\n",
      "88 -> 128     1  /   1        15\n",
      "89 -> 125     1  /   1         7\n",
      "90 -> 128     1  /   1        10\n",
      "91 -> 123     1  /   1        22\n",
      "92 -> 131     1  /   1        64\n",
      "93 -> 128     1  /   1        51\n",
      "94 -> 131     1  /   1        79\n",
      "95 -> 125     1  /   1        23\n",
      "96 -> 123     1  /   1        31\n",
      "97 -> 125     1  /   1        16\n",
      "98 -> 125     1  /   1         5\n",
      "99 -> 125     1  /   1        29\n",
      "100 -> 123     1  /   1       168\n",
      "101 -> 131     1  /   1        26\n",
      "102 -> 123     1  /   1         7\n",
      "103 -> 123     1  /   1        87\n",
      "104 -> 123     1  /   1       147\n",
      "105 -> 129     1  /   1       117\n",
      "106 -> 124     1  /   1       159\n",
      "107 -> 122     1  /   1        57\n",
      "108 -> 122     1  /   1       178\n",
      "109 -> 131     1  /   1       344\n",
      "110 -> 122     1  /   1       135\n",
      "111 -> 122     1  /   1       106\n",
      "112 -> 125     1  /   1       213\n",
      "113 -> 122     1  /   1       336\n",
      "114 -> 131     1  /   1       105\n",
      "115 -> 130     1  /   1        57\n",
      "116 -> 130     1  /   1        69\n",
      "117 -> 124     1  /   1        78\n",
      "118 -> 124     1  /   1        50\n",
      "119 -> 127     1  /   1       463\n",
      "120 -> 130     1  /   1        28\n",
      "121 -> 126     1  /   1       211\n",
      "122 -> 132     3  /   6         0\n",
      "124 -> 132     1  /   6         0\n",
      "125 -> 132    20  /  20         0\n",
      "128 -> 132    20  /  44         0\n",
      "130 -> 132     2  /   2         0\n",
      "131 -> 132     8  /   8         0\n",
      "[ Raw Info all runs for each dist_type ] :\n",
      "      Dist Type   Gini  Avg Dist  Income_Gap  spatial_index\n",
      "0       Random  0.112      0.76        0.40         0.1601\n",
      "1         LIPA  0.079      0.45        0.26         0.1438\n",
      "2   RoundRobin  0.104      0.76        0.38         0.1438\n",
      "3         MCCA  0.220      0.21        0.69         0.3971\n",
      "4       MCCA-L  0.220      0.21        0.69         0.3971\n",
      "5   FairAssign  0.098      0.40        0.27         0.1595\n",
      "6       Random  0.135      0.81        0.61         0.2126\n",
      "7         LIPA  0.018      0.54        0.06         0.0313\n",
      "8   RoundRobin  0.140      0.80        0.61         0.1988\n",
      "9         MCCA  0.274      0.20        1.05         0.5310\n",
      "10      MCCA-L  0.267      0.20        1.04         0.4922\n",
      "11  FairAssign  0.103      0.36        0.27         0.1427\n",
      "12      Random  0.106      0.76        0.38         0.1514\n",
      "13        LIPA  0.069      0.46        0.24         0.1363\n",
      "14  RoundRobin  0.100      0.77        0.40         0.1360\n",
      "15        MCCA  0.208      0.21        0.61         0.3601\n",
      "16      MCCA-L  0.208      0.21        0.61         0.3598\n",
      "17  FairAssign  0.088      0.41        0.26         0.1399\n",
      "18      Random  0.174      0.95        0.91         0.2705\n",
      "19        LIPA  0.029      0.56        0.10         0.0573\n",
      "20  RoundRobin  0.169      0.95        0.67         0.2456\n",
      "21        MCCA  0.299      0.21        1.45         0.5626\n",
      "22      MCCA-L  0.240      0.22        1.25         0.4655\n",
      "23  FairAssign  0.095      0.41        0.33         0.1364\n",
      "24      Random  0.143      0.84        0.64         0.2163\n",
      "25        LIPA  0.008      0.53        0.02         0.0165\n",
      "26  RoundRobin  0.150      0.84        0.66         0.2232\n",
      "27        MCCA  0.297      0.21        1.37         0.5749\n",
      "28      MCCA-L  0.257      0.21        1.16         0.4896\n",
      "29  FairAssign  0.113      0.38        0.32         0.1704\n",
      "30      Random  0.147      0.91        0.62         0.2165\n",
      "31        LIPA  0.036      0.62        0.08         0.0633\n",
      "32  RoundRobin  0.146      0.91        0.55         0.1941\n",
      "33        MCCA  0.230      0.21        0.81         0.4209\n",
      "34      MCCA-L  0.227      0.22        0.82         0.3952\n",
      "35  FairAssign  0.081      0.45        0.24         0.1257\n",
      "36      Random  0.152      0.87        0.66         0.2226\n",
      "37        LIPA  0.004      0.57        0.01         0.0083\n",
      "38  RoundRobin  0.156      0.88        0.62         0.2161\n",
      "39        MCCA  0.231      0.21        0.90         0.4657\n",
      "40      MCCA-L  0.229      0.21        0.91         0.4158\n",
      "41  FairAssign  0.124      0.38        0.39         0.1485\n",
      "42      Random  0.132      0.80        0.56         0.2076\n",
      "43        LIPA  0.019      0.55        0.06         0.0329\n",
      "44  RoundRobin  0.140      0.80        0.59         0.1993\n",
      "45        MCCA  0.266      0.22        1.02         0.5073\n",
      "46      MCCA-L  0.261      0.22        0.97         0.4732\n",
      "47  FairAssign  0.095      0.41        0.32         0.1444\n",
      "[ Mean for each Dist Type ] :\n",
      "                 Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                                \n",
      "FairAssign  0.099625   0.40000     0.30000       0.145937\n",
      "LIPA        0.032750   0.53500     0.10375       0.061213\n",
      "MCCA        0.253125   0.21000     0.98750       0.477450\n",
      "MCCA-L      0.238625   0.21250     0.93125       0.436050\n",
      "Random      0.137625   0.83750     0.59750       0.207200\n",
      "RoundRobin  0.138125   0.83875     0.56000       0.194612\n",
      "\n",
      "[ Max for each Dist Type ] :\n",
      "              Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                             \n",
      "FairAssign  0.124      0.45        0.39         0.1704\n",
      "LIPA        0.079      0.62        0.26         0.1438\n",
      "MCCA        0.299      0.22        1.45         0.5749\n",
      "MCCA-L      0.267      0.22        1.25         0.4922\n",
      "Random      0.174      0.95        0.91         0.2705\n",
      "RoundRobin  0.169      0.95        0.67         0.2456\n",
      "\n",
      "[ Min for each Dist Type ] :\n",
      "              Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                             \n",
      "FairAssign  0.081      0.36        0.24         0.1257\n",
      "LIPA        0.004      0.45        0.01         0.0083\n",
      "MCCA        0.208      0.20        0.61         0.3601\n",
      "MCCA-L      0.208      0.20        0.61         0.3598\n",
      "Random      0.106      0.76        0.38         0.1514\n",
      "RoundRobin  0.100      0.76        0.38         0.1360\n",
      "\n",
      "Number of Drivers: 138\n",
      "num_constraints: 42431\n",
      "Version identifier: 22.1.0.0 | 2022-03-09 | 1a383f8ce\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "CPXPARAM_Simplex_Tolerances_Markowitz            0.90000000000000002\n",
      "CPXPARAM_Simplex_Tolerances_Optimality           1.0000000000000001e-09\n",
      "CPXPARAM_Simplex_Tolerances_Feasibility          1.0000000000000001e-09\n",
      "Parallel mode: deterministic, using up to 4 threads for concurrent optimization:\n",
      " * Starting dual Simplex on 1 thread...\n",
      " * Starting Barrier on 3 threads...\n",
      "Tried aggregator 1 time.\n",
      "LP Presolve eliminated 0 rows and 74400 columns.\n",
      "Reduced LP has 42431 rows, 21510 columns, and 145050 nonzeros.\n",
      "Presolve time = 0.30 sec. (61.36 ticks)\n",
      "Initializing dual steep norms . . .\n",
      "\n",
      "Iteration log . . .\n",
      "Iteration:     1   Dual objective     =             0.537914\n",
      "Iteration:   286   Dual objective     =             1.311511\n",
      "Iteration:   768   Dual objective     =             1.653910\n",
      "Iteration:  1332   Dual objective     =             1.755919\n",
      "Iteration:  1568   Dual objective     =             1.884841\n",
      "Iteration:  1848   Dual objective     =             2.043364\n",
      "Iteration:  2130   Dual objective     =             2.057886\n",
      "Iteration:  2363   Dual objective     =             2.068087\n",
      "Iteration:  2612   Dual objective     =             2.076040\n",
      "Iteration:  2903   Dual objective     =             2.096995\n",
      "Iteration:  3193   Dual objective     =             2.114693\n",
      "Iteration:  3516   Dual objective     =             2.126439\n",
      "Iteration:  3769   Dual objective     =             2.211282\n",
      "Iteration:  3987   Dual objective     =             2.243740\n",
      "Iteration:  4250   Dual objective     =             2.391489\n",
      "Iteration:  4499   Dual objective     =             2.475392\n",
      "\n",
      "Barrier solved model.\n",
      "\n",
      "Solution Quality: [1.0, 0.0]\n",
      "Status: optimal\n",
      "Everything solved, graphs start\n",
      "max_flow_min_cost cost value: 6880\n",
      "maximum_flow flow value: 138\n",
      "Minimum cost: 7632\n",
      "\n",
      "  Arc    Flow / Capacity  Cost\n",
      "1 -> 2     1  /   1         0\n",
      "1 -> 3     1  /   1         0\n",
      "1 -> 4     1  /   1         0\n",
      "1 -> 5     1  /   1         0\n",
      "1 -> 6     1  /   1         0\n",
      "1 -> 7     1  /   1         0\n",
      "1 -> 8     1  /   1         0\n",
      "1 -> 9     1  /   1         0\n",
      "1 -> 10     1  /   1         0\n",
      "1 -> 11     1  /   1         0\n",
      "1 -> 12     1  /   1         0\n",
      "1 -> 13     1  /   1         0\n",
      "1 -> 14     1  /   1         0\n",
      "1 -> 15     1  /   1         0\n",
      "1 -> 16     1  /   1         0\n",
      "1 -> 17     1  /   1         0\n",
      "1 -> 18     1  /   1         0\n",
      "1 -> 19     1  /   1         0\n",
      "1 -> 20     1  /   1         0\n",
      "1 -> 21     1  /   1         0\n",
      "1 -> 22     1  /   1         0\n",
      "1 -> 23     1  /   1         0\n",
      "1 -> 24     1  /   1         0\n",
      "1 -> 25     1  /   1         0\n",
      "1 -> 26     1  /   1         0\n",
      "1 -> 27     1  /   1         0\n",
      "1 -> 28     1  /   1         0\n",
      "1 -> 29     1  /   1         0\n",
      "1 -> 30     1  /   1         0\n",
      "1 -> 31     1  /   1         0\n",
      "1 -> 32     1  /   1         0\n",
      "1 -> 33     1  /   1         0\n",
      "1 -> 34     1  /   1         0\n",
      "1 -> 35     1  /   1         0\n",
      "1 -> 36     1  /   1         0\n",
      "1 -> 37     1  /   1         0\n",
      "1 -> 38     1  /   1         0\n",
      "1 -> 39     1  /   1         0\n",
      "1 -> 40     1  /   1         0\n",
      "1 -> 41     1  /   1         0\n",
      "1 -> 42     1  /   1         0\n",
      "1 -> 43     1  /   1         0\n",
      "1 -> 44     1  /   1         0\n",
      "1 -> 45     1  /   1         0\n",
      "1 -> 46     1  /   1         0\n",
      "1 -> 47     1  /   1         0\n",
      "1 -> 48     1  /   1         0\n",
      "1 -> 49     1  /   1         0\n",
      "1 -> 50     1  /   1         0\n",
      "1 -> 51     1  /   1         0\n",
      "1 -> 52     1  /   1         0\n",
      "1 -> 53     1  /   1         0\n",
      "1 -> 54     1  /   1         0\n",
      "1 -> 55     1  /   1         0\n",
      "1 -> 56     1  /   1         0\n",
      "1 -> 57     1  /   1         0\n",
      "1 -> 58     1  /   1         0\n",
      "1 -> 59     1  /   1         0\n",
      "1 -> 60     1  /   1         0\n",
      "1 -> 61     1  /   1         0\n",
      "1 -> 62     1  /   1         0\n",
      "1 -> 63     1  /   1         0\n",
      "1 -> 64     1  /   1         0\n",
      "1 -> 65     1  /   1         0\n",
      "1 -> 66     1  /   1         0\n",
      "1 -> 67     1  /   1         0\n",
      "1 -> 68     1  /   1         0\n",
      "1 -> 69     1  /   1         0\n",
      "1 -> 70     1  /   1         0\n",
      "1 -> 71     1  /   1         0\n",
      "1 -> 72     1  /   1         0\n",
      "1 -> 73     1  /   1         0\n",
      "1 -> 74     1  /   1         0\n",
      "1 -> 75     1  /   1         0\n",
      "1 -> 76     1  /   1         0\n",
      "1 -> 77     1  /   1         0\n",
      "1 -> 78     1  /   1         0\n",
      "1 -> 79     1  /   1         0\n",
      "1 -> 80     1  /   1         0\n",
      "1 -> 81     1  /   1         0\n",
      "1 -> 82     1  /   1         0\n",
      "1 -> 83     1  /   1         0\n",
      "1 -> 84     1  /   1         0\n",
      "1 -> 85     1  /   1         0\n",
      "1 -> 86     1  /   1         0\n",
      "1 -> 87     1  /   1         0\n",
      "1 -> 88     1  /   1         0\n",
      "1 -> 89     1  /   1         0\n",
      "1 -> 90     1  /   1         0\n",
      "1 -> 91     1  /   1         0\n",
      "1 -> 92     1  /   1         0\n",
      "1 -> 93     1  /   1         0\n",
      "1 -> 94     1  /   1         0\n",
      "1 -> 95     1  /   1         0\n",
      "1 -> 96     1  /   1         0\n",
      "1 -> 97     1  /   1         0\n",
      "1 -> 98     1  /   1         0\n",
      "1 -> 99     1  /   1         0\n",
      "1 -> 100     1  /   1         0\n",
      "1 -> 101     1  /   1         0\n",
      "1 -> 102     1  /   1         0\n",
      "1 -> 103     1  /   1         0\n",
      "1 -> 104     1  /   1         0\n",
      "1 -> 105     1  /   1         0\n",
      "1 -> 106     1  /   1         0\n",
      "1 -> 107     1  /   1         0\n",
      "1 -> 108     1  /   1         0\n",
      "1 -> 109     1  /   1         0\n",
      "1 -> 110     1  /   1         0\n",
      "1 -> 111     1  /   1         0\n",
      "1 -> 112     1  /   1         0\n",
      "1 -> 113     1  /   1         0\n",
      "1 -> 114     1  /   1         0\n",
      "1 -> 115     1  /   1         0\n",
      "1 -> 116     1  /   1         0\n",
      "1 -> 117     1  /   1         0\n",
      "1 -> 118     1  /   1         0\n",
      "1 -> 119     1  /   1         0\n",
      "1 -> 120     1  /   1         0\n",
      "1 -> 121     1  /   1         0\n",
      "1 -> 122     1  /   1         0\n",
      "1 -> 123     1  /   1         0\n",
      "1 -> 124     1  /   1         0\n",
      "1 -> 125     1  /   1         0\n",
      "1 -> 126     1  /   1         0\n",
      "1 -> 127     1  /   1         0\n",
      "1 -> 128     1  /   1         0\n",
      "1 -> 129     1  /   1         0\n",
      "1 -> 130     1  /   1         0\n",
      "1 -> 131     1  /   1         0\n",
      "1 -> 132     1  /   1         0\n",
      "1 -> 133     1  /   1         0\n",
      "1 -> 134     1  /   1         0\n",
      "1 -> 135     1  /   1         0\n",
      "1 -> 136     1  /   1         0\n",
      "1 -> 137     1  /   1         0\n",
      "1 -> 138     1  /   1         0\n",
      "1 -> 139     1  /   1         0\n",
      "2 -> 140     1  /   1       323\n",
      "3 -> 140     1  /   1       131\n",
      "4 -> 141     1  /   1        40\n",
      "5 -> 143     1  /   1        47\n",
      "6 -> 146     1  /   1         4\n",
      "7 -> 146     1  /   1        57\n",
      "8 -> 141     1  /   1        54\n",
      "9 -> 141     1  /   1        65\n",
      "10 -> 141     1  /   1        15\n",
      "11 -> 141     1  /   1        54\n",
      "12 -> 141     1  /   1         0\n",
      "13 -> 146     1  /   1        11\n",
      "14 -> 146     1  /   1        60\n",
      "15 -> 143     1  /   1        17\n",
      "16 -> 143     1  /   1       117\n",
      "17 -> 146     1  /   1        89\n",
      "18 -> 143     1  /   1        64\n",
      "19 -> 143     1  /   1       126\n",
      "20 -> 146     1  /   1        13\n",
      "21 -> 146     1  /   1         8\n",
      "22 -> 146     1  /   1         8\n",
      "23 -> 146     1  /   1        37\n",
      "24 -> 146     1  /   1        60\n",
      "25 -> 141     1  /   1        49\n",
      "26 -> 146     1  /   1        32\n",
      "27 -> 141     1  /   1        34\n",
      "28 -> 146     1  /   1        78\n",
      "29 -> 141     1  /   1        15\n",
      "30 -> 146     1  /   1        58\n",
      "31 -> 146     1  /   1       119\n",
      "32 -> 146     1  /   1        48\n",
      "33 -> 141     1  /   1         8\n",
      "34 -> 146     1  /   1        26\n",
      "35 -> 146     1  /   1        16\n",
      "36 -> 141     1  /   1        18\n",
      "37 -> 146     1  /   1        65\n",
      "38 -> 143     1  /   1       168\n",
      "39 -> 146     1  /   1        56\n",
      "40 -> 143     1  /   1        23\n",
      "41 -> 146     1  /   1        93\n",
      "42 -> 141     1  /   1        43\n",
      "43 -> 146     1  /   1        45\n",
      "44 -> 141     1  /   1        22\n",
      "45 -> 146     1  /   1        17\n",
      "46 -> 146     1  /   1         2\n",
      "47 -> 146     1  /   1       115\n",
      "48 -> 146     1  /   1        35\n",
      "49 -> 141     1  /   1         1\n",
      "50 -> 146     1  /   1        29\n",
      "51 -> 141     1  /   1        68\n",
      "52 -> 143     1  /   1        11\n",
      "53 -> 143     1  /   1       123\n",
      "54 -> 141     1  /   1         6\n",
      "55 -> 146     1  /   1         5\n",
      "56 -> 146     1  /   1        13\n",
      "57 -> 146     1  /   1        94\n",
      "58 -> 146     1  /   1        87\n",
      "59 -> 141     1  /   1       106\n",
      "60 -> 141     1  /   1       135\n",
      "61 -> 141     1  /   1        15\n",
      "62 -> 143     1  /   1        49\n",
      "63 -> 140     1  /   1       101\n",
      "64 -> 140     1  /   1        75\n",
      "65 -> 143     1  /   1         5\n",
      "66 -> 149     1  /   1        65\n",
      "67 -> 146     1  /   1        30\n",
      "68 -> 141     1  /   1        10\n",
      "69 -> 143     1  /   1        54\n",
      "70 -> 141     1  /   1        29\n",
      "71 -> 146     1  /   1         5\n",
      "72 -> 143     1  /   1         4\n",
      "73 -> 146     1  /   1        44\n",
      "74 -> 141     1  /   1        47\n",
      "75 -> 149     1  /   1        56\n",
      "76 -> 141     1  /   1        29\n",
      "77 -> 141     1  /   1         8\n",
      "78 -> 146     1  /   1         3\n",
      "79 -> 141     1  /   1         4\n",
      "80 -> 146     1  /   1         2\n",
      "81 -> 149     1  /   1        43\n",
      "82 -> 146     1  /   1        49\n",
      "83 -> 143     1  /   1        13\n",
      "84 -> 146     1  /   1        24\n",
      "85 -> 146     1  /   1         0\n",
      "86 -> 149     1  /   1        34\n",
      "87 -> 143     1  /   1         0\n",
      "88 -> 146     1  /   1         9\n",
      "89 -> 143     1  /   1        36\n",
      "90 -> 143     1  /   1        14\n",
      "91 -> 146     1  /   1        10\n",
      "92 -> 149     1  /   1        63\n",
      "93 -> 143     1  /   1        16\n",
      "94 -> 146     1  /   1        20\n",
      "95 -> 149     1  /   1        48\n",
      "96 -> 143     1  /   1        27\n",
      "97 -> 146     1  /   1         7\n",
      "98 -> 146     1  /   1        22\n",
      "99 -> 143     1  /   1         3\n",
      "100 -> 146     1  /   1        38\n",
      "101 -> 146     1  /   1         8\n",
      "102 -> 143     1  /   1         6\n",
      "103 -> 143     1  /   1        15\n",
      "104 -> 143     1  /   1         3\n",
      "105 -> 146     1  /   1         0\n",
      "106 -> 143     1  /   1        14\n",
      "107 -> 143     1  /   1        22\n",
      "108 -> 143     1  /   1         2\n",
      "109 -> 146     1  /   1        33\n",
      "110 -> 141     1  /   1        43\n",
      "111 -> 146     1  /   1        43\n",
      "112 -> 141     1  /   1        28\n",
      "113 -> 146     1  /   1         3\n",
      "114 -> 143     1  /   1         6\n",
      "115 -> 141     1  /   1        46\n",
      "116 -> 146     1  /   1        29\n",
      "117 -> 149     1  /   1        70\n",
      "118 -> 141     1  /   1        93\n",
      "119 -> 141     1  /   1        51\n",
      "120 -> 141     1  /   1        66\n",
      "121 -> 141     1  /   1        90\n",
      "122 -> 141     1  /   1       179\n",
      "123 -> 147     1  /   1        19\n",
      "124 -> 142     1  /   1       278\n",
      "125 -> 140     1  /   1        74\n",
      "126 -> 140     1  /   1       114\n",
      "127 -> 140     1  /   1        62\n",
      "128 -> 143     1  /   1       165\n",
      "129 -> 140     1  /   1        52\n",
      "130 -> 143     1  /   1       287\n",
      "131 -> 143     1  /   1       103\n",
      "132 -> 149     1  /   1        55\n",
      "133 -> 148     1  /   1        33\n",
      "134 -> 147     1  /   1       137\n",
      "135 -> 142     1  /   1        53\n",
      "136 -> 144     1  /   1       830\n",
      "137 -> 142     1  /   1        50\n",
      "138 -> 145     1  /   1        56\n",
      "139 -> 145     1  /   1        40\n",
      "140 -> 150     5  /   6         0\n",
      "141 -> 150    12  /  43         0\n",
      "142 -> 150     1  /   6         0\n",
      "143 -> 150    20  /  20         0\n",
      "145 -> 150     1  /   4         0\n",
      "146 -> 150    29  /  44         0\n",
      "149 -> 150     4  /   8         0\n",
      "[ Raw Info all runs for each dist_type ] :\n",
      "      Dist Type   Gini  Avg Dist  Income_Gap  spatial_index\n",
      "0       Random  0.112      0.76        0.40         0.1601\n",
      "1         LIPA  0.079      0.45        0.26         0.1438\n",
      "2   RoundRobin  0.104      0.76        0.38         0.1438\n",
      "3         MCCA  0.220      0.21        0.69         0.3971\n",
      "4       MCCA-L  0.220      0.21        0.69         0.3971\n",
      "5   FairAssign  0.098      0.40        0.27         0.1595\n",
      "6       Random  0.135      0.81        0.61         0.2126\n",
      "7         LIPA  0.018      0.54        0.06         0.0313\n",
      "8   RoundRobin  0.140      0.80        0.61         0.1988\n",
      "9         MCCA  0.274      0.20        1.05         0.5310\n",
      "10      MCCA-L  0.267      0.20        1.04         0.4922\n",
      "11  FairAssign  0.103      0.36        0.27         0.1427\n",
      "12      Random  0.106      0.76        0.38         0.1514\n",
      "13        LIPA  0.069      0.46        0.24         0.1363\n",
      "14  RoundRobin  0.100      0.77        0.40         0.1360\n",
      "15        MCCA  0.208      0.21        0.61         0.3601\n",
      "16      MCCA-L  0.208      0.21        0.61         0.3598\n",
      "17  FairAssign  0.088      0.41        0.26         0.1399\n",
      "18      Random  0.174      0.95        0.91         0.2705\n",
      "19        LIPA  0.029      0.56        0.10         0.0573\n",
      "20  RoundRobin  0.169      0.95        0.67         0.2456\n",
      "21        MCCA  0.299      0.21        1.45         0.5626\n",
      "22      MCCA-L  0.240      0.22        1.25         0.4655\n",
      "23  FairAssign  0.095      0.41        0.33         0.1364\n",
      "24      Random  0.143      0.84        0.64         0.2163\n",
      "25        LIPA  0.008      0.53        0.02         0.0165\n",
      "26  RoundRobin  0.150      0.84        0.66         0.2232\n",
      "27        MCCA  0.297      0.21        1.37         0.5749\n",
      "28      MCCA-L  0.257      0.21        1.16         0.4896\n",
      "29  FairAssign  0.113      0.38        0.32         0.1704\n",
      "30      Random  0.147      0.91        0.62         0.2165\n",
      "31        LIPA  0.036      0.62        0.08         0.0633\n",
      "32  RoundRobin  0.146      0.91        0.55         0.1941\n",
      "33        MCCA  0.230      0.21        0.81         0.4209\n",
      "34      MCCA-L  0.227      0.22        0.82         0.3952\n",
      "35  FairAssign  0.081      0.45        0.24         0.1257\n",
      "36      Random  0.152      0.87        0.66         0.2226\n",
      "37        LIPA  0.004      0.57        0.01         0.0083\n",
      "38  RoundRobin  0.156      0.88        0.62         0.2161\n",
      "39        MCCA  0.231      0.21        0.90         0.4657\n",
      "40      MCCA-L  0.229      0.21        0.91         0.4158\n",
      "41  FairAssign  0.124      0.38        0.39         0.1485\n",
      "42      Random  0.132      0.80        0.56         0.2076\n",
      "43        LIPA  0.019      0.55        0.06         0.0329\n",
      "44  RoundRobin  0.140      0.80        0.59         0.1993\n",
      "45        MCCA  0.266      0.22        1.02         0.5073\n",
      "46      MCCA-L  0.261      0.22        0.97         0.4732\n",
      "47  FairAssign  0.095      0.41        0.32         0.1444\n",
      "48      Random  0.120      0.75        0.46         0.1741\n",
      "49        LIPA  0.003      0.46        0.01         0.0058\n",
      "50  RoundRobin  0.110      0.76        0.43         0.1474\n",
      "51        MCCA  0.186      0.20        0.58         0.3789\n",
      "52      MCCA-L  0.197      0.20        0.58         0.3824\n",
      "53  FairAssign  0.107      0.40        0.26         0.1485\n",
      "[ Mean for each Dist Type ] :\n",
      "                 Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                                \n",
      "FairAssign  0.100444  0.400000    0.295556       0.146222\n",
      "LIPA        0.029444  0.526667    0.093333       0.055056\n",
      "MCCA        0.245667  0.208889    0.942222       0.466500\n",
      "MCCA-L      0.234000  0.211111    0.892222       0.430089\n",
      "Random      0.135667  0.827778    0.582222       0.203522\n",
      "RoundRobin  0.135000  0.830000    0.545556       0.189367\n",
      "\n",
      "[ Max for each Dist Type ] :\n",
      "              Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                             \n",
      "FairAssign  0.124      0.45        0.39         0.1704\n",
      "LIPA        0.079      0.62        0.26         0.1438\n",
      "MCCA        0.299      0.22        1.45         0.5749\n",
      "MCCA-L      0.267      0.22        1.25         0.4922\n",
      "Random      0.174      0.95        0.91         0.2705\n",
      "RoundRobin  0.169      0.95        0.67         0.2456\n",
      "\n",
      "[ Min for each Dist Type ] :\n",
      "              Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                             \n",
      "FairAssign  0.081      0.36        0.24         0.1257\n",
      "LIPA        0.003      0.45        0.01         0.0058\n",
      "MCCA        0.186      0.20        0.58         0.3601\n",
      "MCCA-L      0.197      0.20        0.58         0.3598\n",
      "Random      0.106      0.75        0.38         0.1514\n",
      "RoundRobin  0.100      0.76        0.38         0.1360\n",
      "\n",
      "Number of Drivers: 125\n",
      "num_constraints: 33619\n",
      "Version identifier: 22.1.0.0 | 2022-03-09 | 1a383f8ce\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "CPXPARAM_Simplex_Tolerances_Markowitz            0.90000000000000002\n",
      "CPXPARAM_Simplex_Tolerances_Optimality           1.0000000000000001e-09\n",
      "CPXPARAM_Simplex_Tolerances_Feasibility          1.0000000000000001e-09\n",
      "Parallel mode: deterministic, using up to 4 threads for concurrent optimization:\n",
      " * Starting dual Simplex on 1 thread...\n",
      " * Starting Barrier on 3 threads...\n",
      "Tried aggregator 1 time.\n",
      "LP Presolve eliminated 0 rows and 61560 columns.\n",
      "Reduced LP has 33619 rows, 17190 columns, and 115330 nonzeros.\n",
      "Presolve time = 0.19 sec. (49.17 ticks)\n",
      "Initializing dual steep norms . . .\n",
      "\n",
      "Iteration log . . .\n",
      "Iteration:     1   Dual objective     =             0.585035\n",
      "Iteration:   281   Dual objective     =             1.272618\n",
      "Iteration:   808   Dual objective     =             1.538813\n",
      "Iteration:  1039   Dual objective     =             1.649412\n",
      "Iteration:  1259   Dual objective     =             1.799042\n",
      "Iteration:  1479   Dual objective     =             1.837840\n",
      "Iteration:  1708   Dual objective     =             1.938326\n",
      "Iteration:  1963   Dual objective     =             1.962059\n",
      "Iteration:  2202   Dual objective     =             2.048720\n",
      "Iteration:  2436   Dual objective     =             2.084534\n",
      "Iteration:  2642   Dual objective     =             2.118988\n",
      "Iteration:  2872   Dual objective     =             2.134951\n",
      "Iteration:  3081   Dual objective     =             2.144766\n",
      "Iteration:  3285   Dual objective     =             2.179079\n",
      "Iteration:  3482   Dual objective     =             2.255062\n",
      "\n",
      "Barrier solved model.\n",
      "\n",
      "Solution Quality: [1.0, 0.0]\n",
      "Status: optimal\n",
      "Everything solved, graphs start\n",
      "max_flow_min_cost cost value: 6437\n",
      "maximum_flow flow value: 125\n",
      "Minimum cost: 7011\n",
      "\n",
      "  Arc    Flow / Capacity  Cost\n",
      "1 -> 2     1  /   1         0\n",
      "1 -> 3     1  /   1         0\n",
      "1 -> 4     1  /   1         0\n",
      "1 -> 5     1  /   1         0\n",
      "1 -> 6     1  /   1         0\n",
      "1 -> 7     1  /   1         0\n",
      "1 -> 8     1  /   1         0\n",
      "1 -> 9     1  /   1         0\n",
      "1 -> 10     1  /   1         0\n",
      "1 -> 11     1  /   1         0\n",
      "1 -> 12     1  /   1         0\n",
      "1 -> 13     1  /   1         0\n",
      "1 -> 14     1  /   1         0\n",
      "1 -> 15     1  /   1         0\n",
      "1 -> 16     1  /   1         0\n",
      "1 -> 17     1  /   1         0\n",
      "1 -> 18     1  /   1         0\n",
      "1 -> 19     1  /   1         0\n",
      "1 -> 20     1  /   1         0\n",
      "1 -> 21     1  /   1         0\n",
      "1 -> 22     1  /   1         0\n",
      "1 -> 23     1  /   1         0\n",
      "1 -> 24     1  /   1         0\n",
      "1 -> 25     1  /   1         0\n",
      "1 -> 26     1  /   1         0\n",
      "1 -> 27     1  /   1         0\n",
      "1 -> 28     1  /   1         0\n",
      "1 -> 29     1  /   1         0\n",
      "1 -> 30     1  /   1         0\n",
      "1 -> 31     1  /   1         0\n",
      "1 -> 32     1  /   1         0\n",
      "1 -> 33     1  /   1         0\n",
      "1 -> 34     1  /   1         0\n",
      "1 -> 35     1  /   1         0\n",
      "1 -> 36     1  /   1         0\n",
      "1 -> 37     1  /   1         0\n",
      "1 -> 38     1  /   1         0\n",
      "1 -> 39     1  /   1         0\n",
      "1 -> 40     1  /   1         0\n",
      "1 -> 41     1  /   1         0\n",
      "1 -> 42     1  /   1         0\n",
      "1 -> 43     1  /   1         0\n",
      "1 -> 44     1  /   1         0\n",
      "1 -> 45     1  /   1         0\n",
      "1 -> 46     1  /   1         0\n",
      "1 -> 47     1  /   1         0\n",
      "1 -> 48     1  /   1         0\n",
      "1 -> 49     1  /   1         0\n",
      "1 -> 50     1  /   1         0\n",
      "1 -> 51     1  /   1         0\n",
      "1 -> 52     1  /   1         0\n",
      "1 -> 53     1  /   1         0\n",
      "1 -> 54     1  /   1         0\n",
      "1 -> 55     1  /   1         0\n",
      "1 -> 56     1  /   1         0\n",
      "1 -> 57     1  /   1         0\n",
      "1 -> 58     1  /   1         0\n",
      "1 -> 59     1  /   1         0\n",
      "1 -> 60     1  /   1         0\n",
      "1 -> 61     1  /   1         0\n",
      "1 -> 62     1  /   1         0\n",
      "1 -> 63     1  /   1         0\n",
      "1 -> 64     1  /   1         0\n",
      "1 -> 65     1  /   1         0\n",
      "1 -> 66     1  /   1         0\n",
      "1 -> 67     1  /   1         0\n",
      "1 -> 68     1  /   1         0\n",
      "1 -> 69     1  /   1         0\n",
      "1 -> 70     1  /   1         0\n",
      "1 -> 71     1  /   1         0\n",
      "1 -> 72     1  /   1         0\n",
      "1 -> 73     1  /   1         0\n",
      "1 -> 74     1  /   1         0\n",
      "1 -> 75     1  /   1         0\n",
      "1 -> 76     1  /   1         0\n",
      "1 -> 77     1  /   1         0\n",
      "1 -> 78     1  /   1         0\n",
      "1 -> 79     1  /   1         0\n",
      "1 -> 80     1  /   1         0\n",
      "1 -> 81     1  /   1         0\n",
      "1 -> 82     1  /   1         0\n",
      "1 -> 83     1  /   1         0\n",
      "1 -> 84     1  /   1         0\n",
      "1 -> 85     1  /   1         0\n",
      "1 -> 86     1  /   1         0\n",
      "1 -> 87     1  /   1         0\n",
      "1 -> 88     1  /   1         0\n",
      "1 -> 89     1  /   1         0\n",
      "1 -> 90     1  /   1         0\n",
      "1 -> 91     1  /   1         0\n",
      "1 -> 92     1  /   1         0\n",
      "1 -> 93     1  /   1         0\n",
      "1 -> 94     1  /   1         0\n",
      "1 -> 95     1  /   1         0\n",
      "1 -> 96     1  /   1         0\n",
      "1 -> 97     1  /   1         0\n",
      "1 -> 98     1  /   1         0\n",
      "1 -> 99     1  /   1         0\n",
      "1 -> 100     1  /   1         0\n",
      "1 -> 101     1  /   1         0\n",
      "1 -> 102     1  /   1         0\n",
      "1 -> 103     1  /   1         0\n",
      "1 -> 104     1  /   1         0\n",
      "1 -> 105     1  /   1         0\n",
      "1 -> 106     1  /   1         0\n",
      "1 -> 107     1  /   1         0\n",
      "1 -> 108     1  /   1         0\n",
      "1 -> 109     1  /   1         0\n",
      "1 -> 110     1  /   1         0\n",
      "1 -> 111     1  /   1         0\n",
      "1 -> 112     1  /   1         0\n",
      "1 -> 113     1  /   1         0\n",
      "1 -> 114     1  /   1         0\n",
      "1 -> 115     1  /   1         0\n",
      "1 -> 116     1  /   1         0\n",
      "1 -> 117     1  /   1         0\n",
      "1 -> 118     1  /   1         0\n",
      "1 -> 119     1  /   1         0\n",
      "1 -> 120     1  /   1         0\n",
      "1 -> 121     1  /   1         0\n",
      "1 -> 122     1  /   1         0\n",
      "1 -> 123     1  /   1         0\n",
      "1 -> 124     1  /   1         0\n",
      "1 -> 125     1  /   1         0\n",
      "1 -> 126     1  /   1         0\n",
      "2 -> 130     1  /   1        89\n",
      "3 -> 133     1  /   1        19\n",
      "4 -> 128     1  /   1         0\n",
      "5 -> 133     1  /   1        15\n",
      "6 -> 130     1  /   1        23\n",
      "7 -> 133     1  /   1       102\n",
      "8 -> 133     1  /   1        51\n",
      "9 -> 128     1  /   1        93\n",
      "10 -> 130     1  /   1        76\n",
      "11 -> 128     1  /   1        11\n",
      "12 -> 133     1  /   1       116\n",
      "13 -> 133     1  /   1         3\n",
      "14 -> 133     1  /   1        84\n",
      "15 -> 133     1  /   1        69\n",
      "16 -> 133     1  /   1        21\n",
      "17 -> 128     1  /   1        25\n",
      "18 -> 133     1  /   1        71\n",
      "19 -> 133     1  /   1        42\n",
      "20 -> 130     1  /   1        70\n",
      "21 -> 128     1  /   1        22\n",
      "22 -> 130     1  /   1        76\n",
      "23 -> 130     1  /   1        20\n",
      "24 -> 133     1  /   1        23\n",
      "25 -> 133     1  /   1        34\n",
      "26 -> 130     1  /   1        23\n",
      "27 -> 133     1  /   1        19\n",
      "28 -> 133     1  /   1        97\n",
      "29 -> 128     1  /   1        46\n",
      "30 -> 133     1  /   1       108\n",
      "31 -> 128     1  /   1         4\n",
      "32 -> 130     1  /   1        29\n",
      "33 -> 128     1  /   1        11\n",
      "34 -> 133     1  /   1         8\n",
      "35 -> 130     1  /   1       110\n",
      "36 -> 133     1  /   1        40\n",
      "37 -> 133     1  /   1        14\n",
      "38 -> 130     1  /   1       125\n",
      "39 -> 133     1  /   1       105\n",
      "40 -> 128     1  /   1        10\n",
      "41 -> 130     1  /   1        23\n",
      "42 -> 130     1  /   1        22\n",
      "43 -> 128     1  /   1         4\n",
      "44 -> 130     1  /   1        20\n",
      "45 -> 128     1  /   1        13\n",
      "46 -> 133     1  /   1        41\n",
      "47 -> 133     1  /   1        45\n",
      "48 -> 133     1  /   1        36\n",
      "49 -> 133     1  /   1         0\n",
      "50 -> 133     1  /   1        18\n",
      "51 -> 133     1  /   1        68\n",
      "52 -> 133     1  /   1         6\n",
      "53 -> 133     1  /   1        14\n",
      "54 -> 128     1  /   1        30\n",
      "55 -> 133     1  /   1       108\n",
      "56 -> 133     1  /   1        35\n",
      "57 -> 130     1  /   1        27\n",
      "58 -> 128     1  /   1       173\n",
      "59 -> 128     1  /   1       113\n",
      "60 -> 128     1  /   1       148\n",
      "61 -> 128     1  /   1       276\n",
      "62 -> 130     1  /   1        46\n",
      "63 -> 133     1  /   1        70\n",
      "64 -> 130     1  /   1         5\n",
      "65 -> 133     1  /   1         6\n",
      "66 -> 136     1  /   1        46\n",
      "67 -> 130     1  /   1         5\n",
      "68 -> 130     1  /   1         8\n",
      "69 -> 130     1  /   1        22\n",
      "70 -> 130     1  /   1         0\n",
      "71 -> 130     1  /   1        10\n",
      "72 -> 133     1  /   1         8\n",
      "73 -> 133     1  /   1         5\n",
      "74 -> 133     1  /   1         7\n",
      "75 -> 136     1  /   1        43\n",
      "76 -> 133     1  /   1        11\n",
      "77 -> 133     1  /   1         0\n",
      "78 -> 130     1  /   1        19\n",
      "79 -> 136     1  /   1        37\n",
      "80 -> 136     1  /   1        84\n",
      "81 -> 136     1  /   1        74\n",
      "82 -> 133     1  /   1        44\n",
      "83 -> 130     1  /   1        11\n",
      "84 -> 136     1  /   1        60\n",
      "85 -> 136     1  /   1        52\n",
      "86 -> 128     1  /   1        44\n",
      "87 -> 133     1  /   1        10\n",
      "88 -> 130     1  /   1        46\n",
      "89 -> 130     1  /   1         4\n",
      "90 -> 130     1  /   1         2\n",
      "91 -> 130     1  /   1        15\n",
      "92 -> 133     1  /   1         6\n",
      "93 -> 133     1  /   1        19\n",
      "94 -> 130     1  /   1        28\n",
      "95 -> 133     1  /   1        16\n",
      "96 -> 130     1  /   1        34\n",
      "97 -> 133     1  /   1        44\n",
      "98 -> 133     1  /   1         3\n",
      "99 -> 128     1  /   1        91\n",
      "100 -> 135     1  /   1       217\n",
      "101 -> 128     1  /   1        90\n",
      "102 -> 128     1  /   1        65\n",
      "103 -> 128     1  /   1        78\n",
      "104 -> 134     1  /   1       305\n",
      "105 -> 128     1  /   1         9\n",
      "106 -> 128     1  /   1        33\n",
      "107 -> 136     1  /   1        94\n",
      "108 -> 136     1  /   1        57\n",
      "109 -> 135     1  /   1       227\n",
      "110 -> 134     1  /   1        20\n",
      "111 -> 129     1  /   1       110\n",
      "112 -> 127     1  /   1       226\n",
      "113 -> 127     1  /   1       110\n",
      "114 -> 127     1  /   1        80\n",
      "115 -> 127     1  /   1       105\n",
      "116 -> 127     1  /   1        81\n",
      "117 -> 130     1  /   1       146\n",
      "118 -> 136     1  /   1       130\n",
      "119 -> 136     1  /   1        21\n",
      "120 -> 135     1  /   1        57\n",
      "121 -> 129     1  /   1         5\n",
      "122 -> 129     1  /   1        23\n",
      "123 -> 129     1  /   1         7\n",
      "124 -> 129     1  /   1        40\n",
      "125 -> 131     1  /   1       504\n",
      "126 -> 132     1  /   1        12\n",
      "127 -> 137     2  /   6         0\n",
      "128 -> 137     2  /  43         0\n",
      "129 -> 137     3  /   6         0\n",
      "130 -> 137    20  /  20         0\n",
      "133 -> 137    23  /  44         0\n",
      "135 -> 137     2  /   2         0\n",
      "136 -> 137     7  /   8         0\n",
      "[ Raw Info all runs for each dist_type ] :\n",
      "      Dist Type   Gini  Avg Dist  Income_Gap  spatial_index\n",
      "0       Random  0.112      0.76        0.40         0.1601\n",
      "1         LIPA  0.079      0.45        0.26         0.1438\n",
      "2   RoundRobin  0.104      0.76        0.38         0.1438\n",
      "3         MCCA  0.220      0.21        0.69         0.3971\n",
      "4       MCCA-L  0.220      0.21        0.69         0.3971\n",
      "5   FairAssign  0.098      0.40        0.27         0.1595\n",
      "6       Random  0.135      0.81        0.61         0.2126\n",
      "7         LIPA  0.018      0.54        0.06         0.0313\n",
      "8   RoundRobin  0.140      0.80        0.61         0.1988\n",
      "9         MCCA  0.274      0.20        1.05         0.5310\n",
      "10      MCCA-L  0.267      0.20        1.04         0.4922\n",
      "11  FairAssign  0.103      0.36        0.27         0.1427\n",
      "12      Random  0.106      0.76        0.38         0.1514\n",
      "13        LIPA  0.069      0.46        0.24         0.1363\n",
      "14  RoundRobin  0.100      0.77        0.40         0.1360\n",
      "15        MCCA  0.208      0.21        0.61         0.3601\n",
      "16      MCCA-L  0.208      0.21        0.61         0.3598\n",
      "17  FairAssign  0.088      0.41        0.26         0.1399\n",
      "18      Random  0.174      0.95        0.91         0.2705\n",
      "19        LIPA  0.029      0.56        0.10         0.0573\n",
      "20  RoundRobin  0.169      0.95        0.67         0.2456\n",
      "21        MCCA  0.299      0.21        1.45         0.5626\n",
      "22      MCCA-L  0.240      0.22        1.25         0.4655\n",
      "23  FairAssign  0.095      0.41        0.33         0.1364\n",
      "24      Random  0.143      0.84        0.64         0.2163\n",
      "25        LIPA  0.008      0.53        0.02         0.0165\n",
      "26  RoundRobin  0.150      0.84        0.66         0.2232\n",
      "27        MCCA  0.297      0.21        1.37         0.5749\n",
      "28      MCCA-L  0.257      0.21        1.16         0.4896\n",
      "29  FairAssign  0.113      0.38        0.32         0.1704\n",
      "30      Random  0.147      0.91        0.62         0.2165\n",
      "31        LIPA  0.036      0.62        0.08         0.0633\n",
      "32  RoundRobin  0.146      0.91        0.55         0.1941\n",
      "33        MCCA  0.230      0.21        0.81         0.4209\n",
      "34      MCCA-L  0.227      0.22        0.82         0.3952\n",
      "35  FairAssign  0.081      0.45        0.24         0.1257\n",
      "36      Random  0.152      0.87        0.66         0.2226\n",
      "37        LIPA  0.004      0.57        0.01         0.0083\n",
      "38  RoundRobin  0.156      0.88        0.62         0.2161\n",
      "39        MCCA  0.231      0.21        0.90         0.4657\n",
      "40      MCCA-L  0.229      0.21        0.91         0.4158\n",
      "41  FairAssign  0.124      0.38        0.39         0.1485\n",
      "42      Random  0.132      0.80        0.56         0.2076\n",
      "43        LIPA  0.019      0.55        0.06         0.0329\n",
      "44  RoundRobin  0.140      0.80        0.59         0.1993\n",
      "45        MCCA  0.266      0.22        1.02         0.5073\n",
      "46      MCCA-L  0.261      0.22        0.97         0.4732\n",
      "47  FairAssign  0.095      0.41        0.32         0.1444\n",
      "48      Random  0.120      0.75        0.46         0.1741\n",
      "49        LIPA  0.003      0.46        0.01         0.0058\n",
      "50  RoundRobin  0.110      0.76        0.43         0.1474\n",
      "51        MCCA  0.186      0.20        0.58         0.3789\n",
      "52      MCCA-L  0.197      0.20        0.58         0.3824\n",
      "53  FairAssign  0.107      0.40        0.26         0.1485\n",
      "54      Random  0.128      0.81        0.55         0.1951\n",
      "55        LIPA  0.008      0.57        0.02         0.0142\n",
      "56  RoundRobin  0.133      0.81        0.57         0.1927\n",
      "57        MCCA  0.241      0.20        0.91         0.4569\n",
      "58      MCCA-L  0.240      0.21        0.97         0.4487\n",
      "59  FairAssign  0.098      0.39        0.32         0.1600\n",
      "[ Mean for each Dist Type ] :\n",
      "               Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                              \n",
      "FairAssign  0.1002     0.399       0.298        0.14760\n",
      "LIPA        0.0273     0.531       0.086        0.05097\n",
      "MCCA        0.2452     0.208       0.939        0.46554\n",
      "MCCA-L      0.2346     0.211       0.900        0.43195\n",
      "Random      0.1349     0.826       0.579        0.20268\n",
      "RoundRobin  0.1348     0.828       0.548        0.18970\n",
      "\n",
      "[ Max for each Dist Type ] :\n",
      "              Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                             \n",
      "FairAssign  0.124      0.45        0.39         0.1704\n",
      "LIPA        0.079      0.62        0.26         0.1438\n",
      "MCCA        0.299      0.22        1.45         0.5749\n",
      "MCCA-L      0.267      0.22        1.25         0.4922\n",
      "Random      0.174      0.95        0.91         0.2705\n",
      "RoundRobin  0.169      0.95        0.67         0.2456\n",
      "\n",
      "[ Min for each Dist Type ] :\n",
      "              Gini  Avg Dist  Income_Gap  spatial_index\n",
      "Dist Type                                             \n",
      "FairAssign  0.081      0.36        0.24         0.1257\n",
      "LIPA        0.003      0.45        0.01         0.0058\n",
      "MCCA        0.186      0.20        0.58         0.3601\n",
      "MCCA-L      0.197      0.20        0.58         0.3598\n",
      "Random      0.106      0.75        0.38         0.1514\n",
      "RoundRobin  0.100      0.76        0.38         0.1360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Gini_Index_List = []\n",
    "Avg_Distance_List = []\n",
    "Income_Gap_List = []\n",
    "spatial_inequality_list = []\n",
    "Name_list = []\n",
    "Income_sum_lis = []\n",
    "num_drivers = []\n",
    "# income_lis_lis = []\n",
    "fraction_list = []\n",
    "\n",
    "import copy\n",
    "\n",
    "def sanityCheck(weights):\n",
    "    \"\"\"\n",
    "    To cope with bound violations which can occur upto the feasibility parameter range \n",
    "    So the lower bound of 0.0 on the probabilities can get violated and the values can go down to (0-feasibility_parameter_value)\n",
    "    \"\"\"\n",
    "    for i in range(len(weights)):\n",
    "        last_pos_index = -1\n",
    "        neg_value = 0\n",
    "        \n",
    "        for j in range(len(weights[0])):\n",
    "            assert weights[i][j] > -1e-5 \n",
    "            # or assert weights[i][j] > feasibility_parameter; where feasibility_parameter=Cplex().parameters.simplex.tolerances.feasibility.get() if it's not changed to some other value\n",
    "            # if the parameter is changed then it's value has to be the one specified inside \"fair_clustering\" (can be accessed using a global variable)\n",
    "            if weights[i][j] < 0:\n",
    "                neg_value += weights[i][j]\n",
    "                weights[i][j] = 0\n",
    "            elif weights[i][j] > 0:\n",
    "                last_pos_index = j\n",
    "        \n",
    "        weights[i][last_pos_index] += neg_value\n",
    "        \n",
    "    return weights\n",
    "\n",
    "\n",
    "\n",
    "# configParser.read(configFilePath)\n",
    "number_of_runs = int(configParser.get('dataset-generation','number_of_runs'))\n",
    "random_seed = int(configParser.get('dataset-generation','random_seed'))\n",
    "\n",
    "dis_type = [\"random\",\"low_income_dist\",\"round_robin\",\"vanilla_max\",\"vanilla_maxmin\",\"fair_algo\"]\n",
    "Name_dis_types = [\"Random\",\"LIPA\",\"RoundRobin\",\"MCCA\",\"MCCA-L\",\"FairAssign\"]\n",
    "colors = ['Indigo','Blue','Cyan','Green','Orange','Red']\n",
    "\n",
    "indexs_allowed = [0,1,2,3,4,5] # this is to index dis_type and Name_dis_type\n",
    "\n",
    "\n",
    "# data to be stored for scatter income plot and lorenz curve plot:\n",
    "driver_income_dfs = {dist:{} for dist in dis_type} \n",
    "income_arrs = {dist:{} for dist in dis_type}\n",
    "\n",
    "# Generates result for number_of_runs times, and store the value in differnt list\n",
    "for i in range(number_of_runs):\n",
    "# for i in range(1):\n",
    "    new_drivers = driver_generation(i+random_seed)\n",
    "    \n",
    "    if len(new_drivers) < sum(lower_cap):\n",
    "        print(\"Lower number of drivers generated\")\n",
    "        print(f\"Generated: {len(new_drivers)}, Required: {sum(lower_cap)}\")\n",
    "        continue\n",
    "\n",
    "    ratings = generate_ratings(new_drivers.shape[0])\n",
    "    result = fair_clustering(new_drivers,centre,ratings)\n",
    "    num_samples = len(new_drivers)\n",
    "    num_centres = len(centre)\n",
    "    \n",
    "    # Probability Distribution output from cplex\n",
    "    lpp_prob_dis = np.reshape(result['assignment'][:num_samples*num_centres],(-1,num_centres))\n",
    "    lpp_prob_dis = sanityCheck(copy.deepcopy(lpp_prob_dis))\n",
    "    \n",
    "    print(\"Everything solved, graphs start\")\n",
    "    \n",
    "#     income_lis_lis=[]\n",
    "    \n",
    "    for j in indexs_allowed:\n",
    "        tup = inequality2(algo_type=dis_type[j],lpp_prob_dis=lpp_prob_dis)\n",
    "#         tup = inequality2(algo_type=dis_type[j], num_days=num_testing_days, lpp_prob_dis=lpp_prob_dis)\n",
    "#         print(\"tup[2]:\\n\",tup[2])\n",
    "        tup2 = helper_func(tup[2],new_drivers,ratings) # tup[2] is fair_assignment_totaldays; tup2 is distance_drivers; \n",
    "        spat = spatial_inequality(tup2[1], tup2[2], tup2[3], new_drivers, ratings)\n",
    "\n",
    "        Gini_Index_List.append(tup[0])\n",
    "        Avg_Distance_List.append(tup[1])\n",
    "        Income_Gap_List.append(tup2[0])\n",
    "        spatial_inequality_list.append(spat)\n",
    "        Name_list.append(Name_dis_types[j])\n",
    "        Income_sum_lis.append(tup[3])\n",
    "        num_drivers.append(num_samples)\n",
    "#         income_lis_lis.append(tup[4])\n",
    "        \n",
    "        # for scatter income plot for FairAssign:\n",
    "        driver_income_dfs[dis_type[j]] = tup[2]\n",
    "        # for lorenz curve:\n",
    "        income_arrs[dis_type[j]] = tup[4]\n",
    "        \n",
    "        if j==3: base=tup2[3] # MCCA\n",
    "        if j==5: fair=tup2[3] # FairAssign\n",
    "    \n",
    "    fraction_worse_off = fraction(base,fair)\n",
    "    fraction_list.append(fraction_worse_off)\n",
    "\n",
    "    # Below All_Income contains all info about all runs\n",
    "    All_Income = pd.DataFrame({'Dist Type':Name_list,'Gini': Gini_Index_List,'Avg Dist':Avg_Distance_List,'Income_Gap':Income_Gap_List,'spatial_index':spatial_inequality_list})\n",
    "    print(\"[ Raw Info all runs for each dist_type ] :\\n\", All_Income)\n",
    "    print(\"[ Mean for each Dist Type ] :\\n\", All_Income.groupby('Dist Type').mean())\n",
    "    print()\n",
    "    print(\"[ Max for each Dist Type ] :\\n\", All_Income.groupby('Dist Type').max())\n",
    "    print()\n",
    "    print(\"[ Min for each Dist Type ] :\\n\", All_Income.groupby('Dist Type').min())\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lpp_prob_dis.flatten().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State:  RJ\n",
      "num_ffc_center:  10\n",
      "Grid Size:  7 7\n",
      "Fair Distance:  0.60\n",
      "Alpha_fair:  2\n",
      "number_of_runs:  10\n",
      "\n",
      "Avg Num of Drivers:  123.1\n",
      "\n",
      "#################################### FINAL RESULTS #######################################################\n",
      "[ Mean for each Dist Type ] :\n",
      "              Gini  Avg Dist  Income_Gap  spatial_index  Income_sum\n",
      "Dist Type                                                          \n",
      "FairAssign  0.1002     0.399       0.298         0.1476   10132.502\n",
      "LIPA        0.0273     0.531       0.086         0.0510    6694.142\n",
      "MCCA        0.2452     0.208       0.939         0.4655   10142.688\n",
      "MCCA-L      0.2346     0.211       0.900         0.4319   10145.602\n",
      "Random      0.1349     0.826       0.579         0.2027   10132.683\n",
      "RoundRobin  0.1348     0.828       0.548         0.1897   10132.774\n",
      "\n",
      "[ Max for each Dist Type ] :\n",
      "\n",
      "             Gini  Avg Dist  Income_Gap  spatial_index  Income_sum\n",
      "Dist Type                                                         \n",
      "FairAssign  0.124      0.45        0.39         0.1704    10133.21\n",
      "LIPA        0.079      0.62        0.26         0.1438     8131.38\n",
      "MCCA        0.299      0.22        1.45         0.5749    10146.13\n",
      "MCCA-L      0.267      0.22        1.25         0.4922    10146.33\n",
      "Random      0.174      0.95        0.91         0.2705    10132.95\n",
      "RoundRobin  0.169      0.95        0.67         0.2456    10133.70\n",
      "\n",
      "[ Min for each Dist Type ] :\n",
      "\n",
      "             Gini  Avg Dist  Income_Gap  spatial_index  Income_sum\n",
      "Dist Type                                                         \n",
      "FairAssign  0.081      0.36        0.24         0.1257    10131.42\n",
      "LIPA        0.003      0.45        0.01         0.0058     5521.30\n",
      "MCCA        0.186      0.20        0.58         0.3601    10139.88\n",
      "MCCA-L      0.197      0.20        0.58         0.3598    10143.92\n",
      "Random      0.106      0.75        0.38         0.1514    10132.25\n",
      "RoundRobin  0.100      0.76        0.38         0.1360    10131.63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print all the result\n",
    "All_Income = pd.DataFrame({'Dist Type':Name_list,'Gini': Gini_Index_List, 'Avg Dist':Avg_Distance_List,'Income_Gap':Income_Gap_List,'spatial_index':spatial_inequality_list,'Income_sum':Income_sum_lis})\n",
    "All_Income = All_Income.replace(\"Low Income Distribution\",\"Robinhood\") # just as cool line! no meaning\n",
    "\n",
    "# configParser.read(configFilePath)\n",
    "print(\"State: \",configParser.get('dataset-generation','state'))\n",
    "# print(\"Equal_to_or_not: \",configParser.get('dataset-generation','equal_to'))\n",
    "print(\"num_ffc_center: \",configParser.get('dataset-generation','num_ffc_center'))\n",
    "print(\"Grid Size: \",configParser.get('dataset-generation','grid_length'),configParser.get('dataset-generation','grid_width'))\n",
    "print(\"Fair Distance: \",configParser.get('fairness-constraint','fair_distance'))\n",
    "print(\"Alpha_fair: \",configParser.get('fairness-constraint','alpha_fair'))\n",
    "print(\"number_of_runs: \",configParser.get('dataset-generation','number_of_runs'))\n",
    "print()\n",
    "print(\"Avg Num of Drivers: \",np.mean(np.array(num_drivers)))\n",
    "print() \n",
    "\n",
    "print(\"#################################### FINAL RESULTS #######################################################\")\n",
    "print(\"[ Mean for each Dist Type ] :\")\n",
    "print(All_Income.groupby('Dist Type').mean().round(4))\n",
    "print()\n",
    "print(\"[ Max for each Dist Type ] :\\n\")\n",
    "print(All_Income.groupby('Dist Type').max())\n",
    "print()\n",
    "print(\"[ Min for each Dist Type ] :\\n\")\n",
    "print(All_Income.groupby('Dist Type').min())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Change       Val\n",
      "0       40  0.307614\n",
      "1       35  0.335945\n",
      "2       30  0.367930\n",
      "3       25  0.398957\n",
      "4       20  0.433072\n",
      "5       15  0.476351\n",
      "6       10  0.531594\n",
      "7        5  0.577644\n",
      "8        0  0.628976\n",
      "9        0  0.371024\n",
      "10      -5  0.323432\n",
      "11     -10  0.293309\n",
      "12     -15  0.256445\n",
      "13     -20  0.232095\n",
      "14     -25  0.208535\n",
      "15     -30  0.188154\n",
      "16     -35  0.167734\n",
      "17     -40  0.138374\n"
     ]
    }
   ],
   "source": [
    "# Find the fractional number of people worse off or get better when applied FairAssign algorithm keeping base as MCCA\n",
    "from statistics import mean\n",
    "\n",
    "greater_than_threshold = [40,35,30,25,20,15,10,5,0]\n",
    "lesser_than_threshold = [0,-5,-10,-15,-20,-25,-30,-35,-40]\n",
    "\n",
    "greater_than_matrix = [[0 for j in range(len(fraction_list))] for i in range(len(greater_than_threshold))]\n",
    "lesser_than_matrix = [[0 for j in range(len(fraction_list))] for i in range(len(lesser_than_threshold))]\n",
    "\n",
    "for i in range(len(fraction_list)):\n",
    "    for j in range(len(greater_than_threshold)):\n",
    "        val = (fraction_list[i]>=greater_than_threshold[j]).sum()/len(fraction_list[i])\n",
    "        greater_than_matrix[j][i] = val\n",
    "        \n",
    "for i in range(len(fraction_list)):\n",
    "    for j in range(len(lesser_than_threshold)):\n",
    "        val=(fraction_list[i]<lesser_than_threshold[j]).sum()/len(fraction_list[i])\n",
    "        lesser_than_matrix[j][i]=val\n",
    "        \n",
    "        \n",
    "# Taking average over all runs:\n",
    "avg_greater_than=[]\n",
    "avg_lesser_than=[]\n",
    "\n",
    "for i in range(len(greater_than_matrix)):\n",
    "    avg_greater_than.append(sum(greater_than_matrix[i])/len(greater_than_matrix[i]))\n",
    "for i in range(len(lesser_than_matrix)):\n",
    "    avg_lesser_than.append(sum(lesser_than_matrix[i])/len(lesser_than_matrix[i]))\n",
    "\n",
    "# print(greater_than_threshold + lesser_than_threshold)\n",
    "\n",
    "Change_df = pd.DataFrame({'Change': greater_than_threshold+lesser_than_threshold,'Val':avg_greater_than+avg_lesser_than})\n",
    "print(Change_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Income Distribution Plot and Lorenz Plot'''\n",
    "\n",
    "# configParser.read(configFilePath)\n",
    "\n",
    "# Generates box plot for 2d income list\n",
    "def box_plot(income_2d,city_lis):\n",
    "  fig, ax = plt.subplots()\n",
    "  plt.boxplot(income_2d)\n",
    "  ax.set_xticklabels(city_lis,rotation='vertical')\n",
    "  plt.ylabel('Number of Deliveries')\n",
    "  plt.ylim((0,1000))\n",
    "  ax.set_ylim([0, 700])\n",
    "  plt.show()\n",
    "  \n",
    "    \n",
    "\n",
    "# Generates scatter income plot, labeling drivers according to the range in which their income lies\n",
    "def scatter_income(driver_income_df,fair_type):\n",
    "  # \"fair_type\" input is just going to be used for labeling the plot and for saving the plot !\n",
    "  fig, ax = plt.subplots()\n",
    "  fig.set_size_inches(13, 9)\n",
    "  \n",
    "  # configParser.read(configFilePath)\n",
    "  diff_num = int(configParser.get('results-parameter','diff_num'))\n",
    "  # diff_num is the number of income ranges we're going to plot\n",
    "\n",
    "  driver_income_df = driver_income_df.sort_values('total_income')\n",
    "  driver_income_df = driver_income_df.reset_index()\n",
    "\n",
    "  df_len = (driver_income_df.index)\n",
    "  low_list = [0,45,90,135]\n",
    "  high_list = [45,90,135,100000]\n",
    "  # low_list and high_list are for income ranges: 0-45, 45-90, 90-135, 135+\n",
    "  colors = ['red','orange','green','blue']\n",
    "\n",
    "  for i in range(diff_num):\n",
    "    low_val = low_list[i]\n",
    "    high_val = high_list[i]\n",
    "    print(low_val,high_val)\n",
    "    ind1 = (driver_income_df['total_income']<=high_val)\n",
    "    ind2 = (driver_income_df['total_income']>low_val)\n",
    "    curr_income_range_df = driver_income_df[ind1 & ind2]\n",
    "\n",
    "    label_string = str(low_val)\n",
    "    if i==3:\n",
    "      label_string=label_string+\" + \"\n",
    "    else:\n",
    "      label_string=label_string+\" - \" + str(high_val)\n",
    "    \n",
    "    plt.scatter(curr_income_range_df['geolocation_lng'],curr_income_range_df['geolocation_lat'],color=colors[i],label=label_string)\n",
    "    plt.legend(loc='upper left',prop={'size':20})\n",
    "    plt.xlabel('Longitude',fontsize='26')\n",
    "    plt.ylabel('Latitude',fontsize='26')\n",
    "    plt.title(fair_type, fontsize='26')\n",
    "\n",
    "#   if fair_type==\"fair_algo\":\n",
    "#     plt.savefig(\"Plots/Scatter Plots/\"+state_dataset+\"_result.pdf\")\n",
    "#   else:\n",
    "#     plt.savefig(\"Plots/Scatter Plots/\"+state_dataset+\"_motivation.pdf\")\n",
    "  print(driver_income_df['total_income'].values)\n",
    "  \n",
    "  plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "# Lorenz curves corresponding to different algorithms:\n",
    "def lorenz(arrs, name_dis,colors):\n",
    "    # this divides the prefix sum by the total sum\n",
    "    # this ensures all the values are between 0 and 1.0\n",
    "    import matplotlib.pyplot as plt1\n",
    "    fig, ax = plt1.subplots()\n",
    "    fig.set_size_inches(10, 7.5)\n",
    "    plt1.rcParams['font.size'] = '26'\n",
    "    plt1.rcParams['figure.figsize'] = (10,7.5)\n",
    "    \n",
    "    \n",
    "#     for i in range(len(arrs)):\n",
    "    for idx, i in enumerate(dis_type):\n",
    "#       print(i)\n",
    "      arr = arrs[str(i)]\n",
    "      arr = np.array(arr)\n",
    "#       print(arr)\n",
    "      arr = np.sort(arr)\n",
    "      plt.rcParams.update({'font.size': 14})\n",
    "      scaled_prefix_sum = ( arr.cumsum() / arr.sum() )*100\n",
    "      # this prepends the 0 value (because 0% of all people have 0% of all wealth)\n",
    "      lorenz_cruve = np.insert(scaled_prefix_sum, 0, 0)\n",
    "      \n",
    "      # we need the X values to be between 0.0 to 1.0  \n",
    "      plt1.plot(np.linspace(0.0, 100.0, lorenz_cruve.size), lorenz_cruve, label=name_dis[idx],color=colors[idx])\n",
    "    \n",
    "    plt1.plot([0,100],[0,100],color='Black',linestyle='--')\n",
    "    plt1.legend(loc='upper left',prop={'size':20})\n",
    "   \n",
    "    plt1.xlabel('% of all drivers',fontsize=26)\n",
    "    plt1.ylabel('% of total deliveries',fontsize=26)\n",
    "    \n",
    "#     if len(name_dis)==2:\n",
    "#       plt1.savefig(\"Plots/Lorenz Curves/\"+state_dataset+\"_motivation.pdf\")\n",
    "#     else:\n",
    "#       plt1.savefig(\"Plots/Lorenz Curves/\"+state_dataset+\"_result.pdf\")\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 45\n",
      "45 90\n",
      "90 135\n",
      "135 100000\n",
      "[ 53.99  53.99  53.99 ... 191.33 191.33 191.33]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAycAAAJACAYAAACXLxn/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABS1klEQVR4nO3dfZzc873//8dLJCFXEhLHRayECClFT1f1qIuoyg+tcpSe07hKFUVdHXWKpl+RFq1TDlrtCdWKRlR7KK3LxrXTtKGLKK3LEKmWErlA0pDI+/fHzMZmd2b2YnZ2PjP7uN9uc5uZ9+fqPfvJZD/PfV98IqWEJEmSJFXbOtWugCRJkiSB4USSJElSRhhOJEmSJGWC4USSJElSJhhOJEmSJGWC4USSJElSJhhOJKmXi4iJEfFgRCyOiNURkSLilm7Y76T8vmpuzvparrsk1bJ1q10BSVL1RMRpwGXVrockSWA4kaTe7uz884PAycACYDWwqmo1kiT1WnbrkqReKiJGAJvk316aUnoqpfRWSumdlNKKcvefUpqeUoqUUpS7L0lS72A4kaTea0CL10urVgtJkvIMJ5LUyzQP9gbmtyi+v3kAeMtB4BGxY0R8IyIeiog3ImJlfuD8w/nyoe0dp9Cg8ogY1eJ44yNiYEScGxFPRMRb+fKdy/ycXa57B/c/JCIujIhnI2JFRLwWEb+KiD3yyx/If47pJfYxJiJ+GBHPRcTyiHg7Iv6Y3+/wcuonSbXIMSeSpIIiYidgboFFQ4GP5R9fiogJKaXnyzjUcKAJ2K6Mfayl0nWPiC3IjdMZ3aL4n4DPAp+OiJM6sI8jgR8DfVst+nD+cUJEfDal9NvO1k+SapUtJ5LU+1wHDAa2b1F2QL6s+QGQgHvIDZTfHdiaXJD4MHAqucHzo4AbIqKccSWXAVsAXwO2AUYAnwT+VsY+K1b3iOgD/JJcMFkFnA+Mze9/b2AO8H1gTIl97AVMJxdMXgAOIzf+pwE4AVgEDANuj4gtO1M/SaplkZJTuEtSbxQRo4CX8m/3Tik90MntNwH+TO4iet+U0j2tlk8CrgFoPSi+1bFTfvt7O/UBylBm3Q8nF/AATkgpXdlqeX/gt0BjvujalNKkVuv8kVxQegX4aErp9VbLdyYXcvoDP08p/XtXPqck1RpbTiRJXZJSeo1c6wTAPmXs6vaeDCZQdt2PzD8/C1xVYN/vAucU2zgidiEXTACmtg4m+X3MBZpDz+fKHR8jSbXCcCJJKioi1omIL0TELRGxICL+0Wrg/GH5VceWcZg7u6GqbVSi7vkuYB/Pv70tFe9+cB/wTpFlu7d4/csSh/vf/PO6LY4pSXXNAfGSpIIiYjBwG7BnB1bfoIxDvdT+Kp1TwboPbbH+c8VWSimtjogXgJ0LLG4eQ/JaSmlRiWP9qcXrhk7UUZJqli0nkqRiLiV3cZ+Aq4H9yA0C35APBs5fn1+3nD92/aOMbYupVN0Htni9rJ11i7WcDGpnebO3W7weXHQtSaojtpxIktqIiIHAEfm3304pTS6xXqZUuO4tA0l72w8qUv5OO8sLbf920bUkqY7YciJJKmRbcjNFAfyixHo79EBdOquSdV8CLM2/LjpWJSLWofhUwvPzz5tExLASx2o51fPLHayfJNU0w4kkqZD+LV73KbRCRHyM3P1DsqZidc8PgJ+Tf/vpEqvuTfGWkZY3VTykxD4OzT+vAh7uUAUlqcYZTiRJhcxv8frA1gsjYgDwwx6rTefMb/G6EnVvvsfJdhFxbIH99wcuLLZxSqkJeDL/dkpEDC+wjx2BE/Nvb0opLSmjvpJUMwwnkqQ2Ukqv8sFf+L8eEV+PiDERMSIiDsgv+wi5e31kSg/U/WfAY/nXP4yIqfn9b5S/8/vd5Gbp+muJfZwCrAa2AGZHxL9GxMYRMTIijiM3FXF/4C3g7C7WU5JqjuFEklTMieTGWPQDLgCeB14Hbid38f2ffNDFKWsqVveU0vvkumO9DPQFzs3vfyHwAPAJ4FRgXn6TVQX28SAwCVhJbuzKL4G/A38hd2PHjYDFwKdTSvO7Uk9JqkWGE0lSQSmlp4BGYAbwGrkL6VeBW4BPppT+u3q1K63SdU8pvQzsBFwEvAC8C7xB7t4q+6SUruSDMScFZ9pKKc0gN+h9Wn4f/yA3G9iTwLeBsSml3xbaVpLqVRS/ua0kSeqqiFhM7qaNZ6aULqlydSSpJthyIklSN4uIPcgFE4BHq1gVSaoptpxIktRJ+fuTLEkFfolGxPrkxp58jFyXsi1SSm3GnUiS2vIO8ZKkTIqI9u6gXsh7KaX3ur0ybR0EnBYRVwIPkgshg4B/ASYDO+bX+6bBRJI6znAiScqqggPJ2zEVOK+b61HMzsD/lFh+BbnB7pKkDjKcSJLUeXcBZwL7AtsAG5ObVvjvwO+AK1NKD1StdpJUoxxz0gnDhw9Po0aNqnY1JEmSpJr16KOPLkwpjSi0zJaTThg1ahRNTU3VroYkSZJUsyLi5WLLnEpYkiRJUiYYTiRJkiRlguFEkiRJUiYYTiRJkiRlguFEkiRJUiYYTiRJkiRlguFEkiRJUiYYTiRJkiRlgjdhrJB3332XRYsW8fbbb/P+++9XuzqqM3369GHw4MFsuOGG9O/fv9rVkSRJ6haGkwp49913WbBgAcOGDWPUqFH07duXiKh2tVQnUkqsXLmSt956iwULFtDQ0GBAkSRJdcFuXRWwaNEihg0bxvDhw+nXr5/BRN0qIujXrx/Dhw9n2LBhLFq0qNpVkiRJ6haGkwp4++23GTJkSLWroV5gyJAhvP3229WuhiRJUrcwnFTA+++/T9++fatdDfUCffv2dUyTJEmqG4aTCrErl3qC/84kSVI9MZxIkiRJygTDiSRJkqRMMJxIkiRJygTDiSrqlVde4ZhjjmGzzTajf//+jBo1itNPP53FixdXpT7nn38+EUFEcM8997RZPn369DXLCz2mTZtWhVpLkiTlXR9tH3XEmzCqYubNm8duu+3G66+/zkEHHcR2223HI488wuWXX85dd93F7Nmz2WijjXqsPo899hjf/OY3GTRoEO+8807JdQ866CB23nnnNuWNjY0Vqp0kSVI7igWR6wMmpp6tS4UYTlQxJ510Eq+//jrf+973OOWUU9aUn3HGGVx66aVMnjy5x1oiVqxYwZFHHskuu+zC1ltvzYwZM0quf/DBBzNp0qQeqZskSZJy7Nalipg3bx6zZs1i1KhRfOUrX1lr2dSpUxk4cCAzZsxg2bJlPVKfc845h5deeonp06ezzjr+s5ckScoir9JUEffffz8AEyZMaBMGBg8ezCc+8QmWL1/OnDlzKl6X++67j8svv5xvf/vbbLPNNh3aZu7cuVx22WV85zvfYcaMGbzyyisVrqUkSZIMJ7Vs5kwYNQrWWSf3PHNmtWu0xrPPPgvA2LFjCy5vDgnPPfdcReuxdOlSJk2axB577MGpp57a4e0uv/xy/uM//oNzzjmHo446ilGjRnHCCSewYsWKCtZWkiSpd6vJcBIR342IZyLijxFxc0QMzZdvFBH3R8Q7EXFFie13jog5ETE3Ipoi4mM9VvnuMnMmHH88vPwypJR7Pv74zASUpUuXArDBBhsUXN5cvmTJkorW45RTTmHRokVcc801Hbqb+ujRo/n+97/Ps88+y7Jly/jb3/7GL37xC0aNGsWVV17JMcccU9H6SpIkFVVs0HudDIaH2h0QfzdwTkppVURcBJwDnAWsAP4fsEP+Ucx/AVNTSndGxAH59+MrW+VuNnkyLF++dtny5bnyww+vTp0qZPr06cyfP3+tsvHjxzN+/PiS2910003MmDGDH/zgB2y11VYdOtZee+3FXnvtteb9gAEDOOyww/j4xz/OTjvtxM9+9jPOOussdtppp85+DEmSpPLVURAppCbDSUppVou3c4BD8+XLgN9GxJj2dgEMyb/eAPhbt1ey0hYs6Fx5D2tuGWluQWmtuXzo0KHt7mv69Ok8+OCDbcpLhZNFixZxwgknsM8++3DiiSe2X+F2bLHFFhxwwAHMnDmThx56yHAiSZJUATUZTlo5Bvh5J7c5HfhNRFxMrmvbbt1dqYpraMh15SpUngHbbrstUHxMyfPPPw8UH5PS0gMPPNDp4y9YsICFCxdy7733Fp2da9999wXg0ksv5fTTT293nyNGjADosRnGJEmSepvMhpOIuAfYpMCiySmlX+XXmQysAjo70OJE4D9SSjdFxOeBHwOfKlKP44HjARoycuEPwAUX5MaYtOzaNWBArjwD9t57bwBmzZrF6tWr1woIb7/9NrNnz2bAgAF8/OMfr8jxN9poI770pS8VXPbQQw/x/PPPs//++7PZZpuxww6legB+4OGHHwbocBcxSZIkdU5mw0lKqWBYaBYRk4DPAPuklDrb+e5o4LT86/8Fri5Rj6uAqwAaGxuz08mveVzJ5Mm5rlwNDblgkpHxJltvvTUTJkxg1qxZ/OAHP1jrJoxTpkxh2bJlfPnLX2bgwIEVOf4WW2zB1VcXPq2TJk3i+eef54wzzuBTn1r7n1lTU1Obu8CvXr2aiy66iN///vcMHz6c/fbbryJ1liRJ6u0yG05KiYj9gK8Be6WUlre3fgF/A/YCHgA+CTzffbXrQYcfnpkwUsgPf/hDdtttN0499VTuvfdexo0bx8MPP8z999/P2LFjuSAjrTwt7bLLLuywww7stNNObL755ixdupTZs2fz1FNPMWDAAGbOnMmQIUPa35EkSZI6rSbDCXAF0B+4Oz897JyU0gkAETGf3GD3fhFxMDAhpfTniLgamJZSagKOAy6PiHXJzfB1fM9/hPq39dZb09TUxLnnnstdd93FHXfcwaabbsppp53GlClTGDZsWLWr2MaZZ57JI488wn333ceiRYtYZ511aGho4Ctf+QpnnHGGXbokSZIqKDrfI6r3amxsTE1NTe2u9/TTTzNu3LgeqJHkvzdJklRbIuLRlFJjoWU1eRNGSZIkSfXHcCJJkiQpEwwnkiRJkjLBcCJJkiQpEwwnkiRJkjLBcCJJkiQpEwwnkiRJkjLBcCJJkiQpEwwnkiRJkjLBcCJJkiQpEwwnkiRJkjLBcCJJkiQpEwwnkiRJkjLBcCJJkiQpEwwn6jHXXXcdEUFEcPXVV7dZ/sADD6xZXuhx9tln90g9H3vsMQ477DD+6Z/+iX79+tHQ0MBJJ53E3//+96LbvPLKKxxzzDFsttlm9O/fn1GjRnH66aezePHiHqmzJElSPVi32hVQ7/CXv/yFk08+mUGDBvHOO++UXHevvfZi/Pjxbcp33333CtXuA7fddhuHHHIIq1at4sADD2Ts2LE888wzTJs2jVtvvZXZs2fT0NCw1jbz5s1jt9124/XXX+eggw5iu+2245FHHuHyyy/nrrvuYvbs2Wy00UYVr7skSVJR10fbsomp5+vRDsOJKi6lxBe/+EU22mgjDjnkEC6++OKS648fP57zzjuvZyrXwooVKzj22GNZuXIlN910E4cccsiaZT/72c+YOHEiJ598Mr/+9a/X2u6kk07i9ddf53vf+x6nnHLKmvIzzjiDSy+9lMmTJzNt2rQe+xySJElrKRRMmsszFlDs1qWK+973vsd9993HNddcw8CBA6tdnaJ+97vf8fe//53Gxsa1ggnAF77wBXbaaSduu+02Xn755TXl8+bNY9asWYwaNYqvfOUra20zdepUBg4cyIwZM1i2bFmPfAZJkqRaZjhRRT399NOcffbZnHbaaey5554d2uaFF17giiuu4MILL+QnP/kJzz//fIVrmfPaa68BsNVWWxVcvtVWW5FS4r777ltTdv/99wMwYcIE1lln7a/T4MGD+cQnPsHy5cuZM2dOhWotSZJUP+zWVctemglPTIblC2BAA+x0AYw+vNq1WmPVqlUceeSRNDQ0cOGFF3Z4u5kzZzJz5sy1yj73uc/xox/9iGHDhnV3NdcYPnw4AC+99FLB5S+++CIAzz777Jqy5tdjx44tuM0222zDrFmzeO6559hnn326s7qSJEl1x5aTWvXSTHjkeFj+MpByz48cnyvPiG9+85s8/vjjTJ8+nfXXX7/d9UeMGMF3vvMdnnzySd5++23eeOMN7rzzTj7ykY9w0003ceCBB7J69eqK1fcTn/gEQ4cO5Q9/+AO/+tWv1lr2i1/8gieeeAJgrRm4li5dCsAGG2xQcJ/N5UuWLKlAjSVJkuqLLSe16onJ8P7ytcveX54rz0DrycMPP8yFF17IV7/6Vf7lX/6lQ9tsv/32bL/99mveDxo0iP3224/ddtuNnXfemdmzZ3Prrbdy0EEHldzP/PnzmT59epvy9gbZDxw4kMsvv5xJkyZxyCGH8NnPfpZtttmGZ555httuu42dd96ZuXPntum+JUmSlGkTk7N1qcKWL+hceQ9atWoVRx11FGPHjuVb3/pW2fsbMmQIEydO5IILLuChhx7qUDiZOnVqm/KOzAB21FFHscUWW3DRRRfxwAMPcMcddzBu3DimT5/O66+/zty5c9l4443XrN/cMtLcgtJac/nQoUPbPbYkSVLFZDCIFGI4qVUDGvJdugqUV9k777zDc889B8B6661XcJ3jjjuO4447jtNOO43LLrus3X2OGDECoEOzXo0fP56Uuv4F3Hvvvdl7773blB911FEA7LLLLmvKtt12W4A1n7e15sH8xcakSJIk6QOGk1q10wW5MSYtu3b1GZArr7L+/fvzpS99qeCyxx57jMcff5zdd9+dbbfdtsNdvppnuyo2k1alLVmyhFtvvZURI0aw7777rilvDjGzZs1i9erVa3X5evvtt5k9ezYDBgzg4x//eI/XWZIkqdYYTmpV87iSDM7Wtf7663P11VcXXHbeeefx+OOPc/TRR3PssceutaypqYnGxsY221x33XX8/Oc/p1+/fnz+85+vSJ2bvf322wwePHitsuXLl3P00UezZMkS/ud//of+/fuvWbb11lszYcIEZs2axQ9+8IO1bsI4ZcoUli1bxpe//OVM399FkiQpKwwntWz04ZkII93l0EMPZd1116WxsZGRI0eyYsUK/vCHP/DII4+w7rrrcuWVVzJq1KiK1uHaa6/lkksuYfz48Wy66aa8+eab3Hrrrbz66qucdtppnHDCCW22+eEPf8huu+3Gqaeeyr333su4ceN4+OGHuf/++xk7diwXXFD91ixJkqRaYDhRZpx44oncc889zJ49m4ULF5JSYvPNN2fSpEmcfvrp7LTTThWvQ2NjI+PGjeOuu+7izTffZMiQIXzsYx/jxz/+Mfvvv3/Bbbbeemuampo499xzueuuu7jjjjvYdNNNOe2005gyZUpF780iSZJUT6KcgcO9TWNjY2pqamp3vaeffppx48b1QI0k/71JkqTaEhGPppTa9uXHmzBKkiRJygjDiSRJkqRMMJxIkiRJygTDiSRJkqRMMJxIkiRJygTDiSRJkqRMMJxIkiRJygTDiSRJkqRMMJxIkiRJygTDiSRJkqRMMJxIkiRJygTDiSRJkqRMMJxIkiRJygTDiSRJkqRMMJyoYlJK/OhHP2LXXXdl0KBBDBw4kMbGRqZNm8bq1auLbnfbbbcxfvx4NthgAwYNGsSuu+7Ktdde2yN1fuWVV7jgggs47LDDGDNmDOussw4RwQsvvFB0m5/85CccfPDBjBkzhiFDhjBw4EDGjRvHcccdx7PPPltwm1GjRhERBR+bbLJJpT6eJElSpq1b7Qqofh1xxBFcf/31bLzxxnzhC19gwIAB3H333Zx44on87ne/46c//Wmbba644gpOOeUUNtpoI4444gj69evHjTfeyKRJk3jyySe5+OKLK1rnpqYmvvGNbxARjB49mg022IAlS5aU3Oa6667j1VdfZdddd2WTTTZhnXXW4U9/+hPXXHMNP/3pT7nlllvYf//922y3wQYbcPrpp7cpHzRoUDd9GkmSpNoSKaVq16FmNDY2pqampnbXe/rppxk3blwP1Ci7br75Zg455BBGjx7NI488wvDhwwF47733+NznPsdtt93GTTfdxCGHHLJmm/nz57PddtsxcOBAHn30UUaNGgXA4sWL2WWXXZg3bx6/+93v+Jd/+ZeK1fuVV17hpZdeYqeddmLIkCGMHz+eBx98kOeff54xY8YU3GbFihWst956bcrvvvtuJkyYwLhx4/jzn/+81rLmzzZ//vyy6+y/N0mSVEsi4tGUUmOhZXbrUkXcfPPNAHz1q19dE0wA+vXrx7e+9S0g10rS0k9+8hPeffddTj755DUX7wDDhg3j61//OgDTpk2raL1HjhzJHnvswZAhQzq8TaFgArDvvvsydOjQkl3CJEmS9AG7dakiXnvtNQC22mqrNsuay/7v//6P9957j379+gFw3333AbDffvu12aa5W1TzOrXgt7/9LUuWLOGf//mfCy5/9913ue6661iwYAEDBw5kxx13ZM8996RPnz49XFNJkqRsMJzUsJlPzmTyvZNZsHQBDRs0cME+F3D4hw+vdrUA1rSWvPTSS22WvfjiiwCsWrWKF198ke222w5gzeDxsWPHttlm0003ZeDAgbzyyissX76cAQMGVKrqXXbjjTfy1FNP8Y9//IPnnnuOO+64gw033LBNC1Gz1157jSOPPHKtstGjR3PNNdew11579USVJUmSMsVuXTVq5pMzOf7W43l56cskEi8vfZnjbz2emU/OrHbVAPj0pz8NwH//93+zaNGiNeUrV65kypQpa94vXrx4zeulS5cCuYHihTSXN6+XNTfeeCNTp07lv/7rv7jlllvYcsst+c1vflNwjMwXv/hF7r33Xl577TWWLVvGk08+yZe//GXmz5/P/vvvzxNPPFGFTyBJklRdtpzUqMn3Tmb5yuVrlS1fuZzJ907OROvJv//7vzNjxgx+85vf8KEPfYiDDjqI9dZbj3vuuYdXX32VhoYGFixYwDrrdH8+XrJkCZdddlmb8tNPP52hQ4d2+/Ga3XDDDdxwww289dZbPPXUU0ydOpVPfOITXHnllUyaNGmtdVsGNIAddtiBadOmMWjQIC655BLOO++8NeN2JEmSegvDSY1asHRBp8p7Wp8+fbj11lv57//+b6677jquvfZa1ltvPcaPH89NN93EoYceCsDGG2+8ZpsNNtiAhQsXsnTpUjbaaKM2+2yvZaXZkiVLmDp1apvySZMmVTScNBsyZAi77bYbt956K42NjZx44ol86lOfYuTIke1ue8IJJ3DJJZfw0EMPVbyekiRJWWO3rhrVsEFDp8qroW/fvpx11lk8+eSTrFixgiVLlnDLLbcwatQonn/+eYYPH87o0aPXrL/tttsC8Nxzz7XZ16uvvsqyZcsYOXJku+NNRo0aRUqpzaPlDGA9oV+/fuyzzz6sWLGCOXPmdGibESNGALBs2bJKVk2SJCmTajKcRMR3I+KZiPhjRNwcEUPz5ftGxKMR8WT++ZNFtt8wIu6OiOfzz8N69AN0gwv2uYABfde+SB/QdwAX7HNBlWrUcTfccAPvvfceX/jCF9Yq/+Qnc6frrrvuarPNnXfeudY6teKvf/0rAOuu27FGyuYQU2iWM0mSpHpXk+EEuBvYIaW0I/AccE6+fCFwYErpw8DRwIwi258N3JtS2ga4N/++phz+4cO56sCr2HKDLQmCLTfYkqsOvCoT402avfXWW23K5s6dy3/+538ybNgwzj577R/7F7/4Rfr3788VV1yx1s0JFy9ezIUXXgjkuj1lyZtvvrlm9rHWbrvtNm6++WYGDRq01uxbTz/9dMGWkfnz53PyyScDcMQRR1SmwpIkSRlWk2NOUkqzWrydAxyaL3+8RfmfgPUjon9K6d1WuzgIGJ9/fS3wAHBWRSpbQYd/+PBMhZHW9t13X9Zff3122GEHBg8ezNNPP83tt9/O+uuvz6233spmm2221vqjR4/mu9/9LqeeeiqNjY3827/9G/369ePGG2/klVde4atf/WpF7w7frOXg9WeeeQaAs846i8GDBwNw7LHHsvvuuwPwl7/8hY9+9KM0Njay7bbbsvnmm7NkyRLmzp3LnDlz6Nu3L1dffTXDhn3QOPfzn/+cSy65hD333JMtt9ySwYMHM2/ePG6//XZWrFjBAQccwJlnnlnxzylJkpQ1kVKqdh3KEhG3Aj9PKV3XqvxQ4ISU0qcKbLMkpTQ0/zqAxc3vC6x7PHA8QENDw0dffvnlduv09NNPM27cuE5+kvrz3e9+lxtuuIF58+bxj3/8g80335z999+fc845p+Tg8FtvvZWLL76Yxx57jNWrV/OhD32Ik08+maOPPrpH6p37J1HcNddcsybALF68mEsuuYQHH3yQF154gTfffJO+ffvS0NDAXnvtxWmnndbm38KDDz7ItGnTePzxx9dMJTx06FB23nlnjjzySI488sh269CS/94kSVItiYhHU0qNBZdlNZxExD3AJgUWTU4p/Sq/zmSgETgktfggEbE98GtgQkppXoF9L2kZRiJicUqp3XEnjY2Nqampqd26e7GonuS/N0mSVEtKhZPMdusq1OLRUkRMAj4D7NMqmIwEbgaOKhRM8v4eEZumlF6NiE2B17up2pIkSZK6qCYHxEfEfsDXgM+mlJa3KB8K3A6cnVKaXWIXvyY3YJ78868qVFVJkiRJHVST4QS4AhgM3B0RcyNiWr78ZGAMcG6+fG5EbAwQEVdHRHPz0XeAfSPieeBT+feSJEmSqiiz3bpKSSmNKVJ+PnB+kWXHtnj9JrBPZWonSZIkqStqteVEkiRJUp0xnEiSJEnKBMOJJEmSpEwwnEiSJEnKBMOJJEmSpEwwnEiSJEnKBMOJJEmSpEwwnEiSJEnKBMOJJEmSpEwwnEiSJEnKBMOJKubGG2/klFNOYY899mDIkCFEBEcccUTR9f/yl79w0kknseuuu7LJJpvQv39/NttsM/bYYw+uueYaVq5c2Wab6dOnExFFH9OmTavkR5QkSVI3WrfaFVD9Ov/883niiScYNGgQI0eO5Jlnnim5/rx585g5cya77rorBx98MBtuuCFvvvkmd955J8cccwwzZsxg1qxZrLtu23+2Bx10EDvvvHOb8sbGxu76OJIkSaoww4kq5tJLL2XkyJGMGTOGBx98kL333rvk+rvtthuLFy9mnXXWbtBbuXIlEyZM4P777+eXv/wln//859tse/DBBzNp0qTurP4a48ePZ/78+cyfP78i+5ckSVKO3bpUMXvvvTfbbLMNEdGh9fv169cmmAD07duXgw8+GIDnn3++O6soSZKkDLHlRJn3/vvvc8cddwCw4447Flxn7ty5XHbZZaxYsYLNN9+cvffem5EjR/ZkNSVJklQmw0kNmzkTJk+GBQugoQEuuAAOP7zatSrfwoULueKKK0gp8cYbb3D33XfzwgsvMHHiRA488MCC21x++eVrve/Tpw/HHnssl112Geutt15PVFuSJEllMpzUqJkz4fjjYfny3PuXX869h9oPKAsXLmTq1Klr3kcEZ555JhdeeGGbdUePHs33v/99JkyYwMiRI1m6dCm//e1vOeecc7jyyit56623uP7663uy+pIkSeoix5zUqMmTPwgmzZYvz5XXuu22246UEqtWreLll1/m0ksv5aqrrmLPPfdk0aJFa6271157cfLJJzN27FgGDBjApptuymGHHcb999/PsGHD+NnPfsYTTzzRoeM+8MADBacjfvDBB3n55ZcLLnvggQcq8BOQJEnqnWw5qVELFnSuvBb16dOHhoYGTjvtNP7pn/6JL3zhC5x77rlcccUV7W67xRZbcMABBzBz5kweeughdtppp3a3GTVqFFOmTGlTPn36dJYsWcLpp59ecBtJkiR1D8NJjWpoyHXlKlRej/bff3+ATrVUjBgxAoBly5Z1aP1Ro0Zx3nnntSl/4IEHmD9/fsFlkiRJ6j5266pRF1wAAwasXTZgQK68Hv31r38FKHgDxmIefvhhALbaaquK1EmSJEndy3BSow4/HK66CrbcEiJyz1ddVduD4R977DHef//9NuXvvPMOp512GgCf/vSn11rW1NTUZv3Vq1fz7W9/m9///vcMHz6c/fbbrzIVliRJUreyW1cNO/zwbIeRW265hVtuuQWA1157DYDf//73a+7kPnz4cC6++OI163/zm99k9uzZ7LbbbjQ0NDBgwAD+8pe/cOedd7JkyRJ22203zjnnnLWOscsuu7DDDjuw0047sfnmm7N06VJmz57NU089xYABA5g5cyZDhgzpkc8rSZKk8hhOVDFz587l2muvXavsxRdf5MUXXwRgyy23XCucHHfccQwaNIhHHnmEBx54gOXLlzNs2DA++tGP8vnPf55jjjmmTbeuM888k0ceeYT77ruPRYsWsc4669DQ0MBXvvIVzjjjDLt0SZIk1ZBIKVW7DjWjsbExFepG1NrTTz/NuHHjeqBGkv/eJElSbYmIR1NKjYWWOeZEkiRJUiYYTiRJkiRlguFEkiRJUiYYTiRJkiRlguFEkiRJUiYYTiRJkiRlguFEkiRJUiYYTirE+8eoJ/jvTJIk1RPDSQX06dOHlStXVrsa6gVWrlxJnz59ql0NSZKkbmE4qYDBgwfz1ltvVbsa6gXeeustBg8eXO1qSJIkdQvDSQVsuOGGLF68mIULF/Lee+/Z9UbdKqXEe++9x8KFC1m8eDEbbrhhtaskSZLULdatdgXqUf/+/WloaGDRokXMnz+f999/v9pVUp3p06cPgwcPpqGhgf79+1e7OpIkSd3CcFIh/fv3Z9NNN2XTTTetdlUkSZKkmmC3LkmSJEmZYDiRJEmSlAmGE0mSJEmZYDiRJEmSlAmGE0mSJEmZYDiRJEmSlAmGE0mSJEmZYDiRJEmSlAmGE0mSJEmZYDiRJEmSlAmGE0mSJEmZYDiRJEmSlAmGE0mSJEmZYDiRJEmSlAmGE0mSJEmZUJPhJCK+GxHPRMQfI+LmiBiaL983Ih6NiCfzz5/szPaSJEmSqqcmwwlwN7BDSmlH4DngnHz5QuDAlNKHgaOBGZ3cXpIkSVKV1GQ4SSnNSimtyr+dA4zMlz+eUvpbvvxPwPoR0b+j20uSJEmqnpoMJ60cA9xZoPxzwGMppXe7uD0AEXF8RDRFRNMbb7xRRjUlSZIklbJutStQTETcA2xSYNHklNKv8utMBlYBM1ttuz1wETChnWMU3L6llNJVwFUAjY2NqRMfQZIkSVInZDacpJQ+VWp5REwCPgPsk1JKLcpHAjcDR6WU5nV2e0mSJEnVkdlwUkpE7Ad8DdgrpbS8RflQ4Hbg7JTS7M5uL0mSJKl6anXMyRXAYODuiJgbEdPy5ScDY4Bz8+VzI2JjgIi4OiIa29lekiRJUpWEPZo6rrGxMTU1NVW7GpIkSVLNiohHU0qNhZbVasuJJEmSpDpjOJEkSZKUCYYTSZIkSZlgOJEkSZKUCYYTSZIkSZlQk/c5kSSpy66PtmUTnblSkrLAlhNJUu9RKJiUKpck9SjDiSRJkqRMMJxIkiRJygTDiSRJkqRMMJxIkiRJygTDiSSp9yg2K5ezdUlSJjiVsCSpdzGISFJm2XIiSZIkKRNsOakRUWAK/uQf/yRJklRHbDmpAYWCSalySZIkqRYZTiRJkiRlguFEkiRJUiYYTiRJkiRlguFEkiRJUiYYTmpAsVm5nK1LkiRJ9cSphGuEQUSSJPVK1xeYntSbqdYtW04kSZKUTYWCSaly1TzDiSRJkqRMMJxIkiRJygTDiSRJkqRMMJxIkiRJygTDiSRJkrKp2KxcztZVt5xKWJIkSdllEOlVbDmRJEmSlAmGE0mSJEmZYDiRJEmSlAmGE0mSJEmZYDiRJEmSlAnO1qWCYmq0KUtTnC1DkiRJlWPLidooFExKlUuSJEndwXAiSZIkKRMMJ5IkSZIyoVvGnEREIzARaARGAP1SSlu3WL4JsBvwXkrptu44piRJkqT6UlY4iYgBwI+Af28uyj+3Hjm9DPgJMDgiPpJS+mM5x5UkSZJUf7rcrSsiAriZXDAJ4H7gskLrppTeBm7Kr/e5rh5TPaPYrFzO1iVJkqRKKqfl5EhgX2A5cFBK6d6IGAicXmT9O4AvAnuUcUz1EIOIJEmSelo5A+KPItd965sppXs7sH5zV65tyzimJEmSpDpVTjjZOf98UwfXfyP/vFEZx5QkSZJUp8oJJ4Pzzws7uH7f/POqMo4pSZIkqU6VE06aQ8kmHVy/uTvXa2UcU5IkSVKdKiecNOWfD+jg+hPzz78r45iSJEmS6lQ54eR6clMDT46IrUutGBH7AceRG0B/bRnHlCRJklSnuhxOUko/B/4P2BCYExFnAOOal0dEQ0TsHRH/A/w6f6zbOzizlyRJkqRepqw7xAP/CtwJ7AJ8N1/WfIOMl1qsF+S6cx1R5vEkSZIk1alyunWRUloEfAL4GvAXciGk9ePvwFnA3imlt8qqrSRJkqS6VW7LCSmlVcDFwMURMYbcrFwbAO8AL6aUnir3GJIkSZLqX1ktJ62llF5IKd2eUro+pfTrSgWTiPhuRDwTEX+MiJsjYmi+fN+IeDQinsw/f7Kd/Xw1IlJEDK9EPSVJkiR1XLeGkx50N7BDSmlH4DngnHz5QuDAlNKHgaOBGcV2EBFbABOABRWuqyRJkqQOqMlwklKale9OBjAHGJkvfzyl9Ld8+Z+A9SOif5HdXEpurEwqslySJElSD+rQmJOIeLEbj5lSSiXvi9JJxwA/L1D+OeCxlNK7rRdExEHAX1NKT0REN1ZFkiRJUld1dED8qA6sk8jNztVeeYdaKiLiHmCTAosmp5R+lV9nMrAKmNlq2+2Bi8h122q93wHA1wstK1KP44HjARoaGjqyiSSpHTG17a+LNMWGbEnq7ToaTqaWWHY0ufDyLvAg8Ay5mboGAdsBewHrkbvvyU87WrGU0qdKLY+IScBngH1SSqlF+UjgZuColNK8AptuDYwGmltNRgKPRcTHUkqvFajHVcBVAI2Njf7mlKQyFQomzeUGFEnq3ToUTlJKBcNJRMwkF0yuBr6WUlpSYJ2hwH8BxwJjU0qHd7GuLfe5H7nxInullJa3OtbtwNkppdmFtk0pPQls3GKb+UBjSmlhufWSJKnmXV8gPE40NErqGV2+z0lEHAN8AfhpSun4YuvlA8vxEbEecHhE3J9Surqrx827AugP3J1v/ZiTUjoBOBkYA5wbEefm152QUno9Iq4GpqWUmso8tiRJ9alQMGkuN6CoKwy76qRybsJ4LLnxI5d2cP1LgCOAL5FraemylNKYIuXnA+cXWXZskfJR5dRFkiRJBRh21QXlTCU8Lv/c0fuENK+3XRnHlCRJklSnygknffLPHZ0WuHm9PiXXkiTVtWKD3h0ML0kqp1vXn4FdgLOAwzqwfvNd3P9UxjElSXXAICJJKqSccPJj4GPAIRHxC+CrKaW/tF4pIrYgN97kX8mNUSl3MLwkrcV7ZkjdZGJyALOkqooWtwjp/MYRvwIOJBc6EjCX3H1OlgEDyY0v2ZncTRgD+FVK6V/LqnEVNTY2pqYmJ/tSFXixUFSxe2aAAUWSqs7fXyogIh5NKTUWWlZOywnA54BvA6eTG0vyz8BHWh47//w+uVm9vl7m8aTex9lOJEm1yt9T6qSywklKaRXwnxFxGXA4sBu5mzIOJNd6Mh/4HTAzpfTXco4lSZIkqb6V23ICQD54/Fd37EuSJElS71TOVMKSJEmS1G0MJ5JqmvfMkCSpfnS5W1dEHNXVbVNKP+3qtlKv49Se7TKISJJUH8oZczKd3PTBnZUAw4nUGQYRSZLUC5Q7IL74DQa6dxtJkiRJda7LY05SSuuUegB9gQbgWHJTCs8DdsgvkyRJkqS1VCwopJTeTym9klL6CfBRYBUwKyJGVOqYkiRJkmpXt9znpD0ppcUR8Q3gf4HJ5O4oL0mSpAyLqW174zsJiSqpJ7tY/V/++cAePKYkSZK6oFAwKVUudYdqjP/YrArHlCRJkpRxPRlOPpt/XtKDx5QkSZJUIyo+5iQihgBfAC4md4+T+yp9TKnW2cdXkiT1RuXcIf7FDqy2PjCC3L1NAngLmNrVY0q9Qak+vgYUSZJUz8ppORnVyfWbgBNSSs+VcUxJkiT1gDQl2ZKvHldOOGmvBSQBK4DXgD+klJ4u41iSJEnqYQYR9bQuh5OUkt2zJEmSJHWbakwlLEmSJEltdDmcRMRPIuLHEdG3g+tH8zZdPabUGxRrQrdpXZIk1btIqWsXPBGxmty4ksEppeUdWL8PsBJIKaU+XTpolTU2NqampqZqV0OSJEmqWRHxaEqpsdAyu3VJkiRJyoSeDCfD888revCYkiRJkmpEd4STdvuFRcQ6wEn5t/O74ZiSJEmS6kyHpxIucUf4P0dEqYDSh1yryXrkgswdHa+eJEmSpN6iM/c5GVWgLIAtO7GPOcD5nVhfkiRJUi/RmXDS+qaLU8i1hHwHeK/EdiuBN4HHUkp/6Fz1JEmSJPUWHQ4nre8IHxFT8i8v6MhUwpIkSZJUSmdaTlrbO//8j+6oiCRJkqTercvhJKX0YHdWRJIkSbUtom1ZF+/3rV7KmzBKkiSpbIWCSalyqZAOtZxExLnNr1NK32xd1lnN+5DUjusL/I8+0T9BSZKk+hSpA21tEbGa/M0WU0p9Wpd1VvM+ak1jY2NqamqqdjXUWxQKJs0MKJKkjCnVQmLXLrUUEY+mlBoLLevomJMFtA0ihcokSZIkqUs6FE5SSqM6UiZJkiRJXeWAeEmSJJWtWNctu3SpM8q5z4kkSZK0hkFE5epyy0lErI6IVRExoIPr92nepqvHlHqVYoPeHQwvSZLqVLktJ12ZudrZrqWOMohIkqRepCe7dfXNP6/uwWNKUrZ5LxtJktboyXAyJv/8Vg8eU5Kyq9i9bK4PA0olGAQlKfM6HE4iYs8ii3aPiBUlNu0DbAqcTO6+KE92vHqSVOO8IM4Gg6Ak1YTOtJw8QNubLgZwZwe3j/z2P+rEMSWpdnlBLElSp3S2W1fL37SpQFkxCXga+F5KaWYnjylJkiSpF+hMOBnd4nUAL5ILHdsDy0tstxJYnFL6R+erJ0mSJKm36HA4SSm93PJ9RCwgN/PWSymlUmNOJEmFTEyOSZEkqYUuz9aVUhrVjfWQpN7JINIzshYEs1QXScqQnpxKuNtExHeBA4H3gHnAF1NKSyJiX+A7QL/8sv9MKd1XZB+nAF8B3gduTyl9rUcqL6muxNS2F5lpSv4iM2sXxL1dVn7uTpQgSUXVZDgB7gbOSSmtioiLgHOAs4CFwIEppb9FxA7Ab4DNW28cEXsDBwE7pZTejYiNe7DukupEoWDSXL5WQJEkSR1SdjiJiM2AE4B9gLHABuTubVJMSimVddyU0qwWb+cAh+bLH29R/idg/Yjon1J6t9UuTgS+01yeUnq9nPpIkiRJKl9ZISEiPgNcBwymY1MKV8IxwM8LlH8OeKxAMIFciNojIi4AVgBnppT+UGjnEXE8cDxAQ0ND99RYUnXYxUqSpEzrcjiJiK3JhYL1gf8DbgB+QG564ZOA9YAdgIOBjYA/A5eQm+GrI/u/B9ikwKLJKaVf5deZDKwCZrbadnvgImBCkd2vC2wIfBzYBfhFRGyVUmpzlZJSugq4CqCxsdGrGKlW2c9fkqTMK6fl5D/IBZPfA+NTSikifpBfNiOltBwgIk4lF0pOAPZPKX2+IztPKX2q1PKImAR8BtinZaiIiJHAzcBRKaV5RTZ/BfhlfrtHImI1MBx4oyN1kySpy4pNlABrlxuaJfVC65Sx7SfJtZJcUqjFoVlK6R8ppZOA/wU+FxFHl3FMACJiP+BrwGebQ1C+fChwO3B2Sml2iV3cAuyd32Ysudm9FpZbL0m9y5pB7x0sl9aYmD54FFMswEhSHSun5WSL/PMTLcqa/5ftT9u7xl8MHEZujMi1ZRwX4Ir8Me6OCIA5KaUTgJOBMcC5EXFuft0JKaXXI+JqYFpKqQn4CfCTiHiK3JTDR5cKWJJUjEFEkqTuU0446Zt/XtSibBkwEBgBLG61fnMXqw+VcUwAUkpjipSfD5xfZNmxLV6/BxxRbj0kqSQH4EuS1CnldOtqnn635T1C/pp//nCB9ZtbWgaXcUxJ6ppioaBSYaEjYwokSdJaymk5eYLcDQ43A57Nl/0e2Jbc4PebWq3/1fzzgjKOKUldZ6uFJEmZVk7LyR3554+3KLs6//zJiHgwIk6JiNPz0wIfTm5Myv+WcUxJkupLT7fqSVKGRVfHgefvDP8n4MmU0p4tyv8bOJ0PBsevWUSutWX3lNKyLh20yhobG1NTU1O1qyEp69rruuVFpySpF4uIR1NKjYWWdblbV0rpb8CwAuVnRMRjwJeBHcnNqvUSuRaTi2o1mEhSj3NAvSSplylnzElRKaXrgOtaluXvQbJPRJBS+nUljitJmdfRcOEd7SVJvVBFwkkR25K7+eHqHj6uJEmSpBpQjZDgPJqSVEvsXiZJ6iHlzNYlSSqknmZf8n4tkqQeZPcqSaqEWgwikiRVmS0nkpRF9dT6IklSB9lyIklZ1ZUgkuXxIVmumyQpEwwnklQvsjz9cJbrJqn2+MeOumW3LklScXYvk5Q1TtRR1zrUchIRDd1wrE27YR+SpJ5mEJEk9ZCOduuaD/jbSZLUbeL5/IupH/y1M03xV40k9Wad6dYV3fCQJOmDYNK6fKq/KiSpN+toy8nUitZCkiqpuwZOZn0A5sSU3ToWq5skSS1EShn4pVUjGhsbU1NTU7WrIakzSl0Qd+aivbv2I6B0C4lduyS1K6t/iFGHRMSjKaXGQsucSlhSWQpdZHpx2QP8xSypN/P/u7rlVMKSuqzYX78dN1BhTqMpSapThhNJUo8r1rpmq5sk9W5265Kkluwu1WMMIpKk1mw5kVTfOnOH81LdpbxTuiRJFWfLiaTsK7c1o7sCRMv9NNepZd1qOajUY4tRPX4mSapztpxI6rIeGTeQxcHf1a5Td7fiVPvzVEKtfabro+1DknohW04klaXXjRvIykWjLQD1oyvdCSWpTtlyIkkdlZVgIklSnbLlRFL96epYg4nJcQqSJFWR4URSfSm3i4xBRJKkqrFbl6Rsa2/wd5YGEddqsKnHaZLr8TNJUi9gy4mk7Ct2QVntMNJSrV/01nr9C6mVz2R3wqqIqW1/5r1ugg8pgwwnktRRXkQW5YVemfw31KMK/XttLvffrVRdhhNJ6gwvItvwQk+S1F0ccyKpdzBUSJKUebacSMqW7uo2ZRiRJKnm2HIiKTtKTQNciDMySZJUV2w5kVTbDCKSOilNSU7iIGWU4USSVBYv9FSL/PcpZZPhRFLv4BTAFeWFniSpOzjmRFL96+xYFkmSVBWGE0nZ4QB3SZJ6Nbt1ScoWg4gkSb2WLSeSJEmSMsFwIkmSJCkTDCeS6p9jWSRJqgmOOZHUOxhEJEnKPFtOJEmSJGWC4USSJElSJtitS5LK4Z3nJUnqNracSFJXeed5SZK6leFEkiRJUibUZDiJiO9GxDMR8ceIuDkihubL942IRyPiyfzzJ4tsv3NEzImIuRHRFBEf69EPIEmSJKmNmgwnwN3ADimlHYHngHPy5QuBA1NKHwaOBmYU2f6/gKkppZ2Bc/PvJUmSJFVRTQ6ITynNavF2DnBovvzxFuV/AtaPiP4ppXdb7wIYkn+9AfC3StVVUoY4eF2SpEyryXDSyjHAzwuUfw54rEAwATgd+E1EXEyu9Wi3ylVPUiaUGrze1YAyMfVM4DFUSZJ6icyGk4i4B9ikwKLJKaVf5deZDKwCZrbadnvgImBCkd2fCPxHSummiPg88GPgU0XqcTxwPEBDQ0MXPomkulbpkFCJUCVJUkZFSrX5yy0iJgFfBvZJKS1vUT4SuA/4YkppdpFtlwJDU0opIgJYmlIaUmjdlhobG1NTU1O31F9SDytwkR/Pt10tTcnY/4mlpiU2nEiSalBEPJpSaiy0LLMtJ6VExH7A14C9WgWTocDtwNnFgkne34C9gAeATwIFLlEk1bNCwQQgpkbXA4rdryRJKktNhhPgCqA/cHeu4YM5KaUTgJOBMcC5EXFuft0JKaXXI+JqYFpKqQk4Drg8ItYFVpDvtiVJ7YmpbQNImlJk7AnY/UqSpE6oyXCSUhpTpPx84Pwiy45t8fq3wEcrUztJmVRs8HonFAomzeVpm7J2XReKBjdJkjqoJsOJJHVJyxaMIkGjIsrp7tVTM4KVqWRwM6BIkjrIcCJJ1dCZ7l4ZCyJ1rQaCoCTVs1q9Q7wklaXYX/P9K38vVmrckCSpR9hyIqnX6tYg0g1jWiRJ6u0MJ5LUQWlKKj3ou1D3n+4OLHY7kiTVMcOJJHVCVbt9ZXi64naDmyRJHWA4kVQ/stiqUCOzbXUHg4gkqVyGE0n1IcOtCj1y/ObPX+3PWst6UZCUpKwynEhSPclCGKtl/uwkqaqcSliSJElSJhhOJKlW+Fd9SVKdM5xIUi2ZmAwpkqS6ZTiRVB+KXbB7IS9JUs1wQLyk+tGbgogzS0mS6pDhRJJqVYsgsuYGiC1uhOh9RyRJtcZwIkk1rtCd2ZvLDSgdZCuUJGWCY04kqZ5dHx88VFipG3hKknqULSeSlDWV+iu+N2iUJGWc4USSKqGrAaPUX/ENFpKkOme3LknqbnYTkiSpS2w5kVS7HMQM5GblKjQoPm1ThcpIklQGw4mk2mT3p7WsNSuXLTSd4z1jJCkzDCeSVG+82O48fzaSlAmGE0nKku4KFuVebBtuJElVYDiRpO5WbsCodgiwy5wkqUoMJ5JUCV2dNtiL//rh+ZWkTnMqYUm1qdhFXq1c/DndcH3z/EpSl9hyIql21UoQkSRJHWLLiSRJkqRMsOVEkiqo4M0Rp1S3xafdOjkVsSSpSgwnklQhhUJAc3m17t5esk6tA4okST3Mbl2SVA21PqBfpXl+JalLbDmRpGrxQrW+eX4lqdNsOZEkSZKUCYYTSZIkSZlgty5JqpA0JWVutq4s1qnXcSY0SSrKcCJJFZTFi/4s1qnXKHXneAOKJNmtS5IkSVI22HIiKTPsbiRJUu9my4mkTCh1c0BJktQ72HIiSbXCgdSSpDpnOJGUec2tJ53u4lVPF/MOpK4PE1N9/buUpG5mOJFUM2JqkLahYxdyXswrq/z3J0lFGU4k1Z5iAaNYIJEkSTXBcCIpE4rdHLDDDCbls7uRJKnKnK1LUmakKcmpg6ulVDc4SZJ6iOFEkmpBsRYMWzYkSXXEbl1SL5fFGx8W6+KVtumGndfyxXyputslS5JUBwwnUi9W6saHWQgoQO+86O7sZ+7ozGS98WcpSaopduuSlG0TU9tHsfU6IutjKCo19sMxJZKkGmA4kVQ/OhNQvChfm2NaJEkZYLcuSfWl2B24C/GGjGvzZyFJqjJbTiTVHy+yJUmqSTXbchIR3wUOBN4D5gFfTCktiYiPAVc1rwacl1K6ucD2o4EbgI2AR4EjU0rv9UjlpYwoOitWb7rXSOtWlvaCTRYHlRdrLap2vSRJ6qRIqTZ/eUXEBOC+lNKqiLgIIKV0VkQMAN7Ll28KPAFsllJa1Wr7XwC/TCndEBHTgCdSSv9T6piNjY2pqampMh9IUvfr6riSYhf1pfbXnUGgEkGjMz8LQ40kqYIi4tGUUmOhZTXbcpJSmtXi7Rzg0Hz58hbl6wFtfstGRACfBCbmi64FzgNKhhNJNWZiiemIs6za4cCxOJKkKqmXMSfHAHc2v4mIXSPiT8CTwAmtW03IdeVa0qL8FWDzQjuOiOMjoikimt54440KVF1SxXmhLUlSTch0y0lE3ANsUmDR5JTSr/LrTAZWATObF6aUHga2j4hxwLURcWdKaUVX6pBSuor8GJbGxkavcKRa1TqgVKA1pdeP35EkqUyZDicppU+VWh4Rk4DPAPukAoNnUkpPR8Q7wA5Ay8EibwJDI2LdfOvJSOCv3VZxSb1OoWDSXF4yoPTUOBZJkmpAzXbrioj9gK8Bn205ziQiRkfEuvnXWwLbAfNbbpsPMveTH6cCHA38qgeqLSkrunLTwa7eqLCrd2fvztYdg44kqQZkuuWkHVcA/YG7c+PbmZNSOgHYHTg7IlYCq4GTUkoLASLiDuDYlNLfgLOAGyLifOBx4MdV+AySqqkrF+y1fJHf0a5ttfwZJUk1rWbDSUppTJHyGcCMIssOaPH6ReBjlamdJNUAQ4gkKWNqtluXJEmSpPpiOJGkblBs0HvapocrIklSDavZbl2SlDVpSurc3d0nFlm/tUrcMV6SpAwynEhSd+psaGgvoJSa6cuAIkmqM3brkiRJkpQJhhNJkiRJmWA4kaRq6+rNHSVJqjOOOZGkLOjpIOIge0lSBtlyIklZVolWlVKD7CVJqiJbTiQp62zRkCT1EracSJI+YOuJJKmKDCeSpLUZUCRJVWK3LkmqBAecS5LUabacSFJ3y/qAc0OSJCmjDCeS1BsZUCRJGWQ4kSRJkpQJjjmRlH29cfxGZz5zV38+E1Pv/NlKkjLLcCKp+kpdIJcav1GPF9GlxqW0/MztjV/p6M+nHn+GkqSaZTiRVF31GD662iLR0QHzlR5Yb2uKJKlKDCeSVAm1ejFfj2FRklQzHBAvSZIkKRNsOZFU2+yCJElS3bDlRFK2FQsaxcZ1QHZudtjdOhi64vn8Y2qseUiSVAtsOZFUXR0ZPN4dLSGVbGHprn13dCB9ifWKBZGYGqQptihJkrLNcCKp+irdDaujg7y7c4atjg4gL+ceJZXgvU8kSVVkOJEkqM4sVVmdGcsgIkmqEsecSJIkScoEw4mk2lVqsLwkSao5duuSVNsMImtJUwoPincwvCSpFhhOJNW/cgd5t9629UxiGRtAbhCRJNWqSMlfYh3V2NiYmpqaql0NSZXSmfujZG0aYkmSakREPJpSaiy0zJYTSWrWOhT0xM0cDSKSJK3hgHhJkiRJmWA4kSRJkpQJhhNJkiRJmeCYE0mZkMnpbzM4E5ckSfXMcCKp6goFk+byTAQUSZLUI+zWJUmSJCkTDCeSJEmSMsFuXZJUSxwDI0mqY7acSFKtKHZTyJ64WaQkST3AcCKp6ooNeq/6YHhJktSj7NYlKRMMIpIkyZYTSZIkSZlgy4mk7HLwtyRJvYrhRFI2lRr83ZMBJUsByTvWS5LqnOFEkorJSkBqySBS/wygknoxx5xIkpQVThctqZez5USSVB9scZCkmmfLiSSp9tniIEl1wXAiKZuK/cXbv4RLklS37NYlKbuqHURqbXasWqqrJEkFGE4kqZRaubjP4sxi6rxaC8SS1M1qMpxExHeBA4H3gHnAF1NKSyLiY8BVzasB56WUbi6w/UygEVgJPAJ8OaW0skcqL0lSKQYRSb1YrY45uRvYIaW0I/AccE6+/CmgMaW0M7AfcGVEFApgM4HtgA8D6wPHVrzGkqTKcYySJNWFmmw5SSnNavF2DnBovnx5i/L1gIK/lVJKdzS/johHgJEVqKYkqScZRCSp5tVkOGnlGODnzW8iYlfgJ8CWwJEppVXFNoyIvsCRwGkl1jkeOB6goaGhm6osqddw/IAkSR2W2W5dEXFPRDxV4HFQi3UmA6vIddMCIKX0cEppe2AX4JyIWK/EYX4IPJRS+r9iK6SUrkopNaaUGkeMGFH+B5PUe/TkvTfs1iRJqgOZbTlJKX2q1PKImAR8BtgnpdTmt29K6emIeAfYAWgqsP0UYATw5W6psCSVq9xWFoOIJKnGZbblpJSI2A/4GvDZluNMImJ08wD4iNiS3KD3+QW2Pxb4/4AvpJRW90ilJfUu7bWOtF7uHc4lScpuy0k7rgD6A3dHBMCclNIJwO7A2RGxElgNnJRSWggQEXcAx6aU/gZMA14Gfp/f/pcppW/2/MeQVPPKae3wHiSSJK2lJsNJSmlMkfIZwIwiyw5o8bomP7ekjLG1Q5KkblWT3bokSZIk1R/DiSRJkqRMMJxIUiV0diyJUwFLklSbY04kqSa0DBYdGThvEJEk9XKGE0nqqomp47N1GTwkSWqX4USSymHokCSp2zjmRJIkSVImGE4kSZIkZYLhRJIkSVImGE4kSZIkZYLhRJIkSVImGE4kSZIkZYLhRJIkSVImGE4kSZIkZYLhRJIkSVImGE4kSZIkZYLhRJIkSVImGE4kSZIkZYLhRJIkSVImGE4kSZIkZYLhRJIkSVImGE4kSZIkZYLhRJIkSVImREqp2nWoGRHxBvBytevRzYYDC6tdCa3h+cgOz0W2eD6yw3ORLZ6P7PBcdNyWKaURhRYYTnq5iGhKKTVWux7K8Xxkh+ciWzwf2eG5yBbPR3Z4LrqH3bokSZIkZYLhRJIkSVImGE50VbUroLV4PrLDc5Etno/s8Fxki+cjOzwX3cAxJ5IkSZIywZYTSZIkSZlgOOlFIuKrEZEiYnir8l0iYlVEHFpkuwci4tmImJt/bNwzNa5fZZyLj0bEkxHxQkR8LyKiZ2pc31qfj4g4KCL+mP/33hQRuxfZzu9GNyvjXPjdqIAC5+Pw/Pl4MiJ+FxE7FdluekS81OK7sXOPVrwOlXEuRkfEw/nvxs8jol/P1rw+FTgf20XE7yPi3Yg4s8R2fjfaYTjpJSJiC2ACsKBVeR/gImBWO7s4PKW0c/7xeoWq2SuUeS7+BzgO2Cb/2K9C1ew1ipyPe4GdUko7A8cAV5fYhd+NblLmufC70c2KnI+XgL1SSh8GvkXpPvb/2eK7MbdyNa1/ZZ6Li4BLU0pjgMXAlypZ196gyPlYBJwKXNyBXfjdKMFw0ntcCnwNaD3I6BTgJsCLqp7TpXMREZsCQ1JKc1JusNhPgYMrWM/eos35SCm9kz4YkDeQtudKldGlc+F3o2IKnY/fpZQW59/OAUZWo2K9UJfORb4F8ZPAjfmia/G70R0KnY/XU0p/AFZWrVZ1wnDSC0TEQcBfU0pPtCrfHPhXcn9xbM81+ebH/2d3ia4r81xsDrzS4v0r+TJ1UbHzkV/2rxHxDHA7ub/YF+N3oxuUeS78bnSzUuejhS8Bd5ZYfkG+29GlEdG/e2vYe5R5LjYClqSUVuXf+90oUwfPR3v8bpSwbrUroO4REfcAmxRYNBn4Ornmx9YuA85KKa1u55rq8JTSXyNiMLm/7B9J7i+TKqDC50Kd1MXzQUrpZuDmiNiTXJeJTxVYze9GJ1T4XKiTuno+8tvuTe6CuOAYIOAc4DWgH7nuRmcB3yynvvWswudCnVTO+egAvxvtMJzUiZRSwV/WEfFhYDTwRP6idyTwWER8DGgEbsiXDwcOiIhVKaVbWu37r/nntyPieuBjeAFWVAXPxV9Zu9l+ZL5MJXTlfKSUXmux/UMRsVVEDE8pLWy1b78bnVDBc+F3owu6ej4iYkdyY3/2Tym9WWTfr+ZfvhsR1wBFBwiroufiTWBoRKybbz3xu9EB5f5f1c6+/W60w3BS51JKTwJrZhCKiPlAY/4X++gW5dOB21oHk4hYFxiaUloYEX2BzwD3VL7m9afcc5FSejUi3oqIjwMPA0cB3698zetTqfMREWOAeSmlFBH/DPQn90ueFuv73egm5Z4Lvxvdq53z0QD8EjgypfRcsX1ExKb58xLkxjg8Vdla16dyz0X+e3M/cChwA3A08KuKV7xOtfN7vEP8brTPMScqKCLm5l/2B34TEX8E5pL7i8uPqlStXqnFuQA4idxfyV4A5lG6v7e67nPAU/mf/Q+Af2selO13o8d15FyA342eci65cQw/zI+1ampeEBF3RMRm+bczI+JJ4ElyrcHn93xV615Hz8VZwBkR8UJ+/R/3fFXrX0RsEhGvAGcA34iIVyJiSH6Z341O8A7xkiRJkjLBlhNJkiRJmWA4kSRJkpQJhhNJkiRJmWA4kSRJkpQJhhNJkiRJmWA4kaQ6FBHnRUTKP0ZVuz49JSKm5z/zA9WuS3siYnxvPEeSVIrhRJLUKxgGJCn7DCeSJEmSMsFwIkmqGymlSSmlSCmNr3ZdJEmdZziRJEmSlAmGE0nSWiJiTET8MCKei4jlEfF2RPwxIi6MiOEltnsgP55jev79vhFxZ0S8ERErIuLpiDg3ItZv5/ibRMQVETE/v90rETEzInbML5+fP855BbYtOCA+IhJwf4uil1qMP0kRMb/Fuh0am9L68xZZ55MRcXtEvJn/Wf45IqZGxKBSP4NW+9g1/7lezO/jrYh4LCK+ERGDO7ofSaoF61a7ApKk7IiII4EfA31bLfpw/nFCRHw2pfTbdvZzNnAhEC2KtwOmAvtExD4ppVUFttsJuBfYqEXx5sBE4JCIOKyTH6lq8j+Db7cqHgecCxwK/L92tl8HuAw4pcDij+QfX4qI/VJKz5ZdYUnKAFtOJEkARMRewHRyweQF4DBgE6ABOAFYBAwDbo+ILUvsai9yweRnwMfIBY3tgevzy/cEvlzg+IOAW/PrLwO+CowCNgYOBOYBPwU26MLHGwwc0OL99vmy5seHurDPoiLi03wQTJ4CPk3uc4whF07GAJe0s5uLyQWT94ErgF2B4cBI4EjgZXI/n9s60xIjSVlmy4kkqdn3yf3R6hXgEyml11ssuzIiHgbmAEOAi4B/L7KfUcAPUkontyhbFBFHAGOBRuBo4AettjsN2CL/+tCU0l0tlt0WEb8DHicXljolpfRORPyjRdHylNI7nd1PJ1ycf34R2COltCT//g3gWxHxInBdsY0jYhfgP/Jv/z2ldGOrVa6LiPvI/TzGACcB/9VNdZekqrHlRJLUfDH84fzbqa2CCQAppbnAlfm3n4uIoUV2twz4eoHtEx9ckO8cEa27jh2Zf57VKpg0b78I+FaJj5EJEbEruS5skPtZLmm9TkppJvBIid00d+W6o0Awad7H38i1qECu25sk1TzDiSQJYPcWr39ZYr3/zT+vC3y8yDpzUkpvFVn2fP65L7kuYgBExIbAtvm3t5Y4/q9LLMuK3fLPidL1vbnEsn3yz/dFxKBiD+BP+fU+HBH9yqy3JFWd3bokSQDNY0hey7dQFPOnFq+Lda96tcT2y1u8bjlrV8sxLM8V2zil9HpELAGGljhGtY3KP79WqNWkhWcKFeZDx2b5txfzQRexUtYhN1an1M9ekjLPlhNJEkDzgOr2xmG83eJ1sWls3+/gMVvO5DWwxetl7WxXybEi3aH5s3T1c3RlwD9A/y5uJ0mZYTiRJMEHF8rtzfrUcvnbRdfqvJYX8gOLrtW2DpWQOrhesd4HzZ+lq5+jZWg5Jn/H+4485new3pKUWYYTSRLA/PzzJhExrMR627d4/XI3Hr/lvsYWWykiRlD5Ll0rWrwudcPITYuUz88/bxIRpVpBtitUmFJaSm7aZoCtSmwvSXXHcCJJAmh5U8VDSqx3aP55FfBwdx08P86l+UaCnymx6mfLOMzKFq/7lFjvtRavtym0QkRsTfHg8Lvm1YCDShzn4BLL7s4/H5q/GaMk9Qr+hydJIqXUBDyZfzslIoa3XicidgROzL+9qZ3B3l3RPM3w/xcR+xY4/jDgG2Xs/80Wr4u1epBSehlonkr58AL1WIcSg9RTSg/zQdCaUmjK5YiYSO6misVcmn/eDji/xHpERJ98WJKkmmc4kaT695GI+Hg7j2Hk7q2xmtyNEGdHxL9GxMYRMTIijgPuIzfo+i3g7ArU83JyN4AE+GVEnB4RDRExPCIOAB4iN1h8SRf3/wK5ugOcFRFjIqJ/RKwbEa1bUn6af/58RFwcEVtFxIYRsQdwO7A/8NcSx/pq/nkr4KGI2D//ObaKiG8A1/BB96828gGnOQCdExG/iYjP5s/FBvmfy4SI+A4wjw9u2ChJNc2phCWp/pW6b0mzf00p3RIRk4Afkxv3UWi7xcBnKzH4OqX0dkR8FrgH2JBc68GlLVZZAXye3I0Hh5LrWtaZ/a+KiP8BziLXdaxl97GX+WAKYMi1VnwaGEcuaHy1xbKVwCTgeGDzIse6PSLOAb5N7uaWd7Ra5WlyrUA3lajyWcC7wDnAhPyjmPdKLJOkmmHLiSRpjZTSDHKD3qeRa2n4B7nZp54kd6E9NqX02+J7KPv4jwM7AD8EFpC76H4V+DnwLymlW/lglquuzBb2deB04A/57QvOzJUflP4J4BLgxXw9XgduzNfj+g58lu+Qu5nineRC3T/Idfe6kFyXrlL3kyGltDql9A1y5+N7wFPkWn7ez++vCfgBsB9wZnv1kaRaECl1dMZESZKqK9/9rPmi/tCUUqmWB0lSjbHlRJJUS1p2xXq0arWQJFWE4USSlBkRsWGJZcOBb+bfNnnTQUmqP4YTSVKWnBoRD0bEUfnZtIZGxOiIOAZ4hA8GrU+pXhUlSZXibF2SpKzZM/8oJAFnp5Raz34lSaoDhhNJUpbMIDdF8D7AaGAEuTut/43cfU6+n5/RS5JUh5ytS5IkSVImOOZEkiRJUiYYTiRJkiRlguFEkiRJUiYYTiRJkiRlguFEkiRJUiYYTiRJkiRlwv8PnZhlPmuDLFwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 936x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# driver_income_dfs right now is a dictionary\n",
    "fair_algo_income_df = pd.DataFrame(driver_income_dfs['fair_algo'])\n",
    "scatter_income(fair_algo_income_df, 'fair_algo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 45\n",
      "45 90\n",
      "90 135\n",
      "135 100000\n",
      "[  4.   4.   4. ... 164. 164. 164.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 936x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "maxmin_income_df = pd.DataFrame(driver_income_dfs['vanilla_maxmin'])\n",
    "scatter_income(maxmin_income_df, 'maxmin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnQAAAHVCAYAAAB4wWYZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAADdKklEQVR4nOzddVhVyRvA8e/QgqKyBna7duHa3YXdiYGxdqxrrbrGqru6xqpr19rdit0JdicmdoMicOf3x0V/ooDkBfT9PM99rp4zc+a9LLIvc868o7TWCCGEEEKIuMsspgMQQgghhBCRIwmdEEIIIUQcJwmdEEIIIUQcJwmdEEIIIUQcJwmdEEIIIUQcJwmdEEIIIUQcZxHTAcSkJEmS6PTp08d0GEIIIYQQX+Xh4fFEa500uHPfdUKXPn163N3dYzoMIYQQQoivUkrdCumc3HIVQgghhIjjJKETQgghhIjjJKETQgghhIjjJKETQgghhIjjJKETQgghhIjjJKETQgghhIjjJKETQgghhIjjJKETQgghhIjjvuvCwuHh6+vLs2fPeP36NQEBATEdjhDRytzcnAQJEuDg4IC1tXVMhyOEEOIrJKELA19fX27fvk3ixIlJnz49lpaWKKViOiwhooXWGj8/P169esXt27dJmzatJHVCCBHLyS3XMHj27BmJEycmSZIkWFlZSTInvmlKKaysrEiSJAmJEyfm2bNnMR2SEEKIr5CELgxev36Nvb19TIchhMnZ29vz+vXrmA5DCCHEV0hCFwYBAQFYWlrGdBhCmJylpaU8MyqEEHFArE3olFJzlFKPlFLnPjnmoJTarpS6GvieOPC4UkpNUkpdU0qdUUoViIZ4ovqSQsR68n0vhBBxQ6xN6IB5QJXPjvUDdmqtswA7A/8OUBXIEvhqD/xrohiFEEIIIWJcrE3otNb7gM+fxq4FzA/883yg9ifHF2ijI0AipVQKkwQqhBBCiO/asgkjeePtG6MxxNqELgTJtdZegX9+ACQP/HMq4M4n7e4GHhPfuXnz5qGUYt68eTEdihBCiG/Q8DFLSN1nEGcbZYrROOJaQveR1loDOrz9lFLtlVLuSin3x48fR0Nk3y6lVJCXubk5Dg4OlClThnnz5mH8TyKEEEJ8++7efUbRHufptM6V3GZwr+mvMRpPXCss/FAplUJr7RV4S/VR4PF7QJpP2qUOPPYFrfUMYAZAwYIFJQOJgCFDhgDg5+fHtWvXWLNmDXv37sXd3Z3JkyfHcHRCCCFE9Fq8eD8t2zclZZJ3/HDLm83VbKnXpEuMxhTXErr1QCtgdOD7uk+Od1FKLQUKAy8/uTUrotjQoUOD/P3gwYOUKlWKqVOn0rt3bzJkyBAzgQkhhBDRKCAggGbNRrBs2TCs0qdi1bsn+DjAkY4dqB7DVQFi7S1XpdQS4DDwo1LqrlKqLcZErqJS6ipQIfDvAJuBG8A1YCbwcwyE/N0qXrw42bJlQ2uNh4dHkHMeHh50796dvHnz4uDggI2NDVmyZKF37948f/78i2t9+szb7t27KVOmDAkSJMDe3p7q1atz8eLFYGO4du0aDRo0IHHixNjZ2VGsWDE2bdoUatweHh7Uq1ePZMmSYW1tTbp06fj555/x8vrydwEXFxeUUty8eZPJkyeTI0cObGxsSJ8+PX/88cfH280rVqygUKFC2NnZkSxZMrp06cLbt2/D+qUUQggRS92//5j06cuxbNlQVJPGnCzjz08PoHsFqFOweUyHF3tn6LTWTUI4VT6YthroHL0RibD4vADzzJkzWbNmDaVLl6ZChQoYDAY8PDz4+++/2bJlC0ePHiVBggRfXGfjxo2sW7eOqlWr0rFjRy5cuMDmzZs5fvw4Fy5cIEmSJB/bXr16laJFi/L06VOqVq1Kvnz5uHbtGrVr16Zq1arBxrlx40bq1auH1pr69euTLl06PDw8+Pfff1m3bh0HDhwIdqaxT58+7NmzB2dnZypVqsT69esZOHAg79+/x8HBgX79+lG7dm1KlizJ9u3bmTJlCgEBAfz7r1TSEUKIuOr+fWjQwJ67PsDsefxl706O1l54/mjH3uKOzHTMH9MhGjfi/l5fTk5OOiwuXLgQpnbfOoyLUL44vnfvXm1mZqatrKz0/fv3g5zz9PTU/v7+X/SZNWuWBvTo0aODHJ87d64GtLm5ud6xY0eQc/369dOAHjNmTJDjFStW1ICeMGFCkONr1679GPPcuXM/Hn/9+rV2cHDQZmZmet++fUH6jB49WgO6YsWKQY63atVKAzpdunT67t27H48/f/5c//DDD9rW1lYnSZIkyPfKu3fvdPbs2bWVlZV++PDhF1+DuEK+/4UQ36u3b9/qFi0G6yRJnmvrBgatfP11qb1btKGK0gaFzt9R6YE7B5osHsBdh5DTxNoZurhiRg83bpx6GNNhhCpjvuS0n1A5yq734Rm6TxdFaK0ZO3YsKVIELf+XLl26YK/Rpk0bevXqhZubG7/++uXKoMaNG1O+fNDJ2Pbt2zN69GiOHTv28djdu3fZvn07GTJkoEuXoA+k1qpVi9KlS7N3794gx9etW8ezZ89o0qQJJUuWDHKud+/eTJs2je3bt3P79m3Spk0b5Pxvv/1GqlT/r4iTKFEiatasydy5c+nduzfZs2f/eM7a2ppGjRoxdOhQLl68SLJkyYL9WgghhIh9Lly4RPnyjXnw4DSJK2TGf3Ezkh73ZN2+dqjtmks1C3PS8SjzczaK6VCBWHzLVcRev//+e5C/K6WYPXs2rVu3/qKtn58f06dPZ+nSpVy4cIGXL19iMBg+nr93L9jFyBQsWPCLY2nSGBcyf/rs3cmTJwEoUaIE5ubmX/QpU6bMFwndiRMnAChXrtwX7S0sLChVqhSenp6cPHnyi4QuuLhSpkwJgJOT0xfnPiR/d+/e/eKcEEKI2EdrzeTJ8+jZswsBAbbkaLuBy9OrkeDYfdYfHECipfcgvh39ypuTzSwbuZLliumQAUnoIi0qZ77iCh24AMDb25vDhw/Ttm1bOnbsSLp06b5Ikho1asSaNWvImDEjtWrVwtHREWtrawAmTJiAr2/wlbUTJUr0xTELC+O366ebxb98+RKA5MmTf9EewNHR8YtjH/p8Ppv4wYfjL168+OJcwoQJQ4wrtHN+fn7BjiWEECJ26dr1L6ZM+RWlytJ08UKWNkpBwsN3GbtyKYUMK+A8vBw3kPXPBjK49OBYs+e1JHQiwuzs7KhQoQIbNmygQIECtGrVisuXL2NrawuAu7s7a9asoUKFCmzZsuVjcgNgMBj4888/Ix3DhyTq4cPgb3s/ePAgxD7BnQM+rnINLkETQgjxbQoI0Pz9t2LatOYkTqzoc7QXv2UyI+GhO3Sdsp/WtWegOptB3hwsLGqH3qZpmLNhTIf9UawtWyLijjx58uDq6srdu3cZP378x+PXrl0DoGbNmkGSOYBjx45FSTmP/PmNK4sOHDgQZObugz179oTYJ7hz/v7+7N+/H4ACBQpEOj4hhBCxm8Fg4Pffx5IiRXX69jVQu3ZK/rrzC4MzmZHo4B1ajzrIbz2OoRZdg6cBMOVfll5aQa5kuciRNEdMh/+RJHQiSgwaNAhra2vGjh378Rm39OnTA18mTo8ePaJz56ipMpM6dWoqVqz4sT7cp9atW/fF83MAtWvXxsHBgSVLlnDkyJEg5yZMmMDNmzepUKHCF8/PCSGE+LY8fPiQokWrMXToLzx5Eo+//35LnRXQ3laT6MAdmg7ew8h/EmJxYBJsMYOWLTmUVnHg9gEaxZLFEB9IQieiRKpUqejYsSMvXrz4eCv1p59+onjx4qxevZpixYrRt29fWrVqRa5cubC1tf24mCCypkyZwg8//ECPHj2oXr06AwYMoGHDhtSvXx9nZ+cv2sePH585c+ZgZmZG6dKlad68OQMGDKBy5cr88ssvODo6Mn369CiJTQghROzk5radzJnzcuzYXpIm/Rd395Uk7WlHSzQOB+5Q75ftjFpUApuTLrDYDmzj83hwHxqsaECmxJnoUihmt/r6nCR0Isr0798fW1tbJk2axMOHDzE3N2f9+vV06tSJ+/fvM2nSJA4cOEC7du1wc3P7oghxRGXJkoUjR45Qr149Dh48yMSJE7lz5w5r166lbt26wfapVasWBw8epFq1ari5uTF27FguXrxIx44d8fDwIGPGjFESmxBCiNjnzp331K7dnjdvfqBKleNcu9aRcwUULbXmh323ce66hdFr6xP/oiusfA4nvAkYOpiGB7rx/O1zVjdaTSKbRDH9MYJQH1Ysfo8KFiyo3d3dv9ru4sWLQeqLCfE9ke9/IcS3wtPTkytXUtKqlRXPnl1i3Li0dO5sywIFrbUm6Z5b1Ojhxl9bm+LwZDxMHAKzgaZN+bVlSv48MpYFtRfQIm+LGIlfKeWhtf6yfhYyQyeEEEKI78DixUvJli0vlSsPJWFCOH48G1262DL3QzK3y5Ma3bcakzkzD5gzFOYqqFqVNX1r8ueRsXQq2CnGkrmvkYROCCGEEN8sb29vmjRpS7NmTfD1zUWdOh1wd4c8eWA60BZItv0mNXq68ZdbMxwSv4Xp9WAyUOgnrk77g1abXSmUqhDjK4//ymgxR+rQCSGEEOKbdO7cOapVa8CdO5exsBjItGlDadvWmPpMBroCjpuvUb3fTv50a4aDox1MqQCjnkHmTHivWUndNdWwtrBmRYMVWFtYx+jnCY0kdEIIIYT45vj7w8SJxgUQ6dLtYPPmcuQILBs3HugFpNxwhWoDdzHGrRkOKRLAwo7wyzFInhS9fQ/tD/3K+Ufn2dZiG2kTxu5SVpLQCSGEEOKb8fTpU/79dylubp05cCAXrVtfZvJkCwI3MeJP4Fcg1epLVBu6lzHbmpPYMT5smAqu0yFJfDhwgin317L47GJGlB1BhYwVYvIjhYkkdEIIIYT4Juzbt4969Zrx5MlD4sWrwMKFP9Ks2f9TnRHAb0Dq5ReoPmIfo7Y3J3Hy+LBjAzTsAj9YwgF3Dus79HLrhXNWZ/qX7B9jnyc8ZFGEEEIIIeK0gIAABg/+nTJlyvLkiQ1Zshzm1KkfadbMeF4DQzAmc2kXnaX6iP2M3tEiMJnbDs51wEHDtg08SpKYBisakCZhGhbUWYCZihupkszQCSGEECJOq1q1Htu3rwNa0KbNFKZMSYCNjfGcBgYCo4C0809T7e8jjNrRnETJ7GDNGmjUAJIHwJIR+GcrT+P/KvH07VMOtz0c64oHh0YSOiGEEELEWWvXwsGDrbCxqcf8+S1o2PD/5zTQFxgLpJ91kmr/HOOPHc1JmNQO5s+HNm0gowEm1IDiA/ht5wB2e+5mXq155HPMFyOfJ6IkoRNCCCFEnPLu3Tt69fqF8+ezsG9fNwoUqMPy5ZAp0//baKAnMBHIMM2DqtPc+WNnCxImsYVJk6B7d8hjA/2TQcX/WHd5PaMPjqaDUwda5WsVQ58s4iShE0IIIUSccenSJerWbczFi6eBvnTrBn/+CdaflIgzYKwxNxXI+M8xqs4+xcgdLUj4QzwYNgyGDIGSKaDdI6iwnKuvH9NybUsKpizIxCoTY+aDRZIkdEIIIYSI9bTWzJ07l59/7sr797bY2W1k4cLq1K4dtJ0B6ATMADL/fYSqC88yclcLEiSyhp49jcXpav8EdY9DwXH4JMxNvVlFsDCzYGWDlbG6eHBoJKETQgghRKzn4XGOtm3bAWXJn/8/Vq9OSfr0QdsEAK7AXCDLmINUW3mRETubEz+BJbRtC/PmQYcmUGoFpHJG/9iDDutace7RObY020K6ROlM/bGijCR0QgghhIi1vLy8eP06Be3a5QZ20atXSUaPNsfSMmg7f6A1sBDIOnI/1dZfYfj25sSPp6BBA+PqicH9ocBS0CmgyFz+9ZjGwjMLGVZmGJUzVzb5Z4tKcaO4iogVlFIopcLUNn369Cil8PT0DPb4h5eZmRmJEiWiWLFiTJkyBX9//2Cv5+rqilIKW1tbXrx4EclPIoQQIrYzGAz8+eefpEuXgbx593LnDmzYUIZx44JP5lpgTOZ+HLyHGhuvMmJbM+Kb+0H16sZkbsIEqHAVfG5D8aUceXyVHlt7UD1LdQaWGmjyzxfVZIZOxIju3buTKFEiAgICuHnzJqtWreLw4cPs3LmT1atXB2n7+vVrli5dilKKt2/fsnDhQrp06RJDkQshhIhuDx48oHnzVuzcuQ2oj5NTXlasgNSpv2zrBzQBVgHZ++3E+dBdhmxrhu37N1CtGnh4GEuUFPWG4ysh32ge22ahwcICpLZPzX91/oszxYNDE/c/gYiTevTowdChQxk+fDgLFy7E3d2dePHisWbNGvbu3Ruk7eLFi3nz5g09e/bEysqKmTNnxlDUQgghotu2bdvIlSsvu3btA6bTv/9y9u9PFGwy5wvUx5jM5ei9jdrH7/P7libYvn4KpUvD6dOwahU45wGPnpCiCgE/9qLJqiY89n7MqoarSBwvsWk/YDSRhE7ECjlz5qRMmTIAHDt2LMi5mTNnYmZmRo8ePXB2dubMmTMcPXo0BqIUQggR3ebOPc+zZ0lJlOg4bm7t+eMPhUUw9xN9gJrAeiBnly3UO/+EIRsbY/PgDhQvDrduwZYtUK0cHGgI1j9A0QX8tmcIO2/uZGr1qeRPkd/Eny76SEInYg2tNUCQ5/ROnjyJh4cH5cuXJ02aNLi4uAAwY8aMmAhRCCFENLhx4wYbN+6kVStYurQ7JUoc5/z5XFSqFHz710B1YLvW5Gmznga3XjJobUOsL583JnOvX8OuXVCmDBzrAG+uQ7HFrPM8xKgDo2iXvx1t8rcx4SeMfpLQiVjh/PnzH2+1Fi5c+OPx6dOnA9C6dWsAqlSpgqOjI8uWLePVq1emD1QIIUSUWrJkCXny5KNuXVcWLPBn6FAzdu+OR4oUwbd/AVQG9hk0eZuuofHr9wxY1QCrY4eMt1ktLWH/fvjpJ7g+G24tgdy/c80yFa3WtsIphRP/VPvHhJ/QNGRRRCT16AGnTsV0FKHLl8+4uCc2mTBhQpBFEatXr+bt27fUqVOHkiVLAuDt7c3ixYtJmDAhderUAcDCwoJmzZoxbtw4Fi1aRKdOnWLyYwghhIggb29vunTpyrx5c1GqGEmSLGbZMgvKlg25zxOgktacCdDka7iKpnaW9PivNuabN0KjRpA+PWzbBmnSwIuz4NEVHCvgk7U79eaUwNzMnJUNV2JjYWOqj2kyktCJGDFxonFrFaUU8ePHJ0+ePDRv3pyOHTt+bLN06VJev35Nhw4dsLH5/z8+FxcXxo0bx8yZMyWhE0KIOOj58+cULlyUq1evAAMpV24oixdbkCxZyH0eABW05oq/gQK1ltM8VQI6T6uG+YL54OoKTk6waRMkSQL+3sbn5iwToov8R6fNXTj78Cybm20mfaL0pvmQJiYJXSTFtpmvuOLmzZuk/7zE92c+PCf34bm5D3LlyoWTkxMeHh64u7tTsGDBaIpSCCFEdLhxIxGPH1fHzGwqI0aU49dfwSyUh8DuAOW15pZvAAWqLcElZ1LaT6iE2di/oF8/qFgRVq+G+PGNHY53hleXodx2ZlxYx4LTCxhaeihVMlcxyeeLCZLQiVjpzJkzH1e7Fi1aNMR2M2bMkIROCCHigKdPn9K5c2cyZRrM2LE5SJp0HBs2QIkSofe7gTGZe/DWH6eKC2lfMi2tRpZB/dIHxo+HJk2MW3pZWQV2mA8350OuwRwPsKfb1m5UzVyV30r/Ft0fMUZJQidipQ+zc2XKlCFTpkzBtlm8eDFLlizh77//Jv6H38qEEELEOvv27aNJk2Z4eT1Ea2eqV8/BvHnGu6OhuYwxmXv+5j1OZf+jc62sNO5bGNWyJSxeDN26GZO6D9N7Ly/C8Z8hWWmeZPqZejN+IkX8FCysu/CbKB4cGknoRKzz9u1bFi1ahLm5OYsWLSJlypTBtvP19WXhwoUsWbIEV1dXE0cphBDia/z9/RkxYgTDhw/HzCwjZmaHGTPGiZ49Q7/FCnAW4zNz3i99cSo1nx6t8lC3fS6oWdO48OGPP4y3Wz+UuvL3MT43Z2FHQNH/aLq6BY+8H3GwzUEc4jlE+2eNaZLQiXD7/Jm2T02dOhVbW9tIXX/ZsmW8ePECZ2fnEJM5gHbt2rFw4UJmzJghCZ0QQsRCU6ZM5ffff0epFqRIMYUVKxLwSWWqEHlgXM36/ulbfio5j1+6FaJa3TRQtqyxtMSsWdC27WedusPLc1BmK0OPzmD7je3MdJ6JU0qn6PhosY4kdCLc5s+fH+K5CRMmRDqh+7C1V7t27UJtV7p0abJmzYq7uzunTp0iX758kRpXCCFE1Hj58iX+/gnZurUDkJbatWszezYkDsMuW4eAqlqD1xsKlZrPwCGlKFfMzlgw+P59WLcOqlcP2slzMVyfBTn6sfGNHyP2j6BNvja0KxD6/0e+JZLQiTD7sJNDWHh6eobr+KcOHjwY5nEuX74c5rZCCCGi17t37+jTpw+rV29CqZM8eZKISZNq06XL/++MhmY34Kw1lrdfUqjsAoaMrUixdD5QrBgEBBh3fyhSJGinV1eMu0EkLc6NNK1pMasw+R3zM7na5Gj5jLGVJHRCCCGEiLSLFy/SuHFjzpw5g1K9yJDBlsOHoUCBsPXfCtTRmnjXnlG00iKGTauOU8BlKNUAkiYFNzf48cegnQLeGZ+bM7PiXaG51FvaEIBVDVcRzzJe1H7AWO7bXvIhhBBCiGiltWb27Nk4ORXk4sX7wCYaNRrHyZNWYU7m1gA1tcbu/GNKVFzEmPm1cLq9y7gAIls2OHLky2QO4ERveHEaXWQenfb8wakHp1hYZyEZEmeIyo8YJ0hCJ4QQQogI01rzzz+L8Pcvgrn5aWbOrMbixWBvH7b+S4EGWpPQw4vSzssYt6IeubbNhPbtjQWD9+4FR8cvO95eCVenQrbezHzoxbxT8/it1G9Uz1r9y7bfAbnlKoQQQohwO3bsGI6OaZg6NQWnT68mR44ELF9uTs6cYb/GHKCd1iQ9dJeyrdYxenUd0o/vD//9Z1zF+u+/YGn5Zcc3N+BoW/ihEB7J6tF1XhkqZarEkNJDouzzxTUyQyeEEEKIMDMYDIwZM4bixYvj5NSfMWOgfftEHD8evmTuH6AtkGyXJ5XbbmD8smqk79XCmMwNGwYzZwafzAX4woFGgBnPC0yj7srGOMZ3ZFHdRZibmUfRp4x7ZIZOCCGEEGHy4MEDWrZsyfbt27G0rI+v7wSWLYOGDcN3nT+BX4EUG65QfeAuxswpgUPz6nDjBixcCM2ahdz5VD945k5AiVU0cevPgzcPOND6AElsv7LtxDdOEjohhBBCfJW7uzvVq1fn6dNXwHTy5nVl2TJFxoxhv4YGhgDDgVRLz1N7/GFG/5mN+HUqgp+fcQeI0qVDvsDddXB5AmTtyrDrp3G77sa06tP4KdVPkfps3wK55SqEEEKIr/L3z8TbtwUJCHCnT5/2HDwY/mSuD8ZkLs3cUzSZ5sHYLvGJX6cq2NnB4cOhJ3Pet+CwCzg4sTVBeYbtG0arvK1o79Q+ch/sGyEJnRBCCCGCdf36dVxd2zNz5nvKl0+MtfUmNm/OyV9/gZVV2K9jAH4G/gbSTT6Oy/Lz/FH5ATatmkK+fHD0aPBlST5ewA8ONAYdwN3cY2m6tjV5k+dlavWpqLBULP4OSEInhBBCiC8sWbKE/Pnzs2DBCtq3v0DhwnD6NFStGr7r+ANttGYakHHMITrtvcmQtAewHPAr1Ktn3P0hadLQL3J6IDw9wvufplJrU28M2sCqhquwtYzcVpPfEknohBBCCPGRt7c3bdq0oWnTpvj55cbP7xTDhuVj+3ZImTJ81/IDmmrNfKXIOngPfS7epa/3PMxnTIO+fWHZMoj3lR0d7m2Ci39B5o78fHYPJ7xO8F+d/8jkkCmiH/GbJIsihBBCCPFRixYtWLt2LWZmA/nhh6EsWWJByZLhv847oIFBs9FMka3Pdob6PKHhydGo8+dh2jTo0OHrF/G5C0daQaI8zDPLy+yTnRhYciDOPzqHP6BvXJQndEqp+EAm4KnW+m5UX18IIYQQUUtrzfv373nzxprnz4ehdRdq1CjH3Lnwww/hv543UDPAwC5zM3J12sw4cy8qrf0N3ryBTZugcuWvX8TgDwebQMA7zmUdTMelzaiQsQK/l/k9/AF9B8J1y1UplVop1U0p1TGE86OBJ8AJ4JZSar9S6vvbUE3EWZ6eniilcHFxMfnY8+bNQynFvHnzwtzHxcUFpRSenp7RFpcQ4tv25MkTatWqRe3aHciXDw4ezMWECeVYty5iydwroKK/gd1AXpd1zDO7TKW53YxFgg8dClsyB3B2CDw+wJt843De1IdkdslYXHfxd108ODThfYauCTAeKPX5CaVUV6AvYAWowFdxwE0pZRPJOEUsoJQK8jI3N8fBwYEyZcowb948tNYxHWK0GTp06Bef38bGhsyZM9O+fXtJqIQQcdLevXvJly8fmze74eaWH2trzeHD0L07RGTx6DOgrF8ARzUUaLaGVYaDOP3bG3LkMK5kzZUrbBfy2gbnR6EztqHh8XXce3WPFQ1WkNTuK4snvmPhveVaMfB93acHlVJmQH+MZWb2Y0z6MgMjMN5+7QBMjFSkItYYMsS4V56fnx/Xrl1jzZo17N27F3d3dyZPnhzD0UWv0qVLU6ZMGQCePn3Krl27mDlzJitXruTo0aNkyZLFpPGMGjWKfv36kSpVKpOOK4SI2/z9/Rk+fDgjRozA2joTAQGHadq0ANOmQYIEEbvmI6Ds+wAuAcUaL2P1u3Uk3bLMuJJ1wQKwDeOK1LdecKg5JMzBqLcp2HJtDlOrTaVw6sIRC+w7Ed6E7sPt0xOfHS8BOAJvgFpa65cASikrYCRQG0novhlDhw4N8veDBw9SqlQppk6dSu/evcmQ4du9y16mTJkgn99gMODs7MzmzZv5448/mDt3rknjSZEiBSlSpDDpmEKIuM/Ly4tx4yZiadkC+Ic5cxLg4hKxWTmAe0BpX388DZoq9Rey7NEc4rsfgP79YcQIMAvjDUFDABxqBv7e7E/blUGrO9EiTws6Fgz2SS/xifDeck0W+P7os+NlAt83f0jmAq0NfA/Hdr0irilevDjZsmVDa42Hh8cX55cvX06pUqVImDAh8eLFI3fu3IwaNQpfX98v2iqlPs6AfS6458U+febN09OTxo0bkyRJEmxsbChYsCAbN24M9lqvX7+mV69epE6dGhsbG7Jly8bff/+NwWAI12c3MzP7+Lzd8ePHvzjv5eVF586dSZ8+PVZWViRNmpS6desG+3X61KZNmyhWrBh2dnYkTpyY+vXrc/Xq1S/aReXXRAjx7Tt48CC+vpqJE9Pg7X2WrFnn4eGRgNatI57MeQJF3/lz630AzWv+y5qLo4h/+ijMmQN//BH2ZA7g3HB4uJsnOX+n9pYB5E6em2k1pknx4DAIb0L34Vm4z4vGlMJ4u3X3Z8cfBL4nDOc4Io6ytLQM8vcBAwbQqFEjLl68SNOmTenSpQtaawYMGEDlypV5//59lIx769YtChUqhKenJy1atKBRo0acO3eOWrVqsXt30G9LX19fypcvz/jx40mSJAndu3endOnSDB8+nJ49e0Y4hs8/+82bNylYsCBTp04lU6ZM9O7dm8qVK39M1kJKrFavXk3t2rVJnTo13bt3p2jRoqxatYoiRYpw+fLlMMcTnq+JEOLb9vbtWzp37kyJEiXIkWMR48ZBp05pOHoUsmeP+HUvAUXe+fPgrT+/VBvFHPehWL18Ctu3Q+vW4bvYg11wbhgB6ZpR5dBSAgwBUjw4PLTWYX4Bd4EAoNgnx2wBn8DjuT9r74hxx4/H4RnHVC8nJycdFhcuXAhTu28dxqT9i+N79+7VZmZm2srKSt+/f//j8UOHDmlAp0mTRnt5eX087ufnp2vUqKEBPXLkyC/GKF26dLDjt2rVSgP65s2bH4/dvHnzY1xDhw4N0n7r1q0a0FWrVg1yfOTIkRrQdevW1QEBAR+P37hxQydOnFgDulWrVkH6DBkyRAN6yJAhQY77+/vrypUra0B36dIlyLlKlSppQI8YMSLI8YMHD2pzc3Pt4OCgX79+/fH43LlzP36WDRs2BOkzYcIEDehy5cpFy9ckNPL9L0TcduHCBZ07d24NaCur3tre3levXBn567prrRO+89PWD97oaQU6aIOFhdbZsml97Vr4L+bzQOtVjlpvyKa7rmutGYped2ld5IP8xgDuOoScJrzP0LkDzhi3ZDsUeKwtxpm7h1rrs5+1zxz47hXOceKMHsCpGI7ha/IBE6Lweh+eIft0UYTWmrFjxwZ5nmvOnDkADBo0CEdHx4/HLSwsGDduHJs3b2bWrFkMGDAg0jGlS5eOQYMGBTlWuXJl0qZNy7Fjx4Icnzt3LmZmZvz555+YfXIrIEOGDHTr1o3ffw+5xtGePXs+fv5nz56xfft2Ll26RI4cOfjtt98+trt79y7btm0jbdq09O3bN8g1ihUrRpMmTVi4cCGrV6+mZcuWQc6XK1eOGjVqBDnWpUsX/vnnH3bt2sWtW7dIly5dlH5NhBDfpsWLF9OuXTu0jg9spkCBqixZAunTR+66e4Gq7wMwu/uSDdVcqHhlo7EcybJlkDCcN+W0AQ63AL8XrE35M/+4DaZ/if7U/LFm5IL8zoQ3oZsD1ASaKKV+xJioVcU4GzAnmPYfaktfiHCEItb5POFRSjF79mxafza9fuKEce1MuXLlvrhG1qxZSZ06NTdv3uTly5ckDO8PgM/ky5cPc/MvaxOlSZOGw4cPf/z769evuXbtGmnSpCFTpi+3jSlTpkyoCd3evXvZu3fvF2Pv2bMnyGc4efIkACVLlvziViwYvyYLFy7k5MmTXyR0pUuX/qK9ubk5JUqU4Pr165w8eTJMCV1YvyZCiG/X27fJMDMribf3PPr1S8GwYcZycJGxQWvq+RtIetKTHfUakv3eCejaFf7+GywisF/BhdHwYDu3f/yNJlv/oHyG8gwvOzxyQX6HwvWV11qvV0rNBFwBp09OnQBGBdOlCcZkb0eEI4zlJsR0ADFAB9ab8/b25vDhw7Rt25aOHTuSLl26IMnby5fG9TEhrcJMkSIFt2/f5sWLF5FO6BIlShTscQsLiyALHT7ElDx58mDbfzqTGJwhQ4YwdOhQDAYD9+7dY+zYsUyaNImGDRuyZcuWjzN+YfnsAC9evPji3Ndi+3Dtrwnr10QI8W05evQox44dJ168LnTrVoH48cuzerWiUqXIX/s/g8ZFa3JvPMr2to1J8tor7Nt4BefRfjjzG+9T16XMgf/4Id4PLK4nxYMjIryLItBadwAqYaw1NwloAxTRWr/5tJ1SKivGGoP7ALfIhypiGzs7OypUqMCGDRsICAigVatW+Pj4fDz/IUl78OBBsP29vLyCtAPjbJ+/v3+w7YNLfsLrw1gPHz4M9nxIsX7OzMyMNGnSMHHiROrXr8+2bduC1OCLyGf/4GuxRTb5FUJ8mwwGA2PGjKFEiRL07z8eV1cfiheHM2eiJpn7x99AK6DaP8s53KwqSXiD2rYt4sncuydwsAnaLiPN7r7h7qt7rGy4kmR2yb7eV3wh3AkdgNZ6h9a6t9a6h9Z6ntb6i/8Da62vaK3LaK3Laq3vRD5UEVvlyZMHV1dX7t69y/jx4z8ez58/P2B87uxz165d4+7du2TIkCHITFLixIm5c+fLb5eAgABOnToV6VgTJEhA5syZuXfvHtevX//ifHCxfs24ceOwtrZm2LBhvHr1Cvj/Zz9w4ECwCeqHVaYFChT44tznt3TB+PkPHDgQ5NpCCPHBgwcPqFy5Mv369cPaug5v33owapQtbm7wlRsPX6WBIb7+dLMwo2fXEazr3RybdClRx45B2bIRvKgBjrQC38fMsq3IyqvbGF95PEVSF4lcsN+xCCV0Qnxu0KBBWFtbM3bsWJ4/fw5AmzZtABgxYgSPHz/+2DYgIIA+ffpgMBho27ZtkOsUKlSI27dvs23btiDHR4wYwa1bt6Ik1tatW2MwGPj111+D3Hq8efMmkyZNCvf10qZNi6urK0+fPmXcuHEApE6dmooVK+Lp6cmECROCtD969CiLFy8mceLE1KlT54vr7dq164uSJpMnT+b69euULVs2TM/PCSG+H2/fvuWnn35i796DmJnNwMFhGfv3J6Jfv/CVgAuOBrr5+DHSHGZVbsa4qYMxq1QRdfgwZM781f4hujgO7m/mYhpXOhycRrPczfj5p58jF+x3LlL/qZVSeZRSbZRSvyqlBkdVUGEYt6dS6rxS6pxSaolSykYplUEpdVQpdU0ptSxwlwphIqlSpaJjx468ePGCP//8EzCu5uzbty+enp7kypWLzp0707dvX/Lly8e6desoUaIEv/zyS5Dr9OnTB6UUtWrVwsXFhV69elGkSBGmTp0aYsHh8Orduzc//fQTq1atokCBAvz666906NCBAgUKULJkya9fIBgDBgwgXrx4jB8/nidPngAwbdo0HB0d+eWXX6hUqRIDBgygRYsWlC5dGjMzM+bOnUuCYPbYcXZ2pk6dOjRs2JABAwZQrVo1evTogYODA1OnTo3UZxdCfDsCAgIAeP06Hg4Oo/DzO06tWq6cPq0oVizy1/cHmr15z0LfN+zOXYK22xZDr16wcSOE8IxumDw+DKcH4O1YjZIHl5AzWU6m15guxYMjKUIJnVKqklLqDHASmAn8AQz5rE1WpdQrpdRjpVSiSEf6/+umAroBBbXWuQBzoDEwBhivtc4MPMdYTkWYUP/+/bG1tWXSpEkfnwMbM2YMS5YsIUuWLCxYsIBJkyZhMBgYMWIE27dvx8oqaN5dvnx51q5dS86cOVm6dCnz588nffr0HDt2LMpmpqytrdmxYwc9e/bk8ePHTJw4kb179zJo0KAgt4zDI0WKFHTq1InXr18zapRxfVDGjBlxd3enY8eOXL58mbFjx7JlyxaqVKnCwYMHqVWrVrDXqlu3LmvWrOHOnTtMnDiRQ4cOUbduXQ4fPky2bNki/LmFEN+Oa9euUaRIEYYNW0O+fHD5cnOmTMnJqlWQOHHkr+8LOL98h8e9m5zMmofi104Yd34YNw6CWT0f9gs/g4ON0bapcb7uhZ/Bn9UNV2NnZRf5oL9z6sOKxTB3UKojMJn/J4OPgaQYC86af9Z2F1Aa6Ki1nhn5cD8mdEeAvMArjNuL/QMsAhy11v5KqaLAUK115dCuVbBgQe3u7v7VMS9evEj2yJTSFiIOk+9/IWKXRYsW0alTJ/z8zHn3bj4//liTZcsgb96ouf4boOLzt9gf28fKWvWwtbXBfP1aKFEichfWGvbXgfubGRWvBgNOrWFNozXUzlY7CqL+PiilPLTWBYM7F64ZOqVUbozJnAL+A9ICXxbz+r+VgW0rhmec0Git7wFjgdsY6+C9BDyAF58szrgLpIqqMYUQQoiY9ubNG1xcXGjevDlK5eHdu9O0bl0TD4+oS+aeAUWeeFN47jQ2V62GTaYMmJ/0iHwyB3B5Etxdx7Gk9Rlwag19i/WVZC4KhfeWa6/APuu01q201ncxPjMZkg/l6PNEJLjgKKUSA7WADEBKwA6oEo7+7ZVS7kop908f1BdCCCFis82bN7NgwQJsbH4jIGAPCxemZc4csIuiu5VeQGGvF/T8pSsTevfCUK0GlkcPQ1Q87vL0OJz6hZdJSlP6yGrKpi/LyPIjI39d8VF4E7oyGBO4P8PY/nbge1TOllUAbmqtH2ut/YDVQHEgkVLqQ6Hk1MC94DprrWdorQtqrQsmTZo0CsMSQgghopbWmvPnz/PuHezf3wCtz5IjxzBOnbKgWbOoG+e61pS/dIu59WrQdt5c/H/tj+X6NRA/fuQv/v4lHGiEwTo5ZS974hDvB5bUW4KFWQR2lRAhCm9C96GazaUwtn8f+B6VK05vA0WUUrbKuCSmPMatxXYD9QPbtALWReGYQgghhEk9efKEWrVqUbDgTxQo4MnkyYqePXNy6FDkKoZ87pRfAC0PHGdLxZIUcnfHsGgxFqP/iHzNEzA+N3e0HdrnNr++TcfZF/dY0WAFyeMHvyOOiLjwpsdvMSZn8YAXYWj/IQF8Fs5xQqS1PqqUWolxuzF/jCttZwCbgKVKqRGBx2ZH1ZhCCCGEKe3Zs4dmzZrx6NETzMz+4uHDdGzYADVqRO04e338mLp2DdvatcZgHR/LQwdQBYN95j5irv4Ld1ayO2Flxrq7ManKJIqliYKaKuIL4U2/rwW+/xTG9h8WQ5wL5zih0loP0Vpn01rn0lq30Fr7aq1vaK0Laa0za60baK19o3JMIYQQIrpprRk6dCjlypXjzZv4+PsfoUiRbpw+raI8mVv+1IddY/5gWbNG+KTKTIILp6I2mXt+Ck705Emin6jksY0muZrQpVCXqLu+CCK8Cd1mjKtW+6qvVAAMXLzwC8Zn7tZHLDwhhBDi+6GU4sqVF8SP34rXrz0YOjQ/u3ZB6tRRO87U6w/RHV34fdhQ7lWoTdKzRyFFiqgbwO81HGiIv2ViSly8TrYkOZjpPFOKB0ej8N5ynQh0B4oCK5VSnQDvzxsppQpjvA2aGuPCmVmRjFMIIYT4Zq1duxZHxxQcP16YlSvHkTSpORs2QOnSUT/WH4fPU7lLS/KfPMndboNIPWEYRGWipTUc64B+c53Ob7Ny//093F2keHB0C1dCp7V+rpRqCGwAagPOwNkP55VSu4GMGBM5BbwDGmqt30ZVwEIIIcS34u3bt/Tp04epU6eSIkV9vLxWUL26OfPmQZIkUTuWBoatcKN9Nxfiv3zNwxmLSd2ucdQOAnB9NtxawgbrQsy4coxVDVeR9YesUT+OCCLcS1i01tuBEhhXlloA+QNPKYy7QqQJ/PN5oITW+mDUhCqEEEJ8Oy5cuEDhwoWZOnUq8eP35vHjRUyYABs2RH0y5w/8NXoK/ZrXxF9bEuC2hxTRkcy9OAceXfGyy0mdc8f4pdgv1M1eN+rHEV+IUBEYrbU7kFspVRZj2ZAfgYQYdwy5AWwHtunw7ismhBBCfAdOnDhBiRIlMDOLj1KbSZ68KsuWgZNT1I/l4+/Pyvbd6Tt3KidyFCL7lrXESxuFz8t94O8NBxriZx6foheuUzJdaf4o/0fUjyOCFamqflrr3RjrvwkhhBDiK7TWKKVImjQvSZJ0486d7jRrloJ//4UECaJ+vCdPnnGuXiNa7tvB1oqNqbhuHubxrKN+IIDjndGvLtHmZQreWyVmaf2lUjzYhKKgaqAQQgghvubw4cMULVqU//7zokABc54+Hc3cuSn477/oSeZunTjL88JFKH5oD8tch1DZbXH0JXM35sPN+SwjK0ufPGJ5g+U4xnf8ej8RZSShE0IIIaKRwWBg1KhRlCxZkosXH9Ky5WNSpgQPD3BxidoFph9cWrSKRGVKkOjlc1b8MZ9GM4ZGX8mQlxfh+M/css5Is6uXGVtxLCXSloiesUSIQkzolFItP7yCOxbel2k+johOSimUUpiZmXH9+vUQ25UtW/Zj23nz5gXbxtvbmwkTJlCuXDmSJUuGlZUViRIlolChQgwcOJAbN25EaT+AO3fuYG5ujlKKAQMGhOuzCyFERHh5eVGpUiUGDBiAvX1dXr06yc8/5+HoUciWLRoG1JrzfYeQtUUDbqZLz8EZ62n6S9NoGCiQvw8caMh7ZUXxSzdpkLMR3Qp3i77xRMi01sG+AAMQAPgHcyy8L/+QxonJl5OTkw6LCxcuhKndtw7QFhYWGtD9+/cPts2VK1eCtJs7d+4XbQ4fPqxTpUqlAZ06dWrdqlUr3b9/f92tWzddsmRJbW5uri0tLbWHh0eU9Ptg8ODBGtBKKe3o6Kj9/Pwi/TX5Hsj3vxAR17ZtW21lFU9bW8/QCRMa9OrV0TiYt7e+Wrm21qBX1qijdx2/GY2DBTrSTutF6AYTE+ocU3Lo176vo3/M7xjgrkPK20I8YUzeDIAhuGPhfYU0Tky+JKELH0CnSpVKFyxYMMSEqG/fvhrQderUCTahu3jxora3t9dmZmZ69OjRwV7jxo0bukGDBnr37t2R7veBv7+/Tp06tba3t9c///yzBvSqVavC/TX4Hsn3vxDh4+vrq728vLS3t9bNmz/VcE4XK6a1p2c0Dnrrlr6XJacOUEoP7zFAn7n9IhoHC3RzkdaL0PPmpdLx/4ivLz6+GP1jfucilNB9Dy9J6MLnQ0I3ffp0Deg1a9YEOf/+/XudLFkyXaxYMT1w4MBgE7oKFSqEOsP3qXfv3kW63wcbNmzQgHZ1ddVnz57VgK5SpcpXryXk+1+I8Lh69aouWLCgzpXrJ50tm79WSusBA7SOzhsChr179cuEDvplggTaZdICfefF2+gb7IOXl7VeFl9fW5pCmw9Frzi/IvrHFKEmdLIoQoRbkyZNsLOzY9asoDu6rV+/nkePHuHq6hpsv5s3b7Jjxw5sbGzo27fvV8extraOVL9PzZgxAwAXFxdy5cqFk5MT27Zt49atW1+9nhBChMWiRYvInz8/Fy5c59Kl/rx4Yc727TByJFhER/UOrQmYPIWAcuXxSp6E5nM2MrFDU1IntImGwT4R8A4ONuKdhtLXvOhepBf1c9SP3jHFV4UroVNKdQt85YmugETslyBBAho3bszWrVu5e/fux+MzZ87E3t6ehg0bBtvvwIEDADg5OZEoUaIwjxfRfh/cu3ePzZs3kzVrVooVKwYYEzuDwfBFUiqEEOHl7e2Ni4sLzZs3x9o6Hz4+pyhfvg6nT0P58tE0qK8v713aYN61C9sqVaT3tLWsqlcSeyvzaBrwEyd6w/NTNL3vR8aUJRldYXT0jym+Kry/M0zAuB1c/q+0+2702NqDUw9OxXQYocrnmI8JVSZE6TVdXV2ZPXs2c+bMYfDgwdy6dYvt27fToUMHbG1tg+3j5eUFQOrUqcM1VkT7fTBnzhwCAgJwcXH5eKxp06b07t2bOXPmMHToUMzNTfBDUAjxTVJKsX+/BwkTDubFi9/4808LevcGs+i6B3b/Pr7OtbE+cZwRAwdyvnYnNhRMRTQVJQnq9kq4OpVZbxNx2GDDifrLsDS3NMXI4ivC++32NPD9TlQHIuKWwoULkzt3bubMmfNxpstgMIR4uzWmGAwGZs+ejZmZGS1b/r96joODA87Ozty/f59NmzbFYIRCiLhIa82cOXN49eoNkybZ4unpTuLEv3PwoAW//BKNydyhQ/jlzY//xfPUW7mSF816sMRUydybG+ijbblCYrrce8Xy+stJkSAathATERLeGboLQAkgLfA86sOJe6J65isucXV1pVu3bmzZsoW5c+fi5ORE/vwhT96mSGH8h3/v3r1wjRPRfgBubm7cunWLypUrkypVqiDnXFxcWLVqFTNmzKBmzZrhvrYQ4vv05MkT2rRpw4YNG/jzzzdcvtyNhg2tmTEDEiaMxoGnT8fQpSt3UqSi1rZttHVIR490iaJxwE8E+MKBRvgG+FHp5iv+qDiOkulKmmZsESbh/R1iLqCA2DUNI2JEixYtiBcvHh07duTevXu0b98+1PYlShgrh7u7u/Py5cswjxPRfvD/xRBubm4fix1/eDk7OwOwdetW7tyRSWchxNft2bOHvHnzsnWrG/HjT8TTsyszZsDSpdGYzPn6Qvv20LEjO4qVovCRo/yWOrPpkjmAU7/CM3ea3nvHT1nr07NIT9ONLcIkXAmd1noesBLopJQarJSSXXe/Y4kSJaJ+/frcvXsXOzs7mjRpEmr7DBkyUKFCBd69e8dff/311ev7+vpGqt+DBw/YuHEj9vb2tG3bNthX8eLFCQgIYM6cOWH4xEKI79mcOXMoV64c797Fx8/vCOnSdcPDQ+HqGj3bdwFw/z66TBmYOZMx3fpQb806ViVMRMOkdtE0YDDurIXLE5n5Jh4XrLMyp+ac6NtGTERYuBIypdRg4DxQFBgCdFFK7QJuAm9D66u1HhbRIEXsNWLECOrWrUvSpElJEIbdpSdNmkSRIkUYNWoUiRMnpnv37lh8tp7/9u3b9O3bl44dO1KmTJkI95szZw7+/v40a9aMqVOnBhvPtWvXyJo1K7Nnz+a3337DLNoefBFCxHVZspQlWbKOPHz4J+3bx2f8eAhhDVjU2L8fXb8Bvs9f0nLBYnZWq8VRextyWJjw55T3LfTRNlw22PHrE80B19UksP76z3pheuGdYRuKcZUrGG+9JgEahLGvJHTfoLRp05I2bdowt8+ePTtubm7Ur1+fPn36MHHiRMqXL0/KlCnx9vbm9OnTHDx4EKUUv/76a4T7aa0/liRp165diPFkzpyZ0qVLs2fPHrZs2UL16tUj/sUQQnxzVq9ezbp166hRYx6urhnQeirLlkEI1ZmihtYweTK6Vy/u2yen8rGjvEmViTMO8Uhlypkxgx8caMy7995Uv/2ef2suJUfSHKYbX4RLeBO62/w/oRMiQooUKcKlS5eYOXMm69evZ9OmTTx//hxbW1syZ85M7969ad++PRkyZIhwv+3bt3Pz5k3y589PgQIFQo3H1dWVPXv2MGPGDEnohBAAvH37ll69ejFt2jSSJi3IggUvKFQoMUuXwmc/mqKWjw907Aj//ceBrMVwPrqJ9P5WnEpiS6JoHDZYpwfC0yO09ALnAt1plKuRqSMQ4aCMO0l8nwoWLKjd3d2/2u7ixYtkz57dBBEJEfvI97/43pw/f57GjRtz7tw5kiTpw5MnI+nb14oRI8AyOkuu3bwJdeuiT5/mn0rt6LF5GuVf+rI+cTziReOwwbq3CfbWYMYrCxZYFWZ3q91Sby4WUEp5aK0LBndOFjUIIYQQgfz9/alZsyaPH7/GymoLZmZV2LoVKleO5oG3boWmTfHz9ce1+0Tmj+9Ki9e+zE0cD5OXPfe5i+FwSy77WzPyTUIOd1guyVwcIE+ACyGE+O69fPkSf39/vL0tyJhxCa9fn6ZUqSqcPh3NyZzBACNGoKtV46llYor/vZr547vS39ef+QmsTZ/MGfzRB5vg+/4Vde/5saD+clImSGnqKEQERGqGTimVEHACkgLWWusFURKVEEIIYSKHDx+mSZMmVKzYil27fufWrUKMGgV9+0bjjg8AL19Cy5awfj1nMpai2oyZeJXNwj8BBrpYx9ANtLNDUI8P0PYBtC39F6XTl46ZOES4RehbVSmVWym1EeNWYNuBxRiLDn/aJqtS6oxS6rhSKjoXdgshhBDhZjAYGDVqFCVLluTVK8XcuVUJCIB9+6Bfv2hO5s6dg4IF0Zs3szRnK0qsW8Gj0plZpqCLeQzdPPPahj4/ilkvFe9T16N30d4xE4eIkHB/1yilagFHgaqB/VXgKwit9RXgHVAAqB2pKIUQQogo5OXlRaVKlRgwYABJk9bn+fNT1KpVhJMnoVixaB586VIoXJiAF68YmK8fbbZOQv/4A9sszGgQUwV733oRcLApl/zM+ScgE3NqSfHguCZcCZ1SKj3G2TgbYC9QCkgeSpdlGJO9KhGMTwghhIhy9+7d48gRdxImnMWzZ0uYOjUhK1dC4sTROKifH/TqBU2a8CZDdhpn+41x2wZil9yOA5bmlI3GoUNlCMBwsCnvfZ/T7JEFixuuxd7aPqaiEREU3pv0fYB4wD6gotY6QCkV2v4jhwLfQy8EJoQQQkSz9+/fs2nTJpyd67B2bUG8vW+TLZs9S5dC3rzRPPiDB8ZqxPv3c6tcY5rGq8GxFQ1JY2HGDktzMkbz8KE6NxyzR3vo+BB+qTKHnMlyxmQ0IoLCm9BVwlhYeJjWOiAM7W8GvqcJ5zhCCCFElLl27RqNGzfGw8ODfPlOc+pUHtq0sWfSJLCL7m1RDx6EBg3QL16wv0Z/uv5QmLOznckHbDU3I1k0Dx+qB7vQ54ax4BUkzN6VJrlD35NbxF7hfYYudeD7qTC2/7C/q004xxFCCCGixMKFC8mfPz+XL9/A1nY116/nYdEimD07mpO5wC28KFMGQzxbZhUfRofs5TgzrxbllWJvTCdzbx/if6ARV97DAstCjK00NiajEZEU3oTufeB7WGf2kgS+vwznOEIIIUSkde7cmRYtWpAgQT7evDlF9ux1OHECmjaN5oG9vaFFC+jalfdlKzAwcXdGVS/BpT8r0FhrNpkpYnSLe23A/2AT/H2f0uFFYhY0WI2VuVVMRiQiKbwJ3a3A97A+bfChgM2lcI4jhBBCRFqaNIVIlmwwXl676d07LYcOQebM0Tzo1atQpAgsXszzrv1of6MqC/uW42aPInQHFilFTKdO+vwfWDzaTffHMKTWSlLZp4rhiERkhfcZum1AbqA7xvpzIVJK2WBcRKGBLRGKTgghhAgHrTUTJ04kYcJEKOXC8OGtsLWFTZugWjUTBLB+vXFmzsKCayPn8MvkFxxdXAuv0ukYDfQlmDpfpvZoH/rMYJa8hkwFR1E2Q4ytrxVRKLwzdBMx1parqpSaoJQK9pcMpVRqYAOQDXgNTItUlEIIIcRXPH78GGdnZ3r27Mnvv7vRujUULgynT5sgmQsIgIEDoVYtyJKFvX3m03nSMw65NeVRqbTMAX4lFiRz7x7ju68e199rNiaswS/F+8Z0RCKKhGuGTmt9VynVHlgAdAWaAfs/nFdKzQUyAkUCr60BF6318yiLWAghhPjM7t27adasGU+ePCVJkkncvt2F4cOhf38wj+4NUZ88gSZNYMcOdNu2LLCvy/wZ1znt7srblPFZqxQ1ojmEMNEGfA80Bt8n9PFJw4LGC6V48Dck3DtFaK0XAnUwbvv1A0F3gWgJlAQsA8/X0lqvjXSUIlZQSqGUwszMjOvXr4fYrmzZsh/bzps3L9g23t7eTJgwgXLlypEsWTKsrKxIlCgRhQoVYuDAgdy4cSNK+wHcuXMHc3NzlFIMGDAgXJ/9gz179qCUokyZMhHqL4SIeleuXKFChQoEBNij9VFsbLqyd69i0CATJHPHj0OBArB/P35TpzPqRWVm77yLxylXdMr47IwtyRwQcH4M1o928etTS0bU20RCm4QxHZKIQhHaME5rvQ5IC7TFuHOEB3AdOA2sBjoB6bXWG6MoThFLWFhYoLVm9uzZwZ6/evUqe/bswcIi5MnfI0eO8OOPP9KzZ0+uXr1KtWrV6NOnD61atcLGxoYxY8aQLVs2Tpw4ESX9Ppg1axYGgwGlFHPnzsXf3z/iXwghRIzz8fEBIHHirOTJs5BHj9ypXj0fp09DyZLRPLjWMH06lCgB5ua8WredvnPN2fjEB49jbbC3t+aAUhSN5jDC7PEhODOQFa/hp9JzyJ08d0xHJKKa1vq7fTk5OemwuHDhQpjafesAnSpVKl2wYEHt6Oio/fz8vmjTt29fDeg6depoQM+dOzfI+YsXL2p7e3ttZmamR48eHew1bty4oRs0aKB3794d6X4f+Pv769SpU2t7e3v9888/a0CvWrUq3F+D3bt3a0CXLl063H3jKvn+F7HRypUrddKkSfWUKUd0ypRaW1lpPXmy1gaDCQb38dG6VSutQesqVfSt/Re1S9qJunCT1drSP0Dn0FrfNkEYYfbuqfZe/oO+Pg/de2O7mI5GRALgrkPIaWI8qYrJlyR04fMhoZs+fboG9Jo1a4Kcf//+vU6WLJkuVqyYHjhwYLAJXYUKFTSg+/fv/9Xx3r17F+l+H2zYsEED2tXVVZ89e1YDukqVKl+91uckoRMiZvn4+OgOHTpoQKdM+ZOGa/rHH7U+edJEAVy/rnW+fForpfWQIdp902VdP8FoXajfTq0MBl1ca/3URKGEicGgX20rp30Xol1m59K+/r4xHZGIhNASunDdclVKuSuleiilHKNqhlDEPU2aNMHOzo5Zs2YFOb5+/XoePXqEq6trsP1u3rzJjh07sLGxoW/fr6+ssra2jlS/T82YMQMAFxcXcuXKhZOTE9u2bePWrVtftBVCxE7nz5+nUKFCTJ8+ndSpf+H+/QO0apUJd3fIl88EAWzcCE5OcOsWbNzI5uQ1GFpzObf+qsCxUeWooRTbAAcThBJWvhf+JMHjXfz+0o7h9bdI8eBvWHifoSsAjAPuKKW2K6VaKaVitNi1ML0ECRLQuHFjtm7dyt27dz8enzlzJvb29jRs2DDYfgcOHADAycmJRIkShXm8iPb74N69e2zevJmsWbNSrFgxwJjYGQyGL5JSIUTstWbNGu7ceUT8+Ft58eJP/vvPinnzIH78aB74Q0kSZ2fIkIGAY8eZucOCKV224rWhMcc7ONEW4wPkttEcSnjoJ8cwPz2AdW+gXOW1pLZP/fVOIs4Kb2HhFUANIB5QHigH/KuU2oBxccRmrbVf1IYYy3n0gOenYjqK0CXOB04TovSSrq6uzJ49mzlz5jB48GBu3brF9u3b6dChA7a2wf9I8/LyAiB16vD9UIlovw/mzJlDQEAALi4uH481bdqU3r17M2fOHIYOHYp5tC+FE0JExIsXL7h+/To5czrx4EF/Xr5sT4ECyVi6FLJkMUEAjx4Z9wnbuRPatePtqHGMbbuFQ9tu4HXSldN5kjMAGEEsqDH3qfcveLWrGi/8DNzIOoiemSrEdEQimoW3Dl0jpVR8oC7QFGNSZwPUD3y9UEqtABZrrfdFdbAi9ihcuDC5c+dmzpw5DBo06OMK0pBut8YUg8HA7NmzMTMzo2XLlh+POzg44OzszKpVq9i0aRM1a9YEjGVJ9uzZE+Qa6dOnD5IMCiFM4/DhwzRp0oR37/xJnvw6Z85Y06NHMkaPhmCerIiOAKBBA3j6FGbP5knl+gyvtIwrni+4fa0LF1Ml4B+giwlCCRetebK7Dgn9njLSqgSjS/8e0xEJEwjvDB1a6zcYCwsvUEolAxphLDBcCEgMuAKuSqm7GGftFmutz0ZdyLFMFM98xSWurq5069aNLVu2MHfuXJycnMifP3+I7VOkSAEYb4GGR0T7Abi5uXHr1i0qV65MqlRB9yp0cXFh1apVzJgxI0hC9/vvQX/4lS5dWhI6IUwoICCAMWPGMHjwYBwc0vL69Sr8/a3ZsAFqmKKom9bwzz/QuzekTQuHDnEdR34vNIdndpZcvdWNOwmsWQoE/4BJzHp1bgxJnu5htI8DA1pswExFqEKZiGMi9V9Za/1Ia/2P1roIkBkYClzBOPOcBuO2daeUUmciG6iIfVq0aEG8ePHo2LEj9+7do3379qG2L1GiBADu7u68fPkyzONEtB/8fzGEm5vbx2LHH17Ozs4AbN26lTt37gAwdOjQL1YOfT5jJ4SIPm/evKFy5coMHDiQ1Knr8/jxSYoUKczp0yZK5t68Me760L27cb8wDw+O3rGlb4n5vM7qwMlzHXmUwJotxM5kzv/pcWzODMDNx4xqzjtJZJMopkMSJhJlabvW+obWepjWOjtQEPgbeIQxucsZVeOI2CNRokTUr1+fu3fvYmdnR5MmTUJtnyFDBipUqMC7d+/466+/vnp9X1/fSPV78OABGzduxN7enrZt2wb7Kl68OAEBAcyZMycMn1gIEd3s7OywsnIkWbJZ3L69hN9/T8iOHfDZBHv0uHABChWCFStg9Gj06tWsnXuJEbWXY9kgO/t2NifAypy9GB8gj3X8XvFiRyUeB2he5v+HPI75YjoiYUoh1TOJ6Avjtl91MC6g8AEMQEBUjxMVL6lDFz4E1qH71K1bt/SaNWv0gQMHghwPqQ7dhQsXPhYIHjt2bLAFgm/duqUbNWoUpEBwRPqNHDlSA7pTp04hfqarV69qpZROkyaNDggI+MpXQOrQCREd3r17p3/99Vd99eo1PX681paWWqdOrfW+fSYMYvFire3stE6WTOtdu7Tfe389ueMmXZ1huuXwfdrWYNCZtNbXTBhSuBgM+vam4tp/IXrc2loxHY2IJoRShy7cz9CFRClVDuNCibrAhw3iFOAHbI6qcUTskjZtWtKmTRvm9tmzZ8fNzY369evTp08fJk6cSPny5UmZMiXe3t6cPn2agwcPopTi119/jXA/rfXHkiTt2rULMZ7MmTNTunRp9uzZw5YtW6hevXqYPselS5dCfK4ubdq0DBs2LMxfEyG+Z1evXqVx48acOHGCDRscuXChBzVrwpw58MMPJgjA19f4rNyUKVC8OCxfjredA6NrLOXkthukWFaXuQ1ykFcpNgPJTRBSRDw4PYI0Lw7yr19qOldfFtPhiJgQUqYXlhfghPHW6j0gIPBlCHzfC7QHEkdmjOh8yQxd+BDMDF1IQpqh++D169f677//1mXKlNFJkybVFhYW2t7eXhcoUED369dP37hxI1L9tm3bpgGdP3/+r8a6aNEiDeiaNWt+te2HGbrQXnnz5v3qdeIS+f4X0eW///7T8ePH1/b2Djpx4rXaykrrf/4x0fZdWmt965bWhQppDVr36qX1+/f6wc3nulOOqdrZYoRud/SuRmtdXmv90kQhRYT3wyP67UKld8221Lefe8Z0OCIaEcoMnTKeDzulVBaMM3FNgA9VgD6U3zkHLMK4svVOeJNLUytYsKB2d3f/aruLFy+SPXt2E0QkROwj3/8iOsydO5c2bdqQNm1Jbt9exI8/pmHpUhPt+ACwdSs0awZ+fjB3LtSrx6UjdxlRaznv/QKwPt2ehWkS0giYD5iiSkpE6Pevub8qNWZ+r7haaDmlsjWI6ZBENFJKeWitCwZ3Lly3XJVSxzHuFgH/T+LuAEuARfpbLk8ihBAi0vz9/bGwsKBYsYZkyPCKmzc74+JiwT//mGDHBzDu+jBsGAwfDrlywapVkCULe5eeY4LLehJnSIT3kTasSGhDV2ACUbh6MBpcdqtAVsMrFju2prkkc9+18H6fOmFM5F4AM4EyWut0Wut+kswJIYQIidaa8ePH4+TkxLJl3hQtasfjx91ZuNCCuXNNlMw9fgxVqxoTupYt4cgRdObMLBm2j7+arCFd6XTcOt2BtQlt+AOYSOxO5q65DyLb62MsVVloWlG2MfzehXdRxEqMt1S/vy2+hBBCRMjjx49xcXFh8+bNZMhQk8aN31OggJ3ptu8C464PDRsak7oZM6BdO/zeBzCp5Tp2LzzLT50Lsn5SFU6bKWYDbUwUVkQ99dpPykt/cMTfhmqNDkvxYBHurb9iYx1FIYQQsdSuXbto3rw5T548JVWqf7h5szM9eypGjTLR9l1aw6RJ0KcPpEkDhw5BgQK8fOzNyDoruHDwDhUnV+GfnwtyXynWYtywPDbzf/+KV7uqEqA18cuuI1E8UywHFrFdlJUtEUIIIT6ltea3335Da3vMzbfw7l1e023fBfD6NbRrB8uXQ82aMG8eJE7MnYuP+b3GMp7df01tt6YMrJQJf2AXUMREoUXGyY0l+Ul5sz1DHyqmqxTT4YhYQhI6IYQQUerWrVvEjx8fK6sfSJ58BYcOJaRMGTsWLjTRjg8AZ89C/fpw7RqMHg2//AJmZpzacYNR9VdiaWOB8wlXumdPQmLADchmotAi4/i+jvz07gxbrPJRtcTXd84R348QEzql1I3AP2qtdabPjoXXx2sIIYT4dq1atYp27dpRpEg1rl1bxI0bKRk+HPr3B3NzEwUxfz506gQJE8KuXVC6NABbpnvwb+ctpM2RlJw7m9MhqR3ZgC2AqfLMyPA43IcCd6ZzzJCQcjUPxHQ4IpYJbYYufeC7DuZYeIWv2J0QQog45e3bt/Ts2ZPp06eTNm0hduwYjqMj7NkDJUuaLAjo1g1mzYIyZWDJEnB0JCDAwJw+O1g34ShOVTNjs7oBP9tYUAZYAyQyUXiRcer4YPLeGMdpQ3x+rHMRayu7mA5JxDKhJXS/h/GYEEKI79jVq1epW7cu586dI2PGvty4MZxatayYMwccHEwWBDRoAKdPG6cDhw0DCwt8XvvyV5M1HN90lRo9CnF5XCWGmSkaAP8RewsGf+rsiVHkuDKc8wG2pK99joTxU8R0SCIWCjGh01p/kbwFd0wIIcT3zd7enrdvzXFwcOPu3UpMngw//wxKfb1vlFi5Etq0AQsL2LgRAvdkfnT7JcOcl3L7/GNcp1VjWQcnlkCcKBj8wbnTE8h6cQBXAmxIVfMMDvbpYjokEUvFhe9nIYQQsczz588ZOnQo7975M2VKcq5fP0nSpJU4ehQ6dzZRMvf+PXTvbpyZy5EDTp78mMxdOnKXXj/N5pHnS3pvbco/gcncGGJ/weAPLp7/l0xne3IjwJqkNU6QJJE8ii5CJqtchRBChMuhQ4do0qQJ9+/fZ82aipw5UxwXF2W67bsAbt0yFgo+dgx69IAxY8DKCoC9S84xofV6fkhlT/f9rWif9QfOYdyTtaWJwousq5fmkebkz9wxWJKw6lGSO8h+yiJ0ceGXFCGEELFAQEAAI0eOpFSpUvj6WhAv3kFu3CjOwoWYbvsugE2bIH9+uHTJeLt1/HiwskJrzaIhe/ir6RqyFkpFp+NtaZj1B64CG4g7ydz1q0twdG/DQ4MF8SofJGXSvDEdkogDQitbMjgqB9JaD4uqaymlEgGzgFwYV9C2AS4DyzCuxPUEGmqtn0fVmCJ6eHp6kiFDBlq1asW8efNiOpwISZ8+PWD8LEJ8y9q3b8+cOXPIkqUxV69Oo0CBhKbdvsvfH377zVhXLn9+WLECMhlvQ77z8WNi6/XsX36BCq3z8tO0alS2ssAM2A38ZKIQI8vzxlp+ONqMZwYzzCrsIk3yuBK5iGmh3XIdStSWG4myhA7jIxBbtdb1lVJWgC0wANiptR6tlOoH9AN+jcIxv3vqKw/FzJ07FxcXF9ME8xlXV1dmzZpFvHjxuH//PokSJYqROIT4FmmtUUpRtWpHtm0rztWrrU27fRfA/fvQuDHs3w8dOsCECWBjA8DT+68ZUWsZ1zy8cBlTHptfilJJKRwxFgzObKIQI+vOrS3YH6rHG4PCv6wbmVKaqt6L+BaEltDdJhbWj1NKJQRKAS4AWuv3wHulVC2gTGCz+cAeJKGLFkOGDAn2eL58+cJ9rVSpUnHx4kUSJkwY4Xhev37N0qVLUUrx9u1bFi5cSJcuXSJ8vfDauXOnycYSwpR8fX3p168f/v4BODlNonPnn7C1/enThaSmsX07NGsGPj6wcKHxz4GunfBieM1leL94x6C1DTlf80caA/mATUByE4YZGffu7sJ6Xw3eo/EptZGsacrHdEgirtFax6kXxn+nx4B5wEmMt17tgBeftFGf/j2kl5OTkw6LCxcuhKndtw5jgh/TYXxh2rRpGtC9evXSVlZWOk+ePDEd0jdFvv+/T5cvX9YFChTQgM6atauGAF2mjNZ375owCH9/rYcM0VoprXPm1PrixSCnD666oOvG+0O7pJmgr53y0sO18Yd7Ja31axOGGVle9w9orwXm+uECpc9dXRnT4YhYDHDXIeQ0cXFRhAVQAPhXa50f8MZ4e/WjwA8d7OyiUqq9UspdKeX++PHjaA/2e3P//n2GDRtG8eLFcXR0xMrKipQpU9K0aVMuXLjwRXtPT0+UUl/cqnVxcUEpxY0bN/jnn3/IkycP8eLFo0yZMl9cY+bMmZiZmdGjRw+cnZ05c+YMR48eDTa+hw8f0qdPH3788Ufs7OxIlCgRP/74Iy4uLty48f+d7bTWzJ8/n2LFipE0aVJsbGxIkyYNlStXZtmyZUGumT59+o/P0X3q5cuX9OjRg9SpU2NjY0O2bNn4+++/uXHjRqif2dPTk+nTp5M7d25sbGxInjw57du35+XLl8F/0YWIYgsWLKBAgQJcv+6Jo+Narl2bxPDhZuzYYcK9WB8+hMqV4fffoVUrOHoUshl3W9Vas2zkfv6ot5L0eZLz17G2jMvryG9AC4wLIEy1PiOyHj06TsCOMlhi4EGhheTMXC+mQxJxVFwsW3IXuKu1/vB/7JUYE7qHSqkUWmsvpVQK4FFwnbXWM4AZAAULFox1t5Tjun379jF69GjKli1LvXr1iB8/PlevXmXlypWsX7+egwcPkjdv2Fdsde/enf3791O9enWqVauG+WebQZ48eRIPDw8qVqxImjRpcHFxYdWqVcyYMYPChQsHaevj40Px4sW5fv06FStWxNnZGa01t27dYt26ddSvX5+MGTMCMHDgQEaNGkWGDBlo2LAhCRMmxMvLi+PHj7NixQoaNWoUatzv3r2jXLlynDhxgvz589OsWTNevnzJyJEj2b9/f6h9+/bti5ubG87OzlSqVIndu3czc+ZMrl27xq5du8L8tRMiIu7fv0+nTp1wdCzI7duLSJAgtWm37wLjfmFNmsCLFzB7trFocKD37/yZ1G4Dexado3TTXLSf7UxrGwvWYHzGZhTGWzRxwbOnZ/F1K058/PF0mkX+H5vGdEgiDot0QqeUyggkBay11vsiH1LotNYPlFJ3lFI/aq0vA+WBC4GvVsDowPd10R3L92ro0KFfHEufPj0uLi6UK1eOhw8fkiBBgiDnT58+TfHixenXrx9btmwJ81gnTpzg5MmTZMiQIdjz06dPB6B169YAVKlSBUdHR5YtW8b48eOxt7f/2Hbnzp1cv36dHj16MH78+CDXef/+Pb6+vkGumypVKs6dO4etrW2Qtk+ePPlq3H/99RcnTpygcePGLF68+OOCkoEDB1KgQIFQ+x45coSzZ8+SNm1aAPz9/SlXrhy7d+/m2LFjFCpU6KvjCxFeN27cIEOGDFhapiR//gMcPJiHWrXMTbt9l8FgXMH622/GpbPbtkHu3B9PP3/4hhG1l3P5yD1ajChDxQElcFaKAxh3fuhuojCjwovnl3i15ScclB9X8kymYI62MR2SiOMilNAFzoANBBoDiQMP60+vp5TKAowDfIEmWmv/yIUaRFdgUeAK1xtAa4w19ZYrpdoCt4CGUTheyHr0gFOnTDJUhOXLZ1wRFkV+//3LHeBKly6Ni4sLyZIlC7ZP3rx5KVeuHNu2bcPPzw9LS8swjdW3b98Qkzlvb28WL15MwoQJqVOnDgAWFhY0a9aMcePGsWjRIjp16vRFv3jx4n1xzMrKCqvAoqQfWFpafjEjCJAkSZKvxj1//nzMzMwYNWpUkNXBadKkoUePHgwaNCjEvoMHD/6YzH34TK1bt2b//v2S0Ikop7VmwoQJ/Prrr/TuPZv581vw7Fl+02/f9fgxtGgBbm7G2bnp0+GTXwxvnHrA8JrLePXEh/4r65O2XnZKAVeAJUDoc+axy+tXN3m6qQCO+HI2518UydM5pkMS34BwP0OnlCoKnAY6AQ4YZ7c/vD7SWl8FMgF1gRqRjjTotU9prQtqrfNorWtrrZ9rrZ9qrctrrbNorStorZ9F5Zji/4J7GHPPnj0fz2/atAlnZ2dSpEiBpaUlSimUUmzYsAFfX98wzXB9EFrysnTpUl6/fk3jxo2xCSxfAHx8Nm3mzJlB2pcuXZpUqVIxevRoqlSpwqRJk/Dw8CAgIOCLazdr1gxPT09y5MhB//792bp1a5ifYXv16hXXr18nVapUwT5bV6JEiVD7FyxY8ItjadKkAYzbLQkRVR4/fkyNGjXo1asXGTJUY/ToatjbY9rtuwAOHDDWlduzB/79FxYtCpLMHV57iV+Kz8Ng0Iw54EKietkpCtzBWJYkLiVzb97cwWt9blLyltM/DqdI/j4xHZL4RoRrhk4plRTj86YOwEWMjytcBI6H0GUZxnp21YC1EQ0yVovCma9vwcSJE+nRoweJEyemYsWKpE2bFltbW5RSrF27ltOnTwe5tfk1jo6OIZ6bMWMGwBeLC3LlyoWTkxMeHh64u7t/TJDs7e05cuQIQ4YMYf369bi5uQHGGbeff/6ZQYMGfZw5HD9+PBkzZmTu3LmMHj2a0aNHY2FhQbVq1Rg3bhyZM4dc2erVq1cAJE8efMGEkI5/EFwNPQsL4z/V4JJPISJiz549NG3alGfPnpEx42SuXPnZ9Nt3GQzw558waBBkyACHDxsTu0Baa1aMPsiCAbvJWiilsSxJigTUBOIB+4C4tIeCj48Xd9bmJKPy5nimQZT4KeSZeiHCK7y3XHtjTObOAMW11t5KKbtQ2u8NfJdS198Bf39/hg4diqOjIydOnCBFihRBzh8+fDjc1wypmPGZM2c4duwYAEWLFg2x/4wZM4LMeKVOnZrZs2ejtebChQvs2rWLKVOmMGzYMAwGA8OHDwfA3NycHj160KNHDx49esSBAwdYunQpK1as4Pz585w/fx7rECqqfnhu7+HDh8GeD+m4EKb06tUrzM0TYWW1hceP87JoETQ15TP5T54YV69u3gwNGsCsWfDJM6/v3/nzj+tGdi88S6nGOek+x5lN8SxpinE7oK2B73HFu7dPuLkmB1nVaw6l703pIsNjOiTxjQlvQlcD47Nyg7XW3mFofy3wPX04xxFx0JMnT3jx4gV169b9Ipl78+YNJ06ciLKxPszOlSlThkyBW/98bvHixSxZsoS///6b+J9NOSilyJkzJzlz5qR27dqkTZuWtWvXfkzoPpUsWTLq1q1L3bp1KV++PLt27eLcuXM4OTkFO669vT0ZM2bE09MTT0/PL267HjhwIAKfWIjI8/T05PDhw9Sp0wQ3t5rcvVsVJydLli6FUCado96hQ9CoETx6RHAP6z3zes3IOiu4fPQezYeXodHAEkxViq5AYWAj8IMJw42s974vuLImGzl4wb7UP1Ou+NiYDkl8g8Kb0KUPfD8UxvZvAt9Dm8UT34hkyZJha2uLh4cHb968+ZhE+fn50b1793A9Oxeat2/fsmjRIszNzVm0aBEpU6YMtp2vry8LFy5kyZIluLq6cv78eZIkSfLFLc8PM2YfVrP6+vri7u5O8eLFg7Tz8/Pj2bNnQdqGpGXLlgwdOpT+/fsHWeV6584dJshtehEDVq5cSbt27VDKgpEjq3P+vD29elkyahR8th4o+mgN48ZB//6QNq0xsfvsF6NrHl4Mr2Xc+WHA6gYUrZONgRif76mJcQFE6P/6Yhd/vzdcWP0jefRTdqVoTYXSU2I6JPGNCm9Cpz97/5pEge+vwjmOiIPMzMzo1q0bo0ePJnfu3NSqVYv379+ze/dunj17RtmyZdm9e3ekx1m2bBkvXrzA2dk5xGQOoF27dixcuJAZM2bg6urK9u3b+eWXXyhatChZs2YlWbJk3L17l3Xr1mFmZsYvv/wCGBPGEiVKkDlzZpycnEiXLh3v3r1j+/btXLx4kZo1a5I9e/ZQY+zbty9r165l6dKlXL58mUqVKvHy5UuWL19OqVKlWLt2LWZmcbGut4hrfHx86NmzJzNmzCBDhkJ4eS3h4UN7Nm+GqlVNGMizZ+DiAhs2QL16xvpyn235t3/5eSa4rMc+qR1/HnQhTV5HXIAFQAdgMnGreOrzp2e541aOfDxhW7LGVCo3J6ZDEt+w8P7buAdkAbIDYblvVCTw/UaorcQ3Y/jw4SRNmpRZs2Yxffp0EiZMSMWKFRkxYkSIe8CG14fVq+3atQu1XenSpcmaNSvu7u6cOnWKypUrc/v2bfbt28e6det49eoVKVKkoGLFivTq1YtixYoBYGdnx5gxY9i9ezeHDh1i7dq1JEiQgEyZMvHvv//S5pMipyGJFy8eu3fvZvDgwaxcuZLx48eTIUMGBgwYQMmSJVm7dm2QGnlCRIf3799TtGhRzpw5Q7Zsfbl0aQTlylny338Qyu9CUe/wYWjcGLy8YNIk6NIlyC1Wg0Gz5Pe9LBm2nxzF0zBgdQPMk9nhjHEV63CMdbLiSsFgtObEoe5kujmZTGi2JW9GpYoLYzoq8a0LaU+w4F7AVMAALPjkmF3gsYDP2poBR4AAYGR4xjHVS/ZyFTFhxowZGtDTpk2L6VDCRL7/47ZevSZoR0c3bW6u9YgRxu1RTcZg0HrsWK0tLLTOkEHr48e/aPL2ja8eWW+5rs4wPb71Ov3+nZ/20loX0Fqba63nmDDcqPD82QV9YkkqrRehPebb6QvXN8R0SOIbQih7uYZ3hm4S4Ao0U0qd0FpPCK6RUsoW+BcohLGw8NRwjiNEnHf//v0vbgnfvn2b4cOHY2FhgbOzcwxFJr5lz58/p3379rRp047z5yszaVJ3UqaEffsgcBLaND69xVq3rvEW62cleR7fecnwmsvwPPOItuMqUrtnYa4qRRXgIcYaWaa8KxwpWnPqaF/SXRtHNjRbE1WmXJW1WFnYfL2vEFEgXAmd1vqSUmoQxudTxymlWgMfH4pSSg0BMmKsO/dhs5heWut7URSvEHFGvXr18PPzw8nJiUSJEuHp6cnGjRvx8fFh1KhRoT7/J0REHDx4kKZNm3L//n0uXCjPhQvGXGrWLEic+Ov9o8zhw8ZVrA8ewMSJ0LXrF1WKLx66w8g6K3j/zp/fNjTip2pZOIqxlIIC9hB36l29enGVq24VcQq4xSlDPCyLL6JKpjoxHZb4zoT7+VKt9Ril1FtgDJAbyMX/F0kMDnxXwHuMydy/URGoEHFNixYt+O+//1i1ahUvX74kfvz4FC5cmC5dulC3bt2YDk98QwICAhg1ahRDhw4lWbJ02Nsf5Pr1QkydCh07mnDHB63h77+hXz9IkwYOHoSfvkzLds4/zT/tN5E0jT2j9rQgTfakbMC440NKjDXmTFlFJTLOHBtE6iujyImBLfZlKVdlI9ZWcWkdrvhWKOMt2Qh0VCol0BEoB/wIJMRYpuQGsB2YorW+G0VxRouCBQtqd3f3r7a7ePHiV1c1CvGtku//2G/VqlXUr1+fHDmacOHCNLJnt2fZsiD72ke/p0+Nt1g3bgzxFmtAgIF5v+5kzbgj5C2fgX7L65HAIR6zMK5iLQBsAoLfETp2efPKk8tby+Pkf4Oz/jboInPJk7VxTIclvnFKKQ+t9Zf7QxKJFeBa6/sYZ+QGf62tEEKIqPfo0SOSJUtGgQJ1yZZtGxcuVMDVVTFhAnylVGLUOnTIuIo1lFus3i/f8WeTNXhsuUaNLj/R7u+KmFua8zvG/SGrAssBU+06Fhln3YeR4tLv5FYGttiVoEzVzcSzTvD1jkJEIymEJYQQcYyvry89e/Yka9asTJlyk/z5FffvV2TZMsWMGSZM5gwG+OsvKFUKLCyMiV23bl8kc/euPqV3kTmc2n6DztOq0fGfKmBpTnuMyVxrYB2xP5nzfnOH4yuzkfvKEB4aLDlfYD5Va++XZE7ECnGpRqMQQnz3rly5QuPGjTl58iS5cnWlS5cUFC4MS5YY97c3mU/3Yq1Xz7jy4rNbrACndtxgdMNVmJkpRuxoTu7S6fDG+LzcJoz15YYT+2vMnT81hqTnBpJPBbAlXiFKV9+GrXXCr3cUwkRCTOiUUqWiciCt9b6ovJ6paa1D3CheiG9VRJ+xFdFjwYIF/Pzzz1hYWJMmzTrOnavJr7/C8OFgaWnCQA4cMN5iffwY/vkHOnf+YlZOa83GyceZ2XMbabIn4bf1jXDMkJjHGFeyumOsbdXRhGFHxFtvL85trcBPvhe4ZLDkToFpVM0VelFzIWJCaDN0ewj7Fl9fo78yVqxmbm6On58fVibb8FCI2MHPzw9zc/OYDkME2rt3H6lSFeTWrYVYW6fGzQ0qVTJhAAYD/PknDBoE6dMby5MUKPBFM7/3AfzbeQvbZp2kkHMW+iyqg20Ca24AVYA7wGqglglDj4hLZyaQ6Mwv5Ff+bLEpQMm624lv4/D1jkLEgK8lWVE1JRWnp7YSJEjAq1evSJIkSUyHIoRJvXr1igQJ5PmgmOTh4YGlpSVp0+bhxYvJXLliScWK5ixYAI6OJgzk8WNo2RK2boWGDWHmTAhm+7oXj7z5o+4KLhy8Q6OBJWg2rAxmZgoPjAVK/YGdgClrHIeX79vHnN5SkULvTnPVYMHtfJOpmqdzTIclRKhCS+hCehojEzALSAusBNYAlzCWLIkPZANqAw2AW0A74vherg4ODty+fRsAe3t7LC0t5far+GZprfHz8+PVq1c8f/6ctGnTxnRI3yWDwcCECRPo168f+fOX4eHDbdy7Z8OYMdCnD5iZcknbnj3QtKlx94d//4UOHYItbnf9pBcjai3n1RMf+i6tS6lGOQHjfqz1gCTAFoybgcdWV85PI/7JbjgpP7Za5aFY7e1ksY0LhVTE9y5cdeiUUkmBExgTN2et9YFQ2pbEuHPLK6Cg1vpRJGONcmGtQwfGVWXPnj3j9evXBAQERHNkQsQsc3NzEiRIgIODA9bW1jEdznfn0aNHuLi4sGXLFnLkqM2lS7NJm9aBJUugSBETBhIQYHxAb/hwyJIFli2DvHmDbbpv2Xkmtl5Pgh9sGbSuIZkLpABgAdAWyAlsxlg4ODby8fHi7NaqFH53muv+5jzK/SdF8/eK6bCECCIq69D1w/jvsWtoyRyA1np/4DZhk4D+QM9wjhWrWFtbkyJFClKkSBHToQghvmGXL1+mbNmyPHv2jB9/nMKFC51o0MBYjiSYRaTR5/59aNbMODvXsiVMmQLxvywsYjBoFg3ew7KRB8heLDUDVjUgsWN8NDACY6HS8hifmfvyBm3scMpjBMkvDKWgWQBuVrkp5LyFTAlSxXRYQoRLeBO6moHv68PYfi3GhM6ZOJ7QCSGEKWTMmJEcOSpw8mQfbt/Ow4wZ0K6dCbfvAtiyxZjE+fjA3LnGHSCC4fPKl7HN13Bsw1UqtctPp8lVsLS24DXggjGJaw7MBmLjkrJnzy9zeVtVigbc5LK24n6eyVTOHdvX3QoRvPA+hfHhVxbfMLZ/H/geW2fZhRAixnl6elK/fn28vJ4ycKAlO3cuIEWKPBw/Dq6uJkzm3r+HX36BatUgZUrw8Agxmbt/7Rl9is7BffM1Ok6uQtcZ1bG0tuAyUBhjoeC/Md5yjW3JnDYYOLCvM4aN2XHyv8lOu5Kka/QYJ0nmRBwW3hm6V0BSoDTGBRFfU/qTfkIIIT6zYsUKXF1dCQjQlCt3nkuXStGxo3GP+3jxTBjIzZvQpAkcPQqdOsG4cSEGcGLbdcY0Wo25uWLE9ubkKZsegI1AM4wJ3DaMG33HNnceHOHezpqUUI85jx3PiiygfKa6MR2WEJEW3hm6fRhLkPyllEodWkOlVBrgL4w16PZGLDwhhPg2+fj40L59exo2bEjSpNnQ+hReXqVYudK4kNSkydyyZZAvH1y6BCtWwNSpwQagtWbt+CMMrbqEpGns+ft4W/KUTY8B+B3jszWZMRYNjm3JnH+AH9vdGmK/oyh59GMO/FCbbE2ekVWSOfGNCG9C9wfGMkJpgdNKqYFKqVxKKQsApZRF4N8HAacC2/kH9hNCCBGoT58+zJo1izx5+nHt2n7y5MnAqVPGXbRMxsfHeE+3cWPIkQNOnYL69YNt6vvWj/Eu65nVaztFav/IX4da45ghMS8x1qkaCrQEDgDpTBR+WJ2/sZ6Ti36g4tMV3DL7gZfl9lGi8hrMLWLbzWAhIi5cZUsAlFLNgLkYb9d+2tmfoLdwVeAxF6314kjGGS3CU7ZECCEiS2vNmzdvSJAgAbt3P6RVq7PcvVuB/v1h6FATb9915owxkbt0CX79FYYNCzGAJ3dfMbLOcq66e9F0aCka/1YKMzPFBaAOxkKj44HOxK4q8j7vX7NzSy3Kv95NAIrLadvhVOJflJnsfiLipqgsW4LWepFS6hwwBqjA/2f5Pv1JoDHWkuyntT4d3jGEEOJb8/z5c9q1a8eTJ0+oX38nv/ySnMSJk7N9O5Qvb8JAtDbeUu3d21gHxc0NKlYMsfmFg3f4o94KfL39GLS2IUVq/QjAKowrWW2BXUDJ6I88XA6fm4WNRxecLX05Y5mGtBU3U9AhV0yHJUS0idD+qoFJWhWllCNQBEgP2AHegCdwRGv9IIpiFEKIOO3AgQM0bdoULy8vsmUbRbduZlStCvPmQTJTbkLw9Cm0bQvr1kGVKjB/fqgBbJ1xgmldtpA0XSL+2NWCtDmSEgD8BozCuJp1JRDqA9Um9uTNffZuqY7z+1N4m5txIctA8hQcbuK6L0KYXoQSug8Ck7a1UROKEEJ8WwICAhg1ahRDhgzB0TE9Dg6HuHz5J8aNgx49YmD7rubN4dEj4xLa7t1DDMDP159pXbfiNvMkBSpnou+SOsRPHI9nQFOMt19cgX+A2LKPiNaarcdGkubSUOpZBnAmXg6yVtpKjvhpYjo0IUwiUgmdEEKIkPn4+DB37lxy5WrM2bP/kjGjPZs2QcFgn4CJJv7+8PvvMHIkZM4MR45AgQIhNn9y9xWj6q/k8tF7NOhfnObDy2BubsYJoD5wD5iBMaGLLW49vcTRrVWphydPzS3xzPM3eXJ1i+mwhDApSeiEECKK7dixgxIlSvDqVQIcHY9y6NAPNG2q+PdfsDfl/leentC0KRw+DK1bw6RJwW7f9cG5/bcZXX8lvj5+DFhVn2J1s6MxJnDdgGQYa1cVNknwX+dv8GfV3h4UuD2VhpaacwmKkb3iepLZ/BDToQlhcqac8BdCiG+ar68vPXr0oGLFinTsOIF8+eDUqSTMnatYuNDEydyH2nLnz8OSJTBnTojJnNaaDf8cY2C5/7BNaM24o20oVjc7PkBroAPGKvEniD3J3Jm7B1m9ICWNvKaQwDIejwovIZfzQcwlmRPfKZmhE0KIKHDlyhUaN27MyZMnyZevG/Pn9yRvXli6FLJlM2Eg3t7QrZsxgStSBBYvhgwZQmzu+9aPyR02sfu/sxRyzkLv/2pjl9CGS0BD4BwwBONCiNhQ7MPHz4cl21pR4clK6lvClSTVyFJ2Gcoy5JlHIb4HktAJIUQkbdiwgSZNmmBpaUPGjOs5dcqZrl3hzz/BxsaEgZw4Ydy+6+pVGDgQhgwJtbjdQ88X/FF3BddPPqDZ76VpNKgkZmaK+cDPGEuSbAEqmyj8r9lzZTXPDrSirc0b7lsl4k2pZWRNVSmmwxIiVpCETgghIilLlixkzlyaq1en8+JFatauhVq1TBiAwQATJkC/fpA0KezcCWXLhtrl1I4b/Nl4NQH+BgZvaEShGll5gzGR+w8oAywCUkZ37GHw1OcpizfXo6HPXhyswTN1C9IXnwnmsWWNrRAxT56hE0KICHB3d6dv3768eqX5449snD69CSen1Jw6ZeJk7uFDqF7dWCi4alU4fTrUZE5rzco/DzG48mISOcbn7+NtKVQjK6cAJ4xJ3O/ADmI+mdNas8pjMoeXpKTr+7342zgSUOkw6UstkGROiM/IDJ0QQoSDwWBg/Pjx9O/fHwcHR1au7M2tW8kZMgQGDQILU/5UdXODli3h1SuYMgU6dQq1gO7bN++Z2GY9B1ZcpESD7HSfUxOb+Fb8A/QBkgA7Mc7OxTTP5zdZtbkmbQznsLVReGXqTqqfxoKZ/G9LiODIvwwhhAijR48e0apVK7Zu3UqePHW4eHEWFhYO7NoFpUubMBBfXxgwwFggOGdO4y3WXKFva3XvylNG1l3B3YtPaP1neer2KcozpWgMrAdqYNykO4kJwg+Nv8GfeQeGkv7qKHrHM3DPLiP25TaSIlH2GI5MiNhNEjohhAgDg8FAuXLluHbtGrlzT+XMmY7UqKGYOxeSmDILunjRWFvu1Cn4+WcYOxbixQu1y6E1lxjfah2W1hYMc2tKvgoZ2Qs0Ax4BEzDWmYvpzbFOeZ1g+9badLK8g1k8c57lHE6qPANAydNBQnxNiAmdUqplVA6ktV4QldcTQghT8PPzw9zcHDMzM1q3nsCYMcm4fDkPEydC164m3CJUa5g507hnmJ0drF8Pzs6hdgnwN/Dfb7tZOfoQWX5KSf+V9XFIm5DBwAggM3AY47NzMcnHz4cpO7pR7P5sfokHXvHz4lhuLbbx08dwZELEHaHN0M0DdBSNowFJ6IQQccrNmzdp2rQptWvX5e3bXxg+vAKZMhkfXcuf34SBPH0K7drB2rVQsSLMnw8pUoTa5eVjb/5ssobTO29SpUMBOkyszH1rC0oDhwAXjHuxxnT1tl3X3Dixuyld4z0jIJ4V3gXGk+LH0J8FFEJ86Wu3XKPqX5T8yxRCxCnLly/H1dUVreHFi15cumRcfzBlSqi7Z0W9nTuNAz9+bLy92rMnmIV+C/LysXuMqreSl4+96TbbmUpt8rEC4/6rBowrWZuaIPTQPPV5ysStran9YgN97ODRD6VJVmoZxEsew5EJETeFmNBpreWhBSHEd8fHx4cePXowc+ZMsmYtzMOHS7h7NwP//QfNm5swkPfv4bff4K+/4McfYePGr04Laq3ZMv0EM7q78UPKBPx1qDUpC6SgPTATKAQsBjKZIPzQYlx2Zj5eRzozOL4Pb23t8C08k2QZmsRgVELEfbIoQgghPnH69Gnmzp1LgQL9OHFiGE5OlixZAlmymDCIy5ehWTPw8IAOHYyrWW1tQ+3i+9aPf3/ewo55p3Gqkok+i+pw0yEeBYFLQD9gGBDyvhHRz/OFJ5M2NcbV7yiNE8CzFDVxKD4PrBLHYFRCfBskoRNCfPe01hw9epQiRYqQOHFRsmS5yokT6enZE0aPBisrkwUCs2dD9+7GPcNWr4Y6db7a7cGN5/xRbwU3Tj2kyZBSNB5cin/NFH2AxMA2oEJ0xx6KAEMA/x7+C7OzvzE2gT9vbBMTUHwhDqmqxWBUQnxbJKETQnzXnj17Rrt27VizZg2DBh3l778LYWubno0bjRswmDAQcHU1JnHly8OCBZDy63s1HNt4hXEt1qEUDNnUmAzVslAH2ABUx1hbLmk0hx6aUw9OMXNTQ/pYXCWDPbxO1xL7QpPBMkEMRiXEtyfSCZ1Syg5I+LVraa1vR3YsIYSISgcOHKBp06Y8ePCA/PnHMmJEQcqWhYULw5RLRZ1du4wLHx49Mj4z16vXVxc+BAQYWPL7PpYO30+m/I70X1WfixkSkxd4AkwEuhJzK9J8/Hz4a/cA0t6YxBR7zSurFOhSy0iQrGQMRSTEty1CCZ1SKh/QCygPOIahi47oWEIIER3+/PNP+vfvT8qUGUiW7BCnTxdk2DDjBgzm5iYK4tOFD1mzGmvLFSjw1W4vn/gwttkaTm67QYXWeWk3pSp/xLNkNJAV2ATki+bQQ7Pjxg5WbWvOYNuHJLNXvM3aHfv8o8HcJgajEuLbFu4kSynVAZgU2FfKkQgh4qR48WzJm7cJZ85MJWVKe/buhRIlTBjAlSvGHR8+LHwYN85YMPgrLh+7x+j6K3n+0JsuM6qTqV1+yinFcaAdxl0fvn6V6PHU5ym/u/1MiUfL+dceXttmwrzUcuI5fD1JFUJETrgSusCZucmAObAEWIjxl0GNcStAKyAX0BjICVwAfgF8oixiIYSIoA0bNuDn50eJEnXZtKkzJ092pk4dxaxZ4OBgoiC0hlmzjDs+2NjAmjVQu3YYumm2TPNgRnc3HFIm4M+DLhwqmJIGGFeurgTqRW/koca25OxiDu7rxLCEr0mYwBy/XL+RINcAMIvJdbVCfD/CO0PXDWMyt0Vr3QxA/b+a916ttQ+wDhiplPoVGAX0B8pGTbhCCBF+vr6+9O3bl0mTJpE3bxkePKjDixeKKVOgkyk3JXj61LjwYc2acC18eOf9nikdN7N74Vmcqmam3aLa9Ekcj+VAGYzb8KSJ5tBD4vnCk8GbXGjss5cpDuCdMC8WJZZAwuwxFJEQ36fwJnSlMM7G/fO1hlrrMUqptEBHoAvGZ3SFEMKkLl++TOPGjTl16hQFC3bH3X0M2bMrtm2DPHlMGEgEdnwAuHflKX/UW8Ht849p9ntpUg4qSQkzxX1gJPArxt+yTc3f4M8/Rybi6dGfKYn9sIlvhSH/GOyydgWzmIhIiO9beHeD+LB54MVPjn3Y7zW4p12nYXzOLqZ3mRFCfIdu376Nk5MTt27dIVu2Dbi7T6BtW2uOHzdhMufrC336QIUKYG8PR49C795hSuYOrb5Ij4KzeO71ht/cmnJpcCnKmSksgYPAAGImmTv14BQNZuejwIU+TPzBD4tkJbB0voRZth6SzAkRQ8I7Q/fhJ9DrT469wbi/c3Lg2Wft7we+m7LGuhDiO2cwGDAzMyNt2rTUrz+c1asbcv9+KpYsgcaNTRjI+fPGHR9Onzbe2x079qs7PgD4+wUwr98u1v59hKyFUtJkdQO6p7LnMNAK4y2SmKji5uPnw/DdQzBcGsfiHzTm5rbogpOIl6mNCe9bCyGCE94ZOq/A909LlXgGvjsF0/7DloGyVl0IYRLHjx8nT548HDt2ho4dYf78nmTPnoqTJ02YzGkNkydDwYJw/76xHMnUqWFK5h7feUm/0gtY+/cRqncuSN4DLpRPZc8FjCvR5hEzydzOGztpMONH6t4dy5gkGvOU1bCqeRWVua0kc0LEAuFN6DwC31N/cmw/xtuq3ZVSHzfIUUpZAEMD/3o9ogEKIURYGAwGxo4dS7FixXj69BWNG79l+nTo2xcOHICMGU0UyIMHxi0munaFsmXhzBlwdg5TVw+363TPP5NbZx/ReWV9Dk2uioulOXmA0xjLB5jaU5+ntFvTggObKrA20V3yJkgMJZZjVWYj2Jqy+rIQIjThveW6EePK+BIYtwcEmA50AAoA55VS6zE+1lEJ+BHjM3b/RUm0QggRjIcPH+Li4sLWrVvJl68OFy/OwmBwYOtWqFzZhIGsXw9t28KbN8YZup9/DtPs1YddH5aN2E+6XMmouKERndMl4jbwO8Zn5UxdmV1rzZJzS1iwszPjEr0g5w/gn7YJlj/9A9Y/mDgaIcTXRCShO42xxhwAWuuzgSVKxmK8xdoj8NSHn2JuwLjIhSmEECGbNm0au3fvJn/+qZw82ZGKFRULFoBjWPaxiQre3saFDtOnQ758sGgR5MgRpq7PH7zhr6ZrOLPbk3Jt8vLy3+rUszInDbAPKBadcYfA84UnPTa5UurFDjYnBX+b5FBkDhapqsVANEKIsFBa66+3CsuFlCqOsURJHsAauAmsAOZprQ1RMkgUK1iwoHZ3d4/pMIQQEeDn58etW7fInDkz+/f70bjxNR49ys7IkcZFpWFYRBo13N2NCx+uXjUOPHw4WFuHqevpXf9r767Dozq+Bo5/J0YIBHcL7k5wp4VCgRZKaZEf7sWLWymluBWneFusuLu7uxZ3D05CZOf9Y5aXlEZhNyHJ+TxPns3u3ntnlmWTk5FzrjKi3jK8n7+h1p9fM/nbnOwG6gMTMUWyI1KAJYBxB8axaV8vJiT2JaOzxpK5FQ4FhoNzvAjujRDifUqpI1prz6Ces9kovtZ6D2YnvRBC2NXVq1epW7cut2/fpnnz8wwcGIe0aXOwezcULRpBnQgIgKFD4eefIWVK2LoVypUL46kWFg7azbyfd5A6W2KKHmrGD2njY8GU36lvx24H5/i943Ra1YR6/sdZmwL83NJD8dk4JC8bCb0RQoRXRC/LEEKIj/L333/TsmVLQOHhMY2ff47Dd9/B1KkQP6KGtK5eNUmCd+82W2cnTYKECcN06pP7LxlZfzkntlylePMCnJ1UhQ7OjhQH5gIZ7Nrx/3rt95oB2wdw4cRI5iWHFI4Knb0Lznl/AafYEdwbIcSHCm8tVwtgAeJZy3yFdrwj4AdYtNYSPAohPtibN29o164d06dPJ3v2Yjx4MJ9Ll9IzdSo0bx5BmTO0hjlzoG1b0+CcOWa6NYxObrvGiHrLePXUh4orv2dctSxcU4qfgT5E/F/YW65sodea5nRyucawVOAfLycOxWdD4sIR3BMhxMf6kJ8fH/JjU5IUCSE+irOzMzdu3KJIkV4cPDiAPHmcWbAgzHsPPp6Xl0kOvHAhlC4Nf/0FHh5hOvXtFOv8ATtJkSMxSY+3oEvyuP+/8aGkXTv+X49fP6brxi74XP6D9ckdSODoBLn74ZSzJzi6hH4BIcQnx95/EDpbbz/JTRFCiE+b1ppp06bx5Zdf4uOThsePV3PkiCM//GCKLsSOqBnBLVugUSO4fx+GDIFu3cAxbCWuHt95waj/Lefktmvk61SUbSM/Z5+jQ6RsfNBas+D0AoZsbMfgeE+olhIsiQriUGw2JMgV6vlCiE+XvQO6zNbb53ZuRwgRzXh5edG8eXOWLVvG11/3YevWX3F0dGTpUqhZM4I64eMDffrA6NGQLRusWAGFgiqKE7Qj6y8xuuEKfF75kXd7QyaUSQdKRcrGh+tPr/PD2jakur+OvSkccXOMBfkH45C1g9RfFSIaCDGgU0qVCeapUkopnxBOdQRSAu0wiYVPfVj3QuybI3AYuK21rqaUygAsABJjKlo00Fr72rpdIYT97dq1i/r163Pv3j0KFx7FihWdKFEC5s0L8yznxzt1yqyPO3XKrJkbPjxMpbvA1GL9q+82lgzfR4piqXm9vh5D4rtSArOLNSI3PgRYAhh/cDwzdvZmQuI3lE0OOllpVNHp4J4p9AsIIaKE0EbotmMCssAUsC6M11fW86eFr1th0hE4B7xNjjQMGKO1XqCUmgI0AybboV0hhB0tX76cWrVqkTp1RlKl2sfhw4Xo2xf69weniNg1YLHAmDHQu7fZubpmDXwZ9oS6dy97MaLeMv45eIfMIz5j2Y/Fue2g+AXoRcRufDhx7wStVjWnxOvDHErjgItTHCg4EpWphdRfFSKaCcvPlsCfeh3EY8HRmIBrnNZ6bng7FmKHlEoDVAUGAT8qpRRQAahnPeQPTB1ZCeiEiCK01iilKFeuPOXKdWbXrv4kSeLO5s1QoUIEdeLmTbNWbts2qFHD5EJJmjTMp2+fd4qJrddCLCeSnG3N+BxJyQDsBorZq89B8Pbz5pcdv7Dm8HBmp3CgYFLQqb5EFZkMbmlCv4AQIsoJLaALPDOggCuYQC0XEFLaEj/gidba++O6F6zfgO6Au/V+YuCp1trfev8WkNpObQshbGzlypWMGzeOP/5YTdu28dm6dSRVq8KsWeGKpz7O/Pmm9qqfH0yfDk2bhnkU6/WLN0ztsIHNs0+Q8rucHPnza47FcqIxMI53P6giwpYrW2i3uiW11RWOpnPAwSU+eI5HedSRUTkhorEQAzqt9fXA95VSNzA7Vq9qrUNaQ2c3SqlqwAOt9RGlVLkPOL8l0BIgXbp0tu2cECJcfHx86N69O+PHjydLlgIULvyYR49SM2YMdOwYQfHHkycmkFuwAIoXN+lIMoV9bdnFw3cYXncZ9648IdXS2syrkQ1npVgI1LZfr//j8evHdN3UldPnZrMslQvZnQCP76DQOHCNqKhYCBFZwrWcQ2ud3k79CI+SwFdKqS8BV8waurFAAqWUk3WULg1wO6iTtdZTgalgarlGTJeFEO+7cOECderU4fjx4xQt2pGDB4eRKVMsVq0K10bSj7NlCzRuDPfumRqsPXuGeaGexaJZNmoff/beRpzsiXlzrzPTksahHPAnkNaO3Q7sbSqSnhs60D72Y2akUyjXxFBkCqT5KoJ6IYSIbFGueoPWuhdmbTHWEbquWuv6SqlFwLeYna6NgBWR1UchRMi01jRt2pTr12+SK9cqDhyoRoMGMHEiuEfE/KSPj9n0MGaMSUeybx94BlnvOkhed18wuuEKjm++SvL+pVn/U1keOiiGAl0x2/wjwvWn12mzpg2vbq9jV6pYpHPQkKkFFBgOLgkiqBdCiE/BBwd0SqlsQFOgNJAOs0zkBXAdswZ4ptb6gi06GUY9gAVKqV+BY8CMCGxbCBEGz5+blJTx4sWjQYM/6NUrNtevp+bPP6FBgwjqxPHj8L//wZkz4U5HAnBw9T/81mQV3r7+xD7ekll5k5FVKVYCETWw+DYVybBtfRiY0JfmaUDHSQ1Fp0GKiNpBIoT4lIQ7oLPmfxsJtMdslAi8ysUdSIXZ0NVFKTUO6Ka1DrBBX/9Da70dk1oFrfUVoIg92hFCfLxDhw5Rp04dihYtQeLEfzFhQmYKFjRL17JkiYAOBATAqFHQty8kTgzr1kHlymE+3dfHn1ndN7Nq/CHi18jGpfk1Oe3qTCtgFBDHbh3/txP3TtB8VXOSPj3MSQ9XkhAA2Tqj8g0Ep4jqhRDiU/MhI3SzMelBFGY3607gDGZ0Li5mB2wZwAWTKy4J0NAGfRVCREEWi4XRo0fTq1cvkiZNxaFDrbl0CTp3NlW0YsWKgE5cu2bSkezcCd98A7//DkmShP300w8YWW8ZV089IMHCWiz7NgduSrEc+NpefX6Pt583A3YMYOb+EUxM4Uzt1KDjZUQVmwFJIjIpihDiUxSugE4pVRVTsUYDfwMdtdYPgjguKWajQh2gvlJqvtY6rMmIhRDRxIMHD2jYsCEbNmygUKFvOHt2On5+CcObq/fDaQ1//AEdOpj7s2dDw4Zh3j6rtWb1xMPM7LoJx0wJeX6vM2uTx+ULYBamHE5E2HJlC61Wt6SA3xUuZnQlnvKHXP1QufqAY0RExEKIT114R+iaWW+Xa63rBneQ1vohUE8pFQuoCbQg7NUlhBDRxJs3bzh58hSenpM5fLgV5csr5syBVKkioPGHD6FVK1i2DMqUMYFd+vRhPv3J/ZeMbbqKw2svEb9faTb3L8MzRwfGYmoaOtir34G8TUWy/tRs/kgdh0qxgES5oOhMSJg3AnoghIgqwvszqRhmdG5YGI8far0tGs52hBBRlJ+fHzNmzMBisXDvXlpixbrMsWOtGThQsWlTBAVzq1dDnjymbNeIEbB1a7iCuYOr/6F93qkc3XMTTrRk3i/lSO7owCGgA/YP5t6mIsk5KQeOV//kSiZXKsYOgPzDoNJ+CeaEEP8R3hG6xNbbi2E8/tJ75wkhorGrV69St25dDhw4wP79aZk9uxKpUrmyYweULBkBHXjxAn780VR6yJMHNm6EvGEPfnxe+zGjyybWTTlC3G+zc/6vmlx0daIzMBiT+NLe3qYiOXttHSvSxaOYowWSFIai0yFe1gjogRAiKgpvQPcME5ylAp6E4fi3S0yeh7MdIUQU8/fff9OyZUtAkT//IqZPr8Q335jYKmHCCOjAnj1mfdzVq9CjBwwYEK4dFxcP32HU/5Zz85/HxFn1PcuqZiGxUmwAKtmv1//vbSqSflv70Mrdn+UZXXB2tECBSZC5FaiImOQVQkRV4f0JccJ62zyMx7d47zwhRDTUp08f6tSpQ5o0uXBxOc65c98yaRIsXhwBwdybN9Crl1knp7XZyTp0aJiDuYAAC38P2kXX4rN4HNeZx4+6sqhaVr5UipNETDB34t4Jis8ozpStndmfPhYjE/vikqICquoZyNJGgjkhRKjCO0I3H/gMaK+UugcM11r/p3yWUkphEqZ3wKy5m/exHRVCfLo+++wLtm2Dfft+JkcOZ7ZuNTOednfypMlIfPIkNG8Oo0eHq9TEvatPGN1gBWf33CTBqM9Z26kYbxwU0zA7wOxdStbbz5tfdvzCmL3D6ZcsNj0zOOPgrKDQn5D+fxFUzFYIER2oIOKx4A9WygHYBRTHBGrXMSW2zgIvMXnocmBSM6XH/DzcA5QJKvCLbJ6envrw4cOR3Q0hohytNZMnT+b+/fs0bjyAevVg/35o0QJ++y1chRc+TEAAjBwJ/fpBokRmXrdatTCfrrVm658nmdJ+Pf7xYuG9oyEbMiXCE5gLRMRKta1Xt9JqdSvivrrE8vSJ8LB4QdpvwXMCxE4eAT0QQkQ1SqkjWusg6xSGa4ROa22x5qJbhBmpS48ZhftPm9bbLcB3n2IwJ4T4MF5eXjRr1ozly5dTsGBVxowJQClH/v4bvvsuAjpw6ZJJErx3L9SqBVOmhCtJ8PPHr5nQag17l5wnQVtPDvxWidtOjvQD+gHOduu48TYVyfwTsxmTKgGtEjvg4OIChZdA2m/s3LoQIroKd6UIrfVToKJSqhbQBCgJxA90yFPMqNxMrfUyG/RRCPGJ2LVrF/Xq1eP+/fsULTqaAwc6UqyYA/PmQYYMdm5ca5g8Gbp1AxcX+OsvqF8/XNOSRzde5rfGK3n61IdYexozv3gaPJRiF1DCfj0H3qUi6bi+I9n1Y25kS0SyAC/I2AQKjgKXiNg5IoSIrj6k9BcAWuslwBIApVR8zHTrS631Mxv1TQjxCXn06BGVK1cmSZJUpE69j4MHC9Grl9lM6mzvYa2bN6FZM9i0Cb74wkyxpkkT5tPfePsxu+dWVo07iHvVzFxd+C2n3ZxpjClpE89e/bZ6m4pk5+V1zPBIxnfOGuXqDkXmQ8qI2HYhhIjuPjigC8waxEkgJ0Q09OTJExImTEjixElo1mw5v/9ejESJ3Nm4ET7/3M6Na21G4jp0AH9/M0LXqlW4RuUuHb3LqP8t58a5R8RbWIsV3+YgtlIsAew9wfk2FUnfrX0p7xrAnewJcfd/iMraDvINBue4du6BECKmCG8t16uABciltfYJw/EOwGXAorXO9GFdFEJElhUrVtC0aVOGD5/EmjXfs2xZRSpXNlW0kiWzc+P375vgbcUKKF3a1GHNmDHMpwcEWFgyfC9zf9qBS66kPH/QhbVJ3fgCmIlJpmlPJ++fpPnK5ly8d4hlmVJTkdvg5gFFV0HSiMiyLISIScI7QueB2d0a1qRIKtA5QogowsfHh27dujFhwgSyZi1I374FefTIbCzt3Bkc7J0WbdEiaNMGXr6EUaOgY0dwdAzz6feuPGF0Q5OOJNHwz1jbpTivHFSE1GH19vNm4M6BjNg7gvoJ3NiRLQGuAfcgRy/I8xM4RkS9CSFETGOTKdcQvP0JLAGdEFHE+fPnqVOnDidOnKB48U7s3z+UjBljsXIlFC5s58YfP4Z27WDBAvD0NEOBOXOG+XStNRtnHGd6540EuLug//mBv7IkJj8mHUnYr/Rh3qYief7sEnuypqdIwDVwzw9FZ0KiAnZuXQgRk9n77+y01tuXdm5HCGEjx44d4+bN2+TJs5p9+8ZQt24sjh6NgGBu9WrInduUlxg4EPbtC1cw9+T+SwZ+/TfjW6wmdqO8HLvegXVZEtMTOIB9gzkvby+arWjGZ39+xtcuz7mV1Z0i+i7kGwRfHJRgTghhdyGO0Cml0gXzVFqllHcIpzpi6rj2sN4//wF9E0JEkGfPnnHw4EEqVqyIu3tdtK7C5csJmDXLpHyza8GCZ8/gxx9h5kxTXmLdOsifP1yX2Lf8PBNaruHlaz/c9jVhbtHUpFWK7UAZe/TZSmvN32f+puP6jrj5PuJcroxk970CCUpA0RkQP7sdWxdCiHdCm3K9GsRjClMZIqw0ZrZDCPEJOnjwIHXq1OHBgwfUr3+dqVMTkz9/AhYsgGzZ7Nz4li3QpAncvg29e8NPP4W5BivAq2c+TO24gS1/nCRRjWxcm1eTk7GdaQSMw77pSG48u0GbNW1Yd3EtQ9J50NXNFUfLfSg0DrL8AA5hX/MnhBAfK7SALri/y8P69/pzYLLWenzYuySEiAgWi4WRI0fSp08fkiVLRapUG5k6NTEdOsCwYeBqz7X7r15Bjx4wcSJkzWqqPhQtGq5LnNx2jTGNV/Lo1nMSr/yeRdWy4KYUi4Fa9uk1YFKRTDg4gT5b+5DZycKNPBlJ43MFklaEIr9DXHtnWBZCiP8KLaArH+h7BWzFjLhVBUKacvUDHgOXtNYBH9VDIYTN+fv7U716ddavX4+nZy3Onp2Gj09CVqyAr76yc+N79ph53MuXoVMnGDQoXMVf33j78Wfvbaz47QDxS6bh6YmWrE7gSmVMOpKU9uo3cOLeCVqsasHRO4eYmjkbjR2v4RDgZTY9ZGxs57lpIYQIXogBndZ6R+D76t0Pq51a69f26pQQwr6cnJzIm7cwXl41OHiwJWXLKubMCVfxhfDz8TFTqiNHgocHbNsG5cqF6xIXDtxmTKMV3LrwmJTTqrG0WX68lWIS0JqwTx2El7efN7/s+IWR+0ZSKq479/NmILH3BUhVAwpPgtj2DCOFECJ04UpborW2965YIYSd+Pn50a9fP6pWrYqbW2mWLv2FK1dM6a4+fcKV5i38jhyBhg3h7FmTLHjECHB3D3vffQNY8MtOFg3Zg3v2xHCnE9NTulMYmANktVvH36UiufHkEkty5KW6/1mUdoZSCyHttzIqJ4T4JNg7D50Q4hNw5coV6taty8GDBzl6NBbbt5cmRQrYvt0UYbAbX18zpTpoEKRIYXawVq4crktcOXGPMY1WcvXEfdIPqcDK7iW446DoD/QB7FVG1svbi64buzLr+CxqJU3NsTwexPU+CekbQKExECuxnVoWQojwk4BOiGhuwYIFtGrVClDkz7+ITZu+pUYNmDEDEiWyY8OnTpm1cseOmdG5sWMhQYIwnx7gb2HxsD3MH7CT2CnikuBiWyZlTkRmYA8Qvi0UYRc4FYm39yN25fWkpPcRlEoNZddA6i/t1LIQQnw4CeiEiMbWrVtH3bp1yZWrBA8ezOPcOQ8mTjRVtew2U+jvb9bJ9e9vArhly6BGjXBd4ua5h4xutJKLh+6QuVsxNg/+jDNODrQGRgJx7NBteJeKZO3FtbRJk40xGV2I5X0YsrSB/EPB2Z6JUIQQ4sNJQCdENOTt7U3s2LGpUOELqladwZo1DcmRw4nNmyFvXjs2/M8/ZlRu/36oVQsmT4akScN8eoC/haUj9zHv5x24uMci7bEWTM6fgoTAGsBeY2OBU5HEd9CcLFiMPC/2g1Nm+HwHJLNnemIhhPh4sslBiGhEa82ECRPInDkz+/bdonx5B9asaUqzZk4cOmTHYM5iMVOq+fPDhQswbx4sWhSuYO7a6Qd0LT6TP3ptJXOTfNy63Ykp+VNQDTiN/YK5k/dPUmJmCTpt6EQ3j2xcz+JOnpcHIUd3+PKkBHNCiChBRuiEiCYeP35Ms2bNWLFiBQUKfMkXX8RCKVPn/vvv7djwlSvQtCns2AFVq8K0aZAy7Gk8/P0CWDxsLwt+2Uns+K7kO9CU8UVSAzAbaIh90pF4+3kzcOdARuwdQWa3+FzzLI7Hs30QOw+UWw2JPe3QqhBC2IcEdEJEAzt37qR+/frcv3+fYsVGs39/J4oWVcyfDxnsVbjAYoEpU6B7d5PzZMYMU8YrHIvzrpy4x9gmq7h87B4Fm+fn+IQqDI7lRBngDyC9nbq+7eo2Wq5uySWvS0zJXYYW+jQOLw5DngGQsyc4utipZSGEsI9gAzqlVAfrtxOl2oMQn7bff/8dBwdX0qbdx/79hejRAwYOBGd75fS4dg2aNYOtW6FSJZg+HdKmDfPpfr4BLBy8m4WDduOeKDbldjdiZMl0PAFGAJ0Be6TFC5yKpGRiD/YWLkbSpzshcVEoOgMS5LJDq0IIYX8hjdD9BliA6cBrAKXU29JfX2qt39i9d0KIYN28eZM3b96QKVNmPD0ns2SJIkECdzZuhIoV7dSo1mZKtUsXc3/qVGjePFyjcpeO3OW3Jiu5duoBxZvm4/LEKnRzdSY3sBGwxzK/wKlIHr9+xJKClanpvRf14gEUHA1ZO4CDPTMrCyGEfYU25fr+T+lymIBOfvIJEYlWrFhB06ZNyZo1J6lS7WTp0nhUqgR//gnJk9up0Zs3zajcpk1QoYKZYk2fPsyn+/r4M2/ADpaO2EeC5HGpubMRQ0un4zLQDRgIxLJDtwOnIqmROg9/5vTA/el6SF4eikwD90x2aFUIISJWSAHdayA2kNj6vRAikvn4+NC1a1cmTpxI1qwFuX59JocPK4YPN4NmDvbYt641zJoFnTtDQABMmmTKd4WjsXN7bzK26SpuXXhMhZYFuD+2Mi1dnUgLbAPK2qHbgVOROKDZXvRryjzbiHrlDEWmQqbwjSwKIcSnLKSA7hKQB+iilOqrtX4Z6Dlt324JId538+ZNqlWrxsmTJylR4kf27x9M+vSx2LMHihSxU6O3b0OLFqZkV9myMHMmZMwY5tN9XvnyZ59trBp3kCRp49NkT2MGl0jLUaARMBaIb4dun7x/kharWnDw9kFaZy7FbwleEMtrBaSuDoUng1tqO7QqhBCRJ6SAbhFmOUt7oL1695esAl6q8P1lq7XWsqNWiI+QNGlS4sdPRp48a9i790vq1jWbTOPZo3iB1vDXX9Chg6nHOm4ctG0brlG5E1uvMq75au5ffUqVdp68HFGR+q5OuANLgZp26HbgVCTJXBNwouQ35Hm0CuUTH0rMB4/vZVROCBEthfTTeQSwAhPAvf16S33AlxAinJ49e8aPP/7I8+fP2bzZlbNnN3H58pfMmgVz59opmLt7F77+2lR8yJ0bTp6E9u3DHMy9fOrD+Jar6fPZHBydHOiwvwmLx1ehp6sTlTBJgu0RzG2/tp28U/IyZPcQ+uWqzPUcycj7YCkqbW2oehbS15FgTggRbQU7aqa19gVqKqWyYaZe3TB5PjXQBpBdrkLY0cGDB6lTpw43btzg4sVyrF79FfnymUTB2bPboUGtYc4cMyrn4wOjRkHHjibHXBjtW36eyT+s4+n9V9TsWhw9qBy1XZz+f7t8U2z/152XtxfdN3VnxrEZ5EyYnqtlapP+3hJQKaHMSkhT3cYtCiHEpyfUaVCt9QXgAoBSarb14Tlaa9koIYQdWCwWRo4cSZ8+fUiWLDUZM+5k9eoStG8Pw4eDq6sdGr1712x0WLUKSpQwa+WyZQvz6U/uvWRK+/XsWXyO9HmT0XZtXYblT8EyoAzmL0Fb5zfWWrPwzEI6rO/A49ePmexZh5YBh3C4uwgyt4T8w8HFHiv0hBDi0xPedW1/Ykbo/OzQFyEE0KdPH4YOHYqn57ecPTuNN28SsHIlVLfHQJPWZu62Qwfw9g73qJzWms2zTzCjyybevPaj4aDyuHQvzldOjjzFfkmCbzy7Qdu1bVn9z2rKpirA4sJlSHJ7AcTNCJ9tNSlJhBAiBglXQKe1bmynfggR4wUEBODo6EiDBj+wbVsmDhxoRtmyirlzIbU9NmXevQutW8PKlVC8uElNEo5RuXtXnjCh1RqOb75KzlJpaTKjOqOyJmYGkA/YjFmrYUsBlgAmHppIn619sGgLS0s1p8bz9ag7JyBbZ8g3EJzi2LhVIYT49H30zlOlVFYgHeAOvACua60vfux1hYgpfH196du3L6dPn6Z//9XUr5+Wq1eb88sv0Lt3uJawhY3WMG+e2ejg7Q0jR0KnTmFuKCDAwqpxB/mr73YcHBRtJlYhbutCVHVQXAd6Aj9j+yTBp+6fovmq5hy8fZDvMldgRmp34t6ZDvFzQenFkKSojVsUQoio44MCOqWUO9ALs8Y5aRDPPwRmAEO11i8+qodCRGNXrlyhTp06HDp0iGLFWlOypD+pUrmwYweUKmWHBu/dM6NyK1Z80KjctVP3Gdd8Nf8cvEPhqlloMqUK49LEZzRmjdxOoKSNu+zt582vO39l+N7hJHRNwK4K7Sn5YAHq7hPI/RPk6g2O9qgxIYQQUUe4Azrrrtf1mFG54DasJcP8oV5XKVVZa/3Ph3dRiOhp/vz5tGrVCgcHR/LnX8z+/bWoWdPUuU+UyMaNfeSonN8bf/4etJtFQ/YQJ4Er3ebVJHadXFRWinOYbe/Dgbg27va2q9touboll7wu0TFPbYYneInLzfGQyBM+2wIJbD2pK4QQUVO4AjqllBuwARPMAazEJCA+g5lujQvkAr4FagDpgfVKqdyyK1aId16+fEm3bt1ImzYPDx7M49w5DyZNMoNnNk+VdvcutGnzwaNy5/beZFzz1dw894jyDfLQcHQlxidxYzCQAvMDoZKNu+zl7UW3jd2YeXwmmRJm5MwXXch5czo8fAMFRkC2TuAgucqFEOKt8P5E7IAJ5l4DtbXW64I45gQwTyn1BbAE8ADaYf6AFyJGO3v2LFmyZCFWrLhUq7ad339PT44cTmzdCnlsPdikNfz5pxmJ8/EJ96jc6xdv+KPXVtZOOkzSdPEZsK4uLpUzUwk4DjQAxgEJbNrlf6ciGVqsFV0dL+B4ZRQkKwNFpkO8LDZsUQghoofwlvKuiUlbMiCYYO7/aa03AAMw07K1Pqx7QkQPWmvGjx9PgQIF6NlzGGXKwO+/Z6ZFCycOH7ZDMHfrFlSrBo0bm2oPJ05Aly5hDuYOrbnIDzmnsHbSYap3KMLY063ZVDkzhYA7wDJMDqMENuzyjWc3qD6/OnWW1CF9/LRcq/IjPZ7+haPXEVN/9bNtEswJIUQwwjtCl9V6uyiMxy8ChgU6T4gY5/HjxzRt2pSVK1dSsGBVpk5thaMjLFwItWvbuDGtYcYME7z5+8PYsdCuXZjLdj2595KpHTewa+FZ0uVKSs9FTXAoloZKwH7MX2aTCWIn1Ed4m4qk95beaDSzy/Wgoc8O1MURkLIKFPkd4qS1YYtCCBH9hDege5ujPqw7V98eJ1vQRIy0b98+ateuzYMHDyhWbAz793ekWDHF/PmQPr2NG7t2DVq0gM2boVw5s7siU6YwnWqxaDbOOMas7lvw9fajwa/lqNGtBL+7ONIT88GfC9TFtqW7AqciqZq5En9ly0PCS2PAKS4U/xPS/0/qrwohRBiEN6C7h1lDVwCTNzQ0BQOdJ0SMEzt2bNzcEpE69UoOHChI797w88/g7GzDRiwWmDIFunc3wc/kydCyZZhH5W6ee8iEVms5s+sGecp50O73qvhnTUwVYBvwJTANSGXDLvv4+zBwx0BrKpKErK0yiMqPFqH+GQXpvoNC4yB2chu2KIQQ0Vt4A7odQENgkFJqt9baJ7gDlVKxgIGYNXc7PryLQkQtN2/eZMmSJXTs2Ik9e/Jz/fpxEiVyYNMm+OwzGzd26RI0bw47dkDFijBtGnh4hOlUXx9/Fg0xqUhc47rQYUZ1Pm+Sj5lK0dl6zHRMsklbjpFtv7adlqtactHrIs3z/o9xaRIT+9JPECsplF4GaWvYsDUhhIgZwhvQjcVsbvMEdiulummtt71/kFKqPGZXayHAgtkMJ0S0t2LFCpo0aYKvrx/r1tVi48a0fPmlA7NnQ1KbLjwLgHHjoE8fcHEx6+aaNAnz9OSpHdeZ2GoNty48plz93DQfXYnXyeJQDVgHlAdmYvIO2YqXtxfdN3VnxrEZZEyYkYNfj6Hwzclw8R/I2BQKjgSXhDZsUQghYo7w1nI9ppTqCwzCOu2qlHoKnAdeYvLQZcdsfnv7m6WP1vqYrTosxKfIx8eHrl27MnHiRLJlK8TTp/PZti0to0ebWvdhnP0Mm3PnoGlT2L/f7GSdMiXMxV6fP37NzG6b2TzrBMkzJOCXDfUoUCkT8zC5hd5g/vpqS/i3wAfn/VQk/Yp3pl8Cb5zP/ghxPKD8RkhZ0UatCSFEzBTuzJxa6yFKqVvAKCAJkBAoHsShD4EuWus5H9dFIT5tWmsqVqzI7t27KV78R/bvH0KmTC6sWQOFCtmwIT8/GDECBgwAd3eYMwfq1QvTqJzWmu1zTzGt8yZePfXh254lqNOvDM/dnKmFSUNSHPgDsGVikBvPbvDDmh9Yc3ENhVIWYm+Vn8l0aRg8ugFZ20O+QeBs6/oSQggR83xQqnWt9V9KqYVAdaAUJnlwXMwo3TVgN7BKa+1ro34K8cnRWgOglKJBg048fdqbffuq0KABTJxoYi6bOX7cTKkeP25ynUyYAMmShenUO5e8mNRmLcc3XyVbsdS0n1qV9HmSswRoDTzHrI/4EQhblrrQvU1F0mdrHyzawsTPfqW14z84nPgB4mWDirsgqa2rvgohRMz1wbVztNZvgMXWLyFilGfPntGqVSvKlClDmjQ/0KtXLd68MYUZGjSwYUM+PvDrrzBsGCRODEuWwDffhOlUP98Alo7Yy4KBu3CO5USbiVWo0roQTx0U9YF5mG3of2Lq9dnKqfunaLGqBQduH6By5sr8Uehrkp0dAG8eQq7ekLsfOLqGfiEhhBBhJsUQhQinAwcOULduXW7cuMGtW4XZswcKFoQFCyCLLecr9+0za+XOn4eGDWHMGEiUKEynntl9g4mt1nDj7CNK1c5Bi9++IHEqd9YCzTHrIX4GegO2yqDi7efNwJ0DGbF3BAldE7Kk+kRqvtqGOtoGEuaHcmshUQEbtSaEECIwCeiECCOLxcKIESPo27cvyZKlJn36XezZU5wff4TBgyGWrdJnv3oFffuaKg9p0sDatVClSphOfeHlzaweW9g4/RhJ08Xnp1XfU6RaVp4DLTBpSHIBq3mXJNIWtl/bTotVLbjkdYlGeRsyPkdR3E/3Bf/XkG8w5OgKDrZMvieEECIwCeiECKODBw/Ss2dPPD1rc+bMVPz8ErBmDXz5pQ0b2bABWrc2VR9++AGGDg3TYjytNTvmn2Z65008f/yab7oWp27/MsSK68JfmJG4O0BPzMicrWJPL28vum3sxszjM8mYMCM7v5tL6Xt/wdG2kKQEFJ0B8bPbqDUhhBDBkYBOiFBcu3aN9OnTkyNHMT7/fD+bNxehQgXFnDmQMqWNGnn4EDp3hrlzIXt22LULSpUK06l3Lnkx+Yd1HNt0haxFUvHLhnpkzJ+CTUA34AQmIeRCgt6O/iHeT0XSo3g3fkmbEpdTrQBtKj1kbQvKlvlahBBCBEd+2goRDF9fX7p160aWLFmYMWM/BQrAtm1FGTxYsXGjjYI5rU36kRw5YOFC6NcPjh0LUzDn5xvA34N20Tb3FM7vv0Wr8ZUZsbcJz/On4AugEmYH63zgILYL5q49vUb1+dWps6QOaeOl5VS9BQxVe3E59iMkKQ5fnoZs7SWYE0KICCQjdEIE4fLly9StW5dDhw5RtGhrWrXKR5o0ZuCsuK0io6tXoU0bM81arJgp25U7d5hOPb3zOhNbr+XmuXebHl6lcqcp8Bcms/do4AdsN73qF+DH2ANj6b+9PwrF2M+H0s7tCQ6H6oJzPCg2CzI0CnO1CiGEELYjAZ0Q71mwYAEtW7bEwcGRPHkWc+BALWrXhqlTIUECGzTwtmxX376mhMT48Sawcww9C9yzR6+Z1d1a6SF9AvqvqUOWL7MwBFOXD8w0a09Mxm9bOXDrAK1Wt+LE/RNUz1qd6YVrk+zsz3D9igniCowAV1vWNhNCCBEeEtAJ8Z7r16+TNm1e7t2by6VLHkydCs2b22jg6cQJc7HDh03ZrkmTIG3aUE+zWDSbZ59gVrfNvH7+hm97lKBmv9LMjONCZeAJpsjyQCCdDbr51jOfZ/Te0pvJhyeTyj0Va2rOoMrzTaiDDcE9K3y2FZKXt2GLQgghPoQEdEIAx48f59GjR5Qp8zn373fj7Nku5M7txN9/Q86cNmjA2xsGDoThw02C4AUL4LvvwhQlXj/zgElt1nFm1w1ylkpLmylfciBXMgoAVzFr5YYB+W3Qzbe01iw+u5iO6zty/9V9OhZpz+D06Yl9+kcI8IY8AyBnD3C01YSuEEKIj2HTgE4plQVIDHgD/2itvW15fWsbaTHJ7ZMDGpiqtR6rlEoE/A2kx5Qf+05r/cTW7YvoRWvNhAkT6Nq1KxkyZCNOnOMcPepAmzYOjBoFsWPboJHt26FlS7h40SQKHjEiTAmCfV75Mv+XnSwffQC3eLHoMKM6To3z8Z2D4jCQD9iACehs6drTa7Rd25a1F9dSMGVBNlUfTa5r4+DYODMaV3iyKd8lhBDik/HRAZ1SyhmT5qotJph7K0AptQroprW+8rHtBOIPdNFaH1VKuQNHlFKbgMbAFq31UKVUT8wyoh42bFdEM48fP6Zp06asXLmS/PmrcfHiLJydHcJTXStkT55At24wYwZkygSbN8Nnn4Xp1AMrLzCl/QYe3nhGxab5KTryc35NGJs1QFpgNvA/bFd7Fcymh9/2/0b/7f1xdHBkfMVh/BD7EQ5HGoBLAij2B2RoIJsehBDiE2SLEboVwBfW769gqgolAzICNYHSSqkSWutLNmgLrfVd4K71+xdKqXNAauBroJz1sD+A7UhAJ4Jx7949PD09efjwIYUL/8ahQx0oVUoxdy6k+9hFaFrD4sXQvj08egQ9esBPP4GbW6inPrjxjKkd1rN/xT+ky5WULgeaMrdIan4E3IGhQAfAFgOHge27uY/Wa1pz8v5JamarwdSC1UlybiC8ugYZm0KB4RArcajXEUIIETk+KqBTSn0LVAYOAA211hcDPZcTmINZ2jMEqP0xbQXTfnqggLX95NZgD+AeZkpWiCAlT56czz6rz7ZtdThypAA//WRSwDl97J84N29C27awahUUKgTr1kGB0OuX+vsFsHzMAeYP2AnAd2Mqcb59Yao6OuAPdAT68O8hcFu4+uQqvbb04u8zf5MmXmr2Vv6J4k/Xw+FmEC87fL4DkpWxcatCCCFsLdhfX0qp+FrrZ6GcXwGzju1fwRyA1vqsUqo5cBgI2zxTOCil4gJLgE5a6+cq0DSQ1lorpXQw57UEWgKk++ihGBGV3Lx5k5YtWzJ69G+sW5eN+fOHkTw5bN0KZct+5MUDAmDyZOjVy3w/YgR06hSmCPHM7htMarOW66cf4lkrO7GmVqVrIjceAnWBQUCGj+ze+576PGXwrsGMPTAWR+XArKL1acBFHC//Am7poMg0yNhI6q8KIUQUEdJvmwtKqZ5a69khHPN2i9vTYJ5/+7hL+LoVMuu6vSXAXK31UuvD95VSKbXWd5VSKYEHQZ2rtZ4KTAXw9PQMMugT0c/y5ctp2rQpvr5+NGhwiSNHslGjBkyfbjadfpQzZ0wqkv37oVIlmDIFMoQeggXOKZckXXxKHmzKzMKpuYRZOzAcKPyRXXufX4Afvx/5nZ+3/4yXtxdD8lSik9sTYnnNBbc0ZsNDxqbgaNOPrBBCCDsLqTZPXGCGUmqvUqpgMMccBxTw0/tPKDNk9lOg42zCet0ZwDmt9ehAT60EGlm/b4RZ2ydiOB8fH9q2bUvNmjVJkiQjrq7HOH26KhMnwtKlHxnM+fiYtXEFCpgdrH/9BevXhxrMWSyaDdOP0TrbJLb9dYq8k7/k3JV29C6cmljAGmArtg3mtNasOL+C3JNz035de/6XwoNnhQvRw2cDsbxvgedEqH4JsrSWYE4IIaKgkEbosmGqB9UGDiilZgC9tdZegY6ZBXQBflBKVQE2A48wmyIqYTbkWYBfbdjnkpgcqqeUUsetj/XGrBdfqJRqBlwHvrNhmyKKGj16NJMmTcLTswuHDw8mZ04Xtm2DPHk+8sK7dkGLFnDhAvzvfzB6NCQNvVLClRP3mNRmHef33SJZo7w8GF+ZIe6xSIX5K6URtt25CnD4zmG6buzKjus7qJfcgz0F85HkxVHwSQGFxkLmluDoauNWhRBCRCSldcizjkqp8sB4ICfgBfTRWv8e6Pn0mM0PJYI4/RHQTmu90FYdtiVPT099+PDhyO6GsDGtNY8ePSJp0qScOeNNrVr7uHChAq1ambgrDJtNg/f0qdm1OnUqpE9vple/+CK0s3j94g1z++9g1biDqDzJ8F70LZszJSSeUvQC2gMf062g3Hh2g95bejP31Fwqx0/A7+lTku71OXBNBjl7QubW4GTr/bJCCCHsRSl1RGvtGdRzoa7Y1lpvU0rlw2RL6A9MUkq1wARq+7XW14BS1mOKAkkwiYXPAVu11r42eh1ChOrp06e0atWKI0eO0LPnMTp3dsfJqQKLF0OtWh9xYa3NHG379nD/PnTpAgMGQJw4oZym2bPkHNM6beSutz/+6+qx5/MMKKXoikmWGHqK4fB5/uY5w3YPY/T+0RR0CeB8roxk870CAU6m5mqWNuAUcr+FEEJELWFK0qC1DgDGKKXmASOA+sBupdRfQA+t9QOt9QnghP26KkTI9u/fT926dbl58yZ58/5KixZxKFWKj88td+sWtGsHK1aY9XJvU5KE4s4lL35vv54DO2/wbGgFTrfx5LWTA42AAZj1CLbkb/Fn+tHp9N/en9T+D9iTKTUFLbeBp5B/KGRpC85xbdyqEEKIT0FImyL+Q2t9X2vdECgNnMQs+bmglOqglArXtYSwFYvFwtChQylVqhS+vpAy5W5OnOjJzz87sG3bRwRzFgtMnGiKuW7caOqwHjwYajDn6+PPvAE7aJN/KquzJuLggx/Z374Inzk5cBKYiW2DOa01a/5ZQ97JeZmyqQ2LUwRwNB0UdHwFeX+Fr6+auqsSzAkhRLT1QWlUtdZ7lVKFgDbAQGAM0Ewp1V5rvdOWHRQiNBaLhbVr15I7dy3OnPmdlCkTsH07lC79ERc9c8Zseti3DypWNGvlMmYM9bQj6y8xud16jhVIwY2LbXmU0p2SwDDMbh5bO37vOF03duXe7S2MThGXyglBO/tD9p8hWydwiW+HVoUQQnxqwhzQKaXiAPGAF1rrl9rsppiklPobs8O0CbDNer+r1vqOXXoshNXGjRvJnz8/FksynJ3XcuJEHL75RjFtGiT60IVpPj4weDAMHQrx4sGff5pdrKHUL3106znTOm9kxWNvriytzcO8ycmFGY2rhsntY0u3n9+m77a+HDw7m0FJXfjaQ4GTguw/obJ3NrVXhRBCxBghBnRKKTfMuu3/AR6BHr8BzAeGaK0fAy2UUr8DE4E6QDWl1EBgjNba316dFzGTr68vffr0YeTIkVSv3o4DB8bz/HlcpkyBli0/onb8jh3QqpVJRdKggdkSmyRJiKf4+wWwctxBJi05z6kBZXlQMSNptWYWJreOrVOQvPR9yYg9I1h5eDg94vsywwOUkwsqW1fI3gVi2XqLhRBCiKggpNJfSYAdQHbMAIM/Jg1JYkxw1wP4RilVWmv9UGt9GChqzQM3BOuonVKqo9Z6k51fh4ghLl26RN26dTl8+DD58rVh1arh5M5tynflyvWBF33yBLp3N2UjMmY06+UqVgz1tNO7bjBk8G62N8jLnb1NSBhgYSTQVilsndUtwBLArOOzmLmzF21cH3EktQJHVxyydYDsXcE15MBTCCFE9BbSRobBQA7gFmbWKJbWOpXWOhYmafBlIIv1uP+ntZ5hfXyy9Xa9UmqJHfouYpjt27dTsGBB/vnnEhkyLOHEiUm0bRubgwc/MJjTGhYsgBw5YNYsE9SdOhVqMPf0wSt+6bCeaifuM3/l9zz+Lie9tOaqowNdwObB3IZLG6g2NReOB1uwM+kj6iWIhUOOLjh8fc3sXpVgTgghYryQply/AjTQ4P2NDlrrzUqpOsBhoPr7J2qtnwHtlFLTMEmJa9isxyLGypUrN9mzV+b06ZE8e5aOZcugRo0PvNi1a/DDD7BuHXh6mpJd+fOHeEpAgIVls47T/7EPFwZXQMd2oplFM8DJgVQf2I2QnLp/ipGb2lH6xU5WxQPl4IxD1raonD0gdgo7tCiEECKqCimge7s97mowz799PF5wF7DmpiujlKr/AX0TgmPHjjF69GjGjJlJx45JOHRoIWXLwpw5kCbNB1zQ3x/GjjU1WJWC334zOeYcQ17tdubIHdpuu86+hnnxTRaHL5+/YYyjA1ltvUgOuPfyHmM2dybT3QVMjwcqgRNkboVjrt7gZo/QUQghRFQXUkB3DsgH/AD0CuL5Ntbb86E1orWeG/6uiZhMa824cePo3r078eMnpUCBa9y9m4WBA6FXr1Djr6AdPmx2TRw7BtWqmRxzoSSpe+blTccVF1hU1oPXXYtT4P5LJmtN0XixPuyFheCV7yum7e6P2z9jGejuj0N8R/wzNsY17wBwS23z9oQQQkQfIQV0I4C5QHelVGlgLfAAU9qrElAWMyU70t6dFDHLo0ePaNq0KatWrSJ79upcvDiTNGmSsHMnlAiqYnBoXr6Efv1g3DhInhwWLTJ1wELYDusfYGHwpiuMSROPp03yk/bWc+a98uWr5HFtnoIkwBLA4iPjeHm8H21iv8IhnuJ12jrELzgcpzi2richhBAiOgo2oNNaz1dKJcbkRC0BFA/0tAJ8gJ5a63n27aKIab7//nt2795NlixjOX++Pd9/r5gyBRIk+ICLrVoFbdua8l2tW8OQIRA/5GS7C84+pKuPP7crZybBreeMvf6Udh4JwldWJYx2nV/E9f1tqeX0EGc3xaMU1UlRbDzx43iEfrIQQghhFWIeOq31BGv91q+BPIA78AI4Dayw5qAT4qP5+/vj7++Pq6srX389hiNHArh9uwAzZkCTJh+QW+72bejQAZYuhdy54e+/oXjxEE/Z++g1rW4843TBlLg+eEWng7cZWjgVsT44sV3wLtzexZkdjahsuUpxZ7iRqCwZSs0khXvo1SiEEEKI94VaKUJr7QXMioC+iBjqxo0b1K9fn6xZc+DmNpUJE/KSP7/JKJItWzgvFhAAv/8OPXuCn5+p+tC1Kzg7B3vKFb8AWvzjxdbsiXFyduCbdZeYUiotSYvYft3aQ69zHN1aj1I+x8ms4Jx7QbKU+ZOMCT80iZ4QQgjxgbVchbCVZcuW0axZM3x9/bl+vQ03b0KnTqbyVqzw7js4ccJUejhwAD7/3NRfzZQp2MMfAZ2uP2V+SnfIlJBiyy4wNV8y8lTJ/DEvKUjer25zdOv/yPtsOxUVHImVhUyl/yB3ipBHDYUQQoiwkIBORApvb2+6dOnC5MmT8fDw5O7dBfj4ZGLtWqhSJZwXe/UKBgwwpboSJTI5TerVC3ae9iXwyxNvxsVy4k2aeGRdcp7h8WPxVa3sKBtPr770OsXF/Z3I7LWN4kqz2yE1aUtMpXD6L23ajhBCiJhNAjoRKe7evcucOXPJkqUrFy8OolIlF/74A1KEN1/umjUmj9y1a9C8OQwbZoK6ILwBJvoGMMA3gOcJY5Nq+QW63H9Ju0b5cHG14UdBa25d/IMnJ34hl+9V8gDbLIlIUGgkZXI1sV07QgghhJUEdCLCaK3ZuHEjlSpV4ubNjMSNe5Fr15IxYgT8+CM4hGcb6e3b0LEjLFliSnft2AFlygR5aAAwR2t6vvbjXhwXEu25SdstV/m5dSGSpAk2L3a4WXyfc+5QL9yv/UE69QqXAFjpkpt0noOpmOk/BVWEEEIIm7FHJgYh/uPp06d8//33VK5cme+/X0GFChAnTjL27TN7FsIczAUEmHxyOXKY0blBg+D48SCDOQ2sAHL6+NNYKV6ff8xXbdaw3cmBCb+Wt1kw9+LxMY6tKcerhQnJdX0SXn5vWJagBpavrlHj+1MUlGBOCCGEnckInbC7ffv2Ua9ePW7evEm6dENYtOgrGjWC8ePB3T0cFzp0yOSSO3oUvvjCVHoIZtPDNqC7bwCHXRyJc/0ZJYfvpVeRVFSeUAVHRxv8HaMt3Lwwg2cnB5Hb/zq5NGyzJEFlaU+5Qj3I72T7ShJCCCFEcCSgE3Y1ceJEOnbsSKJEaXF13c2TJ8WYO9fsWQizp0+hb1+YNMkssvv7b6hdO8hND4eBXgEWNjs6EPvBK/IN3EXruC78b+TnxE0Y+6NfT8CbJ5w72IMEN+aSVr3GyR+WueYlY+FhfJGh8kdfXwghhPgQEtAJu0qVKhPp0n3L1atTKFo0AfPmQcaw5s7VGubPhy5d4MEDaN8eBg6EeP+dKj0D9NOaZUoR69kbcvy6i1rXn9J6yGekzpr4o1/H84cHubL/RzI/20tuB80RP2cOp6hNiZKjqeme5qOvL4QQQnwMCeiEza1bt45//vmHUqU60rNnZa5dq0yfPtC/f4j5ff/t3DlTsmvbNihc2KyXK1jwP4ddAX7GbHpwfu1H1mF7KbvpCj8MLEf+zz+y6oK2cP3sZF6dHkrOgFvksMA2nRTHLJ0oV7AbhRzD+mKEEEII+5KATtiMr68vvXr1YvTo0aROXYCuXX8geXJntm6FcuXCeJFXr8xGh5EjIU4ckxy4eXNwdPzXYbeBX4HpWoOfhQy/HaDgzOM061KMirsbf9Q6uQCfx5w90JXEtxbgoXy47Q9LYxcgS5ERVPb47IOvK4QQQtiLBHTCJi5dukTdunU5fPgwadK05datkXzzjTPTpgWbFu7ftIYVK0wqkhs3oHFjk1MuWbJ/HfYIGAZM0Bo/i8Zj+jGyDN1Dne9z8d3BZrjF+/DNCE/v7+XagS5kfXGAPEpzyM+FgynrUqrkKL6Jm/KDryuEEELYmwR04qM9e/aMIkWK4OcH7u5Lefy4JlOnmoG1MBVeuHIFOnQw06q5c8OuXVCq1L8OeQ6MBkZrzUsgw5JzeHTfwheFU9FoawNSZEj4YZ23BHDt7ARenxlOzoA7ZLfANp0clxxdKFuwM4Ud5CMihBDi0ye/rcQH8/Pzw9nZGReX+BQuPJGNG0uSP3865s+H7NnDcAEfHxgxAgYPBicnGDXKbHwItNDOG5gIDAUeA5m2XKVAhw0UcnehxZwa5CiR9oP67u/9gHMHupLk9kLSqzfc8lcsdfMkW9ERVElb7oOuKYQQQkQWCejEBzl27Bh169alffuRTJlSjdOn69K5MwwZArHCMuu5fr0J3i5dMilIRo+GNO92i/oCMzDr5O4AmQ7fIXvrtWR77E3DweUp/X0uHBzCX3f1yd2dXD/YlWwvD5NHafb7xeJgqgaULjmSb+IkC/0CQgghxCdIAjoRLlprxo0bR/fu3XFzS8qPP8YjQQJYtw4qhyUN240bps7XkiWQJQts2ACVKv3/0wHAPKA/cBXI+M9jSrRcQ5oT9/m+bymqtyuMc6xw/re1+HPl1G/4nhtFdss9YllgKymJnaM7ZfO3x9HBMfRrCCGEEJ8wCehEmD18+JAmTZqwZs0akievzv37s6hSJTGzZkHy5KGc/OaNmVIdNMhsgPj1V1PzyzqcZwGWAj8B5wCPOy8o8cNakqy7TLW2ntRZWhv3ROFLDOz3+i5n93chxd0lZFS+XPdXLI1TjJzFRlE1dYkP+BcQQgghPk0S0IkwW7t2LRs3biJevHF4ebVj7FhF+/Zh2PiwYYOZXr14EWrWhDFjwMMDMPVW1wF9gWNAWi9vSnfbjPus45T9PhcNz7cJ94YHr9tbuHGoO9lfHSWfgr1+ruxP05iyJUfyTeyPTzIshBBCfGokoBMh8vf359SpU+TKVYBTpxri51eazJkzsmAB5M0bysnXr0PnzrBsmZleXb/e1GC12oYJ5PYCqV75Uv6XXcQeuY88pdLSZH9TshVJHfaOWvy4fHIEAed/I6vlIbEssFmlIW6unpTO01qmVYUQQkRrEtCJYF2/fp369etz7NhxMmW6xKlTKWjTJiMjR4KbWwgn+viYxMCDB5v7gwaZ8l3W6dX9mEBuC5DMN4BK4w/i2Gsr6TIlpMmy2hSpnhUVpnwn4PvqFuf3/0jKe8vJpPy44qdY4l6S3MVGUS1V0Y95+UIIIUSUIQGdCNLSpUtp1qwZPj4BWCxTuX07BcuXw9dfh3Li2rUmp9zly1Crltm9mi4dYKZU+wFrgMT+FqrOPUVA67UkjheLeuMq80XzAjg6ha3Cw6Nb67l1qCc5Xp8gr4Ldfm7sS9eYssWHUit2WDIZCyGEENGHBHTiXywWC23btmXKlCkkTOiJj88CKlTIxJ9/QuqQZkCvXIFOnWDVKsiWDTZuhIoVAbPJ4SdgMRDfovlqzUX8GyzH1d9CzR4lqNmlGG7uYch1EuDLpRPDsFwYR1b9iFgW2KjSET93H0rlaY6D+vByX0IIIURUJgGd+BcHBwfu3XMkbtyuPH8+iOHDXejSBRyCi5VevzYluoYNM8mBhw835btcXLgCDADmAG5aU3PXDQLqLUPfe8mXLQpSr38ZEqaIG2qf3ry4zvn9nUl9fzWZHfy45KdYGr8s+YqPoXryAjZ89UIIIUTUJAGdQGvNtGnTyJu3IKtWebJ8+XiyZFHMmweensGeZDY7dO5scsvVq2eCudSpuQUMBGYCTlpT4+R9HOovx/vMQ4rXzEbDwRVImz1JaJ3iwY1V3D3SmxzeZ8inYGdAHJ6lbkG54oP5xjW+bf8RhBBCiChMAroY7unTp7Rs2ZJFixaRNGkLHj70pFkzxW+/QdzgBs/Onzfr5DZtgjx5YPt2KFuW+8AQYApg0ZqvLj/BrfEKnuy5Rc6SaWmyp3Gopbq0vw+Xjg/G4eIEMuknxAqAdY4ZSJyvH6VyNpJpVSGEECIIEtDFYPv27aNu3brcunUbF5dh+Pp2ZdEi+PbbYE54/hwGDoTffoM4cWDcOGjTBi8nJ0YA44A3QLXbz0nUai0P1lwkea6ktF3+HUW/Cnnnqs/zy1zY35k0D9aRxcGfC34OLElQngLFx/B1sny2f/FCCCFENCIBXQy1c+dOKlSogKtrWgICdlOqVFH++gvSBjWApjXMmQPdu8O9e9CkCQwdyrNkyfgNGA28AKo+fk2aHzdx88+T4BGfzn98Rbn6eXB0DGZUTWvuX1vK/aP9yOFzjjzAjoC4vErblHLFfiVbLHd7vXwhhBAiWpGALoaxWCw4ODgQEFCCuHH78eJFJwYNik+PHuAYVO7do0dNlYe9e6FwYVixgldFijAeGA48ASq/eEPWn7Zz+beDPEviRosxlfiyTaFga65qv9f8c+wXXC5NIQPPcAmANU6ZSZa/P+Wy1w9zDjohhBBCGBLQxSDr1q2jR4+eVKy4id9+S0aGDP3ZuBGKFAni4EePoE8fmDYNkiSBGTPwbtyYKQ4ODAUeAJ97+5F/5D4u/LyTO27O1B9Qlq87Fw02BYn3swtc2NcZj0cbyeYQwDk/B5YkrIhnid+okSSnPV+6EEIIEa1JQBcD+Pr60qtXL0aPHo2bW15OnXpBo0bJGD8e3N+f1fT3hylToF8/ePECOnXiTf/+TI8fn8HAHaCMbwBNfj/ChW6buaihWvvCfN+nFPGTxvlv41pz7+oiHh7tR843/5AH2B4QD590zSlf7BdyuARxjhBCCCHCRQK6aO7ixYvUrVuXI0eO4OTUFmfnkcyf70qdOkEcvH272b166hR89hl+48bxR86cDARuACX8LTSZc5ILHTZw9pUfFRrlpV7/MiTzSPCfS2m/V1w40h/XK9NIz3NcAmCVU1ZSFBhAhWzfy7SqEEIIYUMS0EVzPXr8xMmTV4BllClTg9mzg9j4cP06dO0KixeDhwcBixcz95tvGKAUV4DCFk2T5Re40GoNxx+9pnjNbDT4tTzpcib9T3uvn5zln/2dyPB4K9kdAjjt68iSxFUoUnIMNRJli4BXLIQQQsQ8EtBFQy9evODFixccP56K3bvHA96MGpWWTp3eq/jw+jWMGAFDh4JSWH75haVdu9IvdmzOA/m1ZsDmq1xptorDN5+T77MMNBxcnmxF3qsBpjV3Ls3B6/gAcvheJjewLSABfhlaUb7wT+R2cYuw1y6EEELERBLQRTNHjx7l++/r8PJlcu7d20nu3EnYvBny5g10kNbw998mDcnNm+jvvmPDiBF0T5eOU0BOrfll701uNlvFwQteZC2Sik6zviL/Zxn+1Zb2e8n5Q31wuzYLD17gHAArnbOTutCvfJ75G5lWFUIIISKIBHTRhNaasWPH0q1bdyAZ/v6/8uOPikGDwNU10IFHjphaq3v2oAsUYN/cubQvXZqjQBat+eX4fe43X8WBo/fwyJ2UvkEkBX7ldZKL+zuT0Ws7ORwsnPB14kiS6hQtOYaaCTNF9EsXQgghYjwJ6KIBLy8vGjRoyNq1a1CqOilSzGLOnMRUqBDooLt3TRqS2bPRSZNyevp0WjZuzH5HRzJozYBzj3jScjUH9twiRcaEdJlTgzJ1cr1LCqw1ty/O5umJgeTwvUouYKslEZZMP1Deszf5nGNHxksXQgghBBLQRQu3brmwfftNYBzffdeOyZMVCRNan/TxgTFjYPBg9Js3XO/alRZ9+rA5fnzSAT9ffMyrH9ZxcPNVkqSJR7upVfm8cT6cnE2WYYvvM84f6oX79T9Jyyuc/GF5rFx4eA6hUsZqMq0qhBBCfAIkoIui/P39GTduPLFjt6J797g4OR1h7lwn6tWzHqA1LFkC3brBtWs8rFGD9iNG8HfmzKQB+l/24k279Rxaf5kEyePQcuwXVG5ZEBdX81/i5aOjXD7QmUxPd5NTWTjq68yhZDUpXmI03yRIH1kvWwghhBBBkIAuCrp+/Tq1a9fj0KG9QGLKlWvIH384kS6d9YAjR6BzZ9i1i5d58vDT5s2M+ewzUgH9rjzBr8N6Dq+5RPykbjQd+Tlfti6EaxwX0BZun5/Gs5O/ktP/Bjk0bA1IgsrWnvKePSno6BKJr1oIIYQQwZGALopZsmQJjRo15/XrABwd5zF8eN136Uju3IG+fWH2bHyTJGHC77/TrVkzkjs40OOfx1g6rOfohismkBvxOV+2MYGc5c0TzuxqR4Ibc0mtXuPgD0tc85Gx8BAqZ6gS2S9ZCCGEEKGQgC4KGTx4FH36dAUKkz37fBYuzESePJh8cqNGwbBhWPz8WNKlC8379iV2vHh0PPsI/7ZrOb3jBolSxqXZqIpUaVUQ1zguvHh4iPPbfiTzsz3kUprDfs4cSP4tJUuOpla897MPCyGEEOJTJQFdFLFvH/z++9eAF1269GfQIBdiOVtgzjzo1Qtu3WJXrVo0HjaMFxkz8r8T9wlovZh/DtwhmUd8fpj8JZ83zoeLi+LG+Sm8Oj2UHP63yGGBrTopjtk6Ub5QNzwdnSP7pQohhBAinCSg+4RprZkyZRqTJu3izJk/8fDIzM6dgyhdGti1C378EQ4f5p+CBWk+dy4XSpemxuG7+H87jevH75MmW2I6z/6KsvVyowKecP5gSxLeXEA65c0tf1gSuwBZigynisfnkf1ShRBCCPERJKD7RD158oQ6dVqyceNioCL/+99rJk6MQ7yHl9Hf9kAtWcKD1Knp+scfbK5Xnyp7b+GRbRK3L3qRIV9yei6sRfFvsvPy0X7OrCtFlhcHyKU0B/1cOJCyDqVKjKKWe6rIfplCCCGEsAEJ6D5Bu3fv5auv6vLkyR3c3Ibzxx9d+Lb8E3T/vlgmTuSNszODf/mFeZ07U3LXPUqlH8/92y/IXSYdHcd+QaFKHtw4N4mLiyuSPeAOWS2wVSfHJUcXyhfsTBEHeduFEEKI6ER+s39iLl/24fPPa/PmjSslS+5h8V95SL5wBH7Nh+Dw4gUzmzZlcr/+ZDvwnDzpJuP1xIfC1bLw3cJaZCngwvkD3bi/YCEe6g03/GGxmyfZigynarrykf3ShBBCCGEnEtB9Ih48eMCWLYlp29YVpVby26gMtE+0Cp+y36Ju3mR9tWqMGTiIxEcDSJn9L177WShbLzffdCtOgsTnuH7wG/yXHiG30uzzi8W+1A0oU3wE38ZNHtkvTQghhBB2JgHdJ2DhwrU0bNiIN286U7RILxY1u4f7+MY4nD7NGU9PRkydgc85d1wLr0LHcqRGq0J83akQr57NxPd0KxJY7uNigU06FW65ulE2fzucZFpVCCGEiDHkt34kevPmDfXr92LJkjFAXn6pnZEW98uTotUOLmXKRO9Zc7hyJTUO1XaTKLEb1X8uwxdN0nDzfG/YXZ0MypdrfoolcYuRs9hIqqcuGdkvSQghhBCRQAK6SHLq1EU+/7wODx4cJV38eiz3fEGBRXW5nywZPw0Zxf5rmXFudpJ0mZ5Sc2IVClV6xN0TnXDddpQ8Cvb4ubI3TRPKlhhOLbckkf1yhBBCCBGJJKCLBMeOwTffPOLRgxv0zV2Bn88u4NXBOIz6sTfrr+fEpdcV8pfyotaSGiTxWEXAhS9Jtu8BbhbYSBri5upB2bxtcHRwjOyXIoQQQohPQLQK6JRSlYGxgCMwXWs9NJK79C9Pn76gdevV7FtXhn7Z/uLbW09xvbiH6fVasORmfmJP8KJSrdhU2/kF/r4jSXGvFUnP+XLZT7HYvSR5io3iq1RFI/tlCCGEEOITE20COqWUIzARqAjcAg4ppVZqrc9Gbs+MFSuOUK9ubXy8r3HSxZmsxyzMrfIdSx8WJtWRWLRtWYCCk+7y5EJ/Mt44SSwFO/3c2JOuIeWLD+fb2Akj+yUIIYQQ4hMVbQI6oAhwSWt9BUAptQD4GojUgM5i0dSp1Z+lKwaRXFuYoxQnS1fj15clKJY0K8N65MTZdQ7qn6qkPf6Y+AGw3iEdCXL3oXSe5jgoh8jsvhBCCCGigOgU0KUGbga6fwuI1PnJFXMnMqFTVzY/8qE60LtoXF5+4YpHut30dd2Bm/Il8bXXxFMB/OPnwKJ4ZShQYgxfJy8Ymd0WQgghRBQTnQK6MFFKtQRaAqRLl86ubT0/tIm6Xj5UzwaNW4F3kle80d68xJGXAc48wJkzDsmwpKpJueKDyOqawK79EUIIIUT0FJ0CuttA2kD301gf+xet9VRgKoCnp6e2Z4dqD5nHsZo3KV42GwDx7NmYEEIIIWKs6LRA6xCQRSmVQSnlAtQBVkZmh1xju/1/MCeEEEIIYS/RZoROa+2vlGoHbMCkLZmptT4Tyd0SQgghhLC7aBPQAWit1wJrI7sfQgghhBARKTpNuQohhBBCxEgS0AkhhBBCRHES0AkhhBBCRHES0AkhhBBCRHES0AkhhBBCRHES0AkhhBBCRHES0AkhhBBCRHES0AkhhBBCRHES0AkhhBBCRHES0AkhhBBCRHES0AkhhBBCRHES0AkhhBBCRHES0AkhhBBCRHES0AkhhBBCRHFKax3ZfYg0SqmHwHU7N5MEeGTnNkT4yfvy6ZH35NMk78unR96TT1NEvC8eWuukQT0RowO6iKCUOqy19ozsfoh/k/fl0yPvyadJ3pdPj7wnn6bIfl9kylUIIYQQIoqTgE4IIYQQIoqTgM7+pkZ2B0SQ5H359Mh78mmS9+XTI+/JpylS3xdZQyeEEEIIEcXJCJ0QQgghRBQnAZ0dKaUqK6UuKKUuKaV6RnZ/YiKlVFql1Dal1Fml1BmlVEfr44mUUpuUUhettwkju68xkVLKUSl1TCm12no/g1LqgPUz87dSyiWy+xiTKKUSKKUWK6XOK6XOKaWKy2cl8imlOlt/fp1WSs1XSrnKZyViKaVmKqUeKKVOB3osyM+GMsZZ35uTSqmCEdFHCejsRCnlCEwEqgA5gbpKqZyR26sYyR/oorXOCRQD2lrfh57AFq11FmCL9b6IeB2Bc4HuDwPGaK0zA0+AZpHSq5hrLLBea50dyId5b+SzEomUUqmBDoCn1jo34AjUQT4rEW02UPm9x4L7bFQBsli/WgKTI6KDEtDZTxHgktb6itbaF1gAfB3JfYpxtNZ3tdZHrd+/wPyCSo15L/6wHvYHUCNSOhiDKaXSAFWB6db7CqgALLYeIu9LBFJKxQfKADMAtNa+WuunyGflU+AExFZKOQFuwF3ksxKhtNY7Aa/3Hg7us/E18Kc29gMJlFIp7d1HCejsJzVwM9D9W9bHRCRRSqUHCgAHgORa67vWp+4BySOrXzHYb0B3wGK9nxh4qrX2t96Xz0zEygA8BGZZp8GnK6XiIJ+VSKW1vg2MBG5gArlnwBHks/IpCO6zESm//yWgEzGCUiousATopLV+Hvg5bbZ6y3bvCKSUqgY80Fofiey+iP/nBBQEJmutCwCveG96VT4rEc+6LutrTMCdCojDf6f+RCT7FD4bEtDZz20gbaD7aayPiQimlHLGBHNztdZLrQ/ffzsEbr19EFn9i6FKAl8ppa5hliNUwKzfSmCdVgL5zES0W8AtrfUB6/3FmABPPiuR63Pgqtb6odbaD1iK+fzIZyXyBffZiJTf/xLQ2c8hIIt1J5ILZhHrykjuU4xjXZc1AzintR4d6KmVQCPr942AFRHdt5hMa91La51Ga50e89nYqrWuD2wDvrUeJu9LBNJa3wNuKqWyWR/6DDiLfFYi2w2gmFLKzfrz7O37Ip+VyBfcZ2Ml0NC627UY8CzQ1KzdSGJhO1JKfYlZJ+QIzNRaD4rcHsU8SqlSwC7gFO/WavXGrKNbCKQDrgPfaa3fX/AqIoBSqhzQVWtdTSmVETNilwg4BvxPa/0mErsXoyil8mM2qbgAV4AmmD/85bMSiZRSA4DvMbv2jwHNMWuy5LMSQZRS84FyQBLgPtAfWE4Qnw1r4D0BMzX+GmiitT5s9z5KQCeEEEIIEbXJlKsQQgghRBQnAZ0QQgghRBQnAZ0QQgghRBQnAZ0QQgghRBQnAZ0QQgghRBQnAZ0Q0ZRSqq5S6qhSykcpdV8pNU0plTSUc9IopV4qpR5YM9RHKqVULKVUH6XUCaXUK6WUtn51iqD2G79tM5jn3/ansZ3aTx+ojXKRfR0hxKfLKfRDhBBRjVKqHTA+0EPJMLmrSimlCmutXwZz6ihMaaGOWusndu5mWCxAio4LIUSoZIROiGhGKZUYGG69OwJID5THFIvOznv1OQOdVx74DjgIzLR7R0OhlMrOu2BuAuZ1uFu/JkZOr4QQ4tMkAZ0Q0c/XQGxgv9a6u9b6utZ6O9DG+vz/3j/BWhNyPKaaRjv9aWQczxPo+77W1/HS+uUXab2KgrTW17TWyvq1PbL7I4SwPQnohIh+3gZCa957fB2mdJCHUsr9vefaA7kwJeoO2bl/YeX29hut9bPI7IgQQnzqJKATIvp5G6w9CPyg1toCPLLejff2caVUCuBn4AnQy9adUUoVVErNVkpds27QeKqUOqiU6qWUihPE8bOtmxBmB3pMB/raHs728yql+iqldiqlHiql/JRST5RSB6yPJ/jY1/gxlFIFlFILrRtXvJVSl5RSo5VSycJw7v9vylBKOSmlOln/bZ9YH69hPS7ITRFKqaqBHs8TTDNvj60S6Ni8QTzvrJRqqZTaZH0tvtbbVUqpr0K47s/Wa16z3s+nlPpTKXXDeo3j7x3/lVJqhVLqtvX559Z/s01Kqe5KqbSh/bsJER3Jpgghop8X1tskgR+0FoxO/N4xYNbbxQPaaq0fYUNKqV7AIEAFejgWUNj61Vop9YXW+rwt2w3Ufj7geBBPJQCKWL+aKaUqaa0v2qMPIVFK1ccEroF/FmcCOmPWMzYK46VcgW1AqXB2YQMmyE8C1CPkgL6+9fa01vpk4CeUUumB1ZhR3sCSAdWAakqpv4CmWmv/4BpQStUC5mL+jwT1/O9Ay/cedsb8EZMJ+BzwBX4L4XUIES3JCJ0Q0c9p622l9x7/DPPL74bW+jmAUqoEZk3dcWCKLTuhlGoADMYEc0eAyphf8JkwGzO8gXTABqVU/ECntsL8gm4d6DH3QF9VwtENDWwG2mGCnUyY4CUP0AG4gdlsscAa8EYYa7A5GxPM3QDqACkAD8wUuDswPYyX6wsUw/x758K8xuK8+78QJGtwtdB6t05w/wZKKTfebVCZ+95z8YGt1nZvYdZqZgESAbkxfzAEAA2AgSF0JyHm3+M88BWQHPP/o5e1nYq8C+YWAKWB1NZ2smMC0r8xAZ0QMY/WWr7kS76i0Rfml7k3Jpjpg/mFVxD4x/rYMOtxDsBRzEaIkjbugyvw0NreMcAtiGO+tD6vgaFBPN/47fN2/LdKAXhZ2/k8vH0I1P/GH9D2euu5TwCPIJ4vjQmE3rZRLoT2NdAkhLbSB3cdoESg54L8fwDUtT5vAdK999wE63OXgWTBnN/MeowvkPq9534O1P4ZIG4w1xhtPeaIvf4/yJd8ReUvGaETIprRZtr0bWqSX4HHmBGyLMAlzCgOmBGwAsAcrfUeAKWUu1KqvVJqplJqslKq9geOXFXn3ZRvN6316yD6uRZYab3bNKJHyKx9uIcZwQMzghkhlFIpgYrWu2O01teD6NsuYHEYL3laaz3rQ/qitd4LXLXerRfMYW+nW3drrW+8fVApFRdoYr3bU2v94D9nGjMxAZ8zUDuE7vykg8+R6Gi9vRvC+ULEWBLQCRENaa3HYqa4TgBvMKNls4BSWutnSqkkmGDvOdAdQCmVATgFjMP8km6NmY5bq5QKck1TCN6u5XoKbAnhuEXW26RAtnC2ESZKKQdlqmYsty609w68yYJ3AUZWe7QfjGK8+/m7PITjloXxeus+qjcwz3r7nTWFzf9TJq/h2+n7f023YqZ13+5G3qWUihvUFyZZ9QnrcZ7B9EFj1vQF57j1topSqkNQG2qEiMkkoBMimtJaz9Fa59dau2qtk2mtm2qt71ufHoJZs/SzdZQK4C/M+q3JmKnI7Jgkw5WB3uFs3sN6e15rHVJOuzOBvk8XzjZCpUx6lm2YgOVrIC1mOjgo8YN53B7SB/o+pA0hYd0scjX0Q0L0NlBLwn/XXn6HGVnz410A/lbgIPwuZrNNcF/fWI8LrvzcwxBG5wDmYJYIOABjgUdKqS1Kqf5KqbJKKccQzhUi2pOATogYRinlCTTFBFPjrY/lB0piAoN2Wuv7WusLmFE+DbRVSoXn50Vc621Iv6Dh37tt38+NZwtjgDKY1zAdE5xmwKwrfLvJ4u3oVETu+n87uuSvtQ5pEX9o/35veX9MZ7TW5zBrHeG/065v76/TWnu999yHBMHBjfaG+Bq0SSZdHhiKScnjClTArMHbDtyyjtxF+NS9EJ8CCeiEiEGsv+wmYj777fW7FBJFrbebtclXB4DW+h/gCibdSZZwNPU2EIkb4lH/fv5FsEd9AOuU3NuqGEO01i201hu0qZrwRFurTvAuuIpIr6y3TkoplxCOC+3fz5bejtJ9bd3VilLKAxPoB34+sLfvswYc9btqFCF9lfvQDmqtn2ute2FGkPMDP2BGDV9ZHxsLDPvQ6wsRlUlAJ0TM0hSTe22h1npboMffbmAIKg/dQ+tt4iCeC8416232UEZMAuct+8/GgI+UjXejQQtDOC63jdsNi2uBvs8ewnEhPWdr8zG7WONi0oaA2d2qMMH2qiDOuWK9VZiRzwihjRNa68la6+8wU+k7rU93UkrFC+F0IaIlCeiEiCGUqYgwBDOa0eW9p99OdwVVnSDZe8eExW7rbQLMtFhwvrXePsSkVbGlwFN7Qa6vUkoVweSmi2j7MaNa8C6/W1BCes6mtNZ3MFOX8G5X69vbpVrroN7/nbzL+/ad/XoXMq31E8z0Opj1fpHxngoRqSSgEyLm+BWzIP1XrfWt9547Z72tFHhxuVIqJ5ARkw8tPAHXKt6N7A1XSsV+/wCl1Be8C1hmhrJ54kNcC/R99SDadwMm2bjNMNFa3wU2Wu92tk5t/otSqjQhp/iwh7fTql9YS4Tlfu/xf9Gmxu4M693eSqlCIV1cKZVMKZXwQzqmlAptF3TgIO7xh7QhRFQmAZ0QMYC1KkFrTFA2OohDtmKmW9MCM5VSmZRSBTE7CwFWa61fBXFekLTWb3g3ClgQ2K6UqqSUSqKUyqCU6gYstT5/AzNyaFPWoOntSGFvpVRvpVRmpVRSpdSX1ucKABds3XYY9QT8MaOYO5VS3ymlkiul0iql2mFKad0I6QJ2sAST5saZd7V072H+fwSnN3ARM1W7Syk1VClVxPpeJ1ZK5VRK1VdKLcBMq3/o6NnvSqlT1vextFIqpVIqkfX6b0vMAewLnCtPiJhCarkKETOMx0w7dgxqV6XW+o01iJgPNLR+veUFdA1vg1rrv5RSaTC/aIsQdI6xG0Bl60iPPbQBdmGCpkG8+6UPZsqzK5AXO+XAC4nW+rhSqjEmcEqHKVsV2B2gOe8SH0dEn54ppVYDtXiXemaB1joghHOeKqXKY4LBokAP61dw/D6ii7n593v4viuYndlCxDgyQidENKeU+h+mjNQKrfX64I7TWv+NKaS+D7Ne7hkmsW1xrfWlD2lbaz0EKAz8iRmdeYNJZnwYM7KTy5oywy601qcxiWz/wow0+WHypS0HKmitgxqtjDBa67mYYHcxZor6DSZ1zHigEKa6QkR7f3p1XpBHBaK1vo0pIVYbE9jdwryWN8BtYBPm/c6qtT4R3HVC0QhT53cRJuWOF2aE8zFmLV8XII/WOjL+zYSIdMr2y1aEEEIIIUREkhE6IYQQQogoTgI6IYQQQogoTgI6IYQQQogoTgI6IYQQQogoTgI6IYQQQogoTgI6IYQQQogoTgI6IYQQQogoTgI6IYQQQogoTgI6IYQQQogoTgI6IYQQQogoTgI6IYQQQogoTgI6IYQQQogo7v8AeYv6x2/B6DAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 720x540 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lorenz(income_arrs, Name_dis_types, colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Drivers: 143\n",
      "[[-23.03980709 -44.56499007]\n",
      " [-22.97110173 -44.15136083]\n",
      " [-23.11457499 -43.63275613]\n",
      " [-23.10672966 -43.4961244 ]\n",
      " [-22.99711814 -43.37293644]\n",
      " [-22.9308963  -43.16175514]\n",
      " [-22.99594437 -43.62901378]\n",
      " [-23.01409233 -43.34761958]\n",
      " [-22.96332301 -43.54994278]\n",
      " [-23.13263235 -43.3865159 ]\n",
      " [-23.0432008  -43.29690434]\n",
      " [-23.15818232 -43.23798838]\n",
      " [-23.11837731 -43.5995675 ]\n",
      " [-22.97663138 -43.41912026]\n",
      " [-23.08612972 -43.53252282]\n",
      " [-23.12048891 -43.25934469]\n",
      " [-23.16500932 -43.15365819]\n",
      " [-22.90099052 -43.6499407 ]\n",
      " [-23.18466186 -43.34905164]\n",
      " [-23.08083795 -43.55214076]\n",
      " [-22.93498729 -43.21474139]\n",
      " [-23.10702652 -43.58572956]\n",
      " [-22.94270977 -43.38260423]\n",
      " [-23.160897   -43.36409792]\n",
      " [-23.16583617 -43.39294468]\n",
      " [-23.00212926 -43.51305416]\n",
      " [-22.99177703 -43.48920429]\n",
      " [-23.12073428 -43.60720778]\n",
      " [-23.02080998 -43.42422763]\n",
      " [-23.06050526 -43.47691236]\n",
      " [-22.99810127 -43.59577022]\n",
      " [-23.00635999 -43.33218164]\n",
      " [-23.02392354 -43.37735226]\n",
      " [-23.155843   -43.49252633]\n",
      " [-23.05020183 -43.24994847]\n",
      " [-23.18845746 -43.66255635]\n",
      " [-23.07202832 -43.18113314]\n",
      " [-23.22106869 -43.42428765]\n",
      " [-23.07371372 -43.54587519]\n",
      " [-23.12982238 -43.35041199]\n",
      " [-23.08970335 -43.28024039]\n",
      " [-22.93399363 -43.56957414]\n",
      " [-23.20056483 -43.43846664]\n",
      " [-22.95006221 -43.62198045]\n",
      " [-23.08327796 -43.46265937]\n",
      " [-23.16634532 -43.39459158]\n",
      " [-23.22303907 -43.43912707]\n",
      " [-22.97687997 -43.24242137]\n",
      " [-22.91317145 -43.64011708]\n",
      " [-23.07113531 -43.22881698]\n",
      " [-23.04012305 -43.5878747 ]\n",
      " [-23.22060278 -43.25202962]\n",
      " [-23.02617217 -43.19982177]\n",
      " [-22.96289365 -43.3856091 ]\n",
      " [-22.99137679 -43.65848635]\n",
      " [-22.94397551 -43.46279498]\n",
      " [-23.09937209 -43.57242931]\n",
      " [-23.01085796 -43.166614  ]\n",
      " [-22.9479295  -43.22245296]\n",
      " [-23.06835181 -43.37533177]\n",
      " [-23.02396515 -43.24011441]\n",
      " [-23.19992701 -43.20241995]\n",
      " [-23.04721094 -43.50692487]\n",
      " [-22.96156987 -43.53413714]\n",
      " [-23.01572522 -43.47464473]\n",
      " [-23.03506976 -43.3032435 ]\n",
      " [-23.18133356 -43.16365176]\n",
      " [-23.16927121 -42.7065641 ]\n",
      " [-22.93970314 -42.71847228]\n",
      " [-23.06767381 -43.00909986]\n",
      " [-23.02132802 -43.06899497]\n",
      " [-23.21675216 -42.69091288]\n",
      " [-22.71784806 -44.05988815]\n",
      " [-22.67170072 -43.64327976]\n",
      " [-22.69467217 -43.28697048]\n",
      " [-22.73604717 -43.56344326]\n",
      " [-22.76583301 -43.53076013]\n",
      " [-22.83179755 -43.54903475]\n",
      " [-22.79944558 -43.46538612]\n",
      " [-22.59945322 -43.1669975 ]\n",
      " [-22.76156459 -43.57802426]\n",
      " [-22.84405558 -43.31592739]\n",
      " [-22.87175318 -43.39512848]\n",
      " [-22.74312135 -43.35895395]\n",
      " [-22.81810775 -43.51359235]\n",
      " [-22.60436773 -43.47919078]\n",
      " [-22.60253956 -43.38109188]\n",
      " [-22.66973217 -43.44775656]\n",
      " [-22.59993432 -43.19831677]\n",
      " [-22.66943032 -43.21161484]\n",
      " [-22.57216204 -43.59932004]\n",
      " [-22.57761027 -43.28033095]\n",
      " [-22.60542062 -43.20412173]\n",
      " [-22.7886686  -43.37771174]\n",
      " [-22.67877967 -43.35755561]\n",
      " [-22.60251664 -43.474537  ]\n",
      " [-22.85168325 -43.39805857]\n",
      " [-22.74221516 -43.53872571]\n",
      " [-22.68193055 -43.18939774]\n",
      " [-22.76473718 -43.31804562]\n",
      " [-22.69161928 -43.24624391]\n",
      " [-22.6586339  -43.4832505 ]\n",
      " [-22.85901734 -43.37922749]\n",
      " [-22.64792673 -43.46280865]\n",
      " [-22.82204107 -43.35087608]\n",
      " [-22.76442321 -43.50613184]\n",
      " [-22.77144939 -43.54080529]\n",
      " [-22.71277307 -43.56590295]\n",
      " [-22.57415603 -43.61321704]\n",
      " [-22.70188965 -43.4473657 ]\n",
      " [-22.58695552 -43.5867932 ]\n",
      " [-22.65940001 -43.33402686]\n",
      " [-22.66392764 -43.19680872]\n",
      " [-22.66864008 -43.33900369]\n",
      " [-22.65606935 -43.38781219]\n",
      " [-22.88316498 -43.35454809]\n",
      " [-22.82505632 -43.30128007]\n",
      " [-22.6479126  -42.83955361]\n",
      " [-22.73517498 -42.92908955]\n",
      " [-22.78123748 -42.65709036]\n",
      " [-22.7094467  -42.83962078]\n",
      " [-22.71584782 -43.09080302]\n",
      " [-22.89180814 -42.9775117 ]\n",
      " [-22.58468045 -43.13343597]\n",
      " [-22.58088276 -42.78121066]\n",
      " [-22.64818699 -42.56587693]\n",
      " [-22.88954148 -42.08452684]\n",
      " [-22.57277064 -41.76362443]\n",
      " [-22.30471534 -44.376698  ]\n",
      " [-22.3833403  -44.57977832]\n",
      " [-22.43662788 -43.96883514]\n",
      " [-22.53987396 -43.92672681]\n",
      " [-22.26676638 -43.71653702]\n",
      " [-22.56538359 -43.48324503]\n",
      " [-22.42645799 -42.7095397 ]\n",
      " [-22.35505907 -42.91412869]\n",
      " [-22.50797231 -42.85454161]\n",
      " [-22.54665361 -41.94321932]\n",
      " [-22.32655397 -41.8471651 ]\n",
      " [-22.42574872 -41.94333777]\n",
      " [-22.38139972 -41.76863545]\n",
      " [-21.69315171 -41.26474698]\n",
      " [-20.96643065 -41.77956808]]\n",
      "[0.         0.41929652 0.93522744 1.07095866 1.19281775 1.40745509\n",
      " 0.9370035  1.21764205 1.01792476 1.18212432 1.26809027 1.33227106\n",
      " 0.96861449 1.14761004 1.03350588 1.30813585 1.41687447 0.92551898\n",
      " 1.22453631 1.01368006 1.35431115 0.98156487 1.18636595 1.20698165\n",
      " 1.17880181 1.05261045 1.07685743 0.96119515 1.14092061 1.08827456\n",
      " 0.97011674 1.23326207 1.18774402 1.07872277 1.31508268 0.91459474\n",
      " 1.384232   1.15501419 1.01967877 1.21790913 1.28571823 1.00102415\n",
      " 1.13793589 0.94727044 1.10318751 1.17721899 1.14067588 1.32406487\n",
      " 0.93350234 1.33654031 0.97711542 1.32534985 1.36523639 1.18188627\n",
      " 0.9077965  1.10635333 0.99434645 1.39867569 1.34567729 1.1900007\n",
      " 1.32497036 1.37194596 1.0580911  1.0338176  1.09061124 1.26175546\n",
      " 1.40846682 1.86292996 1.84922923 1.55613974 1.49610922 1.88241198\n",
      " 0.59898712 0.99249796 1.32380217 1.04659739 1.06990344 1.03703095\n",
      " 1.12556764 1.46570623 1.02543668 1.2643086  1.18187066 1.24199258\n",
      " 1.07451745 1.16985791 1.26206886 1.17693082 1.43571723 1.40314058\n",
      " 1.07294478 1.36527468 1.4285147  1.21354867 1.26025346 1.17486631\n",
      " 1.18199819 1.06854083 1.42138308 1.27692362 1.36393775 1.14693221\n",
      " 1.19946564 1.16977524 1.23348888 1.09408274 1.05875886 1.05124988\n",
      " 1.05957672 1.16759258 1.0779349  1.2884021  1.41887475 1.28094011\n",
      " 1.23814475 1.22053535 1.28182715 1.76938188 1.66402261 1.92534141\n",
      " 1.75671203 1.50936314 1.59436234 1.50216091 1.84186876 2.03711061\n",
      " 2.48501058 2.84003037 0.75882395 0.65663334 0.84807185 0.81074849\n",
      " 1.14780857 1.18120701 1.95419886 1.78723897 1.79122365 2.66774853\n",
      " 2.8098581  2.69260626 2.87282081 3.56441933 3.47238614]\n",
      "[0.         0.41929652 0.93522744 1.07095866 1.19281775 1.40745509\n",
      " 0.9370035  1.21764205 1.01792476 1.18212432 1.26809027 1.33227106\n",
      " 0.96861449 1.14761004 1.03350588 1.30813585 1.41687447 0.92551898\n",
      " 1.22453631 1.01368006 1.35431115 0.98156487 1.18636595 1.20698165\n",
      " 1.17880181 1.05261045 1.07685743 0.96119515 1.14092061 1.08827456\n",
      " 0.97011674 1.23326207 1.18774402 1.07872277 1.31508268 0.91459474\n",
      " 1.384232   1.15501419 1.01967877 1.21790913 1.28571823 1.00102415\n",
      " 1.13793589 0.94727044 1.10318751 1.17721899 1.14067588 1.32406487\n",
      " 0.93350234 1.33654031 0.97711542 1.32534985 1.36523639 1.18188627\n",
      " 0.9077965  1.10635333 0.99434645 1.39867569 1.34567729 1.1900007\n",
      " 1.32497036 1.37194596 1.0580911  1.0338176  1.09061124 1.26175546\n",
      " 1.40846682 1.86292996 1.84922923 1.55613974 1.49610922 1.88241198\n",
      " 0.59898712 0.99249796 1.32380217 1.04659739 1.06990344 1.03703095\n",
      " 1.12556764 1.46570623 1.02543668 1.2643086  1.18187066 1.24199258\n",
      " 1.07451745 1.16985791 1.26206886 1.17693082 1.43571723 1.40314058\n",
      " 1.07294478 1.36527468 1.4285147  1.21354867 1.26025346 1.17486631\n",
      " 1.18199819 1.06854083 1.42138308 1.27692362 1.36393775 1.14693221\n",
      " 1.19946564 1.16977524 1.23348888 1.09408274 1.05875886 1.05124988\n",
      " 1.05957672 1.16759258 1.0779349  1.2884021  1.41887475 1.28094011\n",
      " 1.23814475 1.22053535 1.28182715 1.76938188 1.66402261 1.92534141\n",
      " 1.75671203 1.50936314 1.59436234 1.50216091 1.84186876 2.03711061\n",
      " 2.48501058 2.84003037 0.75882395 0.65663334 0.84807185 0.81074849\n",
      " 1.14780857 1.18120701 1.95419886 1.78723897 1.79122365 2.66774853\n",
      " 2.8098581  2.69260626 2.87282081 3.56441933 3.47238614]\n"
     ]
    }
   ],
   "source": [
    "new_drivers = driver_generation(random_seed) \n",
    "print(new_drivers)\n",
    "\n",
    "def L2Distance(data):\n",
    "\n",
    "  transposed = np.expand_dims(data, axis = 1)\n",
    "  distance = np.power(data - transposed, 2)\n",
    "  distance = np.power(np.abs(distance).sum(axis = 2), 0.5) \n",
    "#   distance = distance*110\n",
    "\n",
    "  return distance\n",
    "\n",
    "dist_matrix = L2Distance(new_drivers)\n",
    "print(dist_matrix[0])\n",
    "print(dist_matrix[:][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean Distance: 0.41929652356739866\n",
      "Haversine Distance: 43.01927724582306\n",
      "Euclidean Distance multiplied by 110: 46.12261759241385\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "pt1 = [-23.03980709, -44.56499007]\n",
    "pt2 = [-22.97110173, -44.15136083]\n",
    "\n",
    "# Euclidean distance between pt1 and pt2\n",
    "dx = pt1[0] - pt2[0]\n",
    "dy = pt1[1] - pt2[1]\n",
    "\n",
    "e_dist = np.sqrt(dx**2 + dy**2)\n",
    "print(\"Euclidean Distance:\", e_dist)\n",
    "\n",
    "# Haversine distance \n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    p = np.pi/180\n",
    "    a = 0.5 - np.cos((lat2-lat1)*p)/2 + np.cos(lat1*p) * np.cos(lat2*p) * (1-np.cos((lon2-lon1)*p))/2\n",
    "    return 12742 * np.arcsin(np.sqrt(a))\n",
    "\n",
    "h_dist = haversine_distance(pt1[0], pt1[1], pt2[0], pt2[1])\n",
    "print(\"Haversine Distance:\", h_dist)\n",
    "\n",
    "print(\"Euclidean Distance multiplied by 110:\", e_dist*110)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the FFCs to which each driver gets assigned over the span of 30 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(driver_ffc_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ffc_index</th>\n",
       "      <th>driver_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ffc_index  driver_index\n",
       "0          6             0\n",
       "1          6             1\n",
       "2          3             2\n",
       "3          1             3\n",
       "4          6             4"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_cols = ['ffc_index', 'driver_index']\n",
    "driver_ffc_maps[0][relevant_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = [x[relevant_cols] for x in driver_ffc_maps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import reduce\n",
    "# df_merged = reduce(lambda left, right: pd.merge(left, right, on=['driver_index']), data_frames).fillna('void')\n",
    "df_merged = pd.concat(data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_ = pd.concat(data_frames)\n",
    "final_gb = final_.groupby('driver_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([6, 1, 0, 3, 0, 3, 1, 3, 6, 6, 6, 6, 6, 0, 0, 1, 1, 1, 6, 3, 0, 0,\n",
      "       0, 1, 1, 1, 1, 0, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 6, 0, 6, 0, 3,\n",
      "       1, 6, 6, 3, 0, 3, 0, 6, 6, 0, 6, 0, 6, 0, 6, 6, 6, 0, 6, 0, 0, 0,\n",
      "       0, 1, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 6, 3, 0, 6, 6, 1, 6, 1, 1,\n",
      "       0, 6, 0, 3, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 0, 6, 0, 6, 6, 6, 0, 3, 6, 6, 6, 6, 6, 3, 6, 0, 6, 1, 6,\n",
      "       6, 1, 0, 1, 1, 3, 6, 1, 6, 6, 6, 1, 3, 0, 1, 1, 1, 0, 0, 6, 3, 1,\n",
      "       1, 6, 0, 1, 0, 6, 3, 3, 1, 6, 6, 3, 3, 6, 6, 6, 0, 3, 0, 3, 1, 6,\n",
      "       3, 1, 6, 6, 6, 6, 0, 0, 6, 1, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 3, 6, 1, 3, 6, 1, 6, 6, 6, 6, 1, 6, 3, 6, 1, 6, 6, 6, 1, 0, 6,\n",
      "       6, 6, 0, 6, 6, 3, 3, 1, 1, 6, 1, 6, 0, 3, 6, 3, 6, 0, 6, 1, 6, 6,\n",
      "       3, 6, 6, 1, 6, 0, 0, 9, 1, 6, 1, 6, 6, 1, 6, 6, 0, 1, 1, 0, 6, 6,\n",
      "       9, 6, 3, 6, 0, 6, 3, 6, 1, 0, 6, 6, 6, 1]), array([6, 0, 1, 0, 6, 1, 6, 6, 1, 0, 1, 6, 6, 6, 1, 0, 6, 6, 1, 6, 6, 1,\n",
      "       1, 6, 0, 6, 6, 6, 6, 1, 6, 6, 0, 6, 1, 1, 0, 6, 6, 6, 0, 6, 1, 1,\n",
      "       1, 6, 6, 1, 6, 6, 6, 6, 6, 3, 0, 0, 1, 6, 1, 6, 6, 1, 1, 6, 1, 1,\n",
      "       3, 6, 6, 6, 1, 6, 1, 1, 6, 6, 1, 6, 6, 6, 6, 0, 6, 6, 6, 6, 1, 6,\n",
      "       3, 6, 1, 3, 6, 6, 6, 0, 0, 0, 6, 6, 1, 1, 6, 6, 6, 1, 6, 0, 0, 6,\n",
      "       6, 9, 6, 6, 6, 6, 6, 6, 0, 1, 0, 0, 6, 1, 1, 0, 6, 6, 1, 6, 3, 6,\n",
      "       6, 3, 0, 3, 6, 3, 0, 6, 3, 6, 1, 3, 6, 6, 0, 6, 1, 6, 6, 1, 6, 1,\n",
      "       3, 3, 6, 6, 6, 6, 1, 6, 1, 6, 1, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 6,\n",
      "       6, 1, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 1, 6, 3, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 1, 6, 1, 1, 1, 3, 6, 1, 1, 6, 6, 6, 3, 3, 6, 1, 1, 6, 1,\n",
      "       1, 1, 3, 6, 6, 6, 9, 6, 6, 3, 3, 6, 6, 6, 9, 6, 3, 6, 9, 6, 6, 1,\n",
      "       0, 1, 3, 3, 3, 1, 1, 3, 6, 6, 0, 3, 6, 1, 1, 1, 0, 6, 1, 0, 1, 6,\n",
      "       6, 1, 6, 3, 1, 6, 3, 7, 6, 0, 6, 1, 1, 6, 9, 1, 6, 6, 6, 6, 1, 7,\n",
      "       6, 1, 1, 1, 6, 1, 6, 1, 6, 6, 1, 1, 1, 6]), array([3, 6, 6, 6, 6, 6, 0, 1, 6, 1, 6, 1, 1, 1, 3, 6, 6, 6, 6, 1, 1, 1,\n",
      "       6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 1, 1, 6, 6, 1, 3, 6, 1, 6, 1, 3, 6,\n",
      "       6, 1, 1, 6, 6, 3, 1, 3, 1, 6, 6, 1, 6, 1, 3, 6, 1, 6, 3, 3, 6, 6,\n",
      "       7, 3, 1, 1, 6, 6, 6, 6, 6, 1, 3, 6, 9, 6, 1, 1, 1, 1, 1, 1, 6, 9,\n",
      "       6, 6, 6, 1, 1, 6, 1, 6, 1, 1, 1, 3, 6, 3, 1, 1, 6, 6, 6, 6, 1, 9,\n",
      "       3, 6, 1, 1, 6, 9, 6, 1, 6, 6, 3, 6, 6, 3, 6, 1, 6, 6, 0, 3, 6, 6,\n",
      "       6, 6, 3, 1, 6, 6, 6, 1, 6, 6, 6, 0, 6, 3, 6, 6, 0, 1, 6, 1, 6, 6,\n",
      "       6, 6, 1, 1, 1, 1, 6, 1, 1, 1, 3, 1, 1, 6, 6, 6, 6, 1, 6, 1, 6, 1,\n",
      "       1, 1, 3, 6, 9, 1, 6, 6, 6, 6, 3, 6, 6, 3, 6, 1, 6, 6, 1, 1, 6, 1,\n",
      "       1, 6, 3, 7, 7, 3, 6, 6, 6, 6, 7, 3, 1, 6, 6, 9, 9, 1, 3, 3, 1, 3,\n",
      "       3, 6, 9, 6, 1, 6, 3, 1, 1, 6, 7, 6, 1, 1, 6, 6, 1, 1, 1, 6, 1, 3,\n",
      "       1, 3, 1, 1, 1, 6, 6, 6, 6, 1, 6, 6, 6, 6, 3, 6, 6, 1, 6, 6, 6, 3,\n",
      "       1, 3, 3, 1, 3, 6, 6, 6, 3, 6, 6, 6, 6, 6, 3, 3, 3, 3, 3, 3, 3, 1,\n",
      "       3, 6, 6, 6, 1, 6, 6, 6, 3, 6, 6, 6, 6, 6]), array([1, 1, 1, 6, 1, 6, 6, 6, 1, 6, 1, 6, 1, 6, 1, 6, 1, 1, 1, 6, 1, 6,\n",
      "       6, 1, 6, 1, 3, 1, 1, 3, 1, 6, 6, 6, 6, 6, 6, 6, 1, 6, 1, 6, 6, 6,\n",
      "       6, 0, 6, 6, 6, 6, 1, 9, 6, 9, 1, 6, 6, 6, 6, 6, 6, 1, 6, 1, 6, 1,\n",
      "       6, 1, 1, 6, 1, 1, 1, 6, 1, 6, 6, 9, 1, 9, 6, 6, 6, 6, 6, 6, 1, 1,\n",
      "       1, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 1, 9, 6, 6, 6, 7,\n",
      "       7, 1, 6, 9, 1, 1, 6, 6, 1, 9, 6, 1, 1, 6, 6, 6, 9, 6, 3, 6, 9, 1,\n",
      "       1, 6, 9, 7, 1, 7, 6, 6, 1, 6, 6, 1, 9, 6, 6, 1, 6, 6, 1, 6, 1, 6,\n",
      "       9, 6, 6, 3, 6, 6, 1, 6, 6, 7, 1, 3, 1, 1, 1, 1, 1, 6, 1, 6, 6, 6,\n",
      "       6, 6, 1, 1, 1, 6, 0, 1, 6, 3, 6, 1, 1, 6, 1, 6, 6, 1, 6, 6, 6, 3,\n",
      "       6, 1, 6, 6, 1, 6, 3, 3, 1, 6, 6, 6, 3, 3, 1, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 3, 6, 6, 6, 6, 6, 1, 6, 3, 3, 6, 6, 3, 6, 3, 6, 6, 6, 0,\n",
      "       3, 6, 6, 6, 6, 3, 6, 6, 3, 3, 0, 1, 1, 6, 6, 6, 1, 6, 3, 6, 6, 1,\n",
      "       6, 6, 1, 6, 0, 1, 6, 6, 6, 1, 6, 6, 6, 6, 1, 6, 1, 6, 6, 1, 6, 6,\n",
      "       6, 6, 6, 1, 6, 3, 1, 1, 6, 1, 6, 1, 6, 1]), array([6, 6, 3, 1, 1, 1, 6, 9, 6, 3, 6, 3, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6,\n",
      "       1, 3, 1, 6, 1, 6, 1, 6, 1, 1, 6, 6, 6, 1, 6, 6, 6, 6, 3, 6, 1, 6,\n",
      "       6, 6, 1, 1, 1, 6, 6, 6, 6, 6, 1, 6, 1, 6, 6, 1, 1, 0, 6, 1, 1, 6,\n",
      "       6, 6, 6, 6, 6, 1, 6, 1, 1, 6, 6, 1, 6, 1, 1, 1, 6, 1, 1, 3, 3, 6,\n",
      "       6, 9, 0, 6, 6, 3, 3, 1, 6, 3, 3, 6, 6, 6, 6, 3, 3, 6, 3, 6, 6, 6,\n",
      "       6, 6, 3, 6, 3, 3, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 3, 3, 6, 1, 6, 6,\n",
      "       6, 1, 6, 6, 3, 6, 3, 6, 6, 3, 6, 6, 6, 6, 1, 3, 6, 6, 3, 6, 3, 1,\n",
      "       6, 1, 1, 6, 9, 1, 6, 1, 6, 1, 6, 6, 6, 3, 9, 1, 1, 6, 7, 1, 1, 6,\n",
      "       1, 6, 1, 1, 6, 6, 1, 6, 9, 1, 1, 6, 1, 6, 6, 6, 1, 6, 3, 6, 1, 6,\n",
      "       9, 6, 1, 6, 6, 6, 1, 6, 6, 1, 3, 6, 6, 1, 1, 1, 6, 6, 6, 6, 3, 6,\n",
      "       6, 6, 1, 6, 6, 1, 6, 3, 3, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 1, 6, 6, 6, 3, 6, 1, 6, 3, 1, 1, 6, 6, 3, 6, 6, 6, 3, 3, 7,\n",
      "       6, 3, 3, 3, 1, 3, 6, 3, 6, 6, 3, 6, 6, 3, 6, 6, 6, 6, 6, 6, 1, 6,\n",
      "       0, 3, 6, 3, 6, 6, 6, 3, 6, 6, 1, 6, 3, 6]), array([1, 6, 6, 6, 3, 6, 1, 6, 6, 1, 6, 1, 9, 1, 6, 1, 6, 3, 9, 1, 3, 1,\n",
      "       3, 6, 6, 6, 6, 1, 6, 1, 6, 6, 6, 3, 3, 6, 6, 6, 1, 1, 6, 6, 6, 1,\n",
      "       6, 6, 6, 6, 1, 6, 1, 6, 6, 6, 6, 6, 3, 6, 6, 1, 6, 6, 1, 1, 1, 1,\n",
      "       6, 6, 1, 1, 6, 6, 1, 1, 1, 1, 6, 1, 6, 6, 1, 6, 1, 6, 1, 1, 6, 1,\n",
      "       1, 3, 6, 6, 9, 6, 6, 1, 3, 6, 6, 6, 3, 6, 3, 6, 6, 1, 9, 1, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 1, 6, 3, 6, 1, 6, 3, 6, 3, 3, 6, 1, 6, 6, 6, 3,\n",
      "       3, 6, 6, 6, 6, 6, 1, 3, 6, 6, 6, 6, 3, 6, 3, 6, 6, 3, 1, 1, 1, 1,\n",
      "       1, 1, 6, 1, 6, 6, 6, 0, 1, 6, 8, 6, 1, 6, 6, 6, 6, 9, 3, 1, 6, 1,\n",
      "       6, 1, 6, 6, 6, 6, 6, 6, 6, 3, 6, 0, 6, 6, 0, 6, 3, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 0, 3, 6, 6, 1, 6, 6, 6, 6, 3, 6, 6, 1, 6,\n",
      "       6, 6, 6, 6, 9, 3, 6, 6, 6, 6, 1, 6, 6, 6, 6, 9, 9, 6, 6, 3, 3, 6,\n",
      "       6, 6, 6, 3, 6, 0, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 1, 6,\n",
      "       6, 6, 6, 6, 6, 1, 6, 6, 1, 1, 6, 6, 1, 6, 6, 1, 6, 1, 6, 6, 6, 3,\n",
      "       6, 1, 1, 6, 3, 1, 9, 6, 1, 1, 3, 3, 6, 1]), array([1, 1, 6, 1, 1, 0, 1, 1, 1, 6, 1, 1, 6, 1, 1, 1, 1, 6, 6, 1, 1, 1,\n",
      "       1, 1, 3, 1, 1, 3, 1, 1, 9, 1, 6, 1, 6, 1, 1, 1, 6, 6, 1, 1, 6, 6,\n",
      "       3, 6, 3, 6, 9, 1, 6, 1, 3, 6, 6, 1, 6, 1, 6, 6, 1, 1, 1, 6, 6, 9,\n",
      "       6, 9, 7, 6, 9, 6, 3, 6, 6, 6, 1, 6, 1, 1, 6, 6, 1, 1, 6, 1, 6, 8,\n",
      "       1, 6, 6, 6, 6, 1, 1, 9, 6, 1, 6, 6, 6, 1, 6, 6, 6, 6, 6, 9, 6, 6,\n",
      "       1, 6, 1, 6, 9, 6, 6, 3, 6, 6, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 1, 6, 0, 6, 6, 6, 6, 6, 1, 1, 6, 6, 6, 6, 3, 3, 1, 6, 6, 6,\n",
      "       6, 6, 1, 6, 1, 6, 1, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 1, 6, 6, 6, 3,\n",
      "       1, 1, 1, 3, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 9, 6, 1, 3, 1, 1, 6, 6,\n",
      "       3, 1, 6, 6, 6, 3, 6, 1, 6, 3, 3, 3, 1, 6, 3, 6, 6, 1, 3, 6, 6, 6,\n",
      "       1, 3, 6, 6, 3, 6, 6, 3, 6, 1, 6, 6, 3, 3, 6, 1, 1, 3, 1, 1, 6, 6,\n",
      "       3, 1, 6, 6, 6, 6, 1, 6, 1, 6, 1, 1, 6, 1, 6, 6, 1, 6, 6, 6, 9, 6,\n",
      "       1, 9, 6, 1, 6, 6, 1, 1, 6, 6, 6, 9, 1, 3]), array([6, 6, 1, 1, 9, 6, 6, 1, 3, 6, 1, 1, 1, 3, 6, 6, 3, 9, 1, 1, 6, 6,\n",
      "       6, 7, 1, 6, 0, 6, 1, 6, 6, 1, 1, 6, 6, 6, 1, 6, 6, 6, 6, 1, 1, 6,\n",
      "       1, 1, 6, 6, 6, 1, 6, 6, 1, 6, 6, 1, 6, 6, 1, 6, 3, 6, 6, 6, 1, 6,\n",
      "       1, 1, 6, 1, 6, 1, 6, 6, 6, 1, 1, 3, 6, 6, 6, 1, 6, 6, 3, 6, 1, 6,\n",
      "       6, 1, 1, 1, 1, 6, 6, 6, 1, 6, 1, 1, 6, 6, 1, 6, 1, 6, 1, 6, 6, 6,\n",
      "       6, 1, 1, 6, 6, 6, 1, 6, 6, 6, 1, 6, 1, 6, 7, 6, 1, 6, 6, 6, 6, 6,\n",
      "       1, 6, 6, 6, 1, 1, 6, 1, 1, 1, 6, 6, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6,\n",
      "       1, 6, 6, 1, 3, 1, 9, 6, 1, 1, 6, 1, 9, 1, 1, 6, 1, 6, 1, 1, 1, 6,\n",
      "       9, 6, 9, 9, 3, 1, 6, 1, 6, 6, 9, 1, 6, 6, 3, 6, 6, 6, 6, 6, 3, 1,\n",
      "       6, 6, 6, 6, 6, 6, 6, 1, 1, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 1,\n",
      "       1, 6, 6, 6, 6, 6, 6, 3, 1, 6, 6, 6, 6, 6, 6, 3, 6, 6, 3, 1, 6, 1,\n",
      "       6, 1, 6, 6, 6, 6, 6, 1, 6, 3, 6, 3, 6, 1, 1, 6, 3, 1, 3, 6, 6, 3,\n",
      "       1, 6, 6, 6, 3, 3, 6, 1, 6, 1, 6, 9, 1, 6, 1, 1, 1, 1, 1, 1, 6, 6,\n",
      "       1, 6, 1, 6, 1, 9, 6, 6, 1, 1, 1, 6, 6, 6]), array([1, 1, 1, 6, 6, 1, 6, 6, 1, 1, 0, 6, 3, 1, 1, 1, 1, 1, 6, 1, 1, 6,\n",
      "       6, 6, 6, 0, 1, 1, 6, 1, 3, 6, 6, 6, 1, 6, 6, 1, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 0, 0, 6, 6, 1, 6, 1, 3, 6, 1, 1, 1, 6, 6, 1, 1, 6, 6, 6,\n",
      "       6, 6, 3, 6, 3, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 6, 1, 6, 6,\n",
      "       9, 6, 6, 6, 6, 1, 6, 3, 9, 6, 1, 9, 1, 1, 6, 1, 6, 3, 6, 6, 3, 1,\n",
      "       6, 1, 6, 6, 1, 1, 6, 1, 6, 1, 9, 1, 9, 1, 6, 1, 1, 1, 1, 1, 6, 1,\n",
      "       6, 6, 1, 1, 6, 6, 1, 6, 6, 1, 9, 6, 6, 1, 6, 6, 1, 6, 6, 1, 1, 3,\n",
      "       1, 1, 6, 6, 6, 1, 1, 6, 6, 6, 1, 6, 1, 6, 1, 1, 1, 6, 6, 6, 1, 1,\n",
      "       6, 1, 6, 6, 6, 6, 1, 6, 6, 1, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 6, 6,\n",
      "       6, 3, 3, 6, 6, 6, 6, 6, 6, 6, 3, 1, 6, 6, 3, 3, 3, 6, 6, 3, 3, 3,\n",
      "       6, 3, 0, 0, 3, 0, 6, 6, 3, 0, 6, 1, 6, 3, 3, 1, 3, 1, 6, 3, 1, 6,\n",
      "       6, 6, 3, 1, 1, 6, 3, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 3, 3, 6,\n",
      "       6, 6, 3, 1, 6, 6, 1, 6, 6, 3, 1, 3, 3, 1, 0, 6, 6, 6, 1, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 1, 3, 6, 6, 6, 6, 6, 1]), array([6, 3, 6, 9, 6, 1, 1, 6, 6, 1, 6, 6, 6, 1, 6, 3, 1, 6, 6, 6, 6, 6,\n",
      "       1, 6, 1, 1, 6, 6, 1, 1, 6, 6, 6, 6, 6, 6, 6, 1, 1, 6, 6, 6, 6, 1,\n",
      "       1, 6, 1, 6, 6, 1, 6, 6, 6, 1, 6, 6, 6, 6, 6, 1, 6, 3, 6, 1, 1, 6,\n",
      "       1, 6, 6, 1, 1, 6, 6, 1, 3, 1, 6, 1, 3, 1, 6, 6, 3, 6, 1, 6, 1, 6,\n",
      "       1, 1, 6, 6, 3, 6, 6, 3, 6, 6, 6, 6, 6, 6, 1, 6, 6, 0, 6, 3, 6, 6,\n",
      "       1, 3, 6, 6, 6, 3, 3, 3, 1, 0, 6, 3, 6, 6, 1, 6, 6, 6, 6, 6, 1, 3,\n",
      "       6, 1, 6, 6, 1, 1, 9, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 1, 1, 0, 6, 1,\n",
      "       6, 1, 3, 6, 6, 6, 3, 1, 6, 3, 6, 1, 6, 6, 6, 3, 6, 1, 6, 6, 1, 6,\n",
      "       6, 6, 6, 1, 1, 6, 6, 3, 1, 6, 6, 1, 6, 3, 6, 1, 6, 6, 3, 6, 3, 6,\n",
      "       6, 6, 6, 6, 3, 3, 6, 6, 9, 6, 6, 6, 1, 7, 1, 6, 6, 1, 3, 6, 1, 9,\n",
      "       6, 6, 7, 1, 6, 1, 6, 6, 1, 6, 6, 0, 3, 1, 6, 6, 6, 6, 1, 6, 3, 6,\n",
      "       7, 6, 6, 6, 1, 7, 1, 7, 6, 3, 1, 6, 6, 7, 1, 1, 3, 6, 6, 6, 6, 9,\n",
      "       3, 1, 1, 6, 6, 1, 6, 6, 6, 6, 6, 1, 6, 1, 1, 1, 6, 6, 6, 6, 1, 1,\n",
      "       6, 1, 6, 6, 1, 6, 6, 6, 6, 6, 6, 1, 1, 6]), array([1, 6, 6, 1, 1, 6, 6, 1, 1, 9, 3, 1, 1, 6, 1, 6, 6, 1, 1, 9, 6, 1,\n",
      "       1, 6, 1, 6, 6, 6, 9, 6, 1, 6, 3, 7, 7, 3, 7, 6, 3, 1, 1, 1, 6, 7,\n",
      "       6, 1, 6, 6, 3, 7, 6, 6, 6, 6, 1, 3, 7, 3, 6, 3, 1, 6, 6, 6, 3, 1,\n",
      "       0, 1, 1, 1, 6, 0, 6, 6, 1, 6, 1, 6, 6, 6, 3, 6, 6, 9, 6, 6, 6, 1,\n",
      "       6, 1, 6, 1, 1, 9, 1, 6, 6, 6, 6, 6, 6, 6, 9, 1, 1, 1, 1, 6, 3, 3,\n",
      "       6, 6, 6, 1, 3, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 0, 6, 6, 6, 6,\n",
      "       6, 3, 6, 3, 3, 3, 6, 6, 1, 6, 3, 6, 1, 6, 6, 3, 6, 6, 6, 3, 6, 1,\n",
      "       1, 6, 1, 6, 1, 3, 6, 3, 1, 1, 1, 1, 6, 1, 6, 6, 3, 3, 6, 3, 3, 6,\n",
      "       3, 3, 1, 1, 6, 6, 3, 1, 6, 6, 1, 6, 9, 9, 6, 6, 6, 9, 9, 6, 6, 1,\n",
      "       1, 6, 1, 1, 9, 1, 3, 6, 6, 1, 1, 7, 6, 6, 3, 1, 1, 6, 6, 6, 6, 6,\n",
      "       6, 1, 6, 6, 1, 6, 1, 6, 6, 1, 6, 1, 6, 6, 1, 6, 3, 6, 6, 1, 6, 3,\n",
      "       3, 1, 1, 1, 6, 6, 1, 6, 1, 1, 6, 1, 1, 1, 6, 3, 6, 6, 1, 6, 1, 1,\n",
      "       6, 6, 6, 6, 3, 6, 1, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6,\n",
      "       1, 6, 6, 6, 6, 1, 6, 1, 1, 6, 1, 1, 6, 6]), array([1, 1, 1, 6, 6, 1, 3, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 3,\n",
      "       6, 1, 6, 1, 1, 1, 3, 1, 6, 3, 1, 6, 1, 6, 1, 6, 3, 0, 6, 3, 6, 3,\n",
      "       1, 3, 1, 3, 6, 6, 1, 0, 1, 1, 6, 6, 6, 6, 6, 9, 6, 6, 6, 1, 6, 1,\n",
      "       1, 1, 6, 6, 1, 6, 6, 3, 6, 6, 6, 6, 1, 3, 6, 6, 6, 1, 1, 6, 1, 1,\n",
      "       6, 6, 1, 1, 6, 6, 6, 6, 1, 6, 6, 6, 1, 6, 6, 1, 6, 6, 6, 1, 1, 6,\n",
      "       6, 6, 6, 1, 6, 6, 1, 1, 1, 6, 1, 6, 6, 3, 6, 3, 6, 3, 1, 1, 6, 6,\n",
      "       3, 6, 6, 6, 6, 6, 6, 1, 3, 1, 0, 3, 6, 6, 6, 0, 6, 0, 6, 6, 1, 9,\n",
      "       6, 6, 1, 1, 6, 6, 3, 6, 3, 6, 6, 6, 6, 6, 1, 6, 6, 1, 1, 6, 6, 9,\n",
      "       1, 1, 6, 6, 1, 6, 1, 6, 3, 1, 0, 6, 6, 6, 1, 6, 6, 0, 6, 1, 9, 6,\n",
      "       6, 1, 6, 0, 6, 1, 1, 6, 3, 6, 1, 6, 3, 6, 6, 1, 6, 3, 6, 3, 6, 6,\n",
      "       3, 6, 6, 6, 3, 1, 3, 6, 6, 3, 1, 6, 3, 6, 6, 1, 1, 3, 1, 6, 1, 3,\n",
      "       6, 3, 6, 3, 6, 6, 6, 6, 6, 6, 3, 3, 3, 6, 3, 6, 6, 6, 3, 3, 3, 0,\n",
      "       6, 3, 6, 3, 6, 6, 6, 1, 1, 6, 1, 6, 1, 6, 3, 6, 1, 1, 6, 1, 6, 1,\n",
      "       6, 6, 6, 1, 9, 1, 1, 0, 1, 1, 6, 6, 1, 9]), array([0, 6, 1, 1, 1, 6, 6, 3, 6, 6, 1, 3, 6, 3, 6, 1, 1, 6, 1, 3, 1, 1,\n",
      "       6, 1, 6, 6, 6, 1, 3, 6, 6, 1, 6, 6, 6, 1, 3, 1, 1, 3, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 1, 6, 3, 6, 6, 6, 6, 6, 6, 1, 6, 6, 1, 1, 1, 1, 6, 6,\n",
      "       6, 6, 6, 6, 6, 1, 1, 1, 6, 3, 3, 1, 6, 6, 1, 1, 1, 3, 6, 1, 6, 3,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 3, 0, 3, 0, 6, 6, 0, 6, 6, 3, 6, 0,\n",
      "       6, 3, 1, 3, 1, 1, 9, 6, 6, 3, 6, 9, 1, 1, 1, 9, 1, 9, 6, 6, 1, 7,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 1, 6, 1, 1, 1, 1, 6, 1, 6,\n",
      "       1, 1, 6, 6, 1, 1, 1, 1, 9, 1, 6, 6, 1, 9, 6, 1, 6, 6, 1, 8, 6, 1,\n",
      "       1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 1, 3, 6, 3, 1, 6, 6, 1, 6,\n",
      "       1, 6, 6, 6, 6, 6, 6, 1, 6, 3, 0, 3, 6, 6, 6, 3, 3, 6, 3, 1, 3, 1,\n",
      "       3, 6, 1, 3, 6, 6, 3, 3, 3, 1, 3, 6, 6, 6, 6, 1, 1, 6, 6, 6, 6, 6,\n",
      "       6, 6, 1, 6, 3, 1, 6, 3, 3, 6, 6, 6, 6, 6, 6, 6, 1, 1, 6, 6, 6, 6,\n",
      "       1, 6, 1, 6, 1, 6, 7, 1, 1, 1, 6, 1, 6, 6, 6, 9, 6, 6, 1, 1, 1, 6,\n",
      "       1, 6, 1, 1, 6, 6, 1, 9, 6, 6, 9, 6, 6, 1]), array([6, 6, 6, 6, 6, 6, 1, 1, 6, 1, 1, 6, 1, 1, 1, 6, 6, 6, 1, 6, 1, 6,\n",
      "       6, 6, 1, 1, 1, 1, 6, 3, 1, 6, 3, 1, 6, 1, 6, 6, 6, 6, 9, 1, 1, 1,\n",
      "       6, 1, 6, 1, 6, 6, 6, 3, 1, 6, 1, 6, 0, 6, 0, 6, 1, 6, 1, 6, 1, 6,\n",
      "       1, 6, 1, 1, 1, 6, 6, 6, 1, 1, 6, 6, 1, 6, 1, 1, 6, 6, 1, 1, 1, 6,\n",
      "       3, 3, 1, 6, 3, 3, 3, 6, 3, 3, 1, 1, 9, 9, 1, 3, 6, 1, 3, 6, 6, 3,\n",
      "       1, 6, 6, 1, 6, 6, 6, 6, 6, 1, 1, 6, 6, 6, 6, 6, 6, 1, 1, 3, 1, 6,\n",
      "       1, 1, 1, 1, 9, 6, 1, 6, 6, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 1,\n",
      "       6, 9, 6, 6, 6, 9, 6, 6, 6, 1, 1, 1, 1, 6, 1, 9, 1, 1, 6, 1, 1, 1,\n",
      "       6, 6, 1, 6, 6, 1, 1, 6, 6, 6, 6, 6, 1, 1, 6, 3, 6, 6, 6, 1, 6, 6,\n",
      "       6, 6, 1, 6, 6, 6, 6, 3, 1, 1, 6, 1, 6, 6, 6, 6, 6, 6, 1, 6, 1, 3,\n",
      "       6, 7, 6, 6, 6, 6, 6, 1, 6, 6, 1, 6, 6, 6, 1, 6, 6, 3, 6, 1, 1, 6,\n",
      "       3, 1, 3, 1, 3, 3, 6, 6, 6, 6, 3, 1, 6, 3, 6, 3, 3, 1, 1, 1, 6, 6,\n",
      "       3, 1, 6, 6, 3, 1, 6, 3, 6, 3, 1, 6, 1, 3, 6, 6, 3, 6, 6, 6, 6, 6,\n",
      "       6, 1, 3, 6, 3, 6, 6, 6, 6, 6, 3, 6, 6, 3]), array([1, 1, 3, 1, 1, 1, 6, 1, 1, 6, 9, 1, 1, 1, 1, 1, 9, 1, 6, 1, 6, 6,\n",
      "       1, 1, 1, 3, 1, 6, 6, 1, 3, 1, 6, 9, 9, 6, 6, 1, 7, 6, 1, 0, 7, 6,\n",
      "       3, 1, 6, 6, 1, 1, 6, 1, 1, 1, 6, 1, 6, 6, 1, 1, 6, 6, 6, 6, 6, 6,\n",
      "       6, 1, 6, 6, 6, 1, 1, 6, 1, 1, 0, 1, 6, 1, 6, 3, 1, 1, 1, 3, 1, 3,\n",
      "       6, 1, 6, 6, 1, 6, 6, 1, 6, 1, 6, 6, 6, 1, 6, 6, 1, 6, 6, 1, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 1, 1, 6, 6, 1, 7, 1, 9, 6, 6, 6, 3, 6, 6, 6,\n",
      "       6, 9, 7, 6, 6, 1, 3, 3, 9, 6, 6, 6, 1, 1, 1, 6, 1, 1, 9, 9, 6, 6,\n",
      "       6, 6, 9, 1, 1, 6, 1, 3, 6, 3, 6, 3, 7, 1, 1, 1, 9, 6, 1, 6, 6, 6,\n",
      "       1, 1, 1, 1, 3, 6, 6, 6, 6, 6, 6, 6, 0, 6, 6, 1, 6, 6, 6, 6, 0, 6,\n",
      "       6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 1, 6, 6, 6, 6, 6,\n",
      "       1, 6, 6, 1, 6, 3, 1, 6, 6, 6, 6, 6, 1, 3, 6, 6, 6, 6, 3, 6, 6, 1,\n",
      "       1, 6, 6, 3, 6, 1, 3, 9, 1, 1, 1, 6, 1, 6, 1, 6, 1, 3, 6, 1, 6, 6,\n",
      "       6, 6, 6, 6, 1, 8, 6, 6, 6, 1, 6, 6, 6, 6, 1, 6, 6, 3, 3, 6, 6, 1,\n",
      "       3, 6, 6, 6, 6, 6, 3, 6, 6, 1, 6, 1, 6, 6]), array([6, 6, 1, 6, 6, 6, 1, 1, 6, 1, 1, 1, 3, 1, 7, 1, 1, 6, 1, 1, 1, 6,\n",
      "       1, 1, 6, 6, 6, 6, 6, 6, 6, 9, 6, 6, 6, 6, 6, 6, 1, 1, 6, 9, 6, 6,\n",
      "       1, 6, 1, 6, 6, 1, 1, 6, 6, 6, 1, 6, 6, 1, 1, 1, 3, 1, 6, 3, 3, 3,\n",
      "       1, 3, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 6, 1, 6, 0, 6, 6, 6, 6, 6,\n",
      "       6, 6, 9, 6, 6, 1, 1, 1, 6, 6, 7, 6, 1, 8, 6, 6, 6, 6, 1, 6, 1, 1,\n",
      "       6, 1, 9, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 1,\n",
      "       1, 1, 1, 6, 6, 6, 6, 3, 6, 6, 1, 1, 1, 3, 9, 1, 6, 6, 1, 1, 1, 6,\n",
      "       1, 6, 1, 1, 6, 1, 6, 6, 1, 6, 1, 1, 6, 6, 3, 6, 6, 6, 6, 1, 1, 6,\n",
      "       6, 1, 6, 1, 6, 6, 6, 1, 6, 6, 3, 1, 6, 6, 6, 6, 6, 3, 6, 3, 6, 1,\n",
      "       6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 1, 8, 6, 6, 1, 6, 6, 7, 6,\n",
      "       6, 3, 1, 8, 1, 6, 7, 6, 6, 6, 6, 3, 7, 1, 6, 6, 6, 7, 6, 6, 3, 1,\n",
      "       1, 9, 1, 9, 6, 6, 1, 1, 6, 1, 1, 6, 9, 6, 3, 1, 1, 1, 6, 1, 1, 6,\n",
      "       1, 9, 1, 1, 8, 9, 6, 1, 6, 6, 6, 1, 6, 6, 6, 6, 1, 6, 6, 9, 6, 3,\n",
      "       6, 6, 1, 3, 1, 6, 6, 6, 6, 6, 6, 1, 3, 6]), array([3, 1, 6, 6, 1, 1, 1, 6, 1, 1, 6, 7, 6, 6, 6, 6, 6, 1, 6, 6, 1, 1,\n",
      "       1, 6, 1, 1, 6, 1, 1, 1, 6, 6, 1, 1, 3, 1, 1, 6, 6, 1, 6, 6, 6, 6,\n",
      "       6, 6, 6, 7, 3, 6, 3, 1, 3, 1, 3, 9, 9, 6, 6, 6, 6, 1, 1, 1, 6, 6,\n",
      "       6, 1, 9, 1, 1, 1, 9, 9, 6, 1, 6, 3, 6, 1, 6, 6, 1, 3, 1, 6, 6, 6,\n",
      "       1, 1, 3, 3, 6, 6, 6, 6, 6, 6, 0, 3, 6, 3, 3, 6, 3, 3, 6, 6, 6, 6,\n",
      "       6, 0, 3, 0, 0, 6, 6, 6, 3, 6, 6, 1, 1, 3, 1, 1, 1, 1, 9, 1, 1, 9,\n",
      "       1, 6, 6, 9, 1, 1, 1, 1, 1, 6, 6, 6, 0, 7, 6, 6, 9, 6, 6, 1, 1, 6,\n",
      "       6, 6, 3, 1, 1, 6, 1, 6, 6, 6, 6, 6, 1, 3, 6, 3, 1, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 1, 3, 3, 6, 6, 6, 6, 6, 1, 6, 6, 6,\n",
      "       3, 1, 1, 1, 6, 6, 1, 6, 6, 6, 6, 1, 6, 6, 6, 7, 6, 6, 6, 1, 6, 6,\n",
      "       6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 1, 3, 6, 6, 6, 3, 6, 6,\n",
      "       6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 3, 3, 3, 6, 6, 6, 6, 6, 3, 6, 3,\n",
      "       6, 3, 6, 3, 6, 6, 1, 6, 1, 6, 6, 6, 3, 1, 6, 1, 6, 6, 6, 6, 3, 6,\n",
      "       6, 6, 6, 1, 6, 6, 6, 1, 6, 6, 6, 6, 1, 6]), array([6, 1, 6, 1, 6, 6, 1, 6, 6, 6, 6, 6, 0, 6, 9, 6, 1, 1, 1, 6, 3, 1,\n",
      "       6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 1, 6, 6, 3, 1, 3, 3,\n",
      "       6, 1, 1, 1, 6, 3, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 1, 6, 3, 6, 1, 1,\n",
      "       6, 1, 1, 1, 1, 6, 1, 1, 1, 3, 9, 6, 1, 1, 6, 1, 1, 6, 9, 6, 6, 6,\n",
      "       1, 0, 6, 1, 6, 6, 9, 6, 1, 6, 6, 1, 6, 6, 1, 9, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 1, 1, 3, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 1, 3, 6,\n",
      "       3, 3, 6, 1, 1, 6, 1, 1, 6, 3, 6, 6, 3, 6, 3, 6, 6, 6, 3, 6, 9, 1,\n",
      "       1, 1, 6, 6, 6, 6, 1, 1, 1, 1, 1, 9, 6, 1, 6, 1, 1, 1, 6, 6, 6, 1,\n",
      "       1, 3, 1, 6, 1, 3, 1, 3, 1, 1, 6, 3, 6, 1, 3, 0, 1, 1, 6, 6, 6, 3,\n",
      "       6, 6, 6, 3, 1, 1, 6, 1, 6, 1, 1, 6, 1, 3, 6, 6, 1, 8, 3, 1, 1, 6,\n",
      "       1, 6, 1, 1, 3, 3, 6, 6, 1, 3, 6, 1, 9, 6, 3, 6, 3, 6, 6, 6, 1, 6,\n",
      "       6, 3, 6, 6, 9, 1, 7, 1, 1, 6, 1, 1, 1, 1, 6, 8, 8, 6, 1, 6, 1, 1,\n",
      "       1, 6, 1, 6, 6, 1, 6, 6, 3, 6, 1, 1, 6, 6, 6, 6, 1, 1, 1, 3, 1, 6,\n",
      "       6, 3, 6, 6, 1, 6, 1, 6, 3, 1, 6, 6, 6, 6]), array([6, 6, 1, 1, 6, 6, 6, 6, 1, 1, 6, 6, 1, 1, 3, 1, 1, 6, 6, 1, 6, 6,\n",
      "       6, 3, 6, 6, 1, 3, 1, 1, 6, 3, 6, 0, 1, 6, 1, 6, 3, 6, 6, 6, 6, 1,\n",
      "       1, 6, 6, 6, 1, 6, 1, 6, 1, 3, 6, 6, 1, 3, 3, 6, 6, 3, 1, 6, 6, 1,\n",
      "       6, 1, 6, 6, 6, 3, 6, 6, 6, 6, 1, 1, 6, 6, 1, 1, 6, 1, 6, 1, 3, 1,\n",
      "       6, 6, 3, 3, 0, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 1, 6, 6, 1, 6, 6,\n",
      "       3, 6, 1, 6, 1, 6, 1, 6, 3, 3, 1, 6, 3, 6, 3, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 1, 6, 6, 6, 3, 6, 6, 6, 3, 6, 3,\n",
      "       6, 1, 6, 6, 1, 1, 6, 1, 1, 6, 3, 1, 1, 6, 1, 6, 6, 6, 1, 3, 1, 1,\n",
      "       1, 6, 6, 6, 6, 6, 6, 1, 1, 0, 6, 1, 1, 0, 6, 6, 6, 6, 6, 1, 1, 6,\n",
      "       6, 9, 6, 3, 6, 1, 6, 6, 6, 6, 6, 3, 6, 6, 3, 3, 6, 1, 6, 6, 6, 1,\n",
      "       6, 6, 6, 6, 6, 1, 6, 1, 1, 1, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3,\n",
      "       6, 3, 6, 1, 1, 3, 6, 1, 6, 3, 6, 3, 6, 6, 6, 3, 6, 3, 3, 6, 1, 1,\n",
      "       3, 3, 6, 1, 6, 6, 3, 6, 6, 6, 6, 3, 6, 6, 1, 3, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 3, 3, 6, 6, 1, 3, 3, 6, 6, 6]), array([1, 1, 6, 6, 1, 3, 6, 1, 6, 6, 1, 1, 6, 6, 6, 6, 6, 6, 3, 3, 1, 1,\n",
      "       6, 1, 3, 1, 6, 1, 1, 6, 1, 6, 6, 3, 6, 6, 6, 3, 6, 6, 6, 3, 6, 6,\n",
      "       6, 3, 3, 1, 6, 6, 6, 6, 6, 6, 6, 1, 6, 1, 6, 6, 6, 1, 6, 1, 1, 6,\n",
      "       1, 6, 1, 1, 6, 1, 1, 1, 3, 6, 6, 6, 3, 6, 1, 6, 3, 6, 6, 6, 1, 1,\n",
      "       1, 6, 6, 9, 6, 6, 1, 1, 6, 9, 1, 6, 6, 6, 6, 1, 6, 6, 1, 6, 3, 1,\n",
      "       6, 1, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 6, 6, 6, 6, 3, 1, 1, 3, 6, 6,\n",
      "       6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 1, 6, 6, 3, 1, 1, 6, 1, 6, 1, 3, 1,\n",
      "       3, 6, 1, 3, 1, 1, 1, 1, 6, 9, 6, 6, 0, 1, 6, 1, 6, 1, 6, 6, 6, 3,\n",
      "       6, 6, 1, 1, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 1, 3, 1, 6, 6, 6, 3, 6,\n",
      "       6, 6, 6, 6, 6, 3, 1, 1, 3, 3, 6, 6, 3, 3, 6, 6, 6, 1, 1, 6, 6, 3,\n",
      "       6, 1, 6, 6, 6, 6, 1, 3, 9, 9, 1, 6, 6, 1, 6, 1, 1, 6, 1, 6, 3, 1,\n",
      "       1, 6, 3, 3, 2, 6, 1, 6, 6, 1, 6, 6, 6, 6, 7, 6, 2, 6, 1, 6, 6, 3,\n",
      "       2, 6, 6, 3, 3, 3, 6, 6, 1, 6, 6, 6, 6, 1, 6, 6, 6, 1, 6, 1, 1, 1,\n",
      "       1, 1, 6, 6, 6, 1, 6, 6, 6, 6, 1, 6, 6, 1]), array([1, 6, 1, 1, 1, 1, 6, 1, 3, 7, 1, 1, 6, 6, 6, 1, 1, 1, 1, 6, 6, 6,\n",
      "       1, 1, 1, 1, 3, 6, 1, 1, 6, 6, 6, 6, 6, 3, 6, 6, 6, 1, 1, 6, 1, 1,\n",
      "       6, 6, 6, 3, 6, 1, 6, 1, 6, 1, 1, 3, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 1, 1, 6, 3, 0, 1, 6, 1, 0, 1, 6, 1,\n",
      "       6, 6, 6, 6, 6, 3, 6, 3, 6, 1, 6, 6, 1, 6, 6, 6, 3, 6, 0, 6, 6, 3,\n",
      "       1, 6, 6, 3, 3, 1, 3, 1, 6, 1, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6,\n",
      "       6, 1, 3, 6, 6, 3, 3, 6, 1, 1, 6, 3, 1, 6, 3, 6, 1, 1, 1, 1, 1, 6,\n",
      "       6, 3, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 3, 6, 1, 6, 1, 6, 3, 1, 6, 6,\n",
      "       6, 1, 3, 1, 6, 1, 6, 6, 6, 6, 6, 6, 3, 6, 1, 6, 6, 6, 1, 6, 6, 3,\n",
      "       1, 6, 1, 6, 1, 6, 9, 6, 1, 6, 6, 6, 6, 1, 6, 6, 6, 6, 1, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 1, 3, 6, 6, 6, 6, 3, 6, 6, 6, 3, 6, 1, 6, 1,\n",
      "       1, 1, 6, 6, 1, 3, 1, 3, 3, 6, 3, 1, 6, 6, 1, 6, 6, 6, 6, 1, 3, 6,\n",
      "       6, 6, 3, 6, 1, 3, 1, 6, 0, 1, 6, 6, 6, 6, 1, 1, 6, 6, 1, 1, 6, 1,\n",
      "       6, 6, 1, 6, 6, 1, 1, 6, 1, 3, 6, 1, 1, 3]), array([6, 6, 6, 6, 3, 6, 1, 0, 6, 6, 3, 6, 1, 6, 6, 6, 3, 3, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 6, 1, 7, 1, 6, 1, 8, 6, 9,\n",
      "       1, 6, 7, 6, 1, 6, 6, 1, 1, 6, 8, 6, 3, 7, 1, 1, 1, 6, 6, 1, 1, 1,\n",
      "       1, 6, 1, 1, 1, 6, 1, 3, 9, 1, 6, 1, 1, 1, 6, 6, 6, 6, 6, 1, 1, 6,\n",
      "       1, 1, 6, 6, 1, 1, 1, 6, 1, 6, 6, 3, 3, 6, 0, 6, 6, 1, 3, 1, 1, 6,\n",
      "       6, 3, 6, 6, 6, 6, 0, 1, 6, 6, 6, 6, 3, 1, 6, 6, 6, 3, 6, 1, 6, 1,\n",
      "       1, 6, 6, 6, 6, 6, 6, 6, 3, 3, 6, 6, 6, 1, 6, 6, 6, 3, 6, 6, 6, 0,\n",
      "       1, 0, 1, 6, 6, 0, 6, 3, 3, 6, 3, 0, 1, 1, 1, 6, 3, 3, 1, 1, 3, 1,\n",
      "       3, 6, 6, 3, 1, 1, 3, 1, 6, 9, 6, 6, 6, 1, 6, 1, 6, 6, 6, 6, 1, 1,\n",
      "       1, 6, 6, 6, 1, 6, 6, 3, 6, 9, 6, 1, 6, 6, 6, 6, 6, 6, 6, 7, 9, 7,\n",
      "       3, 3, 3, 3, 1, 9, 6, 3, 6, 6, 1, 1, 1, 3, 3, 3, 6, 1, 6, 6, 1, 7,\n",
      "       6, 1, 1, 6, 6, 6, 6, 2, 1, 6, 6, 6, 3, 1, 3, 9, 7, 7, 6, 6, 6, 1,\n",
      "       6, 1, 1, 6, 1, 6, 6, 1, 6, 6, 1, 1, 1, 1, 6, 3, 6, 3, 0, 6, 3, 6,\n",
      "       1, 1, 6, 1, 6, 6, 6, 1, 1, 6, 6, 3, 3, 6]), array([6, 1, 1, 1, 6, 1, 3, 6, 1, 3, 6, 1, 1, 1, 1, 1, 6, 6, 6, 1, 1, 3,\n",
      "       1, 6, 1, 1, 1, 6, 6, 6, 1, 6, 3, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6,\n",
      "       6, 1, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 1, 1, 9, 9, 1,\n",
      "       6, 1, 6, 3, 1, 1, 3, 1, 6, 1, 1, 6, 6, 6, 3, 1, 1, 6, 6, 6, 6, 1,\n",
      "       6, 1, 6, 6, 3, 6, 6, 6, 6, 1, 1, 1, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6,\n",
      "       9, 6, 1, 1, 6, 1, 6, 6, 9, 6, 6, 6, 0, 6, 6, 3, 3, 6, 3, 6, 3, 6,\n",
      "       0, 0, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 3, 6, 1, 6, 3, 1,\n",
      "       1, 6, 6, 1, 6, 1, 1, 9, 6, 6, 1, 6, 6, 1, 3, 6, 6, 1, 6, 3, 1, 6,\n",
      "       6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 3, 6, 1, 3, 6, 6,\n",
      "       6, 3, 3, 3, 3, 6, 3, 6, 6, 6, 3, 6, 6, 6, 6, 3, 3, 6, 3, 6, 3, 6,\n",
      "       6, 6, 6, 6, 6, 3, 6, 6, 3, 6, 3, 3, 6, 1, 3, 6, 7, 1, 3, 3, 3, 6,\n",
      "       3, 6, 6, 6, 3, 6, 3, 6, 6, 3, 1, 3, 6, 3, 6, 6, 6, 1, 3, 1, 3, 6,\n",
      "       6, 6, 6, 0, 6, 6, 9, 1, 9, 3, 6, 6, 1, 6, 1, 6, 1, 6, 1, 6, 1, 1,\n",
      "       6, 6, 6, 8, 1, 6, 6, 6, 6, 1, 1, 3, 1, 1]), array([6, 3, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6,\n",
      "       3, 6, 1, 6, 6, 1, 6, 1, 6, 6, 6, 1, 6, 3, 6, 1, 6, 6, 6, 6, 1, 6,\n",
      "       6, 6, 6, 1, 1, 6, 6, 6, 6, 6, 6, 1, 1, 6, 1, 1, 6, 1, 7, 1, 7, 6,\n",
      "       1, 6, 6, 1, 3, 1, 1, 6, 6, 6, 6, 6, 1, 1, 6, 6, 6, 1, 3, 1, 1, 6,\n",
      "       1, 6, 1, 1, 1, 1, 6, 7, 6, 3, 6, 6, 6, 1, 1, 6, 1, 3, 6, 1, 6, 1,\n",
      "       6, 6, 6, 6, 6, 6, 6, 9, 1, 6, 6, 3, 6, 3, 6, 6, 1, 6, 3, 9, 1, 3,\n",
      "       6, 3, 3, 6, 6, 6, 6, 6, 3, 3, 3, 1, 6, 3, 6, 6, 6, 6, 1, 1, 6, 3,\n",
      "       6, 1, 6, 1, 1, 1, 3, 6, 1, 1, 6, 1, 6, 6, 6, 1, 1, 6, 1, 6, 6, 6,\n",
      "       1, 1, 3, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 1, 1, 6, 6, 6, 0,\n",
      "       6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 9, 6, 3, 6, 1, 1, 1, 1, 6, 6, 6, 6,\n",
      "       6, 6, 1, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 3, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 3, 6, 6, 6, 6, 6,\n",
      "       3, 6, 3, 1, 6, 6, 1, 6, 6, 1, 1, 6, 1, 1, 6, 6, 1, 1, 6, 1, 6, 6,\n",
      "       1, 3, 1, 6, 1, 1, 1, 1, 1, 6, 1, 6, 6, 6]), array([1, 6, 6, 1, 6, 6, 1, 1, 6, 6, 6, 6, 6, 1, 6, 6, 1, 1, 1, 1, 1, 1,\n",
      "       1, 6, 6, 6, 6, 1, 3, 1, 3, 7, 6, 6, 3, 6, 3, 1, 1, 1, 6, 1, 6, 1,\n",
      "       9, 6, 9, 9, 6, 6, 6, 1, 1, 1, 1, 6, 6, 1, 6, 3, 1, 6, 9, 6, 6, 1,\n",
      "       3, 1, 1, 6, 6, 6, 6, 6, 1, 6, 6, 1, 6, 1, 1, 6, 1, 6, 1, 6, 6, 1,\n",
      "       6, 1, 1, 6, 6, 7, 3, 6, 3, 6, 6, 1, 1, 3, 6, 6, 6, 1, 7, 6, 1, 6,\n",
      "       3, 6, 3, 6, 1, 1, 1, 6, 6, 6, 3, 1, 1, 6, 1, 6, 6, 3, 6, 6, 6, 1,\n",
      "       3, 6, 1, 6, 1, 3, 6, 3, 1, 6, 6, 6, 6, 6, 1, 1, 6, 6, 1, 3, 1, 6,\n",
      "       1, 6, 3, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 6, 6, 1, 3, 3, 1, 6, 1, 1,\n",
      "       3, 6, 1, 3, 6, 6, 1, 6, 1, 1, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 1, 6,\n",
      "       1, 6, 6, 1, 6, 6, 6, 6, 1, 1, 1, 6, 6, 9, 7, 6, 7, 3, 9, 6, 6, 3,\n",
      "       1, 1, 6, 3, 3, 6, 6, 7, 6, 1, 3, 6, 6, 9, 1, 1, 6, 6, 6, 6, 6, 3,\n",
      "       6, 6, 6, 6, 3, 6, 3, 3, 3, 6, 6, 1, 1, 6, 6, 3, 6, 6, 1, 3, 6, 6,\n",
      "       6, 6, 3, 6, 3, 6, 6, 1, 6, 6, 6, 6, 6, 1, 1, 1, 9, 6, 9, 1, 6, 6,\n",
      "       6, 1, 6, 1, 6, 1, 6, 3, 9, 9, 6, 1, 6, 1]), array([1, 7, 1, 6, 1, 1, 3, 6, 6, 1, 1, 1, 1, 1, 1, 6, 6, 1, 6, 6, 6, 1,\n",
      "       9, 1, 1, 1, 1, 6, 1, 6, 6, 1, 6, 6, 1, 1, 6, 6, 3, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 3, 1, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 3, 1, 6, 6, 1,\n",
      "       6, 3, 6, 6, 6, 7, 3, 1, 1, 6, 1, 6, 1, 6, 1, 3, 6, 6, 1, 1, 1, 6,\n",
      "       6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6,\n",
      "       6, 1, 6, 6, 6, 6, 6, 1, 6, 1, 6, 6, 6, 6, 3, 3, 6, 6, 1, 6, 6, 0,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 3, 6, 3, 6, 6, 6, 6,\n",
      "       1, 6, 1, 1, 1, 6, 1, 1, 6, 6, 9, 1, 6, 1, 6, 6, 6, 6, 6, 6, 6, 0,\n",
      "       6, 6, 6, 1, 1, 1, 6, 6, 1, 6, 3, 9, 1, 3, 6, 3, 6, 1, 3, 6, 6, 1,\n",
      "       3, 3, 3, 1, 6, 6, 1, 9, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 3, 6,\n",
      "       6, 6, 6, 6, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 1, 3, 6, 6,\n",
      "       3, 6, 1, 6, 6, 1, 6, 6, 1, 6, 3, 6, 1, 3, 1, 6, 6, 3, 6, 6, 1, 6,\n",
      "       1, 1, 6, 3, 6, 1, 6, 6, 1, 1, 3, 6, 6, 9, 3, 6, 3, 0, 6, 6, 1, 1,\n",
      "       6, 1, 9, 9, 6, 6, 6, 1, 6, 1, 0, 6, 0, 1]), array([6, 6, 6, 1, 1, 1, 6, 1, 1, 1, 6, 1, 6, 6, 1, 1, 1, 0, 1, 1, 3, 6,\n",
      "       6, 1, 6, 6, 1, 6, 6, 3, 1, 6, 1, 6, 6, 6, 1, 6, 6, 6, 1, 6, 9, 6,\n",
      "       3, 6, 1, 1, 3, 1, 6, 3, 6, 1, 6, 6, 6, 6, 1, 6, 1, 1, 1, 1, 1, 7,\n",
      "       7, 1, 1, 1, 1, 6, 6, 1, 6, 1, 6, 6, 6, 7, 1, 1, 1, 1, 1, 6, 9, 6,\n",
      "       1, 1, 6, 6, 6, 6, 6, 1, 1, 6, 9, 1, 6, 1, 6, 6, 9, 6, 1, 3, 9, 6,\n",
      "       1, 6, 6, 6, 6, 1, 6, 6, 1, 6, 3, 6, 3, 0, 6, 6, 3, 6, 6, 0, 3, 3,\n",
      "       6, 1, 6, 1, 3, 1, 3, 0, 0, 6, 3, 6, 1, 0, 6, 6, 3, 6, 6, 1, 1, 1,\n",
      "       6, 1, 1, 3, 3, 3, 6, 1, 1, 1, 1, 6, 6, 6, 6, 1, 1, 1, 3, 1, 1, 1,\n",
      "       1, 3, 1, 6, 7, 6, 9, 6, 6, 1, 6, 3, 6, 6, 6, 6, 1, 6, 7, 6, 6, 9,\n",
      "       6, 1, 1, 6, 6, 6, 6, 6, 6, 3, 6, 1, 1, 6, 6, 6, 6, 6, 6, 1, 6, 6,\n",
      "       6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 3, 6, 3, 6, 6, 6, 6, 3, 3, 6, 3, 6, 6, 3, 6, 6, 6, 6, 6, 6, 3,\n",
      "       3, 3, 0, 6, 6, 3, 3, 1, 3, 6, 6, 1, 3, 3, 6, 1, 6, 6, 3, 3, 6, 3,\n",
      "       3, 6, 1, 3, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6]), array([6, 1, 1, 3, 1, 1, 1, 6, 0, 6, 3, 6, 1, 6, 1, 1, 6, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 6, 1, 1, 6, 6, 6, 6, 3, 0, 6, 6, 1, 6, 3, 6, 3, 1, 1,\n",
      "       1, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 3, 1, 3, 6, 1, 3, 6, 6, 6, 6, 6,\n",
      "       1, 6, 1, 6, 1, 6, 6, 1, 6, 1, 1, 1, 1, 6, 6, 1, 1, 6, 6, 6, 6, 1,\n",
      "       1, 6, 3, 0, 3, 0, 0, 6, 3, 3, 3, 3, 6, 6, 6, 3, 3, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 3, 6, 0, 0, 3, 6, 3, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6,\n",
      "       1, 6, 6, 6, 6, 6, 6, 1, 6, 1, 1, 3, 3, 9, 3, 6, 1, 6, 3, 1, 6, 6,\n",
      "       0, 1, 1, 0, 6, 1, 1, 1, 0, 6, 0, 6, 1, 1, 3, 1, 0, 6, 6, 6, 1, 3,\n",
      "       6, 6, 1, 1, 3, 1, 1, 6, 6, 6, 6, 1, 1, 1, 1, 1, 6, 6, 6, 1, 1, 6,\n",
      "       6, 6, 6, 6, 1, 6, 6, 1, 1, 6, 1, 3, 9, 1, 3, 6, 6, 6, 6, 3, 6, 1,\n",
      "       6, 1, 6, 6, 1, 6, 1, 9, 6, 1, 6, 9, 3, 1, 6, 6, 3, 6, 3, 6, 3, 3,\n",
      "       9, 1, 3, 1, 6, 1, 6, 6, 6, 1, 1, 2, 3, 1, 2, 7, 3, 1, 1, 3, 3, 4,\n",
      "       6, 6, 1, 7, 1, 6, 1, 1, 1, 1, 9, 1, 6, 6, 6, 6, 6, 9, 1, 6, 6, 6,\n",
      "       1, 7, 1, 1, 1, 7, 3, 6, 6, 1, 7, 1, 1, 6]), array([1, 1, 1, 6, 6, 3, 6, 6, 1, 6, 1, 6, 6, 1, 6, 1, 1, 6, 1, 6, 6, 1,\n",
      "       6, 0, 6, 6, 1, 1, 6, 1, 6, 6, 6, 1, 6, 1, 6, 3, 1, 6, 6, 6, 6, 6,\n",
      "       6, 1, 6, 6, 6, 6, 1, 6, 6, 6, 6, 1, 6, 1, 6, 1, 6, 6, 6, 3, 1, 3,\n",
      "       6, 6, 1, 3, 6, 6, 1, 3, 1, 3, 3, 3, 3, 6, 6, 6, 6, 1, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 1, 3, 6, 6, 6, 1, 6, 6, 6, 6, 1, 6, 6, 6, 9, 6, 1, 1,\n",
      "       3, 6, 1, 6, 1, 3, 6, 6, 9, 1, 3, 3, 6, 3, 6, 3, 6, 6, 6, 3, 6, 6,\n",
      "       6, 6, 3, 3, 6, 6, 6, 6, 6, 3, 3, 6, 6, 0, 6, 3, 6, 6, 1, 6, 1, 1,\n",
      "       3, 3, 6, 6, 1, 1, 7, 6, 3, 1, 1, 1, 3, 3, 1, 3, 6, 1, 1, 9, 3, 1,\n",
      "       1, 1, 6, 1, 6, 9, 6, 6, 6, 6, 1, 6, 3, 6, 6, 6, 1, 1, 3, 3, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 7, 6, 6, 6, 3, 9, 1, 3, 6, 6, 3, 6, 1, 6, 6, 6,\n",
      "       3, 3, 1, 3, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 3, 6, 1, 1, 6,\n",
      "       1, 8, 6, 1, 1, 3, 1, 3, 6, 6, 6, 6, 6, 2, 6, 1, 1, 6, 9, 1, 1, 1,\n",
      "       6, 1, 1, 2, 6, 1, 1, 3, 6, 6, 1, 3, 1, 6, 1, 1, 6, 6, 6, 6, 1, 1,\n",
      "       6, 6, 3, 6, 6, 6, 1, 1, 3, 6, 1, 1, 9, 6]), array([6, 6, 1, 6, 3, 6, 6, 1, 1, 1, 6, 1, 1, 6, 6, 6, 3, 3, 6, 6, 6, 3,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 1, 6, 1, 6, 1, 1, 6, 1, 3, 1, 1, 6,\n",
      "       1, 6, 1, 6, 1, 1, 1, 1, 3, 1, 1, 6, 6, 1, 6, 6, 1, 6, 1, 6, 3, 6,\n",
      "       6, 1, 6, 1, 6, 1, 1, 6, 6, 6, 6, 6, 1, 1, 1, 6, 1, 6, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 6, 6, 1, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 1, 6, 1, 6, 6,\n",
      "       6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 1, 1, 3, 6, 6, 3, 0, 6,\n",
      "       3, 6, 6, 1, 6, 6, 1, 6, 6, 1, 6, 6, 6, 6, 6, 9, 6, 1, 6, 6, 6, 6,\n",
      "       6, 1, 6, 1, 6, 6, 0, 1, 6, 6, 6, 3, 6, 1, 1, 6, 6, 6, 3, 1, 6, 6,\n",
      "       6, 1, 1, 6, 6, 6, 6, 9, 1, 6, 6, 6, 6, 6, 1, 6, 6, 6, 1, 6, 6, 6,\n",
      "       1, 1, 1, 6, 6, 1, 1, 6, 6, 1, 6, 6, 3, 6, 1, 6, 6, 3, 6, 6, 1, 3,\n",
      "       1, 3, 3, 6, 3, 6, 3, 1, 1, 6, 6, 1, 1, 6, 6, 1, 6, 1, 6, 6, 0, 6,\n",
      "       6, 3, 1, 6, 6, 6, 6, 6, 0, 6, 3, 6, 3, 6, 6, 6, 3, 6, 3, 6, 6, 6,\n",
      "       1, 3, 6, 6, 3, 6, 6, 6, 6, 1, 1, 1, 9, 1, 6, 3, 1, 7, 1, 7, 7, 9,\n",
      "       1, 1, 1, 6, 6, 1, 1, 6, 1, 1, 6, 6, 1, 6]), array([3, 1, 6, 3, 1, 1, 1, 6, 6, 6, 1, 0, 1, 6, 3, 6, 6, 1, 1, 0, 1, 6,\n",
      "       1, 3, 1, 3, 9, 3, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 1, 1, 6, 6,\n",
      "       6, 6, 0, 1, 1, 6, 6, 6, 6, 3, 6, 6, 3, 6, 3, 3, 1, 1, 3, 1, 6, 6,\n",
      "       1, 6, 6, 1, 1, 3, 6, 1, 3, 6, 1, 1, 6, 3, 6, 3, 3, 1, 6, 1, 1, 6,\n",
      "       1, 1, 6, 3, 6, 6, 3, 3, 1, 6, 6, 6, 6, 0, 3, 6, 1, 0, 6, 3, 6, 3,\n",
      "       6, 1, 3, 6, 6, 6, 6, 0, 6, 6, 6, 3, 6, 1, 3, 6, 6, 6, 3, 6, 3, 6,\n",
      "       6, 6, 6, 6, 6, 3, 3, 3, 3, 6, 6, 6, 6, 6, 3, 6, 1, 6, 3, 3, 6, 6,\n",
      "       1, 6, 1, 3, 0, 6, 3, 6, 1, 6, 3, 6, 6, 6, 6, 6, 6, 3, 6, 6, 9, 6,\n",
      "       3, 3, 1, 6, 6, 6, 6, 6, 0, 6, 6, 6, 6, 3, 3, 6, 6, 6, 6, 1, 3, 6,\n",
      "       6, 6, 6, 6, 6, 3, 6, 6, 1, 6, 6, 6, 6, 1, 6, 1, 1, 1, 6, 6, 1, 6,\n",
      "       6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 6, 6, 6,\n",
      "       3, 6, 6, 3, 3, 6, 3, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6,\n",
      "       6, 6, 3, 6, 6, 6, 1, 6, 6, 6, 6, 1, 6, 6, 1, 6, 1, 1, 6, 1, 3, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 1]), array([1, 6, 6, 6, 6, 6, 1, 1, 6, 1, 6, 1, 6, 1, 1, 1, 6, 1, 6, 1, 1, 6,\n",
      "       6, 1, 6, 1, 6, 1, 1, 6, 1, 6, 1, 6, 6, 1, 6, 6, 1, 3, 1, 6, 3, 6,\n",
      "       6, 1, 6, 6, 6, 6, 6, 6, 1, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1,\n",
      "       3, 1, 3, 6, 1, 1, 1, 6, 6, 1, 6, 1, 1, 1, 1, 1, 1, 6, 1, 3, 6, 1,\n",
      "       6, 1, 6, 6, 6, 1, 6, 1, 6, 9, 1, 6, 1, 3, 9, 1, 6, 6, 6, 1, 6, 6,\n",
      "       1, 6, 6, 1, 1, 6, 1, 3, 3, 6, 1, 1, 3, 6, 3, 6, 6, 1, 6, 1, 6, 6,\n",
      "       6, 6, 1, 6, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 1, 3, 3, 1, 1, 1, 1,\n",
      "       6, 1, 6, 9, 6, 1, 6, 1, 1, 3, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       6, 6, 6, 1, 6, 6, 6, 1, 3, 3, 6, 6, 6, 1, 6, 1, 6, 3, 6, 6, 6, 6,\n",
      "       6, 1, 6, 1, 1, 6, 6, 1, 6, 7, 6, 6, 6, 6, 3, 3, 6, 6, 3, 3, 3, 6,\n",
      "       6, 6, 3, 1, 6, 3, 3, 3, 3, 3, 6, 1, 3, 3, 3, 6, 1, 3, 3, 7, 6, 6,\n",
      "       3, 6, 6, 1, 6, 3, 6, 6, 1, 1, 1, 6, 1, 1, 1, 1, 6, 8, 6, 6, 1, 3,\n",
      "       6, 6, 6, 6, 9, 6, 6, 6, 6, 3, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "       3, 6, 6, 1, 1, 3, 6, 6, 6, 6, 6, 6, 6, 6]), array([6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 7, 6, 1,\n",
      "       1, 9, 1, 1, 1, 1, 6, 1, 0, 1, 6, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 3,\n",
      "       6, 1, 6, 3, 6, 1, 6, 1, 1, 6, 6, 1, 1, 6, 1, 6, 6, 6, 1, 6, 1, 3,\n",
      "       1, 1, 1, 9, 6, 6, 6, 6, 1, 6, 1, 6, 6, 1, 6, 6, 6, 1, 6, 6, 6, 6,\n",
      "       3, 6, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 1, 6, 6, 6, 1,\n",
      "       1, 3, 6, 6, 3, 6, 1, 6, 1, 1, 6, 6, 6, 6, 6, 3, 0, 0, 6, 6, 1, 6,\n",
      "       3, 3, 6, 3, 3, 6, 6, 6, 6, 6, 6, 0, 3, 3, 1, 6, 6, 6, 6, 6, 0, 6,\n",
      "       1, 6, 3, 6, 1, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 1, 6, 3, 6, 6,\n",
      "       1, 6, 6, 1, 1, 6, 1, 6, 1, 6, 1, 1, 1, 6, 6, 6, 6, 6, 1, 6, 1, 1,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 3,\n",
      "       6, 6, 6, 6, 6, 1, 1, 1, 1, 6, 1, 3, 6, 6, 1, 6, 6, 6, 1, 9, 1, 1,\n",
      "       6, 6, 3, 6, 1, 6, 3, 3, 6, 6, 6, 3, 6, 3, 6, 3, 6, 1, 6, 6, 3, 6,\n",
      "       1, 1, 6, 3, 6, 3, 6, 3, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 1, 6, 6, 1, 6, 6, 1, 6, 6, 6]), array([1, 1, 9, 1, 6, 6, 1, 1, 1, 3, 6, 6, 1, 9, 1, 1, 1, 1, 6, 1, 1, 1,\n",
      "       3, 1, 1, 1, 6, 1, 1, 6, 1, 6, 1, 1, 6, 6, 1, 1, 1, 1, 6, 6, 6, 6,\n",
      "       1, 6, 6, 3, 6, 6, 1, 3, 9, 1, 6, 6, 6, 6, 1, 6, 9, 1, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 1, 1, 6, 1, 1, 1, 6, 6, 1, 6, 6, 9, 6, 1, 8, 1, 8, 1,\n",
      "       6, 6, 6, 6, 7, 6, 7, 1, 6, 6, 1, 1, 6, 6, 7, 6, 7, 6, 6, 6, 1, 6,\n",
      "       6, 6, 6, 1, 6, 1, 3, 6, 6, 6, 6, 7, 6, 6, 6, 6, 6, 3, 6, 6, 6, 1,\n",
      "       6, 6, 3, 6, 3, 6, 6, 3, 3, 6, 1, 3, 6, 3, 6, 6, 6, 6, 1, 6, 1, 1,\n",
      "       1, 3, 6, 6, 1, 6, 1, 6, 6, 6, 1, 1, 6, 6, 6, 6, 1, 6, 1, 1, 6, 6,\n",
      "       6, 9, 6, 3, 6, 3, 3, 6, 6, 1, 1, 6, 6, 6, 1, 9, 3, 6, 6, 1, 6, 6,\n",
      "       6, 6, 1, 9, 6, 6, 3, 3, 6, 6, 1, 1, 6, 1, 6, 6, 6, 1, 6, 6, 6, 6,\n",
      "       1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 3, 1, 6, 1, 1, 3, 6, 6, 6, 6, 6,\n",
      "       6, 1, 6, 6, 6, 1, 6, 1, 3, 3, 6, 1, 3, 6, 3, 3, 1, 3, 3, 1, 6, 6,\n",
      "       3, 6, 1, 6, 6, 6, 6, 0, 1, 1, 6, 0, 6, 1, 1, 1, 6, 3, 6, 1, 0, 6,\n",
      "       1, 3, 6, 6, 1, 1, 1, 6, 1, 1, 1, 0, 1, 3]), array([1, 1, 6, 1, 1, 1, 7, 1, 6, 1, 1, 1, 3, 1, 1, 1, 1, 7, 6, 1, 6, 6,\n",
      "       1, 6, 9, 6, 1, 6, 1, 1, 6, 3, 6, 6, 1, 6, 3, 1, 6, 6, 6, 1, 1, 6,\n",
      "       1, 3, 1, 6, 3, 6, 6, 6, 6, 6, 6, 1, 1, 1, 6, 6, 1, 1, 6, 1, 6, 6,\n",
      "       1, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 1, 6, 6, 9, 6, 6, 1, 3, 6, 3, 6,\n",
      "       6, 6, 3, 6, 6, 1, 6, 6, 3, 1, 6, 6, 6, 1, 6, 1, 6, 6, 1, 1, 3, 6,\n",
      "       6, 6, 1, 6, 6, 6, 6, 1, 1, 3, 3, 3, 6, 6, 6, 6, 3, 6, 6, 6, 6, 3,\n",
      "       6, 6, 3, 6, 6, 3, 6, 6, 6, 3, 3, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 1,\n",
      "       6, 6, 1, 1, 6, 1, 6, 6, 1, 1, 6, 6, 1, 6, 1, 1, 1, 1, 9, 0, 6, 1,\n",
      "       6, 1, 3, 6, 6, 1, 6, 1, 6, 6, 3, 6, 6, 6, 9, 6, 6, 3, 6, 6, 6, 3,\n",
      "       6, 6, 6, 1, 3, 1, 1, 6, 7, 1, 6, 6, 6, 3, 3, 6, 1, 6, 3, 6, 6, 1,\n",
      "       3, 6, 6, 1, 6, 6, 6, 6, 6, 6, 3, 6, 6, 3, 6, 3, 6, 6, 3, 6, 3, 3,\n",
      "       1, 6, 6, 6, 3, 0, 1, 1, 6, 6, 3, 1, 6, 1, 1, 0, 1, 6, 6, 6, 6, 3,\n",
      "       6, 1, 6, 6, 1, 1, 6, 1, 1, 6, 6, 6, 1, 6, 6, 9, 1, 1, 1, 6, 1, 1,\n",
      "       6, 1, 1, 1, 6, 6, 6, 1, 3, 6, 6, 6, 1, 1]), array([6, 6, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 6, 3, 6, 6, 1, 6, 1, 1, 1, 1,\n",
      "       1, 6, 6, 1, 3, 1, 1, 1, 6, 1, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 1, 1,\n",
      "       6, 6, 3, 6, 7, 1, 9, 6, 6, 1, 6, 1, 6, 9, 6, 1, 1, 1, 1, 6, 6, 1,\n",
      "       1, 1, 1, 1, 1, 1, 6, 6, 1, 1, 1, 6, 6, 1, 1, 1, 1, 3, 6, 6, 1, 3,\n",
      "       1, 1, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 6, 6, 6, 9,\n",
      "       6, 6, 6, 1, 6, 1, 3, 6, 6, 1, 6, 6, 6, 3, 6, 6, 6, 6, 3, 3, 3, 3,\n",
      "       6, 3, 6, 3, 0, 6, 6, 6, 6, 6, 6, 6, 3, 6, 3, 3, 3, 3, 6, 6, 6, 1,\n",
      "       6, 1, 6, 6, 1, 1, 6, 1, 1, 6, 6, 6, 1, 3, 6, 9, 6, 6, 6, 6, 1, 6,\n",
      "       1, 6, 1, 6, 3, 6, 6, 3, 6, 1, 6, 1, 1, 6, 6, 6, 1, 1, 6, 3, 6, 6,\n",
      "       1, 1, 9, 6, 1, 9, 6, 1, 6, 0, 6, 6, 3, 6, 6, 3, 6, 0, 1, 1, 6, 6,\n",
      "       1, 3, 6, 3, 3, 1, 6, 3, 6, 3, 3, 6, 6, 1, 6, 6, 6, 6, 6, 1, 6, 1,\n",
      "       3, 6, 1, 6, 6, 3, 0, 6, 3, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 3, 1, 6,\n",
      "       6, 6, 3, 1, 6, 6, 1, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6,\n",
      "       1, 6, 6, 6, 6, 1, 6, 1, 1, 6, 6, 1, 6, 6]), array([1, 3, 6, 1, 6, 6, 3, 3, 1, 6, 6, 6, 1, 6, 1, 9, 6, 1, 1, 6, 1, 6,\n",
      "       6, 1, 3, 6, 3, 6, 6, 6, 3, 6, 3, 6, 6, 1, 3, 6, 6, 6, 1, 1, 3, 1,\n",
      "       6, 6, 1, 1, 1, 6, 6, 6, 3, 6, 1, 6, 1, 6, 1, 6, 0, 6, 6, 6, 6, 6,\n",
      "       6, 6, 1, 3, 6, 6, 1, 0, 0, 1, 1, 1, 1, 6, 6, 6, 1, 6, 1, 1, 6, 6,\n",
      "       6, 6, 0, 1, 6, 3, 6, 6, 1, 1, 3, 6, 1, 6, 0, 3, 6, 3, 3, 6, 6, 3,\n",
      "       6, 6, 6, 6, 6, 3, 1, 6, 6, 6, 6, 6, 6, 3, 3, 6, 1, 3, 6, 6, 6, 6,\n",
      "       1, 1, 6, 3, 6, 6, 3, 6, 1, 3, 6, 6, 6, 1, 6, 6, 3, 3, 9, 1, 1, 6,\n",
      "       6, 6, 1, 1, 6, 6, 1, 6, 6, 3, 1, 3, 3, 1, 6, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 6, 6, 6, 6, 0, 6, 0, 6, 6, 6, 6, 6, 1, 6, 6, 9, 6, 3, 0, 6, 6,\n",
      "       3, 0, 6, 6, 0, 6, 6, 1, 6, 6, 6, 1, 6, 6, 1, 1, 3, 3, 3, 3, 0, 6,\n",
      "       6, 6, 3, 6, 1, 3, 6, 6, 3, 1, 1, 6, 3, 6, 3, 1, 1, 9, 6, 3, 3, 3,\n",
      "       6, 3, 3, 3, 6, 6, 6, 3, 6, 1, 6, 6, 1, 6, 6, 6, 3, 3, 1, 6, 6, 1,\n",
      "       6, 3, 6, 3, 6, 3, 6, 6, 6, 6, 6, 6, 3, 3, 6, 6, 3, 6, 3, 6, 6, 6,\n",
      "       6, 6, 3, 3, 6, 6, 3, 6, 6, 6, 3, 6, 6, 6]), array([6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6,\n",
      "       6, 6, 3, 6, 6, 3, 3, 1, 6, 1, 1, 1, 1, 1, 9, 6, 6, 1, 6, 6, 6, 6,\n",
      "       0, 6, 6, 6, 6, 6, 1, 1, 6, 6, 6, 6, 6, 1, 1, 1, 6, 6, 1, 1, 1, 1,\n",
      "       6, 1, 6, 1, 1, 1, 1, 1, 6, 3, 6, 6, 6, 1, 1, 1, 6, 1, 1, 1, 6, 1,\n",
      "       1, 6, 6, 6, 1, 6, 0, 0, 0, 6, 6, 6, 3, 1, 6, 6, 6, 6, 3, 0, 6, 0,\n",
      "       3, 1, 6, 6, 3, 3, 6, 3, 3, 6, 6, 6, 3, 6, 6, 1, 3, 6, 6, 6, 1, 1,\n",
      "       6, 3, 3, 6, 6, 3, 6, 1, 6, 6, 3, 1, 1, 6, 3, 6, 6, 6, 6, 1, 6, 3,\n",
      "       1, 6, 1, 6, 6, 6, 6, 1, 3, 1, 1, 1, 6, 1, 1, 6, 1, 6, 6, 6, 6, 6,\n",
      "       1, 1, 1, 1, 1, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 1, 6, 1, 6,\n",
      "       1, 6, 0, 1, 1, 0, 6, 6, 1, 6, 6, 6, 3, 3, 6, 6, 6, 6, 6, 1, 6, 6,\n",
      "       6, 6, 6, 3, 6, 6, 1, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 6,\n",
      "       6, 1, 6, 1, 6, 6, 6, 6, 1, 3, 6, 3, 6, 6, 6, 6, 1, 6, 3, 1, 6, 6,\n",
      "       3, 0, 6, 1, 1, 0, 6, 6, 6, 6, 1, 1, 1, 6, 6, 6, 6, 6, 1, 6, 1, 1,\n",
      "       1, 1, 6, 6, 6, 1, 6, 6, 6, 6, 6, 3, 6, 1]), array([6, 1, 1, 6, 6, 1, 1, 6, 1, 6, 3, 3, 6, 6, 6, 3, 6, 6, 6, 6, 6, 1,\n",
      "       6, 1, 6, 6, 1, 6, 6, 6, 1, 6, 6, 6, 6, 6, 1, 1, 6, 1, 1, 6, 6, 1,\n",
      "       3, 1, 6, 6, 6, 6, 6, 1, 6, 3, 1, 6, 6, 6, 6, 6, 1, 1, 6, 6, 1, 1,\n",
      "       9, 1, 1, 1, 6, 6, 6, 6, 1, 6, 1, 1, 6, 1, 6, 1, 9, 6, 6, 6, 1, 1,\n",
      "       6, 1, 6, 7, 6, 6, 1, 6, 1, 6, 6, 6, 6, 9, 1, 6, 1, 6, 6, 9, 1, 6,\n",
      "       1, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 9, 6, 6, 6, 6, 6, 3, 6, 6,\n",
      "       6, 6, 6, 1, 6, 1, 3, 3, 3, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6,\n",
      "       3, 1, 6, 1, 3, 6, 1, 3, 6, 6, 6, 6, 6, 6, 3, 3, 6, 1, 6, 6, 1, 3,\n",
      "       6, 1, 1, 6, 3, 6, 6, 6, 1, 3, 6, 6, 6, 3, 6, 6, 6, 6, 6, 1, 1, 1,\n",
      "       0, 3, 3, 6, 6, 3, 3, 6, 3, 6, 1, 0, 6, 6, 3, 6, 6, 6, 1, 3, 3, 2,\n",
      "       3, 8, 1, 9, 1, 1, 0, 6, 6, 2, 6, 1, 6, 6, 3, 7, 8, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 3, 1, 1, 1, 0, 6, 6, 3, 6, 3, 1, 1, 1, 6, 1, 3, 1, 3, 1,\n",
      "       1, 6, 1, 6, 3, 1, 1, 1, 3, 1, 6, 3, 6, 1, 1, 1, 1, 6, 6, 1, 6, 1,\n",
      "       6, 6, 6, 1, 6, 6, 1, 6, 6, 6, 6, 6, 1, 6]), array([1, 3, 3, 6, 6, 6, 6, 1, 9, 1, 6, 9, 1, 1, 7, 6, 3, 1, 1, 6, 3, 6,\n",
      "       6, 6, 6, 1, 1, 6, 6, 6, 6, 1, 1, 3, 6, 6, 6, 6, 6, 6, 3, 3, 6, 6,\n",
      "       3, 9, 6, 1, 6, 1, 6, 6, 6, 6, 6, 3, 6, 6, 6, 1, 1, 1, 6, 3, 6, 6,\n",
      "       6, 6, 6, 6, 3, 9, 1, 3, 6, 1, 1, 1, 1, 3, 1, 6, 3, 6, 1, 3, 1, 3,\n",
      "       1, 3, 6, 6, 6, 6, 1, 6, 6, 1, 1, 1, 6, 6, 3, 6, 6, 1, 6, 6, 3, 1,\n",
      "       1, 9, 3, 3, 1, 6, 6, 1, 1, 6, 1, 6, 1, 6, 1, 7, 1, 1, 1, 7, 1, 6,\n",
      "       6, 6, 6, 6, 1, 6, 6, 6, 1, 1, 6, 6, 6, 1, 6, 7, 6, 6, 1, 6, 9, 6,\n",
      "       6, 6, 1, 1, 1, 3, 6, 1, 1, 1, 1, 6, 1, 6, 6, 6, 3, 1, 1, 1, 6, 1,\n",
      "       1, 0, 6, 1, 6, 3, 6, 1, 3, 1, 6, 3, 1, 1, 1, 1, 6, 1, 6, 9, 6, 1,\n",
      "       1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 1, 1, 1, 6, 1, 3, 6, 6, 1, 3,\n",
      "       6, 1, 6, 6, 6, 6, 3, 6, 6, 6, 9, 3, 6, 6, 1, 6, 3, 6, 1, 6, 1, 1,\n",
      "       1, 6, 1, 6, 3, 6, 6, 1, 6, 6, 6, 6, 6, 9, 6, 3, 6, 9, 1, 6, 3, 6,\n",
      "       6, 1, 3, 1, 6, 6, 3, 6, 1, 1, 6, 6, 0, 6, 1, 0, 9, 1, 6, 6, 6, 3,\n",
      "       3, 1, 1, 6, 3, 1, 0, 3, 1, 3, 1, 6, 3, 6]), array([3, 9, 6, 1, 1, 3, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 3,\n",
      "       1, 6, 6, 6, 6, 1, 1, 6, 6, 6, 6, 6, 3, 9, 6, 6, 1, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 3, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 1, 6, 1,\n",
      "       6, 6, 1, 6, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 1, 6, 6, 3, 6, 1, 6, 1,\n",
      "       1, 1, 1, 3, 6, 1, 6, 3, 1, 3, 6, 3, 6, 3, 6, 6, 3, 3, 1, 3, 6, 1,\n",
      "       6, 3, 1, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 1, 1, 6, 6, 6, 6, 3, 6,\n",
      "       6, 6, 1, 6, 6, 6, 1, 6, 6, 6, 6, 1, 1, 6, 6, 6, 6, 1, 6, 1, 6, 1,\n",
      "       1, 1, 6, 6, 6, 1, 6, 6, 6, 6, 6, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 1, 1, 1, 6, 7, 7, 6, 7, 1, 1, 6, 6,\n",
      "       6, 1, 1, 6, 6, 1, 6, 6, 6, 1, 1, 6, 6, 6, 6, 1, 6, 7, 6, 6, 6, 1,\n",
      "       9, 6, 3, 1, 3, 3, 6, 3, 7, 6, 3, 6, 1, 1, 6, 3, 6, 3, 3, 6, 6, 3,\n",
      "       6, 6, 6, 1, 1, 6, 3, 6, 3, 1, 1, 3, 6, 3, 3, 6, 3, 6, 6, 6, 6, 3,\n",
      "       6, 3, 6, 6, 3, 6, 6, 6, 6, 9, 3, 9, 6, 9, 6, 6, 6, 6, 1, 1, 1, 0,\n",
      "       6, 6, 1, 6, 1, 6, 1, 9, 6, 1, 6, 1, 6, 9]), array([6, 6, 6, 6, 1, 6, 1, 6, 6, 3, 6, 1, 6, 1, 6, 1, 1, 1, 0, 1, 9, 6,\n",
      "       6, 1, 1, 1, 6, 1, 0, 1, 1, 3, 6, 6, 6, 6, 1, 3, 6, 6, 6, 6, 1, 3,\n",
      "       6, 1, 6, 6, 3, 6, 6, 1, 3, 1, 3, 6, 3, 3, 3, 3, 6, 1, 6, 1, 1, 6,\n",
      "       1, 3, 6, 1, 6, 1, 6, 6, 1, 6, 1, 6, 1, 1, 6, 1, 1, 6, 1, 6, 1, 6,\n",
      "       6, 1, 6, 1, 1, 6, 6, 6, 6, 3, 1, 1, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 0, 6, 6, 6, 1, 1, 3, 6, 1, 1, 6, 6, 6, 6, 6, 6, 1, 1, 1, 6, 1,\n",
      "       9, 7, 6, 1, 1, 1, 6, 1, 6, 6, 1, 6, 6, 1, 1, 1, 1, 6, 1, 1, 1, 0,\n",
      "       6, 3, 6, 3, 1, 0, 1, 3, 6, 1, 1, 1, 6, 3, 0, 3, 1, 1, 1, 3, 1, 1,\n",
      "       1, 3, 1, 1, 6, 1, 6, 6, 6, 1, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "       3, 6, 6, 3, 6, 6, 1, 3, 6, 6, 6, 1, 2, 1, 6, 6, 6, 9, 1, 6, 6, 6,\n",
      "       6, 9, 6, 6, 6, 6, 1, 3, 3, 7, 6, 6, 6, 1, 6, 6, 6, 1, 6, 1, 6, 6,\n",
      "       6, 3, 6, 6, 6, 3, 1, 6, 6, 6, 6, 1, 6, 6, 1, 1, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 3, 6, 6, 6, 1, 1, 6, 1, 6, 1, 6, 6, 1, 6, 1, 1, 6, 6, 6,\n",
      "       6, 6, 7, 1, 1, 1, 6, 6, 1, 6, 1, 1, 1, 6]), array([1, 6, 1, 1, 3, 1, 1, 1, 6, 1, 1, 6, 3, 1, 1, 1, 1, 1, 3, 1, 1, 1,\n",
      "       1, 1, 6, 3, 1, 6, 1, 9, 6, 6, 6, 1, 1, 3, 6, 9, 6, 1, 6, 3, 0, 6,\n",
      "       6, 3, 1, 1, 1, 3, 6, 6, 0, 1, 6, 1, 1, 1, 9, 3, 6, 6, 1, 6, 6, 6,\n",
      "       1, 6, 3, 6, 6, 6, 1, 1, 6, 1, 6, 1, 1, 6, 6, 1, 1, 1, 3, 1, 3, 6,\n",
      "       3, 6, 9, 6, 6, 3, 1, 1, 6, 6, 3, 6, 1, 1, 6, 1, 3, 7, 3, 1, 6, 6,\n",
      "       6, 6, 1, 1, 6, 6, 6, 6, 1, 7, 6, 6, 1, 1, 6, 6, 0, 3, 6, 6, 1, 3,\n",
      "       3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6,\n",
      "       1, 6, 1, 6, 6, 6, 6, 6, 6, 1, 6, 6, 1, 6, 1, 6, 6, 6, 6, 6, 0, 6,\n",
      "       6, 6, 6, 0, 6, 6, 3, 7, 6, 6, 1, 6, 6, 6, 1, 6, 7, 6, 9, 6, 6, 7,\n",
      "       6, 6, 6, 6, 1, 1, 6, 6, 1, 1, 6, 6, 6, 6, 1, 3, 3, 6, 6, 3, 6, 1,\n",
      "       6, 6, 6, 6, 7, 6, 6, 1, 3, 6, 1, 6, 3, 3, 6, 6, 6, 3, 7, 3, 6, 9,\n",
      "       1, 1, 9, 6, 6, 9, 3, 3, 1, 6, 7, 6, 1, 3, 6, 6, 6, 3, 1, 9, 9, 6,\n",
      "       7, 6, 1, 6, 1, 1, 1, 6, 6, 3, 3, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 3, 6, 6, 1, 6, 6, 6, 6]), array([6, 6, 1, 1, 6, 6, 6, 1, 1, 6, 0, 1, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6,\n",
      "       1, 6, 1, 6, 6, 6, 6, 6, 3, 6, 3, 3, 3, 1, 6, 1, 6, 3, 1, 1, 1, 3,\n",
      "       1, 6, 6, 6, 6, 1, 1, 6, 6, 3, 6, 6, 6, 6, 1, 6, 1, 1, 1, 1, 6, 1,\n",
      "       6, 1, 6, 3, 1, 3, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 1, 6, 6, 6, 1,\n",
      "       6, 1, 6, 6, 6, 9, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 6, 6, 6, 1, 1,\n",
      "       6, 6, 9, 6, 1, 6, 1, 6, 6, 9, 6, 1, 6, 6, 1, 6, 6, 6, 3, 1, 6, 6,\n",
      "       1, 1, 6, 6, 6, 9, 1, 6, 1, 9, 6, 6, 1, 6, 1, 3, 1, 9, 1, 6, 6, 1,\n",
      "       1, 1, 1, 6, 6, 3, 6, 1, 1, 3, 3, 6, 3, 6, 6, 0, 3, 3, 3, 1, 1, 6,\n",
      "       3, 1, 3, 3, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 1, 6, 6, 7, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 1, 3, 1, 6, 6, 1, 7, 6, 1, 6,\n",
      "       7, 3, 3, 6, 6, 7, 6, 6, 1, 1, 1, 7, 1, 6, 7, 3, 3, 1, 6, 6, 1, 1,\n",
      "       1, 6, 1, 1, 1, 1, 6, 6, 6, 9, 1, 9, 1, 6, 9, 1, 3, 6, 6, 3, 1, 3,\n",
      "       3, 1, 6, 9, 1, 7, 1, 6, 6, 6, 6, 6, 6, 6, 3, 6, 1, 6, 3, 3, 6, 6,\n",
      "       1, 1, 6, 1, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6]), array([6, 1, 3, 1, 1, 1, 1, 1, 6, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1,\n",
      "       6, 6, 6, 6, 1, 1, 1, 6, 6, 6, 6, 1, 1, 3, 1, 6, 3, 1, 1, 6, 3, 1,\n",
      "       1, 1, 1, 6, 6, 3, 1, 3, 1, 6, 1, 3, 1, 3, 6, 6, 3, 6, 6, 6, 1, 6,\n",
      "       1, 6, 1, 6, 6, 6, 3, 6, 3, 6, 3, 6, 3, 6, 6, 1, 6, 6, 6, 6, 1, 6,\n",
      "       1, 6, 1, 6, 9, 6, 6, 6, 1, 6, 6, 1, 6, 6, 1, 6, 6, 6, 1, 1, 6, 6,\n",
      "       9, 1, 6, 6, 6, 6, 6, 1, 6, 6, 3, 3, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 0, 3, 1, 6, 9, 6, 6, 6, 9, 3, 6, 6, 6, 6, 1, 3, 6, 1, 6,\n",
      "       6, 1, 6, 1, 6, 1, 0, 0, 1, 0, 6, 1, 6, 1, 1, 1, 6, 6, 6, 6, 3, 1,\n",
      "       1, 6, 1, 6, 6, 6, 1, 9, 1, 6, 0, 6, 3, 1, 0, 6, 6, 3, 6, 6, 6, 1,\n",
      "       6, 6, 0, 0, 6, 6, 6, 6, 1, 6, 6, 6, 6, 3, 6, 6, 6, 3, 6, 3, 6, 6,\n",
      "       1, 6, 1, 7, 1, 3, 3, 6, 6, 3, 6, 1, 6, 7, 3, 6, 1, 6, 1, 6, 1, 0,\n",
      "       6, 6, 3, 6, 7, 6, 9, 1, 9, 1, 6, 6, 1, 6, 3, 1, 9, 1, 6, 1, 1, 1,\n",
      "       1, 6, 9, 6, 6, 3, 6, 1, 1, 6, 1, 1, 6, 6, 1, 7, 6, 6, 6, 1, 6, 1,\n",
      "       1, 6, 6, 6, 9, 6, 1, 1, 6, 6, 1, 1, 1, 1]), array([1, 1, 6, 6, 1, 1, 6, 1, 1, 6, 1, 6, 1, 3, 1, 1, 1, 3, 1, 1, 1, 1,\n",
      "       1, 3, 1, 1, 6, 1, 1, 3, 1, 1, 1, 6, 6, 6, 3, 6, 1, 1, 3, 6, 6, 6,\n",
      "       6, 6, 3, 3, 1, 6, 6, 6, 6, 6, 3, 6, 1, 6, 1, 0, 6, 6, 1, 6, 1, 1,\n",
      "       6, 1, 0, 6, 1, 1, 6, 1, 1, 1, 1, 1, 1, 6, 6, 6, 0, 1, 1, 1, 6, 6,\n",
      "       1, 6, 6, 6, 3, 6, 1, 9, 6, 7, 6, 6, 1, 6, 6, 6, 1, 6, 1, 6, 6, 3,\n",
      "       6, 6, 6, 9, 6, 1, 6, 9, 6, 1, 6, 6, 3, 6, 6, 6, 3, 6, 6, 6, 6, 6,\n",
      "       6, 3, 1, 1, 6, 6, 6, 6, 6, 3, 9, 3, 6, 3, 6, 6, 6, 6, 6, 1, 3, 1,\n",
      "       3, 6, 3, 6, 1, 1, 1, 1, 3, 6, 1, 9, 1, 1, 3, 1, 6, 6, 1, 1, 6, 1,\n",
      "       1, 1, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 7, 6, 6, 6, 6, 6, 3, 9, 3, 6,\n",
      "       3, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 3, 1, 6, 1, 6, 3, 3, 1, 3, 3, 6,\n",
      "       6, 1, 6, 6, 6, 6, 6, 6, 3, 3, 3, 6, 6, 1, 6, 6, 6, 6, 3, 3, 3, 3,\n",
      "       6, 3, 1, 6, 6, 3, 6, 6, 6, 1, 6, 6, 6, 1, 6, 6, 1, 1, 1, 6, 1, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 3, 6, 1, 6, 6, 6, 1]), array([6, 6, 1, 6, 6, 6, 1, 6, 6, 6, 1, 1, 1, 1, 6, 3, 6, 1, 1, 1, 1, 6,\n",
      "       6, 1, 1, 6, 1, 6, 1, 1, 6, 6, 1, 6, 1, 1, 6, 3, 6, 9, 6, 6, 6, 6,\n",
      "       6, 6, 6, 1, 1, 1, 6, 1, 6, 7, 7, 6, 6, 6, 6, 1, 1, 9, 6, 1, 3, 1,\n",
      "       3, 1, 1, 1, 6, 6, 6, 1, 1, 9, 1, 6, 6, 1, 3, 1, 6, 6, 1, 6, 1, 1,\n",
      "       6, 6, 6, 3, 6, 0, 3, 3, 3, 6, 6, 6, 6, 3, 6, 3, 6, 6, 6, 6, 6, 6,\n",
      "       6, 3, 3, 3, 3, 6, 3, 0, 3, 3, 6, 6, 6, 6, 9, 6, 1, 6, 1, 6, 6, 3,\n",
      "       3, 1, 6, 6, 6, 6, 6, 9, 6, 6, 6, 6, 1, 6, 6, 6, 1, 6, 1, 3, 6, 6,\n",
      "       6, 1, 6, 1, 3, 6, 1, 6, 1, 9, 6, 6, 6, 6, 1, 1, 1, 1, 1, 6, 6, 6,\n",
      "       0, 6, 6, 1, 6, 6, 1, 1, 6, 1, 9, 9, 6, 6, 6, 1, 1, 6, 1, 1, 6, 6,\n",
      "       6, 1, 1, 9, 9, 6, 1, 6, 6, 6, 9, 1, 6, 6, 6, 1, 3, 3, 1, 6, 9, 9,\n",
      "       6, 1, 9, 1, 6, 1, 6, 9, 1, 6, 6, 3, 6, 7, 9, 1, 6, 6, 3, 3, 9, 1,\n",
      "       3, 3, 6, 3, 1, 6, 1, 6, 1, 6, 9, 1, 8, 6, 6, 6, 1, 1, 7, 1, 6, 1,\n",
      "       9, 1, 1, 1, 7, 1, 3, 1, 6, 6, 6, 3, 1, 3, 6, 6, 6, 6, 6, 6, 3, 1,\n",
      "       6, 6, 6, 3, 6, 3, 6, 6, 3, 6, 6, 6, 3, 3]), array([6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 6, 3, 6, 1, 3, 6, 6, 6, 6, 6, 6, 6,\n",
      "       3, 6, 6, 9, 6, 9, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 1,\n",
      "       6, 6, 6, 6, 6, 6, 1, 6, 7, 6, 6, 6, 6, 6, 6, 7, 6, 3, 6, 0, 6, 6,\n",
      "       0, 6, 6, 6, 3, 6, 1, 6, 6, 6, 6, 3, 0, 1, 1, 3, 1, 6, 6, 1, 6, 1,\n",
      "       6, 1, 3, 6, 3, 1, 3, 1, 6, 6, 1, 3, 9, 6, 6, 1, 6, 3, 6, 6, 1, 6,\n",
      "       1, 6, 6, 1, 6, 3, 9, 6, 6, 1, 1, 1, 1, 6, 1, 1, 7, 6, 6, 9, 1, 6,\n",
      "       6, 6, 1, 6, 1, 6, 1, 6, 6, 1, 7, 6, 6, 1, 7, 1, 7, 9, 0, 0, 1, 1,\n",
      "       6, 0, 6, 1, 6, 1, 6, 1, 6, 6, 1, 6, 6, 1, 6, 6, 6, 1, 6, 3, 6, 3,\n",
      "       6, 1, 6, 6, 6, 1, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 3,\n",
      "       6, 1, 6, 6, 3, 6, 1, 6, 6, 3, 6, 1, 6, 0, 6, 1, 1, 6, 6, 1, 6, 1,\n",
      "       0, 0, 6, 6, 3, 6, 3, 6, 6, 1, 6, 6, 6, 1, 6, 3, 6, 6, 6, 1, 6, 6,\n",
      "       1, 6, 6, 1, 6, 6, 6, 1, 6, 6, 1, 1, 3, 6, 1, 6, 1, 1, 1, 6, 6, 6,\n",
      "       1, 6, 3, 3, 6, 7, 6, 6, 6, 1, 6, 6, 3, 1, 6, 1, 6, 6, 6, 6, 6, 6,\n",
      "       1, 1, 6, 6, 3, 1, 6, 6, 6, 6, 1, 6, 1, 6]), array([1, 1, 1, 3, 1, 9, 1, 3, 6, 1, 1, 1, 1, 6, 1, 6, 1, 1, 1, 1, 6, 1,\n",
      "       6, 1, 1, 1, 6, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 7, 6, 6,\n",
      "       1, 6, 6, 1, 6, 6, 7, 1, 1, 6, 9, 1, 6, 1, 6, 6, 1, 1, 1, 1, 3, 6,\n",
      "       1, 6, 6, 1, 3, 1, 6, 1, 6, 6, 6, 3, 1, 6, 1, 6, 3, 6, 6, 6, 1, 6,\n",
      "       6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 1, 6, 3, 0, 1, 6, 3, 3, 6,\n",
      "       6, 1, 6, 0, 6, 6, 6, 6, 6, 6, 3, 6, 3, 3, 3, 3, 6, 3, 3, 6, 3, 6,\n",
      "       1, 6, 6, 6, 3, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 1, 3, 1, 6, 1, 6, 6,\n",
      "       1, 6, 1, 6, 1, 3, 6, 6, 6, 6, 6, 1, 1, 6, 6, 6, 1, 6, 1, 6, 1, 6,\n",
      "       1, 6, 3, 6, 1, 3, 6, 1, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6,\n",
      "       1, 6, 1, 6, 6, 6, 0, 1, 6, 9, 1, 6, 3, 1, 3, 3, 1, 6, 0, 1, 3, 6,\n",
      "       6, 1, 6, 6, 6, 1, 1, 1, 6, 6, 3, 6, 3, 6, 6, 6, 0, 0, 6, 6, 3, 3,\n",
      "       6, 6, 1, 6, 3, 3, 3, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 3, 6, 1, 3, 1, 6, 6, 6, 6, 6, 6, 6, 1, 3, 6, 1, 6, 1,\n",
      "       6, 1, 1, 6, 1, 6, 6, 6, 6, 1, 6, 1, 6, 1]), array([9, 6, 6, 6, 3, 1, 6, 6, 3, 6, 6, 6, 6, 6, 6, 1, 3, 3, 1, 3, 1, 9,\n",
      "       1, 6, 6, 1, 1, 3, 6, 1, 1, 6, 6, 6, 6, 1, 1, 6, 1, 6, 6, 6, 1, 6,\n",
      "       6, 6, 1, 6, 6, 0, 6, 6, 6, 1, 6, 6, 1, 0, 3, 1, 1, 6, 6, 6, 6, 1,\n",
      "       6, 1, 3, 6, 6, 6, 1, 6, 6, 6, 6, 1, 6, 6, 6, 1, 6, 1, 1, 9, 6, 1,\n",
      "       1, 6, 3, 6, 1, 3, 6, 6, 6, 0, 3, 0, 6, 6, 3, 6, 3, 6, 0, 6, 0, 6,\n",
      "       3, 6, 3, 3, 0, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 3, 6, 7, 6, 6, 6, 1,\n",
      "       6, 6, 6, 3, 6, 1, 7, 7, 6, 6, 6, 6, 3, 6, 6, 3, 6, 6, 6, 6, 1, 1,\n",
      "       1, 1, 1, 6, 1, 6, 6, 1, 3, 1, 6, 6, 6, 6, 3, 1, 1, 1, 6, 1, 6, 1,\n",
      "       6, 6, 1, 1, 6, 9, 9, 6, 0, 3, 6, 1, 1, 3, 6, 6, 0, 1, 6, 6, 6, 9,\n",
      "       0, 6, 6, 1, 1, 6, 6, 8, 1, 6, 1, 6, 1, 6, 6, 0, 0, 6, 6, 0, 6, 3,\n",
      "       3, 6, 6, 6, 3, 3, 6, 0, 0, 3, 1, 1, 0, 3, 6, 0, 1, 1, 0, 6, 6, 6,\n",
      "       6, 1, 3, 1, 6, 1, 6, 3, 3, 6, 6, 6, 3, 3, 1, 3, 6, 6, 6, 6, 3, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 1, 1, 1, 1, 3, 6, 6, 6, 1, 1, 6,\n",
      "       6, 3, 1, 1, 6, 6, 1, 1, 1, 6, 6, 6, 6, 6]), array([1, 6, 1, 1, 6, 6, 6, 6, 3, 0, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 1, 1, 1, 3, 6, 6, 6, 6, 1, 3, 1, 6, 6, 6, 3, 6, 6, 6, 6, 1, 6,\n",
      "       3, 1, 6, 3, 1, 9, 3, 6, 6, 6, 1, 1, 6, 1, 6, 6, 6, 6, 1, 1, 6, 6,\n",
      "       1, 6, 1, 1, 1, 1, 3, 6, 6, 1, 1, 6, 3, 1, 3, 6, 1, 6, 6, 6, 6, 6,\n",
      "       1, 6, 6, 1, 6, 6, 6, 6, 1, 1, 6, 6, 6, 6, 1, 6, 6, 1, 1, 6, 6, 6,\n",
      "       6, 1, 6, 6, 1, 1, 6, 6, 1, 6, 6, 1, 8, 1, 6, 1, 6, 1, 1, 1, 6, 1,\n",
      "       6, 1, 1, 1, 6, 6, 6, 1, 1, 7, 1, 6, 7, 6, 1, 6, 6, 1, 6, 1, 6, 6,\n",
      "       6, 6, 3, 0, 6, 6, 3, 6, 6, 1, 1, 1, 6, 0, 1, 0, 6, 0, 6, 6, 1, 6,\n",
      "       6, 6, 1, 6, 6, 6, 6, 6, 9, 6, 1, 0, 6, 6, 6, 6, 6, 3, 0, 1, 9, 0,\n",
      "       6, 6, 6, 6, 6, 1, 6, 6, 0, 6, 6, 6, 3, 6, 0, 6, 3, 6, 3, 6, 3, 0,\n",
      "       6, 6, 3, 3, 0, 6, 6, 6, 3, 6, 3, 6, 6, 0, 0, 6, 6, 6, 3, 3, 1, 3,\n",
      "       3, 1, 3, 3, 3, 6, 1, 1, 6, 1, 3, 6, 6, 6, 3, 6, 6, 3, 6, 1, 6, 1,\n",
      "       3, 0, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 3, 6, 3, 6, 3,\n",
      "       6, 6, 3, 1, 6, 6, 1, 6, 6, 3, 6, 3, 3, 6]), array([6, 6, 6, 6, 6, 3, 6, 1, 6, 1, 6, 6, 6, 6, 3, 1, 6, 6, 6, 6, 6, 1,\n",
      "       6, 3, 6, 3, 6, 6, 6, 3, 6, 6, 9, 6, 3, 1, 6, 0, 9, 6, 3, 6, 6, 6,\n",
      "       6, 3, 1, 6, 6, 9, 6, 6, 1, 3, 6, 3, 3, 6, 3, 6, 6, 1, 1, 6, 1, 6,\n",
      "       6, 3, 6, 1, 6, 6, 1, 1, 3, 6, 6, 1, 6, 6, 6, 1, 6, 1, 1, 1, 1, 6,\n",
      "       1, 1, 1, 8, 1, 6, 9, 1, 6, 6, 6, 1, 6, 1, 6, 6, 6, 6, 3, 1, 6, 6,\n",
      "       6, 6, 1, 6, 6, 6, 1, 1, 6, 6, 7, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 1, 3, 3, 6, 1, 6, 6, 1, 6, 1, 6, 6, 1, 6, 6, 6, 1, 6,\n",
      "       6, 6, 6, 1, 9, 6, 1, 6, 6, 6, 9, 6, 6, 1, 6, 6, 6, 6, 6, 6, 3, 6,\n",
      "       1, 1, 6, 3, 9, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 9, 6, 6, 6, 6, 1, 3,\n",
      "       9, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 1, 6, 6, 1, 1,\n",
      "       6, 3, 1, 1, 6, 6, 3, 6, 6, 6, 6, 6, 1, 6, 6, 1, 9, 3, 6, 6, 6, 6,\n",
      "       1, 6, 6, 6, 6, 3, 6, 6, 6, 3, 1, 6, 6, 6, 6, 6, 6, 1, 6, 6, 1, 3,\n",
      "       6, 6, 6, 1, 1, 6, 6, 1, 6, 6, 6, 6, 6, 6, 1, 6, 3, 1, 1, 6, 6, 6,\n",
      "       3, 6, 6, 3, 6, 1, 6, 6, 6, 6, 3, 6, 6, 6]), array([6, 1, 6, 6, 6, 6, 6, 6, 1, 6, 3, 6, 1, 6, 1, 1, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 3, 6, 6, 6, 3, 8, 6, 6, 6,\n",
      "       6, 9, 1, 6, 6, 1, 6, 1, 3, 6, 9, 6, 6, 8, 1, 6, 1, 1, 6, 6, 1, 1,\n",
      "       1, 1, 6, 6, 1, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 6, 6, 1, 6, 1,\n",
      "       6, 1, 6, 3, 0, 6, 3, 3, 6, 6, 0, 6, 6, 6, 6, 0, 6, 3, 6, 3, 6, 3,\n",
      "       6, 6, 6, 6, 6, 3, 6, 3, 3, 6, 0, 9, 6, 6, 6, 6, 1, 6, 0, 3, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 9, 6, 6, 6, 6, 3, 6, 3, 3, 6, 0, 0, 3, 3, 6, 3,\n",
      "       3, 1, 6, 3, 6, 1, 1, 1, 6, 1, 3, 3, 3, 3, 1, 1, 3, 3, 6, 1, 6, 3,\n",
      "       6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 6, 1, 6, 0, 1, 6, 6, 1,\n",
      "       6, 6, 6, 6, 1, 6, 6, 3, 3, 1, 6, 3, 1, 3, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "       1, 3, 6, 6, 1, 6, 1, 6, 6, 3, 0, 6, 6, 1, 6, 6, 6, 6, 6, 6, 9, 1,\n",
      "       3, 3, 6, 6, 1, 1, 6, 6, 7, 1, 6, 3, 1, 3, 3, 1, 1, 3, 8, 1, 7, 1,\n",
      "       6, 1, 6, 6, 1, 3, 6, 6, 1, 1, 1, 6, 6, 6, 3, 6, 6, 6, 1, 6, 6, 3,\n",
      "       6, 6, 6, 6, 1, 6, 6, 1, 6, 6, 1, 1, 6, 6]), array([1, 6, 6, 6, 6, 1, 6, 6, 1, 6, 6, 6, 1, 1, 6, 6, 1, 1, 6, 6, 6, 6,\n",
      "       1, 6, 6, 6, 6, 6, 9, 6, 6, 9, 6, 1, 1, 6, 1, 1, 6, 1, 6, 6, 6, 1,\n",
      "       6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 1, 1, 1, 6, 9, 1, 1, 6, 3, 1, 1, 1,\n",
      "       1, 1, 1, 6, 1, 1, 1, 6, 6, 6, 6, 6, 1, 1, 1, 1, 6, 9, 1, 6, 3, 6,\n",
      "       6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 1, 6, 6, 6, 1, 1,\n",
      "       6, 6, 6, 1, 3, 1, 6, 6, 6, 6, 6, 3, 6, 0, 3, 0, 6, 6, 6, 0, 0, 6,\n",
      "       3, 6, 3, 6, 3, 3, 3, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 3, 1, 1, 3, 3,\n",
      "       6, 3, 1, 1, 3, 6, 6, 3, 1, 3, 1, 1, 1, 6, 6, 3, 6, 6, 1, 6, 1, 1,\n",
      "       6, 3, 1, 1, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 9, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 9, 3, 1, 9, 6, 3, 1, 8,\n",
      "       6, 6, 3, 1, 6, 1, 6, 1, 6, 6, 6, 6, 9, 6, 1, 3, 1, 3, 3, 1, 3, 1,\n",
      "       6, 6, 1, 6, 6, 6, 6, 6, 1, 6, 6, 1, 6, 1, 6, 3, 3, 6, 1, 6, 6, 6,\n",
      "       3, 3, 6, 1, 6, 1, 1, 6, 6, 6, 1, 1, 1, 6, 6, 1, 1, 6, 7, 6, 1, 6,\n",
      "       9, 1, 1, 6, 1, 6, 6, 6, 1, 1, 6, 6, 1, 7]), array([1, 1, 1, 6, 1, 1, 1, 1, 6, 3, 1, 1, 6, 1, 1, 3, 1, 6, 1, 6, 1, 1,\n",
      "       1, 1, 9, 0, 1, 1, 3, 1, 9, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 1, 9, 1,\n",
      "       9, 6, 6, 6, 1, 6, 1, 6, 1, 1, 1, 6, 6, 6, 6, 1, 6, 9, 6, 1, 6, 6,\n",
      "       6, 6, 1, 1, 6, 3, 6, 6, 1, 1, 6, 1, 6, 1, 6, 6, 1, 1, 6, 1, 1, 1,\n",
      "       1, 6, 1, 9, 6, 1, 1, 1, 1, 1, 9, 9, 7, 6, 1, 9, 9, 9, 6, 7, 1, 6,\n",
      "       1, 6, 6, 6, 1, 9, 6, 6, 7, 6, 1, 6, 1, 6, 6, 6, 6, 6, 9, 1, 6, 6,\n",
      "       1, 6, 6, 1, 6, 6, 6, 6, 6, 1, 6, 1, 1, 6, 9, 1, 6, 1, 1, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 3, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 3, 3, 1,\n",
      "       3, 6, 6, 6, 6, 6, 1, 1, 3, 1, 3, 6, 3, 6, 1, 6, 3, 1, 3, 3, 6, 6,\n",
      "       1, 3, 6, 3, 3, 3, 3, 1, 1, 3, 1, 9, 6, 6, 6, 6, 6, 6, 3, 0, 6, 3,\n",
      "       1, 6, 6, 6, 6, 3, 0, 3, 3, 3, 6, 3, 3, 6, 3, 6, 6, 0, 6, 6, 6, 6,\n",
      "       1, 1, 1, 1, 6, 6, 1, 3, 1, 6, 6, 3, 3, 1, 6, 1, 6, 6, 3, 3, 6, 0,\n",
      "       1, 1, 3, 6, 3, 6, 6, 1, 6, 6, 6, 1, 6, 1, 3, 6, 6, 1, 6, 9, 1, 6,\n",
      "       6, 3, 6, 6, 6, 1, 6, 1, 6, 6, 1, 1, 9, 6]), array([6, 1, 1, 1, 1, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 9, 6, 6, 6, 1, 6, 6,\n",
      "       6, 6, 6, 6, 6, 1, 1, 6, 6, 1, 1, 6, 6, 9, 1, 6, 6, 6, 6, 1, 6, 0,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 0, 1, 3, 1, 1,\n",
      "       1, 1, 6, 1, 1, 6, 6, 3, 1, 6, 1, 6, 6, 6, 1, 1, 1, 1, 3, 6, 1, 1,\n",
      "       3, 1, 6, 6, 6, 6, 6, 6, 7, 3, 1, 7, 3, 1, 6, 6, 6, 1, 6, 6, 6, 6,\n",
      "       6, 7, 7, 1, 6, 6, 6, 6, 6, 1, 9, 6, 1, 6, 1, 1, 1, 1, 1, 3, 1, 9,\n",
      "       6, 1, 1, 6, 6, 9, 1, 6, 3, 6, 1, 6, 6, 6, 1, 6, 6, 6, 6, 6, 3, 1,\n",
      "       1, 6, 6, 6, 1, 3, 6, 1, 1, 6, 6, 6, 6, 1, 6, 6, 1, 1, 3, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 9, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 1, 3, 1, 6, 3, 1, 6, 1, 0, 6,\n",
      "       6, 9, 6, 7, 1, 6, 8, 3, 1, 6, 3, 1, 6, 6, 6, 6, 6, 1, 2, 0, 6, 6,\n",
      "       6, 6, 3, 3, 0, 1, 3, 3, 6, 6, 3, 1, 6, 6, 3, 0, 6, 3, 6, 6, 1, 6,\n",
      "       6, 6, 1, 3, 6, 6, 1, 6, 3, 1, 0, 6, 6, 3, 6, 6, 6, 6, 6, 3, 3, 6,\n",
      "       1, 6, 6, 1, 6, 6, 1, 3, 6, 1, 6, 6, 6, 6]), array([6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 1, 6, 1, 6, 6,\n",
      "       3, 1, 6, 6, 1, 6, 6, 1, 1, 6, 6, 6, 1, 6, 6, 6, 9, 6, 6, 6, 1, 6,\n",
      "       1, 6, 6, 1, 1, 6, 6, 3, 1, 0, 6, 6, 6, 6, 6, 6, 1, 1, 7, 6, 6, 6,\n",
      "       1, 6, 1, 1, 6, 1, 1, 1, 6, 1, 1, 6, 1, 6, 6, 6, 6, 6, 1, 7, 6, 6,\n",
      "       1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 3, 3, 3, 6, 6, 6, 1, 6, 3, 6,\n",
      "       3, 3, 6, 6, 1, 6, 3, 6, 6, 3, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 3, 3, 6, 1, 6, 6, 3, 6, 3, 3, 6, 3, 1, 6, 6, 1, 3, 6, 1, 1, 6,\n",
      "       1, 1, 1, 1, 6, 1, 6, 6, 6, 6, 6, 6, 1, 1, 9, 1, 1, 6, 6, 1, 1, 6,\n",
      "       7, 6, 9, 6, 1, 1, 6, 6, 6, 6, 3, 1, 6, 6, 1, 6, 1, 6, 6, 1, 6, 6,\n",
      "       6, 1, 1, 6, 6, 9, 1, 6, 3, 6, 6, 1, 6, 6, 3, 3, 3, 3, 6, 6, 6, 6,\n",
      "       3, 0, 1, 0, 3, 6, 6, 6, 6, 1, 3, 6, 6, 3, 3, 3, 3, 6, 6, 3, 3, 1,\n",
      "       6, 1, 6, 6, 1, 6, 6, 6, 1, 3, 1, 6, 6, 3, 1, 6, 3, 1, 3, 6, 1, 6,\n",
      "       1, 3, 3, 6, 3, 1, 6, 1, 7, 1, 1, 1, 1, 7, 1, 6, 6, 6, 1, 6, 6, 6,\n",
      "       6, 6, 1, 6, 1, 1, 7, 6, 6, 6, 1, 6, 6, 1]), array([3, 6, 6, 1, 1, 7, 6, 1, 1, 1, 6, 6, 1, 1, 1, 6, 6, 6, 1, 6, 6, 1,\n",
      "       6, 6, 1, 1, 1, 6, 6, 6, 1, 1, 6, 6, 6, 6, 6, 1, 6, 1, 6, 6, 6, 6,\n",
      "       6, 1, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 3, 6, 7, 6, 6, 1, 3,\n",
      "       6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 7, 1, 6, 1, 6, 1, 6, 7, 1, 1, 6, 6,\n",
      "       7, 1, 3, 1, 3, 6, 6, 6, 3, 6, 6, 6, 0, 6, 1, 3, 6, 6, 6, 6, 9, 1,\n",
      "       6, 6, 6, 6, 9, 0, 6, 3, 0, 0, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6,\n",
      "       1, 6, 6, 6, 6, 0, 6, 6, 6, 6, 6, 3, 6, 3, 3, 6, 6, 6, 6, 6, 6, 1,\n",
      "       6, 6, 6, 6, 8, 8, 1, 6, 8, 1, 6, 1, 8, 6, 1, 6, 6, 1, 6, 6, 7, 9,\n",
      "       1, 1, 7, 2, 1, 6, 6, 6, 1, 6, 6, 3, 6, 3, 6, 1, 1, 6, 1, 6, 1, 6,\n",
      "       1, 3, 1, 6, 1, 1, 1, 6, 6, 1, 3, 3, 3, 1, 6, 3, 6, 6, 1, 3, 6, 6,\n",
      "       1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 1, 3, 1, 3, 6, 6, 1, 6, 6, 6, 1, 6,\n",
      "       1, 6, 1, 1, 1, 3, 1, 1, 6, 1, 3, 1, 1, 1, 6, 6, 1, 6, 6, 6, 6, 1,\n",
      "       1, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 1, 6, 1,\n",
      "       7, 1, 6, 1, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6]), array([1, 3, 6, 1, 6, 9, 1, 6, 7, 1, 1, 1, 1, 9, 1, 1, 1, 1, 3, 1, 1, 7,\n",
      "       1, 1, 6, 6, 0, 1, 1, 7, 6, 6, 1, 1, 6, 1, 6, 1, 6, 6, 1, 6, 8, 6,\n",
      "       1, 6, 3, 1, 9, 1, 6, 6, 8, 6, 1, 6, 3, 1, 6, 6, 6, 6, 6, 7, 6, 1,\n",
      "       6, 1, 7, 6, 6, 6, 1, 1, 1, 1, 1, 6, 1, 6, 1, 6, 1, 6, 6, 6, 7, 1,\n",
      "       6, 3, 1, 6, 6, 1, 1, 6, 9, 6, 6, 1, 6, 6, 6, 6, 1, 6, 6, 6, 6, 1,\n",
      "       1, 6, 6, 6, 8, 8, 1, 6, 6, 1, 6, 6, 6, 6, 3, 3, 3, 6, 1, 6, 1, 1,\n",
      "       6, 6, 1, 3, 6, 6, 1, 8, 6, 6, 6, 6, 6, 6, 1, 1, 6, 6, 1, 6, 6, 1,\n",
      "       6, 6, 1, 6, 1, 6, 1, 7, 6, 6, 1, 7, 1, 3, 7, 6, 6, 6, 1, 6, 6, 6,\n",
      "       6, 1, 6, 1, 3, 6, 6, 3, 3, 9, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 1,\n",
      "       6, 6, 6, 6, 6, 6, 9, 1, 6, 6, 1, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 1, 6, 6, 1, 1, 1, 6, 6, 0, 6, 6, 1, 6, 1, 1, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 9, 6, 6, 3, 6, 1, 6, 6, 6, 6, 7, 1, 6, 1, 6, 6, 7,\n",
      "       6, 1, 1, 3, 1, 3, 1, 6, 1, 6, 7, 7, 6, 6, 7, 1, 1, 1, 6, 6, 6, 6,\n",
      "       6, 6, 9, 6, 7, 6, 1, 6, 1, 7, 6, 6, 1, 1]), array([6, 6, 1, 3, 1, 6, 9, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 1, 6, 6, 3, 6,\n",
      "       6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 6, 6,\n",
      "       6, 1, 1, 6, 6, 6, 1, 6, 6, 6, 6, 9, 6, 6, 1, 9, 3, 6, 1, 1, 6, 6,\n",
      "       6, 1, 6, 6, 1, 1, 1, 6, 6, 6, 1, 6, 1, 6, 6, 6, 1, 6, 6, 1, 1, 3,\n",
      "       6, 1, 6, 0, 1, 3, 3, 3, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 3,\n",
      "       6, 1, 3, 6, 6, 6, 6, 1, 6, 6, 6, 1, 6, 3, 1, 9, 6, 3, 6, 6, 6, 6,\n",
      "       6, 6, 0, 6, 6, 6, 6, 6, 6, 6, 3, 1, 0, 6, 6, 0, 6, 6, 1, 6, 1, 6,\n",
      "       9, 6, 9, 1, 6, 6, 6, 3, 3, 0, 0, 6, 0, 1, 0, 6, 3, 9, 0, 1, 6, 6,\n",
      "       1, 6, 1, 6, 6, 1, 6, 6, 6, 1, 6, 6, 1, 9, 6, 6, 6, 6, 6, 1, 1, 6,\n",
      "       6, 1, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 0, 6, 6, 6, 6, 6, 3, 6, 3, 3,\n",
      "       6, 6, 3, 6, 6, 3, 6, 6, 6, 9, 6, 6, 6, 6, 7, 7, 3, 6, 6, 9, 1, 3,\n",
      "       6, 3, 1, 6, 6, 1, 6, 1, 6, 3, 6, 3, 1, 6, 1, 3, 6, 6, 1, 1, 1, 6,\n",
      "       3, 6, 6, 1, 6, 6, 1, 1, 2, 6, 6, 6, 1, 1, 6, 6, 6, 6, 1, 1, 1, 1,\n",
      "       6, 6, 1, 7, 1, 1, 6, 6, 6, 6, 9, 7, 1, 6]), array([6, 6, 3, 6, 6, 6, 6, 3, 6, 6, 6, 1, 6, 6, 6, 1, 6, 6, 6, 9, 9, 3,\n",
      "       9, 6, 3, 6, 6, 6, 6, 6, 3, 1, 9, 3, 1, 1, 1, 1, 1, 6, 6, 6, 6, 3,\n",
      "       6, 6, 1, 6, 6, 3, 3, 9, 6, 6, 1, 1, 1, 3, 6, 6, 6, 1, 6, 6, 1, 1,\n",
      "       3, 6, 1, 0, 6, 0, 6, 0, 1, 3, 6, 0, 6, 0, 1, 3, 6, 3, 1, 3, 1, 1,\n",
      "       1, 0, 6, 6, 1, 6, 8, 1, 1, 6, 1, 1, 6, 1, 1, 1, 6, 8, 1, 1, 7, 6,\n",
      "       1, 6, 1, 7, 6, 9, 1, 6, 1, 6, 1, 6, 6, 6, 6, 1, 6, 1, 6, 6, 6, 1,\n",
      "       9, 8, 9, 1, 6, 1, 6, 1, 1, 6, 1, 6, 1, 6, 6, 6, 3, 6, 6, 3, 1, 1,\n",
      "       3, 1, 6, 6, 6, 1, 6, 6, 6, 6, 6, 3, 6, 6, 6, 1, 1, 6, 1, 1, 9, 6,\n",
      "       6, 1, 3, 6, 8, 1, 1, 6, 6, 6, 6, 6, 6, 1, 1, 3, 9, 9, 1, 9, 3, 6,\n",
      "       3, 6, 6, 1, 6, 1, 6, 9, 6, 1, 3, 1, 6, 6, 3, 1, 6, 6, 1, 6, 1, 6,\n",
      "       3, 3, 6, 3, 3, 9, 3, 6, 6, 3, 6, 0, 3, 6, 6, 3, 6, 6, 3, 3, 6, 1,\n",
      "       3, 3, 6, 3, 3, 6, 3, 3, 1, 6, 6, 0, 3, 6, 1, 6, 0, 6, 6, 3, 1, 3,\n",
      "       0, 3, 6, 3, 6, 3, 6, 3, 6, 1, 1, 6, 9, 6, 1, 6, 6, 9, 6, 6, 1, 1,\n",
      "       1, 1, 6, 9, 3, 1, 3, 1, 6, 1, 6, 9, 6, 6]), array([6, 1, 6, 6, 6, 6, 6, 1, 6, 6, 1, 6, 3, 6, 6, 6, 1, 6, 1, 6, 6, 6,\n",
      "       6, 6, 1, 1, 6, 1, 1, 6, 1, 6, 6, 6, 1, 6, 1, 6, 6, 9, 6, 1, 6, 1,\n",
      "       1, 6, 6, 0, 6, 1, 6, 6, 6, 1, 3, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 1,\n",
      "       6, 9, 6, 1, 6, 6, 6, 6, 1, 6, 3, 1, 6, 3, 6, 1, 6, 1, 6, 6, 6, 6,\n",
      "       1, 6, 1, 3, 3, 6, 6, 6, 6, 6, 3, 6, 6, 3, 6, 1, 3, 6, 6, 3, 6, 6,\n",
      "       0, 3, 0, 6, 6, 6, 3, 1, 3, 3, 3, 6, 3, 9, 6, 6, 1, 6, 6, 1, 6, 3,\n",
      "       3, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 9, 1, 1, 6, 3, 6, 6, 6, 1, 6, 6,\n",
      "       1, 6, 0, 6, 6, 6, 3, 6, 6, 1, 6, 0, 6, 6, 1, 6, 6, 1, 3, 6, 6, 0,\n",
      "       6, 6, 6, 6, 6, 1, 6, 6, 1, 6, 6, 1, 6, 6, 9, 6, 3, 1, 6, 3, 6, 1,\n",
      "       3, 6, 3, 6, 1, 6, 6, 6, 1, 3, 6, 6, 3, 3, 1, 8, 6, 3, 6, 1, 3, 6,\n",
      "       6, 6, 2, 6, 1, 6, 6, 1, 3, 0, 6, 6, 3, 3, 1, 6, 6, 6, 6, 0, 6, 6,\n",
      "       0, 1, 0, 1, 6, 6, 1, 6, 9, 1, 6, 6, 6, 3, 9, 3, 1, 3, 1, 1, 6, 1,\n",
      "       6, 9, 3, 6, 3, 6, 9, 6, 6, 6, 6, 6, 6, 1, 6, 1, 6, 6, 9, 6, 6, 1,\n",
      "       6, 0, 6, 6, 6, 6, 6, 6, 1, 9, 6, 1, 6, 3]), array([1, 3, 1, 1, 1, 6, 6, 1, 1, 1, 6, 1, 1, 6, 1, 1, 6, 1, 1, 1, 6, 1,\n",
      "       1, 1, 1, 9, 1, 6, 6, 1, 6, 6, 1, 9, 6, 1, 9, 6, 6, 1, 6, 6, 1, 1,\n",
      "       6, 1, 6, 6, 3, 6, 1, 1, 1, 6, 6, 1, 1, 6, 6, 1, 1, 1, 1, 1, 1, 6,\n",
      "       1, 6, 6, 6, 1, 1, 6, 1, 6, 6, 3, 1, 1, 1, 1, 6, 1, 1, 1, 9, 6, 1,\n",
      "       9, 1, 6, 6, 6, 6, 6, 6, 6, 9, 6, 6, 1, 6, 8, 6, 6, 6, 6, 6, 6, 1,\n",
      "       1, 6, 1, 6, 3, 6, 6, 9, 6, 6, 6, 0, 3, 6, 6, 6, 3, 6, 3, 6, 3, 6,\n",
      "       6, 0, 6, 6, 3, 3, 3, 6, 6, 9, 6, 6, 6, 6, 0, 6, 1, 3, 3, 1, 1, 6,\n",
      "       6, 9, 1, 9, 6, 1, 6, 9, 1, 6, 1, 1, 6, 1, 6, 1, 6, 3, 6, 1, 6, 3,\n",
      "       6, 6, 6, 6, 1, 6, 3, 1, 6, 6, 6, 6, 3, 6, 6, 6, 6, 3, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 0, 6, 6, 9, 6, 6,\n",
      "       1, 6, 3, 9, 6, 6, 1, 3, 6, 6, 1, 6, 6, 6, 6, 6, 6, 9, 1, 6, 6, 1,\n",
      "       1, 6, 3, 0, 6, 6, 3, 0, 6, 1, 3, 1, 6, 1, 0, 6, 6, 1, 3, 3, 3, 6,\n",
      "       1, 6, 0, 1, 0, 6, 3, 6, 6, 3, 6, 3, 3, 0, 6, 3, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 3, 3, 6, 6, 6, 3, 3, 6, 6, 6]), array([6, 1, 3, 6, 6, 0, 6, 6, 6, 3, 6, 6, 6, 3, 6, 6, 3, 6, 6, 3, 1, 3,\n",
      "       6, 6, 6, 1, 6, 6, 3, 6, 6, 3, 6, 1, 3, 6, 3, 6, 6, 1, 1, 3, 3, 6,\n",
      "       6, 6, 6, 1, 1, 6, 3, 6, 6, 1, 6, 1, 6, 1, 6, 6, 6, 3, 6, 1, 3, 0,\n",
      "       6, 6, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 3, 1, 6, 6, 6, 6, 6, 6, 1, 6,\n",
      "       6, 6, 6, 1, 9, 6, 6, 1, 6, 6, 6, 6, 1, 6, 6, 9, 1, 1, 1, 1, 6, 6,\n",
      "       6, 6, 9, 1, 6, 6, 6, 6, 6, 6, 1, 1, 6, 6, 6, 6, 6, 9, 3, 8, 6, 6,\n",
      "       6, 6, 6, 9, 9, 6, 1, 3, 6, 1, 6, 3, 6, 6, 6, 6, 9, 6, 1, 6, 6, 3,\n",
      "       6, 6, 3, 6, 1, 6, 6, 6, 6, 6, 1, 6, 1, 6, 1, 6, 6, 6, 6, 6, 6, 1,\n",
      "       1, 6, 6, 1, 6, 3, 1, 1, 6, 1, 1, 6, 1, 6, 6, 6, 6, 6, 1, 6, 6, 8,\n",
      "       6, 6, 9, 1, 6, 6, 6, 1, 3, 6, 6, 6, 1, 6, 6, 6, 6, 1, 9, 6, 6, 3,\n",
      "       0, 1, 6, 6, 3, 1, 3, 0, 3, 1, 0, 1, 6, 1, 0, 0, 1, 3, 6, 1, 1, 3,\n",
      "       9, 6, 6, 6, 1, 6, 1, 6, 6, 6, 6, 6, 3, 3, 6, 6, 3, 0, 6, 1, 1, 6,\n",
      "       6, 6, 1, 6, 1, 1, 6, 3, 6, 9, 6, 1, 1, 6, 1, 1, 3, 1, 3, 6, 6, 6,\n",
      "       1, 9, 3, 1, 6, 6, 6, 1, 1, 6, 1, 3, 1, 1]), array([1, 6, 6, 6, 1, 1, 1, 1, 1, 6, 6, 3, 6, 1, 6, 6, 1, 1, 6, 1, 1, 6,\n",
      "       3, 9, 7, 6, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 1, 3, 6, 9, 6, 1, 1,\n",
      "       6, 6, 3, 6, 6, 1, 6, 1, 3, 6, 6, 6, 1, 6, 6, 6, 7, 6, 1, 6, 6, 6,\n",
      "       6, 1, 6, 6, 7, 6, 1, 6, 1, 1, 6, 1, 1, 6, 7, 1, 6, 6, 1, 6, 9, 1,\n",
      "       6, 8, 9, 6, 6, 6, 1, 6, 1, 6, 9, 6, 6, 6, 6, 1, 6, 9, 6, 9, 6, 6,\n",
      "       6, 9, 6, 9, 6, 6, 6, 6, 1, 6, 6, 6, 1, 3, 6, 3, 6, 3, 1, 6, 1, 6,\n",
      "       6, 3, 6, 3, 6, 6, 6, 6, 3, 3, 6, 6, 3, 6, 3, 6, 6, 6, 6, 6, 6, 1,\n",
      "       1, 1, 6, 1, 6, 1, 1, 1, 6, 1, 6, 1, 6, 1, 3, 6, 9, 6, 6, 9, 1, 1,\n",
      "       6, 1, 6, 6, 6, 9, 6, 6, 1, 6, 6, 6, 6, 1, 3, 1, 1, 6, 3, 6, 3, 6,\n",
      "       6, 1, 1, 3, 1, 6, 1, 6, 1, 1, 6, 6, 6, 1, 3, 6, 6, 6, 6, 3, 1, 6,\n",
      "       6, 6, 6, 3, 6, 6, 6, 6, 6, 3, 6, 1, 1, 6, 3, 6, 6, 3, 6, 6, 3, 3,\n",
      "       6, 1, 6, 1, 6, 6, 6, 6, 6, 3, 1, 6, 6, 6, 3, 6, 3, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 1, 1, 1, 6, 3, 1, 3, 6, 6, 6, 1, 6, 6, 1, 1, 6,\n",
      "       1, 6, 1, 6, 6, 6, 1, 6, 3, 6, 6, 6, 6, 6]), array([1, 9, 6, 1, 1, 6, 1, 3, 9, 1, 9, 1, 6, 1, 1, 1, 1, 6, 1, 1, 7, 1,\n",
      "       1, 1, 7, 1, 6, 1, 1, 9, 1, 0, 3, 1, 1, 0, 6, 6, 1, 6, 6, 6, 6, 3,\n",
      "       3, 3, 6, 3, 1, 6, 6, 6, 6, 6, 1, 6, 6, 0, 3, 1, 1, 6, 6, 6, 6, 1,\n",
      "       1, 3, 6, 6, 3, 6, 6, 1, 1, 1, 1, 6, 6, 6, 6, 1, 3, 3, 6, 1, 6, 6,\n",
      "       1, 3, 6, 6, 6, 1, 6, 6, 6, 6, 1, 9, 1, 7, 3, 6, 1, 6, 1, 6, 3, 9,\n",
      "       6, 1, 6, 6, 1, 1, 7, 6, 9, 1, 6, 6, 6, 1, 0, 6, 6, 6, 6, 3, 6, 0,\n",
      "       6, 6, 6, 6, 6, 1, 6, 0, 6, 6, 3, 6, 6, 3, 6, 1, 3, 6, 6, 1, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 6, 6, 3, 6, 6, 1, 1, 6, 6, 6, 6, 6,\n",
      "       3, 6, 6, 1, 3, 6, 6, 6, 6, 6, 6, 3, 6, 9, 6, 6, 6, 6, 6, 6, 1, 6,\n",
      "       1, 6, 6, 6, 6, 1, 3, 6, 6, 6, 1, 6, 3, 3, 1, 6, 3, 1, 6, 6, 3, 0,\n",
      "       6, 3, 6, 6, 6, 3, 6, 6, 1, 6, 3, 3, 6, 1, 6, 1, 6, 6, 3, 6, 6, 6,\n",
      "       3, 6, 1, 3, 6, 1, 6, 1, 1, 6, 6, 3, 6, 6, 6, 3, 6, 1, 1, 6, 6, 6,\n",
      "       3, 3, 6, 3, 3, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 6, 6,\n",
      "       6, 1, 3, 0, 6, 0, 6, 1, 6, 1, 3, 3, 1, 6]), array([6, 6, 1, 6, 6, 1, 6, 6, 6, 6, 1, 6, 1, 6, 1, 1, 6, 6, 6, 6, 1, 6,\n",
      "       6, 6, 6, 6, 1, 3, 6, 6, 6, 1, 1, 1, 9, 6, 6, 9, 6, 3, 1, 1, 3, 6,\n",
      "       6, 1, 1, 6, 8, 3, 0, 6, 1, 1, 6, 6, 9, 9, 1, 6, 1, 1, 1, 1, 9, 8,\n",
      "       6, 1, 1, 1, 6, 1, 1, 1, 6, 6, 6, 1, 8, 6, 8, 6, 8, 1, 6, 6, 1, 1,\n",
      "       1, 1, 6, 6, 6, 6, 3, 3, 3, 6, 6, 3, 3, 6, 6, 1, 6, 3, 3, 6, 1, 6,\n",
      "       3, 6, 1, 3, 6, 6, 6, 6, 6, 1, 3, 6, 9, 6, 3, 6, 6, 6, 6, 6, 9, 3,\n",
      "       1, 6, 3, 3, 6, 6, 6, 3, 6, 0, 6, 6, 6, 9, 1, 9, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 1, 3, 1, 6, 1, 6, 6, 6, 3, 6, 9, 6, 6, 1, 6, 1, 6, 6, 1, 1,\n",
      "       6, 6, 1, 3, 1, 6, 6, 6, 6, 6, 1, 9, 6, 6, 1, 6, 1, 1, 6, 0, 6, 6,\n",
      "       6, 1, 6, 6, 6, 6, 6, 1, 1, 6, 6, 1, 6, 6, 6, 6, 1, 6, 1, 1, 6, 6,\n",
      "       3, 6, 1, 1, 6, 6, 6, 3, 6, 6, 6, 6, 3, 6, 6, 6, 3, 6, 1, 1, 1, 1,\n",
      "       3, 6, 6, 9, 1, 3, 6, 3, 3, 6, 1, 1, 1, 1, 6, 1, 6, 6, 3, 9, 9, 1,\n",
      "       6, 1, 3, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 3, 6, 1, 1,\n",
      "       6, 6, 0, 6, 1, 6, 6, 1, 6, 3, 6, 6, 3, 6]), array([1, 1, 6, 1, 7, 1, 1, 6, 1, 1, 1, 1, 1, 1, 6, 7, 6, 1, 1, 7, 6, 6,\n",
      "       1, 1, 1, 1, 6, 6, 6, 6, 7, 6, 6, 6, 6, 3, 1, 3, 1, 7, 6, 6, 6, 6,\n",
      "       1, 6, 9, 8, 6, 6, 6, 6, 6, 1, 6, 1, 1, 6, 1, 6, 1, 6, 6, 1, 1, 6,\n",
      "       6, 0, 3, 6, 6, 6, 1, 6, 6, 1, 1, 6, 6, 3, 6, 6, 6, 6, 6, 3, 6, 6,\n",
      "       6, 1, 1, 1, 1, 6, 6, 6, 6, 3, 6, 1, 6, 1, 6, 6, 6, 6, 6, 1, 6, 6,\n",
      "       9, 6, 6, 8, 6, 6, 1, 8, 6, 6, 6, 6, 6, 6, 6, 1, 3, 1, 6, 6, 6, 6,\n",
      "       3, 9, 3, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 3, 6, 3, 6, 6, 1, 6, 6, 6,\n",
      "       1, 3, 6, 6, 1, 1, 6, 1, 0, 3, 1, 1, 6, 6, 1, 3, 6, 6, 6, 6, 0, 6,\n",
      "       1, 9, 1, 6, 6, 6, 6, 3, 6, 3, 6, 1, 6, 6, 6, 1, 6, 6, 9, 6, 6, 3,\n",
      "       6, 6, 6, 6, 3, 3, 6, 6, 6, 1, 6, 9, 6, 6, 6, 1, 6, 6, 3, 6, 6, 1,\n",
      "       6, 1, 6, 6, 1, 1, 6, 6, 6, 1, 9, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6,\n",
      "       0, 1, 3, 6, 3, 1, 1, 6, 6, 6, 3, 6, 3, 6, 6, 1, 3, 3, 6, 6, 6, 3,\n",
      "       6, 1, 6, 6, 6, 3, 1, 6, 6, 1, 3, 6, 6, 1, 6, 6, 1, 6, 6, 3, 6, 6,\n",
      "       6, 3, 6, 6, 6, 3, 1, 6, 6, 6, 1, 6, 6, 1]), array([1, 1, 1, 1, 6, 6, 1, 1, 2, 6, 1, 6, 6, 6, 1, 6, 1, 7, 1, 6, 1, 1,\n",
      "       6, 6, 1, 6, 1, 1, 1, 1, 6, 1, 6, 6, 1, 6, 1, 6, 6, 6, 6, 6, 6, 1,\n",
      "       6, 1, 6, 6, 6, 6, 9, 1, 1, 6, 6, 6, 6, 6, 6, 1, 6, 1, 1, 6, 6, 7,\n",
      "       1, 1, 1, 1, 9, 9, 3, 6, 1, 8, 9, 6, 6, 1, 1, 3, 1, 6, 7, 1, 1, 6,\n",
      "       8, 9, 6, 1, 6, 1, 1, 1, 6, 1, 1, 3, 6, 9, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 1, 6, 6, 6, 6, 1, 6, 3, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 3, 6, 3,\n",
      "       6, 1, 1, 1, 1, 6, 1, 6, 9, 3, 6, 6, 9, 6, 3, 6, 6, 3, 1, 6, 0, 6,\n",
      "       6, 1, 6, 6, 3, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 6, 6,\n",
      "       6, 3, 6, 6, 0, 0, 1, 1, 6, 1, 6, 6, 1, 0, 6, 6, 6, 6, 6, 1, 1, 6,\n",
      "       1, 6, 6, 1, 3, 1, 6, 6, 6, 6, 1, 6, 8, 9, 0, 9, 6, 6, 6, 6, 3, 6,\n",
      "       9, 3, 8, 3, 6, 6, 3, 6, 6, 6, 6, 6, 1, 8, 1, 2, 6, 6, 6, 3, 3, 7,\n",
      "       1, 6, 1, 6, 6, 7, 1, 6, 6, 9, 7, 1, 1, 1, 6, 1, 1, 6, 1, 6, 1, 6,\n",
      "       1, 6, 1, 6, 1, 1, 1, 9, 3, 1, 1, 3, 6, 6, 3, 1, 6, 1, 1, 1, 6, 6,\n",
      "       6, 6, 6, 1, 6, 6, 3, 1, 0, 6, 6, 1, 6, 6]), array([6, 7, 6, 7, 3, 1, 1, 7, 6, 1, 1, 1, 1, 6, 1, 3, 1, 1, 6, 6, 6, 1,\n",
      "       1, 1, 1, 1, 1, 6, 7, 7, 3, 3, 6, 3, 6, 1, 6, 6, 1, 6, 3, 3, 1, 9,\n",
      "       1, 6, 6, 9, 6, 0, 1, 6, 6, 3, 3, 3, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6,\n",
      "       9, 6, 1, 6, 1, 3, 6, 6, 6, 0, 1, 1, 1, 1, 6, 1, 6, 1, 1, 6, 0, 1,\n",
      "       6, 6, 1, 6, 6, 3, 6, 6, 1, 1, 1, 1, 6, 1, 9, 6, 6, 6, 6, 6, 1, 6,\n",
      "       1, 1, 6, 1, 1, 3, 6, 6, 6, 9, 6, 3, 0, 6, 3, 6, 6, 6, 3, 6, 6, 6,\n",
      "       0, 3, 6, 6, 3, 3, 0, 6, 6, 6, 0, 3, 6, 6, 6, 6, 3, 6, 6, 6, 3, 6,\n",
      "       6, 6, 1, 1, 6, 6, 1, 6, 3, 6, 6, 6, 1, 3, 6, 6, 3, 3, 6, 6, 1, 6,\n",
      "       3, 6, 0, 0, 6, 3, 6, 0, 1, 8, 3, 6, 0, 6, 6, 6, 6, 6, 6, 6, 0, 6,\n",
      "       6, 1, 6, 3, 6, 0, 3, 3, 6, 6, 6, 1, 9, 6, 6, 6, 1, 3, 1, 6, 6, 3,\n",
      "       6, 6, 3, 6, 6, 3, 9, 1, 9, 6, 1, 3, 6, 9, 6, 6, 6, 1, 6, 6, 6, 6,\n",
      "       6, 1, 6, 6, 7, 1, 6, 1, 1, 1, 6, 6, 1, 6, 1, 6, 1, 1, 6, 1, 3, 1,\n",
      "       1, 6, 1, 1, 3, 9, 3, 1, 1, 6, 1, 0, 1, 1, 1, 6, 1, 6, 6, 6, 1, 6,\n",
      "       1, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1]), array([3, 6, 7, 6, 1, 7, 6, 6, 1, 1, 1, 1, 6, 1, 3, 1, 6, 6, 1, 1, 6, 1,\n",
      "       1, 7, 6, 6, 3, 1, 6, 8, 1, 6, 1, 6, 3, 6, 6, 1, 0, 1, 6, 6, 6, 6,\n",
      "       0, 6, 1, 6, 1, 1, 1, 0, 6, 6, 6, 1, 6, 1, 6, 6, 1, 6, 6, 6, 1, 6,\n",
      "       1, 6, 6, 3, 1, 1, 6, 6, 3, 3, 0, 1, 6, 6, 1, 6, 1, 1, 6, 6, 6, 6,\n",
      "       1, 6, 8, 9, 6, 1, 9, 1, 6, 6, 6, 6, 1, 6, 1, 7, 1, 1, 8, 8, 6, 8,\n",
      "       6, 6, 6, 6, 7, 1, 9, 1, 1, 6, 3, 3, 3, 6, 6, 3, 9, 6, 6, 6, 3, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 1, 3, 6, 1, 1, 3, 6, 6, 3, 6, 6, 6, 6, 6, 1,\n",
      "       1, 6, 6, 1, 6, 1, 6, 1, 9, 6, 6, 1, 6, 1, 6, 1, 1, 6, 1, 6, 6, 6,\n",
      "       9, 6, 6, 6, 1, 6, 6, 1, 6, 3, 6, 6, 3, 1, 3, 6, 3, 1, 1, 3, 3, 6,\n",
      "       6, 3, 1, 6, 1, 6, 1, 6, 6, 6, 6, 6, 1, 1, 1, 3, 9, 3, 7, 3, 6, 7,\n",
      "       3, 7, 6, 3, 9, 6, 6, 6, 6, 3, 3, 9, 3, 3, 3, 3, 3, 1, 6, 6, 6, 9,\n",
      "       6, 6, 1, 1, 3, 3, 9, 1, 1, 3, 1, 1, 6, 3, 3, 6, 6, 9, 1, 3, 1, 6,\n",
      "       0, 1, 1, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 1,\n",
      "       1, 6, 6, 6, 1, 6, 1, 3, 3, 6, 1, 6, 6, 1]), array([6, 1, 9, 1, 1, 1, 1, 1, 6, 6, 6, 1, 6, 1, 6, 1, 7, 1, 1, 1, 1, 6,\n",
      "       6, 6, 1, 1, 6, 6, 1, 6, 1, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 9, 1, 1,\n",
      "       1, 6, 6, 1, 6, 1, 6, 1, 9, 9, 6, 6, 6, 6, 6, 1, 3, 1, 3, 1, 1, 9,\n",
      "       1, 6, 6, 1, 6, 6, 9, 1, 1, 6, 6, 6, 6, 1, 6, 1, 6, 6, 6, 1, 6, 6,\n",
      "       6, 6, 6, 6, 1, 6, 6, 0, 6, 6, 6, 1, 6, 3, 0, 6, 6, 6, 3, 6, 6, 3,\n",
      "       0, 6, 1, 1, 6, 6, 0, 0, 1, 6, 6, 6, 6, 6, 1, 8, 1, 6, 7, 1, 1, 1,\n",
      "       6, 1, 6, 6, 1, 6, 6, 6, 6, 6, 1, 6, 6, 1, 6, 6, 6, 7, 1, 9, 1, 6,\n",
      "       6, 1, 6, 6, 1, 9, 1, 1, 6, 3, 1, 6, 3, 1, 1, 6, 6, 6, 1, 1, 6, 1,\n",
      "       1, 1, 1, 1, 6, 6, 6, 9, 1, 6, 1, 6, 6, 3, 6, 6, 6, 6, 6, 6, 9, 1,\n",
      "       9, 0, 9, 6, 6, 6, 6, 6, 6, 3, 6, 1, 6, 1, 6, 6, 1, 6, 6, 1, 6, 6,\n",
      "       6, 6, 6, 6, 3, 0, 1, 6, 0, 6, 6, 1, 6, 6, 1, 3, 3, 6, 0, 1, 6, 3,\n",
      "       1, 9, 6, 6, 1, 3, 7, 3, 3, 6, 6, 6, 1, 6, 1, 9, 1, 6, 7, 6, 6, 6,\n",
      "       3, 3, 3, 6, 1, 6, 6, 6, 6, 6, 9, 1, 6, 3, 1, 6, 6, 1, 6, 6, 6, 9,\n",
      "       6, 1, 1, 6, 6, 1, 6, 6, 6, 1, 1, 6, 6, 6]), array([1, 6, 0, 0, 1, 3, 6, 6, 1, 1, 1, 6, 9, 1, 1, 1, 1, 6, 3, 6, 1, 1,\n",
      "       1, 1, 3, 6, 1, 1, 6, 1, 6, 6, 3, 1, 8, 6, 0, 8, 0, 6, 0, 6, 6, 6,\n",
      "       6, 6, 6, 1, 3, 6, 0, 6, 6, 1, 6, 6, 1, 9, 3, 6, 8, 1, 8, 1, 1, 6,\n",
      "       3, 1, 3, 1, 6, 1, 1, 1, 6, 7, 6, 1, 6, 6, 1, 1, 6, 1, 6, 1, 1, 9,\n",
      "       1, 6, 3, 3, 3, 0, 6, 9, 3, 1, 3, 6, 6, 6, 6, 3, 6, 3, 6, 3, 6, 6,\n",
      "       3, 6, 0, 0, 6, 6, 3, 3, 1, 3, 6, 6, 6, 3, 6, 6, 3, 3, 9, 6, 6, 6,\n",
      "       1, 6, 6, 6, 6, 1, 6, 6, 6, 1, 3, 6, 6, 6, 6, 6, 6, 3, 6, 1, 6, 1,\n",
      "       3, 6, 6, 3, 1, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 1, 6, 9, 6, 6, 6,\n",
      "       6, 6, 1, 6, 6, 1, 6, 6, 6, 9, 6, 1, 6, 6, 6, 6, 6, 9, 1, 1, 6, 1,\n",
      "       3, 6, 1, 1, 6, 1, 6, 1, 1, 6, 1, 1, 6, 7, 3, 6, 8, 1, 3, 6, 6, 6,\n",
      "       8, 6, 6, 3, 6, 1, 6, 6, 3, 6, 1, 8, 1, 6, 6, 9, 6, 6, 9, 6, 1, 6,\n",
      "       6, 1, 3, 1, 6, 6, 6, 6, 3, 1, 6, 9, 9, 1, 1, 3, 6, 1, 3, 1, 6, 3,\n",
      "       9, 1, 6, 9, 9, 1, 1, 1, 9, 1, 6, 6, 1, 6, 6, 1, 3, 3, 1, 1, 9, 3,\n",
      "       7, 7, 1, 2, 1, 2, 6, 6, 9, 2, 6, 1, 1, 3]), array([1, 1, 6, 6, 6, 1, 3, 1, 1, 6, 6, 1, 1, 1, 1, 6, 6, 3, 6, 1, 1, 1,\n",
      "       1, 0, 6, 1, 1, 6, 1, 0, 6, 1, 6, 6, 6, 6, 6, 3, 6, 6, 6, 1, 6, 6,\n",
      "       3, 1, 1, 6, 6, 6, 1, 6, 6, 6, 6, 9, 9, 3, 1, 6, 6, 6, 6, 3, 6, 6,\n",
      "       6, 1, 6, 6, 0, 1, 6, 6, 0, 1, 6, 6, 1, 1, 3, 6, 1, 6, 3, 6, 1, 6,\n",
      "       3, 1, 6, 1, 6, 1, 1, 6, 1, 3, 6, 6, 6, 6, 3, 0, 9, 1, 1, 6, 3, 1,\n",
      "       1, 6, 3, 6, 3, 6, 6, 6, 6, 8, 6, 1, 6, 1, 6, 6, 6, 1, 6, 6, 6, 1,\n",
      "       6, 6, 6, 6, 6, 1, 3, 1, 1, 1, 6, 9, 1, 1, 9, 1, 8, 1, 3, 6, 6, 6,\n",
      "       1, 1, 6, 6, 3, 6, 6, 6, 6, 6, 1, 3, 6, 6, 6, 3, 6, 6, 6, 3, 6, 3,\n",
      "       1, 6, 6, 6, 6, 1, 3, 6, 6, 6, 1, 6, 6, 1, 1, 1, 6, 6, 6, 6, 6, 6,\n",
      "       1, 6, 6, 6, 1, 9, 1, 1, 6, 9, 9, 6, 6, 3, 6, 1, 6, 6, 6, 3, 1, 3,\n",
      "       6, 6, 3, 9, 3, 6, 1, 1, 6, 9, 6, 6, 6, 1, 9, 6, 6, 3, 3, 3, 1, 6,\n",
      "       3, 6, 1, 6, 9, 1, 6, 1, 1, 1, 9, 3, 6, 9, 6, 6, 6, 6, 6, 6, 6, 1,\n",
      "       1, 1, 1, 1, 1, 1, 6, 6, 1, 1, 6, 1, 6, 1, 1, 6, 1, 1, 6, 6, 1, 1,\n",
      "       6, 6, 1, 3, 6, 9, 9, 6, 1, 1, 6, 6, 6, 6]), array([0, 1, 1, 1, 1, 6, 7, 1, 6, 1, 3, 6, 1, 6, 6, 1, 1, 1, 1, 1, 1, 1,\n",
      "       6, 1, 1, 6, 6, 1, 6, 1, 6, 6, 9, 6, 6, 6, 3, 6, 1, 1, 3, 6, 6, 3,\n",
      "       6, 1, 6, 6, 6, 6, 3, 3, 6, 6, 1, 3, 3, 6, 6, 3, 6, 1, 1, 1, 6, 1,\n",
      "       6, 6, 1, 6, 6, 6, 1, 3, 1, 1, 1, 6, 1, 6, 1, 6, 6, 6, 1, 1, 1, 3,\n",
      "       6, 6, 6, 6, 6, 9, 6, 6, 9, 6, 6, 6, 9, 1, 1, 6, 3, 6, 9, 1, 9, 6,\n",
      "       6, 3, 6, 6, 6, 1, 8, 1, 6, 1, 1, 6, 6, 1, 6, 6, 1, 3, 6, 6, 6, 6,\n",
      "       6, 6, 3, 6, 6, 6, 6, 6, 9, 3, 6, 6, 3, 3, 6, 3, 1, 6, 1, 1, 1, 6,\n",
      "       6, 6, 1, 6, 6, 1, 6, 6, 1, 1, 3, 1, 1, 6, 1, 1, 1, 1, 6, 1, 1, 1,\n",
      "       6, 1, 6, 1, 1, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 6, 1, 6, 6, 6,\n",
      "       6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 3, 0, 3, 6, 3, 6, 0, 6, 6, 1,\n",
      "       6, 3, 1, 6, 8, 6, 3, 9, 3, 6, 7, 6, 9, 9, 3, 6, 6, 6, 6, 6, 6, 6,\n",
      "       1, 3, 6, 3, 3, 6, 1, 6, 6, 6, 6, 6, 1, 6, 6, 1, 3, 6, 6, 8, 1, 6,\n",
      "       6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 1, 6, 1, 6, 6, 6, 6, 6, 6, 1, 3, 6,\n",
      "       6, 6, 6, 3, 1, 6, 1, 1, 1, 1, 6, 6, 1, 6]), array([6, 6, 1, 0, 1, 6, 6, 6, 3, 6, 6, 6, 1, 1, 3, 6, 3, 6, 6, 6, 6, 6,\n",
      "       1, 6, 6, 1, 6, 9, 6, 1, 6, 6, 1, 6, 6, 6, 6, 6, 3, 6, 1, 1, 1, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 3, 1, 1, 1, 1, 3, 6, 6, 1, 3,\n",
      "       1, 1, 6, 3, 1, 6, 6, 1, 1, 6, 1, 1, 6, 6, 6, 6, 9, 1, 1, 6, 6, 1,\n",
      "       6, 1, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 1, 6, 6, 6, 1, 9, 6, 6, 6, 1,\n",
      "       1, 1, 6, 6, 9, 6, 6, 6, 6, 6, 6, 6, 1, 6, 1, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 1, 6, 6, 9, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3,\n",
      "       6, 6, 3, 1, 6, 6, 9, 3, 1, 6, 6, 3, 6, 9, 6, 6, 6, 1, 6, 0, 6, 6,\n",
      "       6, 6, 6, 9, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 3, 3, 6, 6, 3,\n",
      "       6, 6, 1, 1, 6, 6, 6, 6, 6, 0, 3, 3, 6, 6, 6, 3, 6, 6, 3, 1, 1, 6,\n",
      "       1, 6, 6, 6, 6, 3, 6, 6, 1, 6, 6, 6, 6, 3, 6, 1, 1, 1, 3, 3, 6, 6,\n",
      "       6, 6, 6, 3, 1, 6, 6, 6, 6, 6, 8, 6, 1, 1, 3, 6, 6, 1, 6, 3, 3, 3,\n",
      "       6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 3, 1, 6, 6, 6, 6, 6, 6,\n",
      "       1, 6, 6, 6, 6, 6, 6, 6, 6, 3, 1, 6, 6, 6]), array([1, 6, 6, 6, 9, 1, 1, 1, 1, 1, 1, 1, 0, 7, 1, 1, 1, 9, 6, 3, 6, 9,\n",
      "       6, 1, 1, 6, 1, 3, 0, 6, 1, 9, 6, 6, 9, 1, 6, 6, 6, 3, 6, 6, 6, 0,\n",
      "       6, 6, 1, 9, 1, 1, 6, 6, 6, 1, 1, 6, 6, 3, 6, 6, 6, 3, 9, 6, 6, 1,\n",
      "       6, 6, 1, 1, 6, 6, 1, 6, 6, 6, 1, 6, 9, 1, 6, 9, 1, 1, 6, 3, 6, 1,\n",
      "       1, 1, 6, 6, 1, 6, 9, 1, 6, 6, 1, 6, 6, 6, 6, 1, 6, 6, 0, 6, 0, 6,\n",
      "       6, 6, 6, 6, 1, 6, 6, 6, 9, 6, 1, 9, 3, 6, 6, 9, 6, 1, 1, 1, 3, 6,\n",
      "       1, 3, 1, 1, 1, 6, 1, 3, 3, 6, 6, 6, 6, 9, 1, 6, 9, 1, 9, 1, 1, 9,\n",
      "       1, 6, 6, 9, 1, 3, 3, 1, 6, 1, 1, 6, 1, 1, 3, 6, 6, 6, 1, 6, 3, 1,\n",
      "       6, 3, 3, 6, 6, 3, 6, 6, 1, 0, 6, 1, 1, 6, 6, 1, 1, 6, 6, 1, 1, 1,\n",
      "       1, 6, 3, 9, 6, 6, 9, 6, 6, 1, 0, 6, 6, 6, 1, 6, 6, 3, 9, 6, 6, 6,\n",
      "       1, 6, 3, 1, 6, 1, 6, 3, 6, 1, 6, 1, 6, 6, 6, 6, 3, 6, 1, 6, 1, 2,\n",
      "       1, 1, 6, 7, 6, 1, 3, 9, 1, 8, 6, 1, 3, 3, 6, 6, 9, 3, 6, 6, 8, 6,\n",
      "       1, 6, 3, 7, 6, 6, 6, 6, 6, 3, 6, 1, 1, 1, 9, 6, 1, 1, 1, 6, 6, 6,\n",
      "       3, 1, 1, 6, 6, 1, 1, 1, 6, 6, 3, 1, 1, 1]), array([6, 1, 1, 1, 6, 1, 3, 1, 1, 7, 1, 3, 6, 1, 1, 6, 1, 8, 1, 6, 1, 6,\n",
      "       1, 1, 1, 1, 6, 1, 1, 1, 6, 6, 6, 1, 6, 6, 6, 1, 1, 9, 1, 6, 1, 6,\n",
      "       1, 0, 1, 6, 3, 1, 6, 3, 6, 6, 6, 1, 6, 6, 1, 6, 1, 1, 6, 1, 6, 6,\n",
      "       6, 1, 6, 1, 1, 6, 6, 6, 1, 1, 6, 3, 1, 6, 6, 1, 6, 6, 3, 1, 6, 6,\n",
      "       6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6,\n",
      "       9, 6, 1, 1, 1, 6, 6, 1, 6, 6, 3, 1, 6, 3, 1, 1, 6, 6, 6, 6, 6, 3,\n",
      "       6, 6, 6, 3, 6, 6, 6, 9, 0, 6, 3, 1, 1, 0, 6, 6, 6, 6, 6, 3, 6, 6,\n",
      "       6, 6, 1, 6, 0, 3, 1, 1, 1, 6, 6, 6, 6, 6, 6, 1, 0, 6, 3, 1, 1, 6,\n",
      "       6, 1, 1, 3, 3, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 0, 3, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 9, 6, 6, 6, 1,\n",
      "       6, 3, 6, 6, 1, 6, 1, 6, 6, 6, 1, 3, 6, 6, 3, 6, 6, 6, 6, 6, 3, 1,\n",
      "       6, 6, 1, 6, 1, 6, 6, 3, 6, 6, 3, 6, 6, 6, 1, 1, 6, 6, 6, 1, 6, 6,\n",
      "       6, 6, 1, 3, 1, 3, 2, 6, 1, 1, 6, 6, 6, 1, 6, 1, 6, 6, 3, 1, 6, 6,\n",
      "       6, 1, 6, 6, 1, 6, 6, 6, 7, 6, 1, 1, 6, 6]), array([6, 1, 3, 9, 6, 6, 6, 6, 6, 1, 6, 6, 1, 6, 6, 6, 6, 1, 1, 1, 6, 1,\n",
      "       6, 6, 6, 1, 1, 6, 6, 3, 6, 1, 0, 0, 6, 6, 6, 6, 6, 1, 1, 6, 6, 6,\n",
      "       6, 3, 3, 6, 6, 3, 6, 1, 6, 6, 6, 1, 6, 6, 6, 6, 9, 6, 6, 3, 1, 6,\n",
      "       6, 6, 1, 6, 6, 1, 6, 6, 6, 1, 1, 1, 6, 1, 1, 3, 1, 6, 6, 6, 1, 6,\n",
      "       6, 6, 6, 6, 1, 1, 6, 6, 1, 1, 6, 6, 1, 6, 9, 1, 1, 1, 1, 1, 1, 1,\n",
      "       6, 6, 6, 3, 6, 9, 1, 6, 3, 6, 6, 0, 6, 0, 3, 3, 3, 6, 0, 3, 6, 6,\n",
      "       6, 6, 3, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 0, 3, 1, 6, 1, 1,\n",
      "       6, 1, 6, 1, 3, 6, 6, 6, 9, 6, 6, 6, 6, 3, 6, 8, 6, 1, 1, 1, 3, 1,\n",
      "       6, 1, 6, 1, 6, 6, 0, 3, 9, 6, 6, 6, 1, 6, 6, 0, 0, 6, 3, 6, 6, 9,\n",
      "       6, 6, 6, 6, 3, 6, 6, 3, 6, 6, 6, 0, 1, 6, 6, 3, 1, 7, 1, 3, 7, 6,\n",
      "       6, 1, 7, 1, 7, 1, 6, 1, 7, 6, 3, 6, 7, 6, 6, 3, 1, 3, 6, 9, 6, 6,\n",
      "       3, 6, 9, 1, 3, 6, 1, 1, 0, 6, 1, 1, 6, 1, 1, 6, 1, 1, 1, 7, 6, 9,\n",
      "       6, 1, 9, 1, 6, 6, 7, 6, 1, 8, 1, 9, 1, 6, 1, 6, 1, 1, 1, 6, 6, 9,\n",
      "       9, 9, 1, 1, 1, 6, 6, 9, 1, 6, 6, 6, 0, 1]), array([1, 6, 6, 1, 1, 6, 1, 9, 6, 6, 7, 1, 7, 1, 6, 1, 6, 1, 1, 1, 3, 1,\n",
      "       1, 1, 1, 1, 7, 1, 1, 6, 6, 3, 1, 6, 6, 6, 1, 1, 6, 6, 6, 6, 6, 1,\n",
      "       6, 6, 6, 1, 6, 6, 6, 6, 6, 9, 1, 6, 6, 1, 6, 6, 6, 6, 6, 6, 1, 1,\n",
      "       1, 6, 9, 1, 6, 3, 1, 1, 6, 6, 6, 6, 6, 3, 3, 6, 6, 3, 1, 6, 6, 6,\n",
      "       6, 3, 1, 6, 6, 6, 6, 8, 6, 9, 6, 1, 6, 1, 6, 6, 6, 6, 6, 6, 8, 6,\n",
      "       6, 9, 1, 1, 6, 1, 6, 6, 6, 6, 6, 6, 0, 9, 6, 0, 6, 6, 6, 6, 1, 1,\n",
      "       3, 6, 6, 3, 3, 6, 9, 6, 6, 1, 0, 6, 3, 6, 3, 0, 6, 0, 6, 1, 6, 6,\n",
      "       6, 3, 6, 6, 6, 1, 1, 6, 1, 1, 1, 1, 1, 6, 1, 6, 1, 1, 6, 6, 9, 3,\n",
      "       1, 3, 1, 1, 9, 6, 9, 1, 6, 1, 3, 6, 6, 6, 1, 6, 6, 6, 6, 6, 8, 6,\n",
      "       3, 1, 6, 6, 6, 1, 6, 9, 1, 6, 6, 6, 6, 3, 1, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1,\n",
      "       6, 3, 3, 1, 6, 1, 6, 6, 3, 1, 6, 6, 1, 1, 6, 1, 6, 6, 6, 6, 6, 1,\n",
      "       3, 6, 6, 6, 3, 1, 1, 1, 6, 6, 1, 6, 6, 6, 6, 6, 9, 6, 1, 6, 1, 1,\n",
      "       3, 6, 6, 1, 6, 6, 6, 1, 6, 1, 6, 1, 1, 3]), array([9, 1, 1, 6, 6, 1, 6, 6, 1, 6, 1, 1, 6, 6, 0, 1, 6, 0, 1, 6, 1, 0,\n",
      "       6, 1, 6, 6, 6, 0, 6, 1, 1, 6, 6, 6, 1, 3, 9, 9, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 1, 6, 1, 6, 6, 6, 6, 1, 1, 6, 6, 1,\n",
      "       6, 6, 6, 1, 1, 1, 1, 6, 0, 9, 3, 6, 1, 6, 9, 1, 1, 1, 6, 1, 6, 3,\n",
      "       1, 6, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 1, 3, 6, 1, 6, 6, 1,\n",
      "       6, 6, 6, 6, 1, 6, 6, 7, 1, 6, 9, 1, 6, 3, 6, 6, 6, 6, 3, 3, 6, 6,\n",
      "       6, 6, 6, 1, 6, 6, 6, 1, 3, 3, 6, 3, 6, 6, 1, 1, 6, 1, 1, 6, 1, 1,\n",
      "       0, 1, 1, 1, 6, 6, 1, 3, 6, 6, 1, 8, 6, 6, 3, 6, 8, 6, 9, 6, 6, 6,\n",
      "       3, 0, 6, 3, 1, 1, 1, 6, 6, 6, 6, 1, 6, 1, 6, 6, 1, 1, 6, 6, 6, 6,\n",
      "       8, 6, 6, 1, 8, 6, 1, 6, 9, 6, 6, 6, 3, 6, 6, 7, 3, 6, 1, 6, 6, 3,\n",
      "       7, 6, 1, 6, 3, 3, 3, 6, 1, 1, 6, 6, 1, 0, 1, 1, 6, 6, 7, 6, 3, 6,\n",
      "       6, 1, 3, 6, 6, 1, 3, 6, 6, 3, 1, 3, 6, 6, 6, 6, 3, 6, 3, 6, 1, 3,\n",
      "       1, 3, 6, 3, 6, 6, 6, 3, 3, 6, 3, 1, 6, 1, 6, 3, 6, 6, 6, 6, 3, 1,\n",
      "       6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6]), array([1, 6, 1, 6, 1, 6, 6, 6, 1, 1, 6, 6, 1, 6, 1, 3, 1, 6, 6, 6, 6, 6,\n",
      "       1, 3, 6, 6, 9, 1, 1, 1, 1, 1, 6, 3, 6, 6, 6, 6, 1, 1, 6, 6, 1, 6,\n",
      "       1, 1, 6, 1, 1, 1, 9, 6, 1, 3, 6, 6, 1, 6, 9, 1, 3, 0, 6, 9, 6, 6,\n",
      "       1, 3, 1, 6, 1, 1, 6, 9, 1, 6, 1, 6, 1, 9, 1, 6, 6, 1, 1, 1, 1, 1,\n",
      "       3, 1, 7, 6, 1, 6, 1, 9, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 9, 6,\n",
      "       1, 1, 1, 6, 9, 7, 1, 6, 1, 1, 6, 3, 1, 6, 6, 6, 1, 3, 1, 6, 1, 6,\n",
      "       3, 6, 6, 6, 6, 6, 6, 1, 1, 6, 9, 6, 6, 6, 6, 6, 3, 6, 6, 1, 3, 1,\n",
      "       1, 6, 1, 0, 1, 1, 6, 1, 3, 3, 6, 1, 6, 1, 1, 3, 1, 1, 6, 6, 1, 6,\n",
      "       6, 1, 0, 6, 6, 1, 6, 6, 6, 1, 1, 3, 9, 6, 9, 6, 6, 1, 6, 6, 6, 6,\n",
      "       6, 1, 6, 6, 6, 1, 6, 1, 1, 6, 1, 6, 7, 1, 6, 6, 1, 6, 2, 3, 3, 6,\n",
      "       3, 3, 6, 6, 2, 6, 2, 6, 6, 3, 3, 7, 6, 3, 6, 3, 3, 6, 1, 6, 0, 6,\n",
      "       1, 1, 1, 6, 1, 6, 6, 3, 1, 6, 6, 6, 6, 6, 3, 3, 6, 3, 1, 3, 6, 1,\n",
      "       9, 9, 1, 6, 1, 9, 6, 1, 6, 6, 0, 6, 6, 1, 1, 1, 6, 0, 6, 3, 1, 3,\n",
      "       6, 6, 6, 6, 1, 1, 1, 6, 6, 1, 1, 1, 3, 0]), array([1, 1, 6, 1, 6, 1, 6, 1, 6, 6, 6, 6, 6, 1, 9, 6, 1, 1, 6, 6, 1, 1,\n",
      "       6, 6, 1, 6, 6, 6, 6, 6, 3, 0, 6, 1, 0, 1, 1, 6, 6, 6, 6, 1, 6, 1,\n",
      "       6, 3, 3, 6, 6, 6, 1, 9, 3, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 6,\n",
      "       1, 1, 1, 6, 3, 6, 6, 1, 6, 3, 6, 9, 3, 6, 6, 1, 1, 6, 1, 6, 3, 6,\n",
      "       1, 1, 1, 1, 9, 1, 1, 7, 1, 1, 6, 6, 1, 7, 6, 9, 1, 1, 6, 1, 6, 9,\n",
      "       6, 1, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 9, 6, 6, 6, 1, 6, 6, 1, 6, 6,\n",
      "       6, 1, 1, 9, 6, 1, 1, 0, 6, 9, 6, 6, 6, 6, 6, 6, 1, 6, 6, 9, 6, 6,\n",
      "       1, 1, 3, 6, 6, 6, 1, 6, 1, 1, 6, 6, 6, 6, 6, 1, 6, 6, 6, 9, 1, 6,\n",
      "       1, 6, 3, 6, 6, 6, 6, 6, 1, 6, 1, 6, 6, 6, 3, 9, 6, 6, 6, 3, 1, 1,\n",
      "       6, 9, 3, 6, 6, 6, 1, 1, 3, 6, 6, 3, 1, 6, 1, 9, 6, 6, 6, 1, 1, 9,\n",
      "       1, 1, 1, 1, 6, 7, 6, 1, 6, 1, 1, 3, 3, 1, 1, 6, 6, 1, 6, 8, 6, 3,\n",
      "       6, 3, 6, 3, 6, 3, 1, 6, 6, 1, 3, 1, 9, 3, 9, 6, 1, 1, 3, 6, 3, 0,\n",
      "       6, 8, 3, 1, 6, 6, 6, 6, 6, 1, 6, 3, 1, 6, 6, 7, 6, 1, 6, 1, 2, 7,\n",
      "       1, 3, 1, 1, 6, 3, 6, 6, 3, 6, 6, 6, 6, 1]), array([6, 6, 6, 6, 6, 6, 1, 1, 1, 6, 3, 9, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 3, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 3, 6,\n",
      "       1, 6, 6, 6, 9, 6, 6, 6, 1, 1, 6, 6, 6, 6, 6, 1, 6, 6, 6, 1, 6, 1,\n",
      "       6, 6, 6, 9, 6, 6, 1, 1, 1, 1, 6, 1, 6, 6, 6, 6, 6, 6, 9, 6, 1, 1,\n",
      "       6, 6, 7, 2, 6, 7, 6, 2, 8, 2, 1, 2, 2, 2, 2, 6, 1, 2, 2, 1, 6, 2,\n",
      "       1, 2, 6, 2, 6, 7, 6, 2, 1, 1, 0, 6, 3, 6, 3, 6, 6, 9, 6, 6, 9, 3,\n",
      "       1, 3, 1, 6, 3, 3, 3, 6, 6, 6, 3, 6, 1, 6, 6, 3, 6, 6, 1, 6, 7, 6,\n",
      "       1, 1, 6, 1, 1, 1, 6, 6, 6, 1, 1, 6, 1, 1, 1, 1, 9, 1, 1, 1, 6, 1,\n",
      "       9, 6, 9, 1, 6, 6, 1, 6, 3, 6, 9, 6, 6, 6, 1, 6, 6, 3, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 0, 6, 1, 3, 6, 6, 6, 6, 1, 6, 6, 6, 2, 3, 1,\n",
      "       6, 6, 3, 3, 1, 2, 6, 7, 6, 6, 2, 6, 6, 2, 2, 6, 6, 6, 9, 1, 1, 1,\n",
      "       1, 6, 6, 6, 1, 3, 6, 9, 1, 6, 1, 3, 6, 3, 1, 1, 1, 7, 6, 1, 6, 1,\n",
      "       6, 7, 6, 6, 6, 6, 1, 8, 1, 1, 6, 6, 6, 3, 1, 6, 1, 6, 7, 1, 1, 6,\n",
      "       1, 6, 9, 6, 6, 6, 1, 6, 1, 6, 1, 8, 6, 1]), array([6, 1, 6, 1, 1, 1, 1, 6, 6, 1, 6, 1, 1, 6, 1, 6, 9, 6, 9, 1, 1, 6,\n",
      "       1, 6, 8, 1, 1, 0, 1, 1, 6, 8, 1, 6, 6, 1, 1, 6, 3, 6, 3, 1, 6, 6,\n",
      "       6, 1, 6, 3, 6, 6, 1, 1, 3, 6, 0, 1, 6, 6, 6, 9, 1, 6, 1, 6, 1, 6,\n",
      "       6, 1, 1, 6, 8, 6, 6, 6, 1, 1, 1, 1, 6, 1, 6, 1, 6, 1, 6, 1, 6, 1,\n",
      "       6, 6, 1, 1, 6, 2, 7, 2, 6, 2, 9, 1, 7, 1, 2, 8, 6, 6, 1, 1, 1, 6,\n",
      "       6, 6, 1, 1, 1, 1, 1, 9, 1, 6, 8, 6, 6, 6, 1, 1, 6, 1, 6, 1, 6, 1,\n",
      "       6, 6, 6, 6, 7, 6, 6, 6, 6, 1, 1, 1, 6, 1, 1, 1, 6, 6, 6, 6, 1, 1,\n",
      "       1, 6, 1, 6, 6, 6, 6, 1, 6, 6, 3, 1, 3, 9, 6, 6, 6, 3, 6, 1, 1, 6,\n",
      "       6, 6, 6, 1, 3, 6, 6, 1, 6, 3, 6, 3, 6, 3, 6, 6, 6, 6, 6, 1, 3, 6,\n",
      "       6, 3, 6, 3, 6, 6, 3, 6, 6, 6, 6, 6, 4, 3, 6, 6, 6, 1, 6, 6, 6, 6,\n",
      "       9, 1, 9, 6, 6, 6, 6, 3, 1, 7, 4, 1, 3, 1, 6, 9, 6, 8, 6, 6, 1, 1,\n",
      "       7, 9, 1, 1, 3, 6, 1, 1, 3, 6, 6, 6, 1, 6, 6, 6, 6, 6, 1, 6, 1, 6,\n",
      "       7, 3, 1, 1, 1, 1, 9, 1, 6, 3, 1, 1, 3, 1, 6, 6, 3, 3, 1, 6, 6, 6,\n",
      "       6, 1, 6, 6, 6, 1, 3, 1, 6, 1, 6, 6, 1, 6]), array([1, 6, 1, 6, 3, 1, 1, 6, 6, 6, 1, 1, 6, 1, 6, 1, 6, 3, 1, 1, 6, 1,\n",
      "       1, 1, 1, 1, 6, 1, 1, 1, 9, 6, 3, 6, 1, 6, 3, 1, 6, 6, 1, 3, 6, 6,\n",
      "       6, 9, 6, 1, 6, 6, 6, 1, 0, 3, 6, 1, 1, 1, 1, 3, 6, 1, 9, 6, 3, 1,\n",
      "       1, 1, 6, 6, 6, 1, 3, 1, 6, 6, 6, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 6,\n",
      "       1, 6, 0, 6, 3, 3, 0, 6, 3, 0, 0, 6, 6, 6, 6, 6, 6, 0, 6, 6, 6, 3,\n",
      "       3, 3, 6, 6, 6, 3, 6, 3, 6, 6, 1, 1, 6, 1, 6, 1, 1, 6, 6, 6, 7, 9,\n",
      "       7, 3, 6, 6, 1, 6, 6, 3, 6, 6, 6, 7, 6, 1, 6, 6, 6, 6, 1, 3, 8, 9,\n",
      "       3, 9, 6, 6, 7, 6, 1, 9, 1, 6, 6, 9, 1, 6, 1, 6, 3, 6, 1, 6, 6, 1,\n",
      "       1, 9, 6, 6, 6, 6, 6, 6, 6, 1, 6, 9, 1, 8, 6, 6, 6, 6, 8, 9, 6, 6,\n",
      "       1, 6, 6, 6, 9, 6, 6, 6, 6, 6, 6, 6, 6, 6, 9, 3, 6, 6, 3, 9, 6, 3,\n",
      "       6, 6, 6, 3, 6, 6, 6, 3, 9, 6, 6, 1, 1, 6, 6, 6, 6, 3, 6, 6, 6, 6,\n",
      "       6, 6, 6, 1, 6, 6, 6, 1, 6, 0, 6, 3, 1, 1, 6, 3, 0, 6, 6, 6, 6, 6,\n",
      "       3, 6, 3, 6, 3, 0, 6, 6, 1, 9, 1, 6, 1, 6, 6, 1, 6, 1, 6, 6, 6, 1,\n",
      "       1, 1, 3, 6, 9, 6, 6, 1, 6, 6, 9, 3, 6, 1]), array([6, 3, 6, 3, 6, 6, 6, 6, 6, 1, 6, 6, 1, 3, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 1, 3, 3, 6, 3, 6, 1, 6, 6, 1, 1, 6, 6, 6, 1, 6, 6, 3, 9, 1,\n",
      "       1, 6, 6, 6, 1, 1, 3, 6, 6, 6, 1, 6, 6, 6, 1, 6, 1, 6, 3, 1, 1, 1,\n",
      "       1, 6, 3, 6, 1, 1, 6, 3, 6, 1, 6, 6, 1, 6, 3, 1, 3, 6, 6, 6, 6, 6,\n",
      "       1, 1, 6, 0, 1, 6, 6, 6, 0, 6, 6, 0, 0, 6, 3, 3, 6, 6, 9, 3, 3, 6,\n",
      "       1, 1, 3, 6, 6, 6, 3, 6, 6, 3, 1, 6, 6, 6, 8, 6, 6, 6, 1, 6, 3, 6,\n",
      "       6, 6, 1, 6, 6, 1, 6, 6, 1, 6, 1, 6, 6, 6, 6, 9, 6, 6, 1, 1, 6, 1,\n",
      "       6, 7, 2, 6, 1, 1, 9, 8, 1, 8, 7, 1, 6, 2, 6, 9, 1, 1, 1, 1, 6, 6,\n",
      "       6, 7, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 3, 3, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 3, 1, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 1, 3, 6, 3, 6, 1, 6, 6, 6, 6, 6, 3, 8, 1, 6, 3, 3, 6, 6,\n",
      "       6, 6, 9, 3, 9, 3, 1, 6, 6, 3, 6, 1, 3, 6, 1, 1, 9, 6, 9, 3, 3, 3,\n",
      "       1, 1, 6, 1, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 3, 3, 6,\n",
      "       6, 0, 6, 6, 3, 0, 1, 0, 6, 6, 0, 6, 6, 6]), array([6, 6, 6, 6, 6, 3, 6, 6, 6, 3, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "       3, 6, 6, 6, 1, 6, 6, 6, 3, 1, 1, 6, 3, 1, 6, 6, 6, 1, 6, 6, 6, 6,\n",
      "       9, 6, 9, 6, 6, 1, 6, 6, 6, 1, 3, 6, 6, 1, 6, 6, 6, 1, 6, 6, 1, 6,\n",
      "       3, 1, 1, 1, 6, 6, 1, 6, 3, 6, 1, 6, 6, 1, 0, 0, 1, 6, 6, 1, 1, 1,\n",
      "       1, 1, 6, 6, 6, 6, 6, 6, 1, 3, 6, 6, 1, 0, 6, 1, 0, 1, 6, 6, 6, 0,\n",
      "       6, 6, 6, 1, 0, 0, 6, 6, 0, 6, 3, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 3,\n",
      "       6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 3, 6, 6, 3, 6, 1, 9, 6,\n",
      "       6, 3, 6, 1, 6, 1, 6, 6, 1, 6, 6, 6, 9, 1, 6, 1, 1, 6, 6, 6, 1, 1,\n",
      "       6, 6, 1, 1, 6, 6, 6, 1, 1, 6, 0, 1, 0, 1, 6, 9, 6, 0, 1, 6, 6, 1,\n",
      "       6, 0, 1, 0, 6, 3, 6, 6, 0, 1, 9, 1, 3, 1, 6, 6, 1, 3, 6, 6, 1, 1,\n",
      "       3, 6, 0, 1, 6, 6, 1, 6, 3, 3, 6, 6, 6, 1, 1, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 1, 3, 6, 0, 6, 3, 1, 6, 1, 1, 9, 6, 1, 3, 6, 1, 1, 1, 1, 6, 1,\n",
      "       6, 6, 1, 6, 6, 6, 6, 6, 6, 1, 6, 3, 6, 6, 1, 6, 1, 1, 9, 6, 9, 1,\n",
      "       6, 1, 6, 1, 6, 6, 7, 3, 8, 6, 6, 6, 9, 1]), array([1, 6, 9, 6, 9, 6, 8, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 1, 1, 6,\n",
      "       6, 6, 3, 6, 6, 6, 1, 6, 6, 6, 6, 9, 1, 6, 1, 6, 6, 6, 9, 1, 1, 1,\n",
      "       6, 6, 1, 1, 3, 3, 1, 1, 6, 1, 6, 6, 6, 6, 6, 1, 6, 1, 6, 1, 0, 1,\n",
      "       6, 6, 6, 1, 1, 6, 6, 6, 1, 1, 9, 6, 6, 6, 1, 6, 9, 1, 6, 0, 6, 1,\n",
      "       6, 6, 6, 6, 0, 6, 3, 3, 6, 6, 3, 3, 3, 3, 6, 6, 6, 3, 3, 0, 6, 6,\n",
      "       6, 0, 6, 3, 3, 6, 6, 6, 6, 0, 6, 6, 1, 6, 6, 3, 6, 6, 6, 3, 6, 6,\n",
      "       6, 1, 6, 6, 6, 1, 1, 6, 1, 3, 6, 3, 3, 6, 6, 1, 3, 1, 6, 6, 1, 1,\n",
      "       1, 1, 6, 1, 6, 9, 6, 6, 6, 1, 1, 6, 1, 6, 1, 6, 6, 1, 3, 1, 6, 6,\n",
      "       1, 1, 6, 1, 1, 6, 1, 6, 6, 9, 6, 6, 1, 7, 6, 1, 1, 1, 6, 7, 1, 3,\n",
      "       6, 1, 6, 1, 6, 7, 6, 1, 6, 6, 1, 6, 1, 1, 6, 6, 6, 3, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 9, 6, 3, 6, 6, 1, 6, 3, 6, 6, 6, 1,\n",
      "       3, 6, 6, 6, 1, 1, 1, 3, 6, 6, 3, 6, 0, 3, 6, 6, 3, 3, 6, 6, 1, 6,\n",
      "       3, 3, 6, 6, 3, 6, 3, 3, 6, 6, 1, 1, 1, 6, 6, 6, 1, 6, 6, 1, 6, 6,\n",
      "       1, 6, 1, 1, 1, 9, 1, 1, 1, 9, 1, 6, 3, 6]), array([6, 6, 1, 1, 1, 3, 1, 1, 1, 9, 1, 7, 1, 1, 1, 1, 1, 1, 1, 6, 6, 7,\n",
      "       1, 1, 1, 1, 6, 3, 6, 2, 6, 6, 6, 6, 6, 3, 6, 3, 6, 1, 6, 6, 3, 6,\n",
      "       3, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 0, 6, 1, 0, 6, 9, 7, 1, 1, 6, 6,\n",
      "       6, 6, 1, 1, 9, 1, 1, 1, 1, 9, 6, 1, 1, 1, 6, 1, 6, 1, 1, 8, 1, 6,\n",
      "       6, 0, 9, 6, 6, 6, 1, 6, 6, 8, 8, 1, 6, 6, 1, 6, 9, 6, 6, 9, 1, 1,\n",
      "       1, 6, 8, 6, 6, 1, 1, 1, 6, 9, 1, 1, 6, 1, 6, 6, 9, 6, 1, 9, 6, 6,\n",
      "       9, 9, 9, 1, 6, 9, 1, 1, 6, 1, 6, 1, 6, 6, 3, 6, 1, 1, 1, 6, 6, 6,\n",
      "       6, 6, 1, 1, 1, 6, 1, 6, 6, 1, 6, 3, 1, 6, 1, 6, 6, 6, 1, 6, 6, 9,\n",
      "       1, 1, 1, 6, 1, 1, 6, 9, 9, 6, 1, 1, 6, 6, 1, 6, 6, 6, 6, 9, 3, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 8, 6, 3, 6, 7, 6, 3, 1, 6, 1, 9, 6,\n",
      "       6, 3, 6, 6, 6, 6, 6, 6, 3, 6, 1, 9, 6, 6, 6, 6, 6, 1, 1, 3, 1, 3,\n",
      "       1, 1, 6, 1, 6, 6, 6, 1, 1, 6, 6, 6, 6, 6, 1, 6, 6, 6, 3, 1, 3, 1,\n",
      "       1, 1, 1, 6, 1, 3, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 3, 6, 1, 6, 3, 6, 6, 6, 6, 6, 0, 1, 0]), array([3, 1, 6, 1, 6, 6, 0, 3, 6, 6, 6, 1, 6, 6, 9, 1, 6, 1, 6, 3, 6, 3,\n",
      "       6, 6, 3, 6, 1, 1, 3, 6, 1, 6, 6, 1, 6, 6, 6, 1, 9, 6, 6, 6, 6, 9,\n",
      "       6, 1, 1, 6, 1, 6, 6, 6, 9, 6, 1, 6, 6, 6, 6, 1, 6, 9, 1, 6, 1, 6,\n",
      "       1, 1, 6, 3, 6, 1, 6, 6, 6, 6, 1, 6, 6, 9, 1, 6, 1, 6, 1, 6, 6, 0,\n",
      "       1, 1, 6, 7, 6, 1, 6, 6, 9, 6, 7, 7, 6, 1, 6, 6, 6, 7, 1, 7, 6, 6,\n",
      "       2, 6, 6, 6, 1, 1, 7, 7, 6, 1, 6, 3, 6, 3, 9, 6, 6, 6, 3, 6, 6, 6,\n",
      "       1, 1, 3, 3, 3, 6, 6, 3, 3, 6, 3, 3, 6, 6, 6, 1, 6, 9, 6, 1, 1, 1,\n",
      "       6, 1, 6, 6, 6, 1, 6, 1, 6, 6, 1, 6, 1, 1, 6, 1, 1, 6, 6, 1, 6, 6,\n",
      "       6, 6, 6, 7, 9, 3, 6, 6, 6, 6, 1, 8, 6, 6, 8, 6, 9, 6, 6, 6, 6, 6,\n",
      "       1, 6, 1, 6, 1, 1, 8, 6, 6, 6, 6, 8, 6, 3, 6, 1, 3, 6, 1, 6, 6, 6,\n",
      "       6, 6, 6, 6, 1, 3, 9, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 3, 6,\n",
      "       8, 3, 6, 6, 3, 6, 3, 6, 3, 6, 6, 6, 6, 6, 3, 1, 6, 3, 6, 3, 6, 6,\n",
      "       6, 6, 6, 3, 6, 6, 1, 1, 3, 1, 6, 6, 6, 6, 6, 9, 6, 6, 1, 1, 6, 6,\n",
      "       1, 1, 1, 6, 1, 6, 9, 6, 9, 1, 6, 1, 6, 3]), array([6, 1, 1, 6, 1, 1, 3, 1, 6, 0, 1, 6, 6, 9, 8, 3, 1, 6, 6, 6, 6, 1,\n",
      "       1, 0, 6, 1, 6, 1, 6, 1, 6, 1, 1, 6, 6, 9, 1, 6, 1, 6, 1, 9, 1, 1,\n",
      "       6, 1, 6, 6, 6, 1, 6, 3, 6, 1, 3, 6, 1, 1, 1, 6, 6, 6, 1, 6, 6, 3,\n",
      "       1, 3, 1, 6, 6, 3, 3, 9, 6, 6, 3, 6, 1, 6, 6, 1, 6, 9, 6, 6, 1, 1,\n",
      "       6, 1, 2, 1, 1, 2, 6, 1, 2, 7, 2, 2, 8, 6, 7, 7, 8, 2, 1, 2, 1, 7,\n",
      "       8, 8, 2, 9, 2, 6, 9, 1, 6, 2, 6, 6, 1, 6, 3, 6, 6, 6, 3, 1, 3, 1,\n",
      "       6, 6, 6, 6, 1, 6, 0, 6, 6, 6, 1, 6, 6, 9, 6, 6, 1, 6, 7, 1, 6, 3,\n",
      "       6, 6, 1, 1, 1, 7, 1, 6, 1, 1, 1, 1, 6, 1, 6, 6, 6, 1, 1, 6, 1, 1,\n",
      "       1, 1, 1, 9, 6, 6, 6, 6, 1, 1, 6, 6, 1, 6, 9, 6, 6, 6, 9, 6, 6, 1,\n",
      "       7, 8, 7, 8, 6, 6, 1, 1, 6, 1, 1, 6, 6, 9, 1, 6, 6, 6, 6, 3, 6, 3,\n",
      "       6, 6, 1, 6, 9, 1, 1, 6, 6, 1, 6, 3, 6, 3, 3, 6, 9, 6, 6, 6, 6, 3,\n",
      "       6, 6, 1, 6, 6, 3, 6, 6, 1, 3, 3, 6, 6, 6, 6, 3, 1, 6, 6, 6, 6, 3,\n",
      "       6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 1, 3, 1, 6, 6, 6, 6, 6, 1,\n",
      "       6, 6, 6, 3, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6]), array([6, 6, 6, 1, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 1, 9, 1, 1, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 6, 6, 6,\n",
      "       1, 6, 6, 1, 1, 6, 6, 6, 1, 6, 6, 1, 1, 6, 6, 1, 1, 6, 6, 1, 1, 6,\n",
      "       6, 6, 6, 6, 1, 6, 9, 1, 1, 6, 6, 1, 1, 6, 6, 1, 6, 6, 1, 1, 9, 1,\n",
      "       6, 6, 6, 6, 2, 6, 6, 6, 6, 1, 6, 1, 6, 6, 1, 6, 7, 6, 6, 6, 2, 1,\n",
      "       6, 6, 9, 7, 1, 1, 6, 6, 7, 6, 3, 1, 6, 6, 6, 6, 1, 6, 6, 6, 6, 0,\n",
      "       1, 6, 6, 9, 1, 6, 9, 6, 1, 6, 6, 6, 9, 1, 1, 6, 6, 6, 1, 7, 6, 7,\n",
      "       9, 1, 1, 6, 1, 6, 1, 1, 6, 6, 6, 1, 6, 1, 1, 1, 1, 9, 1, 1, 1, 1,\n",
      "       6, 6, 1, 1, 6, 6, 1, 1, 6, 7, 7, 1, 6, 2, 1, 8, 1, 1, 1, 1, 1, 6,\n",
      "       6, 6, 1, 2, 6, 8, 6, 6, 1, 6, 6, 1, 9, 6, 6, 6, 9, 6, 6, 6, 3, 1,\n",
      "       6, 9, 1, 1, 6, 9, 3, 1, 6, 6, 3, 1, 1, 6, 6, 1, 3, 9, 1, 6, 3, 6,\n",
      "       6, 6, 2, 1, 6, 1, 1, 8, 7, 7, 1, 1, 2, 9, 1, 6, 6, 1, 1, 6, 3, 6,\n",
      "       6, 6, 6, 1, 9, 6, 1, 6, 6, 3, 1, 1, 1, 6, 6, 8, 3, 9, 6, 1, 6, 6,\n",
      "       6, 6, 1, 6, 6, 1, 3, 6, 6, 1, 3, 6, 8, 6]), array([6, 9, 3, 6, 0, 6, 6, 6, 9, 1, 9, 6, 6, 6, 6, 6, 9, 6, 6, 1, 3, 6,\n",
      "       6, 6, 6, 3, 6, 6, 6, 3, 1, 1, 1, 1, 1, 6, 1, 1, 6, 6, 7, 1, 6, 3,\n",
      "       6, 8, 8, 1, 6, 9, 1, 6, 1, 6, 9, 6, 9, 6, 6, 3, 1, 6, 1, 1, 6, 1,\n",
      "       6, 6, 6, 1, 6, 1, 1, 6, 6, 1, 6, 9, 6, 1, 1, 6, 1, 1, 6, 0, 6, 6,\n",
      "       1, 1, 1, 2, 7, 8, 2, 1, 2, 1, 2, 8, 1, 2, 1, 2, 2, 1, 7, 6, 2, 2,\n",
      "       7, 1, 1, 2, 2, 2, 2, 1, 8, 2, 6, 6, 6, 1, 6, 1, 8, 1, 6, 6, 1, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 1, 6, 6, 6, 6, 6, 3, 6, 6, 6,\n",
      "       1, 6, 6, 1, 6, 6, 3, 3, 1, 9, 9, 1, 1, 1, 9, 6, 1, 1, 6, 3, 1, 6,\n",
      "       6, 1, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "       7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 6, 6, 3, 3, 6, 6, 3, 6, 6, 6,\n",
      "       1, 1, 6, 6, 1, 1, 6, 3, 6, 3, 6, 6, 6, 6, 1, 3, 1, 1, 3, 6, 4, 1,\n",
      "       1, 6, 6, 6, 4, 4, 6, 7, 6, 4, 6, 7, 3, 1, 6, 1, 6, 6, 6, 1, 6, 3,\n",
      "       4, 6, 6, 9, 1, 1, 3, 1, 0, 6, 6, 6, 3, 3, 1, 6, 1, 1, 1, 1, 1, 3,\n",
      "       1, 6, 6, 6, 0, 6, 0, 1, 1, 3, 1, 1, 1, 1]), array([6, 6, 1, 3, 6, 1, 6, 1, 6, 6, 6, 6, 1, 6, 6, 6, 6, 9, 1, 6, 1, 8,\n",
      "       9, 8, 6, 6, 6, 6, 1, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 9, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 1, 1, 6, 9, 6, 6, 6, 1, 1, 6, 6, 6, 6, 6, 3, 1,\n",
      "       0, 1, 6, 6, 1, 6, 6, 6, 1, 6, 1, 3, 6, 6, 3, 0, 0, 6, 6, 6, 6, 6,\n",
      "       6, 3, 1, 9, 2, 9, 2, 6, 1, 1, 1, 9, 9, 1, 1, 1, 2, 1, 2, 2, 7, 1,\n",
      "       2, 2, 7, 6, 6, 2, 2, 2, 2, 1, 9, 8, 3, 6, 1, 3, 9, 1, 6, 6, 6, 6,\n",
      "       3, 1, 6, 6, 6, 3, 6, 1, 7, 6, 6, 6, 1, 8, 9, 6, 6, 6, 6, 3, 6, 6,\n",
      "       1, 6, 9, 3, 6, 6, 3, 6, 6, 6, 1, 6, 6, 6, 6, 1, 6, 6, 3, 6, 6, 1,\n",
      "       1, 1, 8, 6, 6, 6, 6, 6, 3, 6, 9, 6, 6, 9, 0, 0, 6, 6, 6, 6, 0, 6,\n",
      "       0, 6, 0, 6, 0, 0, 0, 0, 6, 0, 6, 0, 6, 6, 1, 6, 1, 1, 1, 1, 1, 6,\n",
      "       9, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 9, 6, 6, 6, 1, 6, 6, 6, 1, 3,\n",
      "       3, 3, 0, 3, 1, 1, 6, 6, 1, 1, 9, 6, 3, 3, 1, 6, 3, 1, 0, 9, 3, 6,\n",
      "       1, 0, 1, 3, 3, 6, 6, 6, 6, 1, 9, 6, 9, 1, 1, 6, 6, 1, 1, 6, 1, 0,\n",
      "       6, 6, 3, 1, 1, 6, 6, 6, 1, 1, 1, 6, 6, 6]), array([1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 0, 0, 1, 1, 3, 6, 6, 6, 3, 1, 1, 6,\n",
      "       6, 1, 1, 9, 1, 6, 6, 1, 6, 1, 1, 6, 6, 1, 6, 6, 1, 3, 6, 1, 1, 1,\n",
      "       1, 1, 6, 6, 1, 6, 6, 1, 6, 1, 1, 1, 0, 3, 3, 6, 1, 1, 6, 6, 1, 6,\n",
      "       6, 6, 1, 1, 3, 6, 1, 1, 6, 6, 6, 6, 1, 1, 6, 6, 1, 6, 1, 1, 6, 6,\n",
      "       6, 6, 2, 1, 8, 1, 1, 1, 7, 6, 1, 6, 2, 9, 6, 2, 1, 6, 6, 1, 1, 6,\n",
      "       6, 7, 2, 1, 7, 6, 1, 6, 2, 7, 1, 6, 6, 6, 6, 6, 6, 3, 6, 1, 1, 1,\n",
      "       6, 6, 1, 1, 6, 6, 3, 6, 6, 6, 1, 6, 6, 1, 6, 3, 6, 6, 1, 8, 1, 3,\n",
      "       3, 6, 6, 8, 9, 1, 6, 1, 1, 6, 6, 6, 1, 6, 1, 7, 7, 6, 6, 1, 1, 6,\n",
      "       1, 6, 6, 1, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 9, 1, 0, 6, 3,\n",
      "       6, 6, 3, 6, 1, 6, 3, 6, 6, 9, 0, 9, 1, 6, 6, 6, 6, 0, 6, 6, 6, 6,\n",
      "       6, 6, 6, 3, 6, 6, 6, 6, 1, 6, 6, 6, 0, 1, 6, 6, 6, 6, 6, 6, 3, 9,\n",
      "       6, 3, 6, 1, 6, 6, 6, 6, 3, 9, 1, 3, 6, 7, 6, 9, 1, 1, 3, 3, 1, 6,\n",
      "       3, 3, 3, 6, 6, 1, 6, 9, 6, 6, 3, 1, 1, 6, 6, 6, 1, 6, 3, 6, 6, 1,\n",
      "       1, 1, 6, 6, 3, 1, 1, 1, 3, 6, 6, 6, 6, 6]), array([1, 6, 6, 6, 6, 6, 6, 3, 1, 6, 3, 6, 9, 1, 6, 6, 6, 6, 6, 1, 6, 6,\n",
      "       3, 3, 6, 6, 1, 1, 6, 6, 0, 3, 1, 6, 6, 6, 6, 1, 6, 6, 1, 6, 6, 6,\n",
      "       3, 3, 6, 6, 3, 1, 6, 6, 1, 0, 6, 3, 6, 6, 6, 0, 3, 3, 1, 3, 1, 1,\n",
      "       1, 1, 6, 6, 6, 6, 6, 6, 3, 3, 6, 1, 6, 6, 6, 6, 6, 6, 3, 6, 1, 3,\n",
      "       1, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 9, 6, 1, 6, 1, 1, 1, 3, 1,\n",
      "       6, 6, 6, 6, 6, 1, 6, 9, 6, 6, 6, 3, 6, 6, 1, 6, 1, 9, 2, 6, 6, 6,\n",
      "       7, 1, 1, 6, 1, 1, 1, 1, 7, 1, 1, 1, 6, 1, 1, 2, 1, 8, 2, 6, 6, 1,\n",
      "       1, 1, 2, 1, 0, 0, 3, 6, 6, 1, 6, 3, 3, 6, 6, 6, 6, 6, 6, 1, 6, 6,\n",
      "       1, 6, 6, 6, 3, 1, 6, 6, 6, 3, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 1,\n",
      "       3, 1, 6, 6, 0, 3, 6, 6, 6, 3, 6, 3, 6, 6, 3, 1, 0, 6, 3, 3, 6, 6,\n",
      "       9, 6, 6, 6, 3, 6, 3, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 1,\n",
      "       6, 1, 6, 6, 6, 3, 6, 6, 1, 6, 1, 6, 6, 1, 1, 1, 6, 6, 1, 6, 6, 6,\n",
      "       3, 1, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6]), array([6, 6, 0, 6, 3, 9, 6, 9, 6, 3, 1, 3, 6, 6, 6, 1, 3, 3, 6, 6, 6, 6,\n",
      "       6, 6, 9, 0, 6, 3, 6, 6, 6, 6, 6, 1, 1, 6, 1, 6, 6, 1, 6, 6, 6, 6,\n",
      "       6, 6, 1, 3, 6, 6, 3, 6, 6, 6, 6, 6, 3, 6, 9, 6, 6, 1, 6, 1, 6, 1,\n",
      "       6, 6, 1, 1, 6, 1, 6, 6, 6, 1, 1, 1, 6, 1, 6, 1, 6, 1, 6, 1, 3, 1,\n",
      "       1, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 6, 1, 7, 6, 6, 6, 3, 6, 9, 6, 3,\n",
      "       1, 6, 6, 6, 6, 1, 6, 1, 3, 6, 6, 1, 9, 6, 6, 6, 6, 1, 7, 7, 1, 2,\n",
      "       8, 1, 7, 7, 2, 6, 7, 1, 1, 1, 1, 1, 6, 7, 7, 1, 1, 7, 6, 7, 7, 7,\n",
      "       7, 8, 1, 1, 6, 9, 0, 6, 6, 0, 6, 0, 6, 1, 6, 3, 1, 6, 0, 6, 9, 0,\n",
      "       6, 1, 6, 1, 6, 3, 6, 6, 6, 1, 6, 6, 9, 6, 9, 0, 6, 3, 3, 3, 6, 3,\n",
      "       6, 3, 6, 3, 3, 6, 3, 3, 3, 1, 3, 6, 1, 3, 6, 3, 6, 3, 9, 1, 6, 6,\n",
      "       1, 1, 1, 9, 1, 3, 6, 1, 1, 3, 6, 6, 6, 6, 1, 1, 6, 9, 1, 1, 1, 1,\n",
      "       3, 1, 1, 1, 1, 1, 1, 1, 6, 1, 6, 1, 1, 6, 9, 1, 1, 1, 6, 1, 6, 1,\n",
      "       6, 6, 1, 6, 2, 6, 6, 6, 6, 6, 1, 1, 1, 2]), array([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 1, 6, 1, 6, 6, 1, 1, 6, 3, 1,\n",
      "       1, 6, 6, 1, 3, 6, 6, 1, 1, 6, 6, 6, 6, 3, 9, 1, 9, 1, 1, 6, 1, 1,\n",
      "       1, 6, 1, 1, 6, 6, 6, 3, 9, 8, 1, 6, 6, 1, 7, 1, 6, 6, 1, 6, 6, 3,\n",
      "       1, 0, 6, 6, 6, 6, 1, 6, 1, 1, 1, 6, 3, 3, 1, 6, 3, 6, 1, 6, 6, 6,\n",
      "       3, 6, 6, 6, 6, 1, 6, 6, 6, 6, 8, 6, 1, 6, 6, 6, 1, 1, 1, 7, 8, 6,\n",
      "       7, 1, 6, 1, 6, 6, 6, 1, 7, 7, 6, 6, 1, 1, 6, 0, 6, 6, 0, 3, 6, 6,\n",
      "       0, 0, 0, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 1, 1, 6, 3,\n",
      "       6, 6, 3, 6, 9, 6, 6, 6, 9, 1, 6, 6, 6, 6, 6, 6, 6, 9, 9, 6, 1, 1,\n",
      "       6, 6, 3, 6, 1, 6, 2, 6, 3, 1, 6, 6, 6, 6, 3, 6, 1, 6, 6, 8, 4, 6,\n",
      "       6, 6, 6, 2, 3, 6, 1, 4, 2, 1, 1, 7, 9, 1, 6, 6, 6, 6, 6, 1, 1, 6,\n",
      "       6, 1, 1, 6, 6, 1, 7, 3, 1, 3, 6, 6, 9, 6, 6, 6, 9, 6, 1, 3, 1, 6,\n",
      "       1, 1, 1, 6, 1, 1, 6, 6, 6, 6, 6, 9, 8, 6, 6, 6, 7, 9, 6, 6, 6, 1,\n",
      "       1, 1, 1, 9, 1, 1]), array([1, 6, 6, 9, 6, 1, 1, 1, 1, 1, 6, 1, 3, 1, 1, 6, 1, 1, 6, 1, 1, 9,\n",
      "       1, 1, 1, 6, 6, 6, 1, 6, 1, 6, 1, 1, 3, 1, 3, 6, 8, 6, 1, 1, 1, 6,\n",
      "       6, 6, 6, 6, 1, 1, 1, 6, 1, 6, 6, 1, 3, 3, 6, 3, 1, 6, 6, 6, 1, 6,\n",
      "       6, 1, 3, 1, 1, 1, 6, 1, 1, 6, 6, 6, 1, 6, 1, 1, 3, 6, 6, 1, 6, 6,\n",
      "       6, 1, 6, 1, 9, 6, 1, 1, 6, 9, 1, 6, 6, 6, 1, 1, 6, 6, 6, 6, 6, 6,\n",
      "       1, 7, 9, 7, 6, 1, 6, 6, 6, 6, 0, 6, 9, 1, 6, 1, 0, 6, 1, 6, 1, 6,\n",
      "       3, 3, 6, 6, 1, 3, 6, 0, 6, 0, 1, 1, 1, 9, 6, 9, 1, 9, 6, 6, 6, 6,\n",
      "       6, 3, 6, 6, 6, 3, 3, 1, 3, 3, 3, 3, 6, 6, 3, 6, 6, 3, 6, 6, 6, 3,\n",
      "       9, 6, 6, 1, 6, 9, 3, 6, 6, 1, 6, 1, 3, 6, 6, 6, 3, 6, 6, 6, 1, 6,\n",
      "       6, 9, 1, 3, 6, 6, 8, 6, 3, 3, 6, 6, 6, 1, 1, 6, 3, 6, 6, 0, 1, 1,\n",
      "       3, 1, 1, 1, 1, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 3, 3, 3, 3, 6, 6, 1,\n",
      "       7, 6, 6, 1, 6, 6, 1, 1, 6, 6, 1, 6, 6, 6, 6, 1, 6, 7, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 7]), array([3, 3, 3, 6, 6, 6, 9, 6, 6, 6, 6, 3, 6, 6, 6, 1, 6, 6, 6, 3, 6, 1,\n",
      "       6, 6, 6, 6, 6, 1, 6, 9, 6, 6, 6, 6, 6, 1, 6, 3, 3, 6, 6, 0, 1, 6,\n",
      "       1, 6, 0, 6, 6, 9, 8, 1, 6, 1, 1, 6, 1, 6, 6, 6, 6, 1, 1, 1, 6, 6,\n",
      "       1, 6, 1, 6, 1, 1, 1, 0, 6, 6, 0, 3, 3, 1, 6, 6, 1, 1, 1, 3, 1, 6,\n",
      "       1, 3, 6, 6, 1, 6, 1, 6, 1, 8, 6, 7, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6,\n",
      "       1, 6, 1, 6, 6, 6, 7, 6, 3, 6, 6, 0, 6, 6, 6, 1, 1, 1, 6, 1, 0, 1,\n",
      "       6, 1, 1, 1, 0, 6, 6, 6, 3, 1, 1, 6, 6, 1, 6, 6, 6, 6, 6, 6, 9, 1,\n",
      "       1, 6, 6, 6, 8, 6, 6, 6, 6, 8, 6, 6, 6, 9, 6, 6, 6, 6, 1, 6, 6, 6,\n",
      "       8, 1, 1, 6, 3, 6, 6, 1, 6, 6, 6, 6, 1, 1, 6, 6, 6, 1, 6, 6, 6, 6,\n",
      "       6, 6, 1, 6, 1, 6, 6, 6, 6, 7, 1, 6, 3, 6, 6, 3, 3, 3, 1, 6, 6, 3,\n",
      "       6, 6, 6, 3, 3, 6, 6, 6, 3, 6, 3, 3, 6, 3, 6, 6, 6, 3, 6, 6, 1, 6,\n",
      "       1, 6, 8, 6, 6, 9, 6, 1, 8, 8, 6, 6, 7, 1, 8, 6, 6, 1, 6, 1, 6, 6,\n",
      "       1, 1, 8, 7, 6, 9]), array([6, 1, 6, 6, 1, 6, 3, 6, 6, 6, 6, 1, 0, 6, 3, 1, 0, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 3, 3, 6, 6, 7, 1, 1, 7, 6, 6, 1, 6, 6, 1, 6, 6,\n",
      "       7, 7, 6, 1, 1, 6, 6, 7, 6, 6, 6, 1, 1, 6, 6, 6, 1, 6, 3, 1, 6, 6,\n",
      "       8, 6, 9, 0, 1, 6, 1, 8, 1, 1, 1, 1, 1, 1, 1, 1, 6, 3, 1, 6, 1, 1,\n",
      "       1, 6, 2, 2, 2, 2, 2, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,\n",
      "       2, 2, 7, 2, 2, 2, 2, 7, 2, 2, 1, 1, 6, 0, 1, 6, 6, 1, 3, 0, 6, 0,\n",
      "       6, 6, 3, 6, 6, 1, 3, 3, 0, 1, 0, 1, 0, 3, 0, 0, 3, 6, 6, 8, 6, 6,\n",
      "       7, 6, 8, 6, 6, 1, 6, 6, 6, 6, 6, 8, 1, 1, 1, 9, 6, 6, 6, 1, 1, 6,\n",
      "       1, 6, 6, 3, 6, 1, 1, 1, 1, 6, 1, 6, 8, 6, 6, 6, 1, 6, 6, 6, 6, 6,\n",
      "       1, 6, 6, 1, 6, 1, 6, 6, 6, 6, 6, 2, 6, 6, 6, 1, 1, 3, 3, 6, 3, 6,\n",
      "       1, 6, 3, 6, 6, 6, 3, 3, 6, 3, 1, 1, 6, 6, 1, 6, 1, 6, 6, 6, 6, 6,\n",
      "       6, 6, 1, 1, 6, 1, 6, 6, 7, 1, 6, 1, 1, 6, 6, 1, 1, 1, 6, 6, 1, 1,\n",
      "       6, 7, 1, 1, 6, 6]), array([6, 1, 6, 1, 6, 1, 6, 6, 6, 6, 1, 6, 6, 3, 1, 6, 1, 1, 6, 6, 6, 3,\n",
      "       6, 1, 6, 1, 6, 1, 1, 6, 6, 1, 7, 6, 6, 7, 6, 6, 1, 6, 6, 7, 6, 1,\n",
      "       6, 1, 6, 6, 6, 1, 6, 6, 1, 6, 6, 7, 6, 1, 1, 1, 1, 3, 6, 6, 1, 1,\n",
      "       3, 6, 6, 3, 1, 6, 6, 1, 6, 3, 6, 0, 6, 6, 1, 6, 1, 1, 6, 6, 6, 6,\n",
      "       6, 1, 3, 3, 6, 6, 6, 6, 6, 0, 6, 6, 0, 6, 6, 3, 0, 0, 3, 0, 6, 6,\n",
      "       6, 0, 6, 6, 6, 6, 6, 6, 3, 6, 3, 6, 0, 1, 0, 3, 3, 3, 6, 1, 6, 6,\n",
      "       1, 6, 6, 3, 1, 6, 9, 9, 1, 3, 6, 3, 1, 6, 9, 6, 1, 3, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 1, 6, 6, 6, 7, 6, 6, 1, 6, 6, 2, 6, 6, 6, 1, 6, 6, 1,\n",
      "       6, 6, 6, 1, 6, 1, 6, 6, 6, 6, 8, 6, 6, 1, 3, 6, 6, 6, 6, 9, 9, 6,\n",
      "       6, 6, 2, 6, 1, 1, 6, 6, 6, 1, 6, 0, 0, 1, 1, 6, 3, 0, 1, 1, 6, 6,\n",
      "       6, 6, 6, 7, 6, 6, 1, 6, 6, 6, 6, 6, 6, 1, 6, 1, 6, 1, 1, 6, 8, 7,\n",
      "       1, 6, 6, 6, 1, 6]), array([6, 3, 6, 6, 1, 6, 6, 6, 3, 6, 6, 6, 3, 1, 6, 6, 1, 3, 9, 9, 9, 6,\n",
      "       1, 6, 6, 6, 1, 6, 6, 6, 6, 6, 9, 3, 1, 6, 3, 6, 6, 3, 3, 6, 3, 6,\n",
      "       6, 1, 1, 3, 6, 3, 1, 1, 6, 6, 6, 1, 8, 1, 6, 9, 6, 1, 1, 6, 3, 6,\n",
      "       1, 1, 6, 6, 6, 1, 1, 3, 6, 0, 6, 6, 6, 6, 6, 1, 6, 6, 6, 1, 3, 1,\n",
      "       3, 1, 6, 6, 6, 6, 0, 6, 3, 6, 6, 0, 6, 6, 3, 6, 3, 3, 0, 3, 6, 6,\n",
      "       0, 6, 3, 0, 3, 6, 6, 6, 6, 6, 6, 1, 3, 6, 1, 6, 1, 6, 6, 6, 6, 1,\n",
      "       6, 1, 6, 0, 6, 0, 0, 6, 6, 6, 1, 0, 6, 0, 3, 6, 6, 0, 6, 1, 8, 2,\n",
      "       6, 6, 6, 2, 2, 6, 6, 6, 8, 6, 1, 6, 6, 6, 6, 1, 9, 1, 6, 6, 6, 9,\n",
      "       6, 8, 1, 2, 6, 2, 1, 6, 2, 6, 6, 6, 6, 6, 1, 6, 6, 2, 6, 6, 6, 2,\n",
      "       2, 1, 6, 6, 2, 6, 1, 6, 1, 1, 6, 6, 1, 6, 6, 1, 1, 1, 6, 9, 3, 3,\n",
      "       9, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 6, 1, 9, 6, 1, 6, 6, 6, 3, 1, 1,\n",
      "       3, 1, 6, 8, 1, 6, 6, 3, 6, 6, 6, 6, 9, 6, 6, 6, 9, 6, 1, 7, 6, 1,\n",
      "       6, 8, 6, 1, 9, 1]), array([1, 6, 1, 3, 1, 6, 6, 1, 0, 1, 1, 9, 6, 6, 6, 3, 3, 6, 7, 6, 6, 0,\n",
      "       6, 9, 1, 3, 1, 7, 1, 6, 6, 1, 6, 6, 6, 6, 1, 1, 6, 6, 6, 9, 1, 6,\n",
      "       1, 6, 6, 1, 1, 6, 6, 6, 1, 6, 6, 6, 6, 6, 1, 6, 1, 6, 6, 3, 9, 6,\n",
      "       6, 9, 6, 6, 6, 6, 6, 3, 3, 6, 1, 6, 1, 6, 9, 3, 6, 1, 0, 6, 0, 3,\n",
      "       6, 6, 6, 6, 3, 3, 3, 3, 6, 6, 6, 3, 6, 6, 0, 1, 9, 6, 6, 6, 6, 3,\n",
      "       9, 3, 6, 6, 0, 6, 3, 9, 6, 3, 6, 1, 1, 6, 1, 6, 9, 1, 1, 6, 1, 1,\n",
      "       1, 6, 9, 1, 6, 6, 6, 1, 6, 6, 6, 9, 3, 1, 6, 1, 6, 6, 1, 7, 7, 8,\n",
      "       6, 1, 6, 1, 7, 1, 6, 1, 2, 1, 2, 1, 2, 6, 6, 7, 2, 6, 6, 9, 6, 2,\n",
      "       6, 6, 2, 6, 6, 2, 2, 2, 9, 2, 2, 2, 1, 2, 2, 2, 6, 1, 6, 2, 2, 6,\n",
      "       2, 8, 2, 6, 6, 9, 2, 1, 2, 6, 2, 9, 6, 6, 3, 9, 6, 1, 1, 1, 0, 1,\n",
      "       6, 6, 6, 3, 6, 3, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 1,\n",
      "       9, 7, 7, 1, 8, 2, 1, 1, 1, 7, 1, 1, 6, 9, 1, 1, 1, 6, 6, 1, 1, 3,\n",
      "       1, 1, 1, 6, 1, 1]), array([6, 6, 1, 6, 6, 1, 1, 0, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 0, 6,\n",
      "       6, 6, 1, 1, 9, 6, 6, 1, 6, 6, 6, 8, 1, 6, 6, 1, 6, 1, 7, 6, 6, 6,\n",
      "       7, 6, 6, 7, 6, 6, 7, 7, 6, 1, 1, 6, 7, 6, 6, 6, 6, 1, 1, 6, 6, 1,\n",
      "       6, 1, 1, 1, 6, 9, 6, 6, 9, 1, 6, 1, 6, 3, 1, 6, 1, 1, 1, 1, 6, 6,\n",
      "       6, 9, 1, 6, 6, 1, 1, 6, 0, 6, 1, 6, 6, 1, 6, 0, 1, 6, 1, 6, 1, 1,\n",
      "       6, 1, 6, 6, 1, 6, 0, 1, 6, 1, 1, 6, 6, 6, 6, 1, 8, 6, 6, 6, 1, 6,\n",
      "       6, 1, 1, 6, 1, 1, 6, 6, 1, 1, 1, 6, 6, 6, 1, 6, 1, 1, 3, 6, 6, 0,\n",
      "       0, 6, 6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 6, 6, 9, 3, 8, 6, 6, 6, 9, 6,\n",
      "       3, 6, 6, 6, 6, 3, 6, 0, 6, 6, 0, 3, 6, 6, 1, 3, 3, 3, 1, 9, 9, 3,\n",
      "       6, 6, 0, 6, 3, 6, 3, 6, 3, 0, 0, 6, 3, 0, 6, 6, 6, 6, 6, 6, 6, 3,\n",
      "       6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 1, 6, 6, 6, 3, 1, 1, 1,\n",
      "       6, 9, 1, 6, 6, 9, 6, 6, 6, 1, 2, 6, 1, 6, 6, 6, 3, 6, 6, 1, 6, 6,\n",
      "       9, 6, 6, 1, 6, 8]), array([1, 6, 6, 7, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 6, 0, 6, 1, 1, 6, 1, 1,\n",
      "       1, 3, 6, 6, 3, 6, 1, 1, 1, 9, 6, 6, 6, 9, 6, 6, 6, 7, 6, 6, 6, 1,\n",
      "       6, 1, 7, 9, 1, 1, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6,\n",
      "       6, 1, 1, 1, 6, 1, 1, 1, 6, 6, 1, 1, 1, 0, 1, 6, 6, 6, 3, 6, 1, 1,\n",
      "       6, 1, 6, 6, 6, 6, 6, 9, 6, 1, 9, 6, 6, 9, 8, 6, 6, 6, 8, 6, 6, 6,\n",
      "       6, 8, 1, 6, 6, 3, 6, 3, 9, 6, 6, 9, 1, 1, 7, 7, 6, 7, 1, 1, 1, 6,\n",
      "       6, 6, 6, 9, 7, 8, 1, 1, 9, 6, 6, 6, 1, 1, 6, 7, 1, 1, 4, 2, 2, 4,\n",
      "       2, 2, 2, 4, 4, 4, 2, 2, 4, 4, 4, 4, 4, 2, 2, 2, 4, 4, 2, 2, 4, 4,\n",
      "       2, 2, 4, 4, 6, 0, 3, 6, 6, 3, 9, 6, 3, 3, 3, 1, 9, 6, 3, 3, 6, 6,\n",
      "       6, 0, 6, 6, 6, 3, 6, 6, 0, 6, 6, 3, 6, 3, 1, 6, 6, 6, 6, 1, 6, 6,\n",
      "       1, 6, 3, 0, 3, 6, 6, 3, 1, 3, 3, 3, 1, 1, 3, 6, 3, 6, 6, 6, 3, 6,\n",
      "       6, 6, 6, 6, 6, 3, 3, 6, 6, 6, 6, 3, 3, 6, 1, 6, 6, 6, 6, 8, 6, 6,\n",
      "       6, 3, 6, 3, 6, 6]), array([6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 1, 6, 0, 1, 1, 6, 1, 6, 1, 1, 6,\n",
      "       6, 6, 6, 1, 6, 9, 6, 0, 8, 1, 1, 1, 1, 1, 2, 2, 6, 1, 1, 6, 6, 8,\n",
      "       6, 6, 1, 6, 6, 8, 1, 6, 1, 6, 7, 1, 1, 1, 1, 8, 1, 1, 6, 0, 1, 1,\n",
      "       1, 6, 6, 6, 1, 3, 6, 6, 6, 1, 6, 6, 9, 6, 6, 9, 6, 6, 6, 1, 6, 1,\n",
      "       9, 6, 6, 7, 6, 1, 6, 1, 7, 6, 6, 6, 9, 6, 6, 7, 6, 1, 6, 1, 7, 1,\n",
      "       6, 6, 6, 1, 1, 7, 1, 1, 1, 6, 1, 6, 1, 1, 4, 1, 1, 1, 6, 6, 6, 1,\n",
      "       1, 2, 1, 5, 1, 9, 8, 1, 2, 4, 8, 5, 9, 8, 1, 5, 6, 1, 2, 5, 6, 6,\n",
      "       8, 5, 1, 7, 1, 6, 1, 5, 1, 2, 6, 2, 1, 1, 5, 6, 1, 1, 1, 5, 2, 7,\n",
      "       9, 5, 6, 1, 3, 3, 6, 6, 3, 6, 1, 3, 3, 0, 6, 6, 6, 9, 9, 6, 3, 6,\n",
      "       3, 6, 3, 0, 1, 3, 6, 3, 6, 6, 3, 1, 1, 3, 1, 3, 1, 3, 3, 6, 6, 6,\n",
      "       3, 6, 3, 6, 6, 6, 6, 6, 3, 6, 1, 1, 3, 3, 6, 1, 6, 1, 1, 6, 6, 6,\n",
      "       6, 6, 6, 6, 7, 6, 7, 6, 1, 6, 6, 1, 6, 6, 9, 6, 1, 6, 8, 6, 1, 1,\n",
      "       6, 1, 6, 6, 6, 6]), array([1, 1, 1, 6, 1, 6, 9, 1, 3, 3, 6, 6, 6, 6, 6, 1, 1, 6, 6, 6, 6, 6,\n",
      "       1, 1, 1, 6, 6, 1, 0, 6, 2, 7, 1, 7, 7, 6, 7, 7, 1, 8, 1, 1, 7, 7,\n",
      "       8, 7, 6, 6, 7, 7, 2, 6, 7, 7, 2, 8, 1, 2, 1, 7, 6, 6, 1, 6, 6, 6,\n",
      "       9, 3, 1, 6, 6, 1, 6, 1, 1, 6, 1, 1, 1, 1, 6, 1, 1, 3, 6, 6, 1, 6,\n",
      "       1, 6, 6, 1, 1, 6, 6, 6, 1, 6, 3, 6, 8, 8, 6, 6, 8, 6, 9, 8, 3, 6,\n",
      "       8, 6, 8, 8, 1, 6, 8, 6, 6, 8, 1, 1, 6, 1, 6, 2, 1, 5, 1, 1, 1, 7,\n",
      "       2, 1, 6, 4, 6, 6, 2, 1, 4, 5, 9, 1, 2, 2, 1, 6, 1, 1, 5, 4, 5, 5,\n",
      "       5, 4, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 4, 4, 4, 5, 5, 4, 4, 5, 5,\n",
      "       5, 4, 5, 5, 0, 3, 6, 3, 0, 9, 3, 6, 0, 6, 6, 1, 6, 6, 6, 3, 6, 1,\n",
      "       6, 3, 6, 6, 6, 6, 9, 0, 3, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 3, 6, 6,\n",
      "       3, 3, 6, 1, 6, 1, 8, 1, 1, 9, 6, 1, 6, 1, 6, 3, 6, 1, 6, 1, 8, 1,\n",
      "       1, 6, 6, 9, 2, 6, 2, 1, 6, 2, 1, 1, 1, 1, 6, 6, 6, 1, 1, 1, 1, 8,\n",
      "       6, 6, 7, 1, 6, 9]), array([9, 6, 1, 1, 6, 3, 6, 6, 1, 6, 1, 6, 1, 6, 1, 6, 1, 6, 6, 6, 6, 1,\n",
      "       6, 6, 3, 6, 1, 6, 9, 1, 1, 3, 6, 6, 6, 6, 1, 6, 6, 6, 6, 1, 0, 3,\n",
      "       6, 6, 1, 6, 0, 6, 6, 1, 3, 1, 3, 6, 6, 6, 6, 6, 1, 1, 1, 1, 6, 1,\n",
      "       6, 6, 6, 1, 6, 6, 1, 1, 6, 1, 6, 6, 1, 1, 6, 3, 1, 6, 1, 1, 1, 1,\n",
      "       1, 6, 1, 6, 1, 7, 1, 1, 6, 1, 1, 6, 1, 1, 7, 1, 1, 6, 6, 1, 1, 6,\n",
      "       6, 6, 6, 1, 6, 1, 1, 6, 1, 6, 2, 2, 2, 2, 5, 5, 2, 2, 2, 2, 2, 2,\n",
      "       2, 5, 2, 2, 2, 5, 5, 5, 2, 2, 5, 2, 5, 2, 2, 2, 5, 5, 5, 5, 4, 5,\n",
      "       4, 5, 4, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       4, 5, 5, 5, 6, 6, 0, 1, 6, 6, 6, 0, 6, 1, 6, 6, 6, 0, 0, 1, 0, 6,\n",
      "       1, 6, 6, 6, 6, 6, 0, 6, 6, 6, 3, 3, 1, 1, 6, 6, 3, 1, 6, 6, 6, 1,\n",
      "       6, 9, 6, 3, 1, 3, 3, 6, 6, 6, 9, 6, 1, 6, 6, 6, 1, 6, 0, 3, 4, 2,\n",
      "       5, 1, 4, 5, 4, 7, 1, 1, 1, 5, 5, 7, 1, 2, 2, 1, 2, 5, 1, 1, 6, 9,\n",
      "       1, 6, 2, 9, 1, 5]), array([6, 0, 6, 6, 3, 1, 1, 3, 1, 6, 6, 1, 6, 1, 0, 6, 6, 0, 1, 1, 3, 1,\n",
      "       0, 1, 6, 1, 1, 1, 9, 6, 9, 1, 3, 1, 1, 1, 1, 0, 6, 0, 6, 3, 6, 9,\n",
      "       6, 6, 3, 1, 6, 6, 6, 1, 6, 3, 6, 3, 6, 1, 3, 1, 6, 1, 6, 6, 7, 3,\n",
      "       1, 1, 3, 6, 1, 1, 6, 6, 6, 1, 3, 6, 6, 7, 3, 6, 6, 1, 6, 6, 3, 9,\n",
      "       6, 1, 6, 1, 7, 6, 7, 2, 6, 7, 7, 1, 1, 6, 1, 9, 7, 7, 7, 9, 1, 1,\n",
      "       1, 9, 2, 6, 7, 1, 1, 8, 6, 1, 8, 1, 1, 8, 9, 8, 7, 2, 7, 1, 8, 1,\n",
      "       7, 7, 1, 7, 1, 7, 2, 1, 7, 7, 2, 7, 2, 7, 1, 1, 7, 7, 6, 1, 6, 6,\n",
      "       6, 0, 6, 6, 6, 3, 6, 0, 6, 3, 6, 0, 1, 3, 6, 1, 6, 6, 6, 6, 6, 1,\n",
      "       1, 1, 1, 6, 7, 6, 6, 6, 3, 6, 6, 8, 1, 1, 9, 6, 1, 1, 6, 1, 1, 6,\n",
      "       1, 1, 3, 6, 1, 6, 1, 1, 6, 6, 7, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), array([3, 1, 6, 1, 8, 1, 6, 6, 6, 1, 1, 6, 1, 3, 1, 6, 6, 6, 3, 1, 1, 6,\n",
      "       8, 6, 6, 6, 6, 9, 6, 3, 3, 6, 6, 9, 6, 0, 6, 9, 6, 6, 6, 6, 9, 6,\n",
      "       6, 6, 6, 6, 1, 6, 6, 9, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 3, 6, 1, 6,\n",
      "       3, 6, 1, 6, 0, 6, 3, 6, 1, 6, 1, 1, 6, 6, 6, 1, 1, 1, 1, 1, 6, 6,\n",
      "       0, 6, 7, 9, 6, 1, 9, 6, 1, 6, 6, 1, 7, 7, 9, 6, 6, 1, 1, 6, 6, 2,\n",
      "       6, 1, 1, 9, 8, 6, 6, 2, 1, 1, 1, 2, 4, 1, 1, 1, 6, 6, 1, 5, 9, 1,\n",
      "       1, 1, 1, 1, 5, 1, 1, 6, 6, 9, 7, 1, 1, 6, 8, 1, 9, 6, 3, 6, 6, 6,\n",
      "       1, 3, 3, 6, 9, 6, 1, 6, 0, 1, 6, 1, 6, 0, 3, 6, 9, 3, 3, 0, 6, 6,\n",
      "       9, 3, 6, 6, 3, 1, 3, 6, 1, 6, 1, 6, 3, 3, 6, 1, 1, 6, 3, 3, 1, 3,\n",
      "       3, 6, 6, 1, 6, 6, 3, 6, 1, 3, 3, 3, 1, 9, 1, 1, 6, 6, 0, 6, 0, 6,\n",
      "       0, 1, 6, 6, 6, 6, 0, 6, 6, 0, 6, 6, 1, 3, 6, 1, 3, 6, 6, 3]), array([6, 6, 6, 6, 1, 6, 1, 6, 6, 1, 3, 1, 6, 6, 6, 9, 6, 1, 1, 6, 6, 1,\n",
      "       3, 6, 1, 1, 1, 1, 3, 6, 6, 6, 1, 6, 9, 6, 8, 6, 1, 6, 9, 6, 6, 6,\n",
      "       1, 9, 6, 1, 6, 1, 6, 8, 6, 6, 6, 6, 6, 6, 8, 6, 3, 6, 6, 1, 3, 1,\n",
      "       1, 6, 6, 6, 1, 7, 1, 6, 1, 6, 1, 6, 6, 1, 1, 6, 7, 6, 1, 6, 6, 1,\n",
      "       6, 6, 2, 5, 5, 2, 2, 2, 5, 2, 2, 5, 2, 5, 2, 2, 5, 2, 5, 5, 5, 5,\n",
      "       5, 5, 5, 2, 2, 5, 5, 2, 2, 2, 1, 1, 2, 9, 1, 2, 1, 9, 4, 4, 5, 1,\n",
      "       1, 6, 6, 6, 1, 6, 6, 4, 1, 1, 4, 6, 6, 1, 2, 1, 6, 1, 1, 6, 3, 3,\n",
      "       3, 6, 6, 1, 6, 6, 0, 3, 1, 6, 3, 6, 3, 9, 0, 3, 6, 6, 1, 3, 3, 3,\n",
      "       1, 6, 6, 0, 6, 3, 6, 7, 6, 6, 6, 3, 1, 6, 1, 6, 6, 9, 1, 6, 0, 9,\n",
      "       7, 1, 1, 6, 6, 1, 1, 1, 6, 1, 6, 6, 0, 6, 6, 6, 3, 3, 1, 0, 6, 0,\n",
      "       1, 1, 6, 6, 1, 6, 1, 1, 1, 1, 3, 1, 6, 6, 1, 6, 6, 6, 1, 6]), array([1, 1, 6, 1, 6, 6, 6, 6, 1, 6, 6, 1, 6, 6, 1, 6, 1, 6, 6, 6, 1, 6,\n",
      "       1, 1, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 1, 6, 6, 6, 1, 6, 6, 1, 1,\n",
      "       6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 1, 0, 1, 3, 0, 6, 1, 6, 6, 6, 3, 0, 6, 1, 1, 6, 6, 6, 1, 6, 6,\n",
      "       1, 6, 5, 2, 2, 5, 5, 5, 2, 5, 5, 2, 5, 2, 5, 5, 2, 5, 2, 2, 2, 2,\n",
      "       2, 2, 2, 5, 5, 2, 2, 5, 5, 5, 5, 5, 7, 5, 2, 9, 1, 1, 5, 9, 2, 2,\n",
      "       5, 9, 2, 2, 9, 1, 1, 6, 1, 2, 1, 2, 1, 1, 5, 1, 2, 6, 1, 1, 6, 6,\n",
      "       6, 2, 6, 7, 6, 1, 3, 9, 3, 6, 6, 1, 6, 6, 6, 6, 3, 2, 6, 6, 6, 1,\n",
      "       6, 6, 6, 6, 8, 6, 3, 1, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6,\n",
      "       6, 6, 6, 6, 3, 6, 6, 3, 6, 3, 6, 1, 6, 0, 6, 3, 6, 6, 3, 6, 6, 6,\n",
      "       6, 6, 0, 6, 6, 6, 3, 6, 6, 6, 6, 6, 3, 6, 6, 0, 6, 3, 6, 6]), array([1, 6, 1, 3, 1, 1, 6, 1, 6, 6, 6, 6, 1, 3, 6, 7, 8, 3, 6, 1, 6, 1,\n",
      "       6, 6, 1, 6, 6, 1, 1, 6, 2, 4, 2, 5, 2, 2, 4, 2, 5, 2, 4, 2, 4, 4,\n",
      "       5, 2, 2, 2, 4, 4, 4, 2, 2, 2, 2, 4, 2, 2, 2, 2, 6, 1, 3, 9, 6, 0,\n",
      "       6, 1, 6, 6, 1, 1, 1, 1, 6, 1, 6, 1, 3, 6, 6, 6, 6, 1, 9, 3, 1, 6,\n",
      "       6, 6, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 5, 1, 1, 6, 5, 1, 1, 2, 1, 9,\n",
      "       6, 1, 5, 1, 1, 2, 1, 2, 1, 6, 6, 1, 1, 1, 1, 1, 1, 2, 6, 8, 6, 2,\n",
      "       6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 1, 6, 6, 6, 1, 6, 1, 6, 6, 2, 1, 2,\n",
      "       6, 9, 6, 1, 6, 6, 6, 3, 6, 3, 6, 6, 1, 1, 6, 6, 0, 6, 1, 6, 6, 0,\n",
      "       6, 6, 6, 3, 6, 3, 6, 6, 3, 6, 3, 6, 6, 3, 6, 0, 1, 6, 6, 6, 6, 6,\n",
      "       3, 6, 3, 1, 0, 3, 6, 3, 0, 6, 1, 6, 6, 6, 3, 6, 1, 1, 3, 6]), array([0, 6, 1, 1, 6, 1, 1, 1, 6, 1, 6, 6, 6, 1, 6, 1, 6, 1, 1, 6, 1, 6,\n",
      "       1, 1, 3, 3, 3, 1, 6, 1, 7, 6, 8, 1, 1, 1, 6, 6, 2, 1, 2, 1, 1, 1,\n",
      "       1, 1, 6, 6, 9, 2, 9, 1, 2, 1, 9, 2, 1, 7, 7, 1, 7, 3, 6, 1, 1, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 1, 6, 6, 3, 6, 6, 6, 6, 6, 6, 1, 6,\n",
      "       7, 1, 4, 1, 1, 4, 1, 4, 4, 4, 1, 7, 4, 4, 9, 4, 4, 1, 4, 1, 1, 7,\n",
      "       1, 1, 1, 1, 4, 5, 4, 2, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 3, 1, 1,\n",
      "       3, 6, 1, 6, 6, 6, 2, 3, 6, 8, 6, 1, 6, 2, 6, 3, 6, 1, 3, 6, 3, 2,\n",
      "       6, 1, 1, 6, 1, 6, 1, 1, 6, 1, 6, 1, 1, 3, 1, 3, 6, 0, 6, 1, 6, 6,\n",
      "       6, 3, 6, 6, 1, 6, 0, 6, 9, 6, 6, 1]), array([6, 1, 8, 6, 7, 6, 1, 1, 1, 6, 1, 1, 1, 6, 1, 6, 1, 1, 1, 1, 6, 1,\n",
      "       1, 6, 6, 6, 1, 6, 1, 6, 6, 2, 6, 6, 6, 6, 6, 1, 1, 6, 1, 2, 2, 2,\n",
      "       9, 2, 9, 2, 2, 6, 1, 6, 1, 1, 1, 9, 2, 9, 1, 2, 1, 6, 1, 6, 6, 6,\n",
      "       1, 3, 1, 7, 3, 6, 3, 7, 6, 3, 6, 6, 7, 6, 6, 6, 1, 1, 1, 9, 6, 1,\n",
      "       3, 6, 9, 4, 1, 7, 2, 1, 1, 1, 9, 1, 1, 5, 4, 2, 7, 6, 2, 4, 4, 1,\n",
      "       5, 1, 1, 4, 8, 4, 1, 4, 1, 8, 6, 6, 6, 1, 2, 1, 6, 6, 2, 1, 6, 2,\n",
      "       2, 2, 2, 6, 7, 6, 6, 2, 6, 1, 2, 6, 6, 6, 7, 2, 6, 2, 1, 6, 6, 6,\n",
      "       6, 1, 1, 1, 9, 1, 6, 1, 3, 6, 6, 1, 6, 1, 3, 6, 3, 6, 6, 3, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 9, 6, 1, 1, 6, 8, 6, 1, 6, 6, 8, 9, 6, 6, 1, 4,\n",
      "       8, 1, 1, 6, 1, 1, 6, 6, 6, 6, 1, 1]), array([1, 1, 6, 1, 1, 6, 1, 6, 7, 1, 1, 6, 6, 8, 1, 1, 1, 1, 6, 8, 6, 1,\n",
      "       6, 2, 1, 1, 2, 6, 6, 1, 1, 1, 2, 2, 2, 2, 1, 1, 7, 4, 1, 1, 6, 6,\n",
      "       4, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 7, 1, 6, 2, 1, 6, 6, 1, 6, 1, 1,\n",
      "       1, 6, 8, 1, 6, 2, 2, 1, 2, 6, 1, 1, 1, 1, 1, 1, 6, 6, 6, 1, 6, 6,\n",
      "       6, 1, 5, 6, 4, 4, 1, 4, 4, 4, 6, 6, 4, 1, 1, 4, 4, 6, 1, 5, 4, 4,\n",
      "       1, 4, 8, 6, 6, 6, 6, 6, 1, 1, 3, 1, 1, 6, 1, 6, 6, 3, 6, 1, 6, 3,\n",
      "       1, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 1, 8, 1, 6, 6, 7, 8, 6,\n",
      "       6, 6, 1, 1, 9, 1, 6, 6, 1, 6, 1, 1, 1, 6, 1, 1, 7, 3, 6, 1, 1, 9,\n",
      "       6, 1, 1, 6]), array([7, 6, 2, 6, 6, 3, 6, 6, 3, 1, 2, 8, 2, 1, 6, 1, 6, 6, 6, 1, 6, 6,\n",
      "       6, 1, 1, 1, 6, 1, 1, 6, 4, 5, 4, 2, 4, 5, 5, 4, 2, 5, 5, 4, 5, 2,\n",
      "       2, 4, 4, 5, 2, 2, 5, 5, 5, 4, 4, 2, 5, 5, 4, 5, 1, 6, 1, 1, 6, 1,\n",
      "       9, 7, 1, 6, 1, 6, 6, 6, 1, 1, 6, 7, 6, 1, 1, 1, 1, 6, 6, 6, 1, 7,\n",
      "       1, 7, 6, 6, 1, 6, 6, 6, 8, 8, 4, 9, 1, 4, 6, 6, 6, 6, 6, 4, 8, 6,\n",
      "       6, 6, 4, 1, 4, 9, 4, 2, 4, 4, 6, 6, 3, 3, 1, 1, 3, 6, 3, 6, 3, 6,\n",
      "       6, 7, 1, 3, 3, 3, 6, 6, 6, 2, 2, 1, 3, 1, 6, 6, 6, 3, 9, 1, 1, 2,\n",
      "       9, 6, 6, 6, 4, 6, 1, 9, 1, 4, 1, 4, 6, 1, 1, 6, 6, 9, 1, 1, 6, 4,\n",
      "       6, 1, 6, 6]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 6, 1, 1, 6, 1, 1, 2, 1,\n",
      "       7, 1, 6, 1, 6, 1, 8, 1, 5, 2, 5, 4, 5, 4, 2, 5, 4, 2, 2, 5, 2, 5,\n",
      "       2, 5, 5, 4, 5, 5, 2, 4, 4, 5, 5, 5, 4, 4, 5, 4, 1, 1, 6, 6, 1, 1,\n",
      "       6, 9, 6, 1, 6, 8, 1, 9, 6, 1, 1, 1, 9, 6, 6, 1, 6, 1, 1, 6, 6, 1,\n",
      "       1, 1, 6, 4, 6, 9, 4, 1, 1, 9, 2, 4, 6, 6, 4, 6, 6, 4, 1, 1, 9, 1,\n",
      "       6, 9, 6, 4, 1, 6, 6, 4, 6, 6, 1, 1, 6, 1, 6, 7, 6, 6, 3, 3, 1, 1,\n",
      "       6, 1, 6, 6, 1, 1, 1, 3, 3, 1, 3, 2, 1, 1, 3, 6, 3, 1, 1, 1, 1, 7,\n",
      "       2, 1, 1, 1, 6, 4, 2, 1, 6, 1, 1, 6, 1, 8, 1, 1, 9, 1, 2, 2, 4, 1,\n",
      "       1, 2, 7, 1]), array([9, 1, 7, 1, 1, 6, 6, 9, 1, 6, 7, 6, 6, 1, 1, 6, 7, 1, 7, 1, 1, 3,\n",
      "       1, 1, 6, 6, 7, 1, 1, 6, 6, 6, 6, 8, 6, 1, 1, 8, 1, 6, 1, 6, 1, 6,\n",
      "       1, 6, 6, 6, 1, 1, 1, 6, 1, 6, 1, 1, 1, 1, 6, 6, 2, 8, 1, 6, 3, 6,\n",
      "       6, 6, 8, 6, 6, 6, 6, 6, 3, 6, 3, 6, 3, 3, 2, 3, 4, 8, 6, 6, 2, 3,\n",
      "       3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), array([6, 1, 6, 6, 6, 6, 1, 8, 6, 1, 6, 6, 1, 6, 1, 3, 6, 6, 6, 6, 1, 6,\n",
      "       1, 6, 1, 1, 8, 6, 6, 1, 6, 6, 6, 1, 6, 9, 6, 6, 6, 9, 6, 1, 9, 7,\n",
      "       7, 6, 6, 7, 6, 6, 6, 7, 7, 1, 1, 6, 1, 6, 1, 7, 6, 6, 6, 1, 5, 1,\n",
      "       9, 1, 6, 6, 6, 2, 4, 1, 5, 9, 1, 6, 9, 1, 1, 7, 6, 6, 9, 6, 6, 1,\n",
      "       4, 6, 1, 5, 6, 5, 1, 1, 6, 4, 8, 9, 9, 4, 1, 6, 6, 1, 4, 1, 6, 4,\n",
      "       1, 6, 4, 7, 2, 1, 1, 6, 7, 6]), array([2, 3, 1, 1, 6, 1, 1, 1, 1, 6, 1, 1, 6, 1, 1, 6, 6, 1, 6, 3, 6, 1,\n",
      "       3, 1, 1, 1, 1, 7, 7, 3, 1, 6, 9, 6, 1, 6, 1, 6, 3, 1, 6, 1, 8, 1,\n",
      "       6, 6, 1, 1, 6, 1, 1, 6, 1, 1, 6, 1, 6, 6, 6, 9, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 6, 6, 1, 6, 6, 2, 5, 5, 1, 1, 7, 1, 4, 2, 4, 1, 6, 5, 6, 9,\n",
      "       5, 4, 6, 6, 7, 1, 1, 4, 5, 1]), array([6, 8, 9, 6, 6, 6, 6, 1, 9, 6, 6, 9, 1, 9, 3, 6, 6, 6, 6, 6, 6, 1,\n",
      "       6, 6, 6, 6, 6, 6, 6, 1, 6, 1, 1, 1, 6, 6, 6, 6, 6, 7, 1, 6, 7, 3,\n",
      "       1, 1, 6, 6, 1, 6, 6, 6, 6, 6, 3, 1, 3, 3, 6, 1, 6, 3, 3, 0, 6, 0,\n",
      "       6, 6, 1, 6, 3, 0, 3, 0, 6, 0, 0, 6, 6, 6, 1, 3, 6, 6, 6, 6, 6, 6,\n",
      "       6, 1, 5, 4, 1, 4, 5, 1, 9, 1, 1, 2, 5, 6, 9, 5, 5, 5, 5, 9, 4, 6,\n",
      "       4, 5, 9, 4, 5, 6, 4, 1, 4, 4]), array([6, 6, 6, 6, 1, 1, 6, 1, 6, 6, 1, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 6,\n",
      "       1, 1, 6, 8, 6, 6, 1, 1, 6, 6, 1, 6, 1, 6, 6, 1, 1, 1, 1, 1, 6, 6,\n",
      "       6, 1, 6, 6, 6, 6, 6, 9, 1, 2, 6, 6, 6, 1, 6, 6, 6, 6, 6, 0, 6, 3,\n",
      "       0, 3, 0, 0, 3, 3, 6, 3, 3, 6, 6, 3, 3, 3, 6, 6, 6, 6, 0, 3, 6, 6,\n",
      "       6, 6, 1, 1, 4, 1, 1, 4, 7, 1, 5, 5, 4, 1, 1, 8, 1, 8, 1, 2, 5, 6,\n",
      "       6, 1, 5, 5, 1, 5, 5, 5, 2, 1]), array([7, 6, 1, 6, 6, 1, 6, 6, 1, 6, 3, 1, 1, 7, 2, 1, 2, 6, 1, 2, 1, 6,\n",
      "       6, 6, 6, 7, 1, 2, 6, 6, 1, 1, 6, 4, 1, 1, 1, 1, 2, 2, 6, 1, 6, 1,\n",
      "       1, 2, 1, 9, 1, 4, 1, 1, 6, 1, 6, 6, 6, 1, 4, 2, 3, 6, 6, 3, 3, 6,\n",
      "       3, 6, 6, 6, 0, 0, 3, 6, 6, 6, 6, 6, 1, 6, 6, 6, 0, 3, 6, 6, 3, 0,\n",
      "       6, 3]), array([1, 1, 1, 1, 6, 2, 1, 6, 6, 1, 6, 2, 1, 6, 1, 2, 6, 2, 8, 6, 6, 1,\n",
      "       1, 1, 1, 6, 1, 6, 1, 1, 2, 1, 1, 2, 6, 1, 1, 7, 1, 6, 7, 6, 1, 1,\n",
      "       7, 1, 2, 6, 2, 6, 1, 2, 2, 1, 2, 2, 6, 6, 2, 1, 6, 6, 3, 6, 6, 3,\n",
      "       6, 3, 6, 3, 6, 6, 1, 6, 6, 1, 6, 1, 6, 6, 6, 6, 6, 1, 6, 3, 1, 1,\n",
      "       1, 6]), array([1, 1, 1, 6, 2, 1, 2, 2, 1, 9, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2,\n",
      "       7, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 7, 1, 6, 1, 6, 9, 1, 6, 6, 7, 1,\n",
      "       1, 6, 7, 2, 1, 1, 7, 7, 1, 7, 1, 2, 9, 7, 6, 1, 1, 1, 1, 0, 1, 6,\n",
      "       1, 1, 1, 1, 6, 6, 1, 6, 1, 0, 6, 6, 6, 1, 0, 0, 0, 1, 1, 6, 6, 6,\n",
      "       1, 6]), array([1, 0, 6, 6, 1, 6, 1, 1, 1, 1, 6, 1, 6, 1, 6, 0, 0, 6, 0, 1, 6, 6,\n",
      "       0, 1, 0, 6, 6, 1, 6, 0, 3, 1, 0, 1, 6, 0, 6, 0, 1, 6, 1, 3, 0, 6,\n",
      "       1, 6, 1, 6, 0, 1, 6, 6, 3, 0, 1, 6, 1, 1, 0, 6, 3, 1, 6, 6, 9, 0,\n",
      "       1, 6, 1, 9, 1, 1, 6, 1, 3, 8, 1, 3, 6, 1, 1, 6, 1, 6, 1, 9, 8, 1,\n",
      "       6, 6]), array([6, 1, 1, 3, 0, 6, 0, 0, 0, 1, 1, 3, 9, 6, 6, 6, 1, 6, 1, 0, 1, 1,\n",
      "       9, 6, 9, 1, 1, 6, 1, 9, 6, 6, 0, 0, 6, 3, 6, 6, 6, 0, 1, 6, 1, 6,\n",
      "       9, 6, 3, 1, 6, 6, 3, 3, 1, 6, 6, 6, 6, 6, 1, 1, 1, 1, 6, 3, 6, 6,\n",
      "       3, 6, 6, 6, 1, 3, 1, 6, 0, 0, 6, 6, 6, 0, 0, 6, 1, 6, 3, 6, 0, 3,\n",
      "       6, 9]), array([3, 6, 6, 6, 3, 9, 6, 3, 6, 6, 6, 6, 3, 6, 6, 6, 1, 6, 6, 6, 3, 6,\n",
      "       6, 6, 0, 6, 6, 6, 6, 6, 6, 1, 6, 6, 0, 1, 6, 6, 0, 6, 6, 1, 6, 6,\n",
      "       6, 1, 6, 3, 6, 1, 1, 6, 6, 6, 1, 6, 6, 6, 6, 3, 9, 6, 6, 1, 8, 8,\n",
      "       8, 1, 6, 6, 1, 6, 6, 1, 6, 3, 3, 1, 1, 6, 3, 1, 6, 9, 6, 6, 6, 6,\n",
      "       1, 3]), array([6, 6, 3, 1, 6, 1, 6, 6, 6, 1, 1, 0, 6, 0, 1, 1, 0, 6, 0, 6, 0, 6,\n",
      "       1, 6, 1, 6, 0, 6, 6, 6, 0, 6, 1, 6, 1, 6, 3, 1, 6, 6, 6, 6, 0, 1,\n",
      "       6, 6, 6, 6, 6, 6, 0, 6, 6, 0, 0, 3, 6, 1, 6, 6, 6, 6, 6, 6, 6, 1,\n",
      "       6, 1, 3, 3, 8, 6, 6, 6, 6, 6, 6, 1, 6, 3, 6, 6, 6, 3, 6, 1, 4, 6,\n",
      "       6, 6]), array([1, 6, 1, 1, 9, 0, 1, 1, 1, 6, 6, 1, 6, 1, 1, 6, 6, 1, 1, 0, 6, 1,\n",
      "       6, 9, 1, 1, 1, 1, 1, 6, 0, 1, 6, 3, 9, 6, 6, 1, 6, 3, 1, 1, 6, 6,\n",
      "       6, 1, 6, 1, 1, 1, 6, 1, 6, 9, 6, 6, 1, 0, 1, 6, 6, 3, 1, 6, 6, 2,\n",
      "       6, 2, 6, 1, 6, 6, 6, 3, 6, 6, 1, 6, 3, 6, 6, 3, 1, 6, 1, 6, 6, 6,\n",
      "       6, 2]), array([6, 6, 6, 6, 6, 6, 3, 6, 1, 3, 1, 6, 6, 6, 6, 6, 3, 9, 6, 6, 1, 3,\n",
      "       6, 6, 6, 6, 1, 3, 6, 6, 9, 6, 6, 6, 6, 1, 1, 6, 1, 1, 6, 9, 6, 6,\n",
      "       6, 6, 6, 1, 1, 9, 6, 1, 9, 3, 1, 1, 6, 6, 1, 6, 1, 6, 1, 6, 4, 1,\n",
      "       5, 1, 2, 6, 1, 7, 9, 1, 4, 5, 9, 6, 6, 1, 1, 9, 9, 1, 6, 7, 9, 4,\n",
      "       6, 6]), array([1, 1, 6, 1, 1, 6, 1, 6, 6, 8, 9, 6, 1, 6, 6, 6, 1, 6, 9, 6, 1, 6,\n",
      "       6, 6, 1, 7, 6, 6, 1, 1, 6, 1, 6, 1, 1, 6, 2, 1, 6, 8, 1, 1, 6, 1,\n",
      "       8, 1, 9, 1, 7, 6, 9, 6, 1, 6, 1, 1, 1, 1, 6, 1, 5, 4, 5, 5, 7, 9,\n",
      "       1, 6, 6, 5, 6, 1, 5, 1, 1, 1, 5, 1, 4, 4, 1, 6, 5, 1, 5, 1, 7, 9,\n",
      "       5, 1]), array([1, 6, 6, 9, 1, 6, 6, 6, 6, 9, 6, 6, 8, 6, 6, 8, 6, 6, 6, 9, 9, 6,\n",
      "       6, 1, 6, 6, 6, 8, 1, 1, 6, 6, 1, 1, 6, 1, 1, 6, 1, 9, 6, 6, 1, 6,\n",
      "       9, 1, 6, 6, 6, 6, 1, 6, 6, 6, 6, 1, 1, 6, 6, 6, 6, 1, 2, 2, 7, 4,\n",
      "       1, 6, 1, 1, 6, 1, 1, 4, 7, 4, 6, 4, 1, 2, 4, 4, 1, 1, 8, 4, 7, 5,\n",
      "       6, 4]), array([6, 1, 1, 8, 6, 8, 6, 6, 8, 6, 6, 3, 6, 1, 6, 6, 9, 6, 3, 6, 8, 6,\n",
      "       6, 3, 6, 9, 1, 1, 6, 6, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 6, 1,\n",
      "       4, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 2, 2, 1, 2, 1, 9, 4, 7, 1, 5,\n",
      "       1, 5, 4, 4, 4, 5, 6, 6, 9, 6, 1, 5, 1, 5, 5, 1, 1, 6, 1, 5, 5, 1,\n",
      "       2, 1]), array([6, 2, 1, 1, 1, 2, 1, 7, 1, 2, 1, 1, 1, 1, 1, 1, 6, 1, 2, 1, 1, 2,\n",
      "       2, 6, 1, 1, 1, 1, 6, 1, 1, 2, 2, 1, 2, 2, 6, 2, 6, 1, 9, 6, 1, 2,\n",
      "       6, 7, 1, 6, 6, 2, 6, 2, 2, 1, 2, 7, 2, 1, 2, 1, 7, 5, 9, 4, 6, 6,\n",
      "       6, 1, 5, 1, 5, 1, 1, 5, 7, 1, 4, 1, 5, 1, 9, 5, 7, 5, 1, 1, 1, 1,\n",
      "       9, 5]), array([8, 1, 1, 2, 6, 1, 6, 1, 6, 1, 2, 2, 1, 2, 9, 1, 2, 1, 1, 2, 7, 1,\n",
      "       1, 1, 2, 1, 9, 6, 2, 1, 2, 4, 4, 6, 4, 6, 1, 1, 1, 6, 6, 2, 1, 1,\n",
      "       1, 1, 1, 1, 1, 6, 1, 1, 6, 1, 6, 4, 1, 1, 1, 1]), array([1, 9, 2, 6, 6, 1, 9, 1, 6, 2, 1, 1, 7, 1, 1, 1, 1, 2, 1, 6, 6, 1,\n",
      "       1, 1, 2, 1, 2, 1, 1, 6, 1, 6, 6, 6, 6, 1, 6, 1, 2, 1, 1, 1, 6, 6,\n",
      "       6, 6, 2, 2, 6, 2, 2, 6, 6, 2, 6, 6, 6, 6, 1, 6]), array([2, 2, 6, 2, 2, 1, 2, 2, 2, 1, 1, 6, 1, 6, 2, 2, 1, 1, 1, 1, 2, 9,\n",
      "       2, 2, 6, 2, 6, 2, 1, 2, 4, 1, 2, 2, 8, 4, 1, 6, 1, 6, 1, 1, 2, 6,\n",
      "       1, 1, 1, 6, 1, 8, 6, 4, 1, 1, 4, 1, 1, 2, 6, 1]), array([5, 5, 4, 5, 4, 4, 4, 5, 4, 5, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 4,\n",
      "       4, 5, 4, 5, 4, 5, 4, 4, 6, 9, 1, 1, 1, 9, 2, 2, 6, 2, 2, 6, 1, 2,\n",
      "       1, 2, 6, 1, 2, 1, 2, 1, 1, 6, 7, 1, 1, 9, 9, 6]), array([4, 4, 5, 4, 5, 5, 5, 4, 5, 4, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 5,\n",
      "       5, 4, 5, 4, 5, 4, 5, 5, 1, 8, 1, 9, 1, 1, 1, 1, 4, 4, 4, 1, 4, 4,\n",
      "       1, 9, 4, 4, 4, 1, 4, 1, 1, 8, 1, 9, 7, 4, 1, 1])]\n"
     ]
    }
   ],
   "source": [
    "driver_ffc_all = []\n",
    "for d_id in driver_ffc_maps[0].index:\n",
    "    # ffcs to which driver 'd_id' was assigned over all 30 days:\n",
    "    all_ffcs = final_gb.get_group(d_id)['ffc_index'].values\n",
    "    driver_ffc_all.append(all_ffcs)\n",
    "print(driver_ffc_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ffc_index</th>\n",
       "      <th>driver_index</th>\n",
       "      <th>ffcs</th>\n",
       "      <th>ffc_span</th>\n",
       "      <th>num_ffc_span</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[6, 1, 0, 3, 0, 3, 1, 3, 6, 6, 6, 6, 6, 0, 0, ...</td>\n",
       "      <td>[0, 1, 3, 6, 9]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[6, 0, 1, 0, 6, 1, 6, 6, 1, 0, 1, 6, 6, 6, 1, ...</td>\n",
       "      <td>[0, 1, 3, 6, 7, 9]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[3, 6, 6, 6, 6, 6, 0, 1, 6, 1, 6, 1, 1, 1, 3, ...</td>\n",
       "      <td>[0, 1, 3, 6, 7, 9]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[1, 1, 1, 6, 1, 6, 6, 6, 1, 6, 1, 6, 1, 6, 1, ...</td>\n",
       "      <td>[0, 1, 3, 6, 7, 9]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>[6, 6, 3, 1, 1, 1, 6, 9, 6, 3, 6, 3, 6, 6, 6, ...</td>\n",
       "      <td>[0, 1, 3, 6, 7, 9]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ffc_index  driver_index                                               ffcs  \\\n",
       "0          6             0  [6, 1, 0, 3, 0, 3, 1, 3, 6, 6, 6, 6, 6, 0, 0, ...   \n",
       "1          6             1  [6, 0, 1, 0, 6, 1, 6, 6, 1, 0, 1, 6, 6, 6, 1, ...   \n",
       "2          3             2  [3, 6, 6, 6, 6, 6, 0, 1, 6, 1, 6, 1, 1, 1, 3, ...   \n",
       "3          1             3  [1, 1, 1, 6, 1, 6, 6, 6, 1, 6, 1, 6, 1, 6, 1, ...   \n",
       "4          6             4  [6, 6, 3, 1, 1, 1, 6, 9, 6, 3, 6, 3, 6, 6, 6, ...   \n",
       "\n",
       "             ffc_span  num_ffc_span  \n",
       "0     [0, 1, 3, 6, 9]             5  \n",
       "1  [0, 1, 3, 6, 7, 9]             6  \n",
       "2  [0, 1, 3, 6, 7, 9]             6  \n",
       "3  [0, 1, 3, 6, 7, 9]             6  \n",
       "4  [0, 1, 3, 6, 7, 9]             6  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver_ffc_df = driver_ffc_maps[0][relevant_cols].copy()\n",
    "driver_ffc_df['ffcs'] = driver_ffc_all \n",
    "driver_ffc_df['ffc_span'] = driver_ffc_df['ffcs'].apply(lambda x:np.unique(x))\n",
    "driver_ffc_df['num_ffc_span'] = driver_ffc_df['ffc_span'].apply(lambda x:len(x))\n",
    "\n",
    "driver_ffc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg number of zones to which a driver is assigned over 30 days: 7.146853146853147\n"
     ]
    }
   ],
   "source": [
    "print(\"avg number of zones to which a driver is assigned over 30 days:\", np.mean(driver_ffc_df['num_ffc_span']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(driver_ffc_df['num_ffc_span']), np.max(driver_ffc_df['num_ffc_span'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State:  RJ\n",
      "num_ffc_center:  10\n",
      "Grid Size:  7 7\n",
      "Fair Distance:  0.60\n",
      "Alpha_fair:  2.0\n",
      "number_of_runs:  10\n",
      "\n",
      "Avg Num of Drivers:  123.1\n",
      "\n",
      "#################################### FINAL RESULTS #######################################################\n",
      "[ Mean for each Dist Type ] :\n",
      "\n",
      "              Gini  Avg Dist  Income_Gap  spatial_index  Income_sum\n",
      "Dist Type                                                          \n",
      "FairAssign  0.1002     0.399       0.298         0.1476   10132.502\n",
      "LIPA        0.0273     0.531       0.086         0.0510    6694.142\n",
      "MCCA        0.2452     0.208       0.939         0.4655   10142.688\n",
      "MCCA-L      0.2346     0.211       0.900         0.4319   10145.602\n",
      "Random      0.1349     0.826       0.579         0.2027   10132.683\n",
      "RoundRobin  0.1348     0.828       0.548         0.1897   10132.774\n",
      "\n",
      "[ Max for each Dist Type ] :\n",
      "\n",
      "             Gini  Avg Dist  Income_Gap  spatial_index  Income_sum\n",
      "Dist Type                                                         \n",
      "FairAssign  0.124      0.45        0.39         0.1704    10133.21\n",
      "LIPA        0.079      0.62        0.26         0.1438     8131.38\n",
      "MCCA        0.299      0.22        1.45         0.5749    10146.13\n",
      "MCCA-L      0.267      0.22        1.25         0.4922    10146.33\n",
      "Random      0.174      0.95        0.91         0.2705    10132.95\n",
      "RoundRobin  0.169      0.95        0.67         0.2456    10133.70\n",
      "\n",
      "[ Min for each Dist Type ] :\n",
      "\n",
      "             Gini  Avg Dist  Income_Gap  spatial_index  Income_sum\n",
      "Dist Type                                                         \n",
      "FairAssign  0.081      0.36        0.24         0.1257    10131.42\n",
      "LIPA        0.003      0.45        0.01         0.0058     5521.30\n",
      "MCCA        0.186      0.20        0.58         0.3601    10139.88\n",
      "MCCA-L      0.197      0.20        0.58         0.3598    10143.92\n",
      "Random      0.106      0.75        0.38         0.1514    10132.25\n",
      "RoundRobin  0.100      0.76        0.38         0.1360    10131.63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print all the result\n",
    "All_Income = pd.DataFrame({'Dist Type':Name_list,'Gini': Gini_Index_List, 'Avg Dist':Avg_Distance_List,'Income_Gap':Income_Gap_List,'spatial_index':spatial_inequality_list,'Income_sum':Income_sum_lis})\n",
    "All_Income = All_Income.replace(\"Low Income Distribution\",\"Robinhood\") # just as cool line! no meaning\n",
    "\n",
    "# configParser.read(configFilePath)\n",
    "print(\"State: \",configParser.get('dataset-generation','state'))\n",
    "# print(\"num_training_days: \",num_training_days)\n",
    "# print(\"num_testing_days: \",num_testing_days)\n",
    "# print(\"Equal_to_or_not: \",configParser.get('dataset-generation','equal_to'))\n",
    "print(\"num_ffc_center: \",configParser.get('dataset-generation','num_ffc_center'))\n",
    "print(\"Grid Size: \",configParser.get('dataset-generation','grid_length'),configParser.get('dataset-generation','grid_width'))\n",
    "print(\"Fair Distance: \",configParser.get('fairness-constraint','fair_distance'))\n",
    "# print(\"Alpha_fair: \",configParser.get('fairness-constraint','alpha_fair'))\n",
    "print(\"Alpha_fair: \",alpha_fair)\n",
    "print(\"number_of_runs: \",configParser.get('dataset-generation','number_of_runs'))\n",
    "print()\n",
    "print(\"Avg Num of Drivers: \",np.mean(np.array(num_drivers)))\n",
    "print() \n",
    "\n",
    "print(\"#################################### FINAL RESULTS #######################################################\")\n",
    "print(\"[ Mean for each Dist Type ] :\\n\")\n",
    "print(All_Income.groupby('Dist Type').mean().round(4))\n",
    "print()\n",
    "print(\"[ Max for each Dist Type ] :\\n\")\n",
    "print(All_Income.groupby('Dist Type').max())\n",
    "print()\n",
    "print(\"[ Min for each Dist Type ] :\\n\")\n",
    "print(All_Income.groupby('Dist Type').min())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "cluster.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
